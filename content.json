[{"title":"redis基本数据结构浅析 之 BitMap(位图)","date":"2021-04-18T10:36:56.000Z","path":"2021/04/18/redis/04. basic-data-structure-sorted-BitMap/","text":"场景参考","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"redis基本数据结构浅析 之 Sorted set(有序集合)","date":"2021-04-17T06:09:51.000Z","path":"2021/04/17/redis/04. basic-data-structure-sorted-set/","text":"场景参考","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"redis基本数据结构浅析 之 set(集合)","date":"2021-04-15T14:12:04.000Z","path":"2021/04/15/redis/03. basic-data-structure-set/","text":"场景参考","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"redis基本数据结构浅析 之 List(列表)","date":"2021-04-14T12:43:20.000Z","path":"2021/04/14/redis/02. basic-data-structure-list/","text":"Redis的list底层采用的数据结构是双向链表(每个子元素都是String类型)，可以通过push和pop操作从列表的头部或者尾部添加或者删除元素，这样List即可以作为栈，也可以作为队列。 获取越接近两端的元素速度越快，但通过索引访问时会比较慢。 LPUSH key element [element ...]： 将一个或多个值插入到列表头部时间复杂度：每添加一个元素是O(1)，当添加 N 个元素时是 O(N)。 Lpop key [count] : 移出并获取列表的第一个元素默认情况下，该命令从列表的开头弹出一个元素。当提供可选count参数时，将返回count个元素。tip：count参数是从 Redis 版本 6.2.0 开始新增的。时间复杂度：O(N) 其中 N 是返回的元素数，所以只返回一个元素的话，时间复杂度自然就是 O(1)。# 场景 Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现。 List的另一个应用就是消息队列， 可以利用List的PUSH操作，将任务存在List中，然后工作线程再用POP操作将任务取出进行执行。 比如微博： 在Redis中我们的最新微博ID使用了常驻缓存，这是一直更新的。但是我们做了限制不能超过5000个ID，因此我们的获取ID函数会一直询问Redis。只有在start&#x2F;count参数超出了这个范围的时候，才需要去访问数据库。我们的系统不会像传统方式那样“刷新”缓存，Redis实例中的信息永远是一致的。SQL数据库（或是硬盘上的其他类型数据库）只是在用户需要获取“很远”的数据时才会被触发，而主页或第一个评论页是不会麻烦到硬盘上的数据库了。 参考","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"redis基本数据结构浅析 之 Hash表","date":"2021-04-11T11:43:20.000Z","path":"2021/04/11/redis/01. basic-data-structure-hash/","text":"O(1)时间复杂度的操作 了解数据结构的都知道，Hash表这种数据结构最基本的 增HSET、删HDEL、改HSET``HSETNX、查HGET、HEXISTS 操作时间复杂度都是O(1)； HLEN 获取哈希中的字段数 (todo: redis估计也是在散列表发生变化时，对长度额外做了记录) 留意：HSET已经具备了HMSET同时为指定的一个hash key设置多个field&#x2F;value的功能，所以从 Redis 版本 4.0.0 开始，此命令被视为已弃用。(参考redis手册) O(n)时间复杂度的操作 不过，redis中 HSET、HDEL 都支持同时设置或者删除多个field, 此时的时间复杂度就是 O(n) 了。 HGETALL key 获取哈希表中指定key 中的所有字段和值 HVALS key 获取哈希表中指定key 中的所有值 HKEYS key 获取哈希表中指定key 中的所有字段 lant: 上面的操作虽然都是 O(n) 级的时间复杂度，但其实这些操作在操作Hash表时，都是针对指定 key 进行操作的。 你的每个key中的 field/value 对儿会很多么? 所以，效率下降应该不是特别严重，感觉也还算是常量级的时间复杂度吧! 应用场景特别适合存储对象信息 比如存储 用户信息 这种map信息: 12&gt;hset jm:user:1 name austin age 25 address guangzhou &gt;hset jm:user:2 name austin age 25 address guangzhou 如果用普通的 key&#x2F;value 结构来存储，主要有下面两种存储方式:用户信息对象有多少成员就存成多少个key-value对儿，用用户ID+对应属性的名称作为唯一标识来取得对应属性的值，key部分的用户ID为重复存储，如果存在大量这样的数据，内存浪费还是非常可观的。 123&gt;set user:1:name austin&gt;set user:1:age 25&gt;set user:1:address guangzhou 将用户ID作为查找key,把其他信息封装成一个对象以序列化的方式存储，这种方式的缺点是，增加了序列化&#x2F;反序列化的开销，并且在需要修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护，引入CAS等复杂问题。 123&gt;set user:1 &#123;&quot;name&quot;:&quot;austin&quot;,&quot;age&quot;:&quot;25&quot;,&quot;address&quot;:&quot;guangzhou&quot;&#125; &gt;set user:1 &#123;&quot;name&quot;:&quot;austin&quot;,&quot;age&quot;:&quot;25&quot;,&quot;address&quot;:&quot;guangzhou&quot;&#125;&gt;set user:1 &#123;&quot;name&quot;:&quot;austin&quot;,&quot;age&quot;:&quot;25&quot;,&quot;address&quot;:&quot;guangzhou&quot;&#125; 再比如存储 帖子 点赞数,评论数,点击数 信息： 123&gt;hset article:1 star 9 comment 3 click 21&gt;hset article:2 star 2 comment 0 click 7&gt;hset article:3 star 6 comment 4 click 19 甚至存储 订单信息： 123&gt;hset order:692343390123213 amount 218.5 orderTime 2021-04-11 19:20:20 productId 1232 productName 黑人牙膏 ...&gt;hset order:128043390155801 amount 18.9 orderTime 2021-04-11 13:11:09 productId 345 productName 黑人牙刷 ...&gt;hset order:752344450123149 amount 21.35 orderTime 2021-04-11 21:29:56 productId 124 productName 短袖 ... 参考Redis手册","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」图的遍历 (TODO)","date":"2020-11-11T07:21:16.000Z","path":"2020/11/11/data-structure-algorithm/12-4.map/","text":"前言 树代表的是“一对多”的关系，而图则具有更高的自由度，可以表示任意的“多对多”关系。因此，我们可以把树看作是图的一种特例。显然，树的遍历操作也是图的遍历操作的一种特例。 图和树都需要应用搜索算法来实现遍历操作。图的遍历方式可分为两种：「广度优先遍历 breadth-first traversal」和「深度优先遍历 depth-first traversal」。它们也常被称为「广度优先搜索 breadth-first search」和「深度优先搜索 depth-first search」，简称 BFS 和 DFS 。 广度优先遍历广度优先遍历是一种由近及远的遍历方式，从某个节点出发，始终优先访问距离最近的顶点，并一层层向外扩张。如下图所示，从左上角顶点出发，先遍历该顶点的所有邻接顶点，然后遍历下一个顶点的所有邻接顶点，以此类推，直至所有顶点访问完毕。 算法实现 BFS 通常借助队列来实现。队列具有“先入先出”的性质，这与 BFS 的“由近及远”的思想异曲同工: 将遍历起始顶点 startVet 加入队列，并开启循环。 在循环的每轮迭代中，弹出队首顶点并记录访问，然后将该顶点的所有邻接顶点加入到队列尾部。 循环步骤 2. ，直到所有顶点被访问完成后结束。 为了防止重复遍历顶点，我们需要借助一个哈希表 visited 来记录哪些节点已被访问。 广度优先遍历的序列是否唯一？不唯一。广度优先遍历只要求按“由近及远”的顺序遍历，而多个相同距离的顶点的遍历顺序是允许被任意打乱的。以图 9-10 为例，顶点 (1)、(3) 的访问顺序可以交换、顶点 (2)、(4)、(6) 的访问顺序也可以任意交换。 TODO 代码 复杂度分析时间复杂度： 所有顶点都会入队并出队一次，使用 (O(|V|)) 时间；在遍历邻接顶点的过程中，由于是无向图，因此所有边都会被访问 (2) 次，使用 (O(2|E|)) 时间；总体使用 (O(|V| + |E|)) 时间。 空间复杂度： 列表 res ，哈希表 visited ，队列 que 中的顶点数量最多为 (|V|) ，使用 (O(|V|)) 空间。 深度优先遍历 深度优先遍历是一种优先走到底、无路可走再回头的遍历方式。如下图所示，从左上角顶点出发，访问当前顶点的某个邻接顶点，直到走到尽头时返回，再继续走到尽头并返回，以此类推，直至所有顶点遍历完成。 算法实现 这种“走到尽头再返回”的算法范式通常基于递归来实现。与广度优先遍历类似，在深度优先遍历中我们也需要借助一个哈希表 visited 来记录已被访问的顶点，以避免重复访问顶点。深度优先遍历的算法流程如下图 直虚线代表向下递推，表示开启了一个新的递归方法来访问新顶点。 曲虚线代表向上回溯，表示此递归方法已经返回，回溯到了开启此递归方法的位置。为了加深理解，建议将图示与代码结合起来，在脑中（或者用笔画下来）模拟整个 DFS 过程，包括每个递归方法何时开启、何时返回。 深度优先遍历的序列是否唯一？与广度优先遍历类似，深度优先遍历序列的顺序也不是唯一的。给定某顶点，先往哪个方向探索都可以，即邻接顶点的顺序可以任意打乱，都是深度优先遍历。以树的遍历为例，“根 (\\rightarrow) 左 (\\rightarrow) 右”、“左 (\\rightarrow) 根 (\\rightarrow) 右”、“左 (\\rightarrow) 右 (\\rightarrow) 根”分别对应前序、中序、后序遍历，它们展示了三种不同的遍历优先级，然而这三者都属于深度优先遍历。 复杂度分析时间复杂度： 所有顶点都会被访问 (1) 次，使用 (O(|V|)) 时间；所有边都会被访问 (2) 次，使用 (O(2|E|)) 时间；总体使用 (O(|V| + |E|)) 时间。空间复杂度： 列表 res ，哈希表 visited 顶点数量最多为 (|V|) ，递归深度最大为 (|V|) ，因此使用 (O(|V|)) 空间。 TODO 代码 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」图的基础操作 (TODO)","date":"2020-11-09T15:53:07.000Z","path":"2020/11/09/data-structure-algorithm/12-3.map/","text":"前言图的基础操作可分为对边的操作和对顶点的操作。在“邻接矩阵”和“邻接表”两种表示方法下，实现方式有所不同。 基于邻接矩阵存储 给定一个顶点数量为 n 的无向图，其各种操作如下： 初始化：传入 n 个顶点，初始化长度为 n 的顶点列表 vertices ，使用 O(n)时间；初始化 n*n 大小的邻接矩阵 adjMat ，使用 $O(n^2)$ 时间。 添加或删除边：直接在邻接矩阵中修改指定的边即可，使用 O(1) 时间。而由于是无向图，因此需要同时更新两个方向的边。 添加顶点：在邻接矩阵的尾部添加一行一列，并全部填 0 即可，使用 O(n) 时间。 删除顶点：在邻接矩阵中删除一行一列。当删除首行首列时达到最差情况，需要将 $(n-1)^2$ 个元素“向左上移动”，从而使用 $O(n^2)$ 时间。 代码实现可去参考本节末尾的文献 基于邻接表存储 设无向图的顶点总数为n、边总数为m，则可根据下图所示的方法实现各种操作初始化：在邻接表中创建 n 个顶点和 2m 条边，使用 O(n+m) 时间。添加边：在顶点对应链表的末尾添加边即可，使用 O(1) 时间。因为是无向图，所以需要同时添加两个方向的边。删除边：在顶点对应链表中查找并删除指定边，使用 O(m) 时间。在无向图中，需要同时删除两个方向的边。添加顶点：在邻接表中添加一个链表，并将新增顶点作为链表头节点，使用 O(1) 时间。删除顶点：需遍历整个邻接表，删除包含指定顶点的所有边，使用 O(n+m) 时间。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」图 的存储","date":"2020-11-09T14:49:32.000Z","path":"2020/11/09/data-structure-algorithm/12-2.map/","text":"前言 在前面掌握了图的概念之后，我们今天聚焦在 图存储 这一方面，看下如何在内存中存储图这种数据结构。实际上，涉及图的算法有很多，也非常复杂，比如 图的搜索、最短路径、最小生成树、二分图等等。 后面会分好几章节来依次讲解图相关的算法。 邻接矩阵存储方法 图最直观的一种存储方法就是 邻接矩阵（Adjacency Matrix）。邻接矩阵的底层依赖一个二维数组。 对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j] 和 A[j][i] 标记为 1； 对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j] 标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i] 标记为 1。 对于带权图，数组中就存储相应的权重。 用邻接矩阵来表示一个图，虽然简单、直观，但是比较浪费存储空间。为什么这么说呢？ 对于无向图来说，如果 A[i][j] 等于 1，那 A[j][i] 也肯定等于 1。实际上，我们只需要存储一个就可以了。也就是说，无向图的二维数组中，如果我们将其用对角线划分为上下两部分，那我们只需要利用上面或者下面这样一半的空间就足够了，另外一半白白浪费掉了。 还有，如果我们存储的是 稀疏图（Sparse Matrix），也就是说，顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。比如微信有好几亿的用户，对应到图上就是好几亿的顶点。但是每个用户的好友并不会很多，一般也就三五百个而已。如果我们用邻接矩阵来存储，那绝大部分的存储空间都被浪费了。 但这也并不是说，邻接矩阵的存储方法就完全没有优点。首先，邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。其次，用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。比如求解最短路径问题时会提到一个Floyd-Warshall 算法，就是利用矩阵循环相乘若干次得到结果。 邻接表存储方法 针对上面邻接矩阵比较浪费内存空间的问题，我们来看另外一种图的存储方法，邻接表（Adjacency List）。 下面是一张邻接表的图，你可以先看下 乍一看，邻接表是不是有点像散列表？每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。另外需要说明的是，图中画的是一个有向图的邻接表存储方式，每个顶点对应的链表里面，存储的是指向的顶点。对于无向图来说，也是类似的，不过，每个顶点的链表中存储的，是跟这个顶点有边相连的顶点，你可以自己画下。 还记得我们之前讲过的时间、空间复杂度互换的设计思想吗？邻接矩阵存储起来比较浪费空间，但是使用起来比较节省时间。相反，邻接表存储起来比较节省空间，但是使用起来就比较耗时间。就像图中的例子，如果我们要确定，是否存在一条从顶点 2 到顶点 4 的边，那我们就要遍历顶点 2 对应的那条链表，看链表中是否存在顶点 4。而且，我们前面也讲过，链表的存储方式对缓存不友好。所以，比起邻接矩阵的存储方式，在邻接表中查询两个顶点之间的关系就没那么高效了。在散列表那几节里，我讲到，在基于链表法解决冲突的散列表中，如果链过长，为了提高查找效率，我们可以将链表换成其他更加高效的数据结构，比如平衡二叉查找树等。我们刚刚也讲到，邻接表长得很像散列。所以，我们也可以将邻接表同散列表一样进行“改进升级”。 比如将邻接表中的链表改成平衡二叉查找树。 实际开发中，我们可以选择用红黑树。 这样，我们就可以更加快速地查找两个顶点之间是否存在边了。当然，这里的二叉查找树可以换成其他动态数据结构，比如跳表、散列表等。除此之外，我们还可以将链表改成有序动态数组，可以通过二分查找的方法来快速定位两个顶点之间否是存在边。 精选留言 参考文献 《数据结构与算法之美》王争 hello-algo","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」图","date":"2020-11-09T14:01:12.000Z","path":"2020/11/09/data-structure-algorithm/12-1.map/","text":"前言 微博、微信、QQ 这些社交软件你肯定都玩过。 在微博中，两个人可以互相关注；在微信中，两个人可以互加好友。那你知道，如何存储微博、微信等这些社交网络的好友关系吗？ 这就要用到我们今天要讲的这种数据结构：图。 实际上，涉及图的算法有很多，也非常复杂，比如 图的搜索、最短路径、最小生成树、二分图等等。我们今天聚焦在 图存储 这一方面，后面会分好几节来依次讲解图相关的算法。 认识 图(无向) 前面已经学过了树这种非线性数据结构，今天我们要讲另一种非线性数据结构 图(Graph)。 和树比起来，这是一种更加复杂的结构。 顶点 我们知道，树中的元素我们称为节点，图中的元素我们就叫作顶点（vertex）。 边 从下图可以看出，图中的一个顶点可以与任意其他顶点建立连接关系。我们把这种建立的关系叫作边（edge）。 度 我们生活中就有很多符合图这种结构的例子。比如，开篇问题中讲到的社交网络，就是一个非常典型的图结构。我们就拿微信举例子吧。我们可以把每个用户看作一个顶点。如果两个用户之间互加好友，那就在两者之间建立一条边。所以，整个微信的好友关系就可以用一张图来表示。其中，每个用户有多少个好友，对应到图中，就叫作顶点的度（degree），就是跟顶点相连接的边的条数。 有向图 实际上，微博的社交关系跟微信还有点不一样，或者说更加复杂一点。微博允许单向关注，也就是说，用户 A 关注了用户 B，但用户 B 可以不关注用户 A。那我们如何用图来表示这种单向的社交关系呢？ 我们可以把刚刚讲的图结构稍微改造一下，引入边的“方向”的概念。如果用户 A 关注了用户 B，我们就在图中画一条从 A 到 B 的带箭头的边，来表示边的方向。如果用户 A 和用户 B 互相关注了，那我们就画一条从 A 指向 B 的边，再画一条从 B指向 A 的边。我们把这种边有方向的图叫作“有向图”。以此类推，我们把边没有方向的图就叫作“无向图”。 出度、入度 我们刚刚讲过，无向图中有“度”这个概念，表示一个顶点有多少条边。在有向图中，我们把度分为入度（In-degree）和 出度（Out-degree）。顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。对应到微博的例子，入度就表示有多少粉丝，出度就表示关注了多少人。 加权图 前面讲到了微信、微博、无向图、有向图，现在我们再来看另一种社交软件：QQ。 QQ 中的社交关系要更复杂的一点。不知道你有没有留意过 QQ 亲密度这样一个功能。QQ不仅记录了用户之间的好友关系，还记录了两个用户之间的亲密度，如果两个用户经常往来，那亲密度就比较高；如果不经常往来，亲密度就比较低。 如何在图中记录这种好友关系的亲密度呢？这里就要用到另一种图，带权图（weighted graph）。在带权图中，每条边都有一个权重 （weight），我们可以通过这个权重来表示 QQ 好友间的亲密度。 小结关于图的概念比较多，今天也只是介绍了几个常用的，理解起来都不复杂。掌握了图的概念之后，我们再来看下，如何在内存中存储图这种数据结构呢？ 图常见应用如下表所示，许多现实系统都可以用图来建模，相应的问题也可以约化为图计算问题。 顶点 边 图计算问题 社交网络 用户 好友关系 潜在好友推荐 地铁线路 站点 站点间的连通性 最短路线推荐 太阳系 星体 星体间的万有引力作用 行星轨迹计算 参考文献 《数据结构与算法之美》王争 hello-algo","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」堆 的应用 -- TopK问题 (TODO)","date":"2020-11-04T12:11:32.000Z","path":"2020/11/04/data-structure-algorithm/11-4.heap-TopK/","text":"给定一个长度为 n 的无序数组 nums ，请返回数组中前 k 大的元素。 对于该问题，我们先介绍两种思路比较直接的解法，再介绍效率更高的堆解法 方法一：遍历 如下图所示，进行k轮遍历，分别在每轮中提取第 1、2、……、k大的元素，时间复杂度为 O(kn)。此方法只适用于 k远小于n 的情况，因为当 k 与 n 比较接近时，其时间复杂度趋向于 O(n^2)，非常耗时。（因为 当 k&#x3D;n 时，我们可以得到完整的有序序列，此时等价于“选择排序”算法。） 方法二：排序 如下图所示，我们可以先对数组 nums 进行排序，再返回最右边的 k 个元素，时间复杂度为 O(n logn)。显然，该方法“超额”完成任务了，因为我们只需要找出最大的 k 个元素即可，而不需要排序其他元素。 高效解决Top-K问题 - - 堆我们可以基于堆更加高效地解决 Top-K 问题，流程如下：*初始化一个小顶堆，其堆顶元素最小。*先将数组的前 k 个元素依次入堆。*从第 k+1 个元素开始，若当前元素大于堆顶元素，则将堆顶元素出堆，并将当前元素入堆。*遍历完成后，堆中保存的就是最大的 k 个元素。 总共执行了 n 轮入堆和出堆，堆的最大长度为 k，因此时间复杂度为 O(nlogk)。该方法的效率很高，当 k 较小时，时间复杂度趋向 O(n)；当较大时，时间复杂度不会超过 O(nlogn)。 另外，该方法适用于动态数据流的使用场景。在不断加入数据时，我们可以持续维护堆内的元素，从而实现最大 k 个元素的动态更新。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」建堆 从 O(nlogn) 到 O(n) 🐂🐂🐂","date":"2020-11-03T14:07:39.000Z","path":"2020/11/03/data-structure-algorithm/11-3.heap/","text":"方式一: 逐个元素执行 入堆 操作 首先创建一个空堆，然后遍历数组，依次对每个元素执行“入堆操作”，即先将元素添加至堆的尾部，再对该元素执行“从底至顶”堆化。 每当一个元素入堆，堆的长度就加一。由于节点是从顶到底依次被添加进二叉树的，因此堆是 自上而下 地构建的。 设元素数量为 n ，每个元素的入堆操作使用 O(log n) 时间，因此该建堆方法的时间复杂度为 O(log n)。 方式二: 通过遍历堆化实现第一种建堆思路的处理过程是从前往后遍历数组数据，并且每个数据插入堆中时，都是从下往上堆化。实际上，我们可以用一种更为高效的建堆方法(从后往前遍历数组，并且每个数据都是从上往下堆化)： 因为叶子节点往下堆化只能自己跟自己比较，不需要堆化，所以我们直接从第一个非叶子节点开始，依次堆化就行了。 因此在开始倒序遍历数组时，要从下标为 n/2 开始往前遍历，因为只有 下标从 n/2 到 1 的数据才需要进行堆化，而下标从 n/2 + 1 到 n 的节点是叶子节点，不需要堆化。 实际上，对于完全二叉树来说，下标从 n/2 到 n 的节点都是叶子节点。 时间复杂度分析这里主要是针对第二种建堆方法进行分析。 假设完全二叉树的节点数量为 n，则叶节点数量为 (n+1)&#x2F;2，其中 为向下整除。因此需要堆化的节点数量为 (n-1)&#x2F;2。在从顶至底堆化的过程中，每个节点最多堆化到叶节点，因此最大迭代次数为二叉树高度 logn。将上述两者相乘，可得到建堆过程的时间复杂度为 O(logn)。 但这个估算结果并不准确，因为我们没有考虑到二叉树底层节点数量远多于顶层节点的性质（lant：越往下，节点越多，一棵完美的二叉树其叶节点就能占一半数量）。 为了减小计算难度，假设给定一个节点数量为 n，高度为 h 的“完美二叉树”，该假设不会影响计算结果的正确性。 其时间复杂度最终为 O(n), 非常高效。 🐂！ 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」堆 基本操作","date":"2020-11-03T11:43:20.000Z","path":"2020/11/03/data-structure-algorithm/11-2.heap/","text":"建堆 - 暂无基础 后面再说之前已经了解 堆 这种数据结构的底层采用是 数组 这种最基本数据结构进行存储的(即 物理上是顺序存储)。现在的问题是，假如给了我们一组数据，我们如何使用这些元素在逻辑上构建出一个 堆 呢？毕竟要讲对某个数据结构的操作效率，就得写代码去操作这个数据结构，所以我们得先构造出这个数据结构才行啊 😝 不过，建堆操作比较特殊，堆的建造过程需要我们先了解它的一些基本的核心操作，所以，我们先假设有了一个堆，然后先看它的一些基本操作，之后再来看如何建堆。 访问堆顶元素堆顶元素即为二叉树的根节点，也就是数组的首个元素 1234/* 访问堆顶元素 */int peek() &#123; return maxHeap.get(0);&#125; 元素入堆 - - heapify 堆化操作我们首先将元素添加到堆底。 之后，由于元素值可能大于堆中其他元素，堆的成立条件可能会被破坏。因此，需要修复从插入节点到根节点的路径上的各个节点，这个操作被称为「堆化 heapify」。 考虑从入堆节点开始，从底至顶执行堆化。如下图所示，我们比较插入节点与其父节点的值，如果插入节点更大，则将它们交换。然后继续执行此操作，从底至顶修复堆中的各个节点，直至越过根节点或遇到无须交换的节点时结束。 设节点总数为n，则树的高度为log(n)。由此可知，堆化操作的循环轮数最多为O(logn)，元素入堆操作的时间复杂度为O(logn)。代码参考hello-algo 堆顶元素出堆堆顶元素是二叉树的根节点，即数组首元素。 如果我们直接从数组中删除首元素，那最后堆化出来的堆可能并不满足完全二叉树的特性。如下图案例： 因此我们需要改变一下思路，比如以下这个巧妙的步骤: 123交换堆顶元素与堆底元素（即交换根节点与最右叶节点）。交换完成后，将堆底从列表中删除（由于已经交换，实际上删除的是原来的堆顶元素）。从根节点开始，从顶至底执行堆化。 因为我们移除的是数组中的最后一个元素，而在堆化的过程中，都是交换操作，不会出现数组中的“空洞”，所以这种方法堆化之后的结果，肯定满足完全二叉树的特性。 如下图，“从顶至底堆化”的操作方向与“从底至顶堆化”相反，我们将根节点的值与其两个子节点的值进行比较，将最大的子节点与根节点交换。然后循环执行此操作，直到越过叶节点或遇到无须交换的节点时结束。 与元素入堆操作相似，堆顶元素出堆操作的时间复杂度也为 O(logn)。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」堆","date":"2020-11-02T13:16:14.000Z","path":"2020/11/02/data-structure-algorithm/11-1.heap/","text":"认识堆 lant:之所以树这种数据结构学完紧接着就是堆，是因为其实堆也是树，不过是一种特殊的树，怎么个特殊法呢?首先它得是一棵完全二叉树；其次，堆中的每个节点的值都必须 大于等于&#x2F;小于等于 其子树中每个节点的值；(前者叫大顶堆，后者叫小顶堆)对于大顶堆（小顶堆），堆顶元素（即根节点）的值分别是最大（最小）的。 根据堆的特性区判断下面这几个二叉树是不是堆其中第 1 个和第 2 个是大顶堆，第 3 个是小顶堆，第 4 个不是堆。除此之外，从图中还可以看出来，对于同一组数据，我们可以构建多种不同形态的堆。 堆的存储与表示之前在学二叉树时，已经了解到完全二叉树非常适合用数组来存储。而堆正是一种完全二叉树，所以我们也将采用数组来存储堆。 当使用数组表示二叉树时，元素代表节点值，索引代表节点在二叉树中的位置。节点指针通过索引映射公式来实现。如下图，给定索引 i，其左子节点索引为 2i，右子节点索引为 2i+1，父节点索引为 i&#x2F;2（向下取整）。当索引越界时，表示空节点或节点不存在。 我们可以将索引映射公式封装成函数，方便后续使用 1234567891011121314/* 获取左子节点索引 */int left(int i) &#123; return 2 * i + 1;&#125;/* 获取右子节点索引 */int right(int i) &#123; return 2 * i + 2;&#125;/* 获取父节点索引 */int parent(int i) &#123; return (i - 1) / 2; // 向下整除&#125; lant:其实我们从堆的存储原理中看出，将堆中元素放入数组的顺序，其实是个 “层序遍历”(即 广度优先遍历) 的顺序来的。 堆的应用在熟悉堆这种数据结构的常用操作前，我们还是先了解下堆一般被用到哪些场景吧。 首先就是 优先队列：堆通常作为实现优先队列的首选数据结构 lant:因为我们如果对一个堆结构不断地做堆顶元素出堆操作(下一篇会讲到这个操作)，你会发现元素会根据大顶堆&#x2F;小顶堆的不同，按照从大到小&#x2F;从小到大的顺序依次排列出来，且元素入堆和出堆的时间复杂度均为O(logn)。如果是个大顶堆的话，我们就可以将其看做一个优先队列(元素进入后，可以按值从大到小被取出)，其入队和出队操作的时间复杂度均为 O(logn)，而建堆操作为 O(n)，这些操作都非常高效。 堆排序：给定一组数据，我们可以用它们建立一个堆，然后不断地执行元素出堆操作，从而得到有序数据。然而，我们通常会使用一种更优雅的方式实现堆排序，详见后续的堆排序章节。 求解 Top K (即获取最大的K个元素)：这是一个经典的算法问题，同时也是一种典型应用，例如选择热度前 10 的新闻作为微博热搜，选取销量前 10 的商品等。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」红黑树 Red-Black Tree","date":"2020-10-31T06:06:23.000Z","path":"2020/10/31/data-structure-algorithm/10-9.red-blackTree/","text":"参考文献 《数据结构与算法之美》王争 https://blog.csdn.net/yang_yulei/article/details/26066409","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」2-3树","date":"2020-10-30T15:13:09.000Z","path":"2020/10/30/data-structure-algorithm/10-8.2-3Tree/","text":"参考文献 《数据结构与算法之美》王争 从2-3树到 红黑树","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」平衡二叉搜索树--AVL树（下）","date":"2020-10-29T15:13:09.000Z","path":"2020/10/29/data-structure-algorithm/10-7.AVL/","text":"AVL 树常用操作插入操作AVL 树的节点插入操作与二叉搜索树在主体上类似。唯一的区别在于，在 AVL 树中插入节点后，从该节点到根节点的路径上可能会出现一系列失衡节点。因此，我们需要从这个节点开始，自底向上执行旋转操作，使所有失衡节点恢复平衡。 删除操作类似地，在二叉搜索树的删除节点方法的基础上，需要从底至顶地执行旋转操作，使所有失衡节点恢复平衡 查找节点AVL 树的节点查找操作与二叉搜索树一致，在此不再赘述。 AVL 树典型应用组织和存储大型数据，适用于高频查找、低频增删的场景。用于构建数据库中的索引系统。红黑树在许多应用中比 AVL 树更受欢迎。这是因为红黑树的平衡条件相对宽松，在红黑树中插入与删除节点所需的旋转操作相对较少，其节点增删操作的平均效率更高。 参考文献 hello-algo 《数据结构与算法之美》王争 https://blog.csdn.net/yang_yulei/article/details/26066409 https://zhuanlan.zhihu.com/p/594775323 https://zhuanlan.zhihu.com/p/604835603?utm_id=0","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」平衡二叉搜索树--AVL树（上）","date":"2020-10-29T14:09:21.000Z","path":"2020/10/29/data-structure-algorithm/10-6.AVL/","text":"lant：通过上一篇对 BST 和 hash表 这两种数据结构的对比，我们知道虽然 BST在平衡状态下的 查、插、删 时间复杂度能达到O(logn)，但相比 hash表的 O(1)常量级时间复杂度还是逊色一点，不过它有hash表无法做到的，所以有存在的必要性和合理性。但上面也提到了，BST需要在平衡状态下才能发挥出威力，否则它的操作效率会逐渐降低到O(n)级。为了解决极端情况下，二叉树会退化为链表的情况，我们就需要设计一种平衡二叉查找树，也就是今天要讲的这种数据结构。通俗的讲，平衡二叉查找树就是说，一棵二叉查找树在频繁地增删改查操作后，它依然能不断通过自我修复来维护自身的平衡性，从而始终保持高效的数据操作性能。 自平衡二叉查找树其实平衡二叉查找树有挺多，常见的比如 AVL树，SplayTree(伸展树)、Treap(树堆)、红黑树。不过你可能留意到，每当提到平衡二叉查找树，听到的基本都是红黑树。它的出镜率甚至要高于“平衡二叉查找 树”这几个字，有时候，我们甚至默认平衡二叉查找树就是红黑树，不过本篇暂时不聊这个明星树，后面会专门再聊。下面先看最早的AVL树。 AVL树 AVL树是最先被发明的自平衡二叉查找树, 它严格符合平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。 AVL 树既是二叉搜索树也是平衡二叉树，同时满足这两类二叉树的所有性质，因此也被称为「平衡二叉搜索树 balanced binary search tree」。 AVL树如何实现自平衡 AVL 树之所以在不断地增删改查操作后，依然能保持自身的平衡，就是因为它的“旋转”操作。它的旋转操做能够在不影响二叉树的中序遍历序列的前提下，使失衡节点重新恢复平衡。换句话说，旋转操作既能保持“二叉搜索树”的性质，也能使树重新变为“平衡二叉树”。 在介绍AVL树的旋转操作之前，我们先了解一个概念叫 平衡因子， 它用来标识当前节点是否是失衡节点，如果是，就需要对其做旋转操作来保证二叉树的平衡。 当发现失衡因子时，如何对其进行旋转才能保证二叉树的平衡呢？下面根据节点失衡情况的不同，将旋转操作分为四种：右旋、左旋、先右旋后左旋、先左旋后右旋。下面我们将详细介绍这些旋转操作。 lant: 其实我们可以想下，为什么是四种旋转操作呢？其实很简单，平衡的条件是 任意节点**的左子树和右子树的高度之差的绝对值不超过 1 ，那就意味着，当你插入一个节点时，只要破坏了这个条件，就得做旋转操作。所以，我们只用看插入节点后，破坏平衡的状况有哪几种，无非就四种：父是左节点，自己是左节点，父左,自己右; 父右,自己左，父左,字节右每种失衡情况有各自对应的旋转操作。 另外 ，在学习具体的旋转操作之前，我们切记要做到有的放矢，不要太执迷于一些玄学，比如陷入”为什么这么转就能保持平衡，怎么能论证这个结论?”、“这么神奇的操作是怎么想出来的，为什么我就想不出这个方法?” …..可以你看看技术大咖们对此的看法： 旋转操作右旋https://www.hello-algo.com/chapter_tree/avl_tree/#1_1 左旋https://www.hello-algo.com/chapter_tree/avl_tree/#2_1 先左旋后右旋https://www.hello-algo.com/chapter_tree/avl_tree/#3 先右旋后左旋https://www.hello-algo.com/chapter_tree/avl_tree/#4 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」二叉搜索树 binary search tree","date":"2020-10-28T13:35:43.000Z","path":"2020/10/28/data-structure-algorithm/10-5.bst/","text":"前言说到二叉查找树，从名字你也能猜出这种数据结构的估计就是用二叉树来做快速查找的。事实上二叉搜索树最大的特点就是，支持动态数据集合的快速插入、删除、查找操作。而我们之前学过的散列表也是支持这些操作的，并且散列表的这些操作比二叉查找树更高效，时间复杂度是 O(1)。既然有了这么高效的散列表，还要二叉查找树干啥？有没有哪些地方是散列表做不了，必须要用二叉查找树来做的呢？ 带着这些问题，下面来学习今天的内容，二叉查找树！ 二叉搜索树 binary search tree首先二叉查找树是建立在二叉树的基础上的，不过，它在二叉树的基础上又新增了自己的特性：二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。下面是几个二叉查找树的例子，估计你一看应该就清楚了 TODO 初始化一棵平衡的二叉查找树 学到本篇,目前还有难度 😰lant: 回忆之前我们的二叉树一直都是把一些节点通过指针随意串连起来的，只不过在串连的时候，我们会尽量让它更像一棵树(你要是追求完美的话，还能让它更像一棵 完美二叉树)。而现在的二叉搜索树不一样了，它要求我们在串连节点时，除了尽量更像一棵树，还要遵循它的额外特性。 所以，如果你使用一组数据来初始化一棵 二叉查找树，你可能要花费点时间了，你除了要保证二叉查找树的特性，又要尽可能让树平衡… 还是要花费点时间的 (可以点击这个数据结构可视化站点试试) 比如给你一组数 [1~10] 做节点，让你做个二叉搜索树如果你直接挨个拿出节点连接，企图构建一棵二叉树，那效果就尴尬了：而一棵平衡的二叉查找树应该像下面这样：如果让你手动将这些节点连接成一棵平衡的二叉查找树，怕是不告诉你用什么技巧，你可能要连一阵子了 😝 我们暂时先不考虑如何能初始化一棵平衡的二叉搜索树，这个问题后面再聊…下面先假设我们已经有了一棵平衡的 二叉搜索树，然后看我们能用它做些什么操作，时间复杂度怎么样。 二叉搜索树的操作查找节点 假设我们现在已经有了一棵平衡的二叉查找树，那如何在二叉查找树中查找一个节点？ 从根节点开始，如果它等于我们要查找的数据，那就返回;如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。 二叉搜索树的查找操作与二分查找算法的工作原理一致，都是每轮排除一半情况。循环次数最多为二叉树的高度，当二叉树平衡时，使用 O(log n)时间。 123456789101112131415161718/* 查找节点 */TreeNode search(int num) &#123; TreeNode cur = root; // 循环查找，越过叶节点后跳出 while (cur != null) &#123; // 目标节点在 cur 的右子树中 if (cur.val &lt; num) cur = cur.right; // 目标节点在 cur 的左子树中 else if (cur.val &gt; num) cur = cur.left; // 找到目标节点，跳出循环 else break; &#125; // 返回目标节点 return cur;&#125; 插入节点 如何在二叉查找树中插入节点？ 二叉查找树的插入过程有点类似查找操作。 我们只需要从根节点开始，依次比较要插入的数据和节点的大小关系。如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置； 如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。代码参考 这里 很显然，即便你最初拥有一棵非常平衡的二叉查找树，随着你不断地插入节点(或者后面的删除节点)，你原本的 平衡二叉查找树 可能就逐渐退化成了链表。这时各种操作的时间复杂度也会退化为 O(n)。 删除节点如何在二叉查找树中删除节点？参考 这里 二叉搜索树 中序遍历 的 福利由于 二叉查找树 有 任意节点左子节点 &lt; 根节点 &lt; 右子节点的特性。而二叉树中序遍历的遍历顺序正好又是左-&gt;根-&gt;右。所以，对于二查找叉树来说，它的中序遍历得到的序列就是个升序序列。 利用中序遍历升序的性质，我们在二叉搜索树中获取有序数据仅需O(n)时间，无须进行额外的排序操作，非常高效。 二叉搜索树的效率在理想情况下，二叉搜索树是“平衡”的，这样就可以在 O(log n) 的时间复杂度下，查、插、删 节点。 开头的问题之前我们学过，散列表 的插入、删除、查找操作的时间复杂度可以做到常量级的O(1)，非常高效;而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn); 相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？ 我认为有下面几个原因： 第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。 比如，如果做索引的话(如mysql)，用户一般会有排序要求，散列表当然不能满足了。 第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在O(logn)。 第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。 第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。 最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。综合这几点，平衡二叉查找树在某些方面还是优于散列表的，所以，这两者的存在并不冲突。我们在实际的开发过程中，需要结合具体的需求来选择使用哪一个。 二叉搜索树常见应用用作系统中的多级索引，实现高效的查找、插入、删除操作。作为某些搜索算法的底层数据结构。用于存储数据流，以保持其有序状态。 lant:所以我们现在的问题是 如果我们有了一棵平衡的二叉搜索树，我们只能对树上现有的静态数据做查询操作，如果频繁地做插入，删除操作，我们目前还没办法保持树继续平衡，极端情况下，树有可能退化为链表。 即便我们只是想对一组静态数据进行查询操作，我们目前也还没办法先将他们逻辑地组成一棵平衡的 二叉搜索树 😓。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」用数组表示(存储)二叉树","date":"2020-10-28T12:57:19.000Z","path":"2020/10/28/data-structure-algorithm/10-4.binary-tree/","text":"之前我们的二叉树是使用链表这种最基本的数据结构来存储的（链式存储）。 而本篇我们将使用数组这种最基本的结构来存储二叉树（顺序存储）。 尝试用数组存储一棵二叉树 如果将根节点A存储在下标 i = 1 的位置，那左子节点B会存储在下标 2 * i = 2 的位置，右子节点C会存储在 2 * i + 1 = 3 的位置。以此类推，B 节点的左子节点D会存储在 2 * i = 2 * 2 = 4 的位置，右子节点E存储在 2 * i + 1 = 2 * 2 + 1 = 5 的位置。……最终的二叉树和数组的对应关系如下图:总结一下，就是，如果节点 X 存储在数组中下标为 i 的位置，下标为 2 * i 的位置存储的就是它的左子节点，下标为 2 * i + 1 的位置存储的就是它的右子节点。反过来，下标为 i&#x2F;2 的位置存储就是它的父节点。通过这种方式，我们只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为 1 的位置），这样就可以通过下标计算，把整棵树都串起来。 比较遗憾的是，刚刚我们举的例子是将一棵完全二叉树存储到了数组中，为了方便通过下标计算树中各节点位置，所以“浪费”了一个下标为 0 的存储位置。但如果我们往数组中存储的是一棵非完全二叉树，那就会浪费比较多的数组存储空间了。 可以看到，我们为了使 根节点下标为i, 左子节点下标为2 * i, 右子节点下标为 2 * i + 1 这个公式来仍然生效(方便计算各节点位置从而串起整棵树)，就不得不将一些None节点的位置也在数组中留出来。 这样就会浪费比较多的数组存储空间。 以下代码实现了一个基于数组表示的二叉树，包括以下几种操作 给定某节点，获取它的值、左（右）子节点、父节点。 获取前序遍历、中序遍历、后序遍历、层序遍历序列。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/* 数组表示下的二叉树类 */class ArrayBinaryTree &#123; private List&lt;Integer&gt; tree; /* 构造方法 */ public ArrayBinaryTree(List&lt;Integer&gt; arr) &#123; tree = new ArrayList&lt;&gt;(arr); &#125; /* 节点数量 */ public int size() &#123; return tree.size(); &#125; /* 获取索引为 i 节点的值 */ public Integer val(int i) &#123; // 若索引越界，则返回 null ，代表空位 if (i &lt; 0 || i &gt;= size()) return null; return tree.get(i); &#125; /* 获取索引为 i 节点的左子节点的索引 */ public Integer left(int i) &#123; return 2 * i + 1; &#125; /* 获取索引为 i 节点的右子节点的索引 */ public Integer right(int i) &#123; return 2 * i + 2; &#125; /* 获取索引为 i 节点的父节点的索引 */ public Integer parent(int i) &#123; return (i - 1) / 2; &#125; /* 层序遍历 */ public List&lt;Integer&gt; levelOrder() &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); // 直接遍历数组 for (int i = 0; i &lt; size(); i++) &#123; if (val(i) != null) res.add(val(i)); &#125; return res; &#125; /* 深度优先遍历 */ private void dfs(Integer i, String order, List&lt;Integer&gt; res) &#123; // 若为空位，则返回 if (val(i) == null) return; // 前序遍历 if (order == &quot;pre&quot;) res.add(val(i)); dfs(left(i), order, res); // 中序遍历 if (order == &quot;in&quot;) res.add(val(i)); dfs(right(i), order, res); // 后序遍历 if (order == &quot;post&quot;) res.add(val(i)); &#125; /* 前序遍历 */ public List&lt;Integer&gt; preOrder() &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); dfs(0, &quot;pre&quot;, res); return res; &#125; /* 中序遍历 */ public List&lt;Integer&gt; inOrder() &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); dfs(0, &quot;in&quot;, res); return res; &#125; /* 后序遍历 */ public List&lt;Integer&gt; postOrder() &#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); dfs(0, &quot;post&quot;, res); return res; &#125;&#125; lant: 所以，其实二叉树中，也就完全二叉树比较适合用 数组来存储。 因为如果一棵二叉树是一棵完全二叉树，那它用数组存储就会非常节省空间，它不需要像链式存储那样要存储额外的左右子节点的指针。这也是为什么完全二叉树要求最后一层的子节点都靠左的原因，因为右边的None节点会一起排在数组的末尾，可以直接省略，也不影响 数组存储二叉树的公式 计算。 优势与局限性二叉树的数组表示主要有以下优点： 数组存储在连续的内存空间中，对缓存友好，访问与遍历速度较快。 不需要存储指针，比较节省空间。 允许随机访问节点。 然而，数组表示也存在一些局限性： 数组存储需要连续内存空间，因此不适合存储数据量过大的树。 增删节点需要通过数组插入与删除操作实现，效率较低。 当二叉树中存在大量None时，数组中包含的节点数据比重较低，空间利用率较低。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」二叉树遍历","date":"2020-10-27T13:52:36.000Z","path":"2020/10/27/data-structure-algorithm/10-3.binary-tree/","text":"到目前为止，我们的二叉树从下层的物理结构角度来看, 仍然是使用链表这种最基本的的数据结构进行的存储，因此其遍历方式仍是通过指针逐个访问节点。 然而，从上层的逻辑角度来看，二叉树是一种非线性数据结构，这就使得二叉树(在应用层逻辑上)的遍历要比遍历链表更加复杂，需要借助搜索算法来实现。 二叉树常见的遍历方式包括 层序遍历、前序遍历、中序遍历 和 后序遍历 等。 广度优先遍历 – 「层序遍历 level-order traversal」原理从顶部到底部逐层遍历二叉树，并在每一层按照从左到右的顺序访问节点。层序遍历本质上属于 「广度优先遍历 breadth-first traversal」 ，它体现了一种“一圈一圈向外扩展”的逐层遍历方式。 代码仔细看上图的 广度优先遍历 方式，你会发现它遍历节点时，节点出现的方式 和 队列的“先进先出”规则很像，因此广度优先遍历也通常借助“队列”来实现 1234567891011121314151617/* 层序遍历 */List&lt;Integer&gt; levelOrder(TreeNode root) &#123; // 初始化队列，加入根节点 Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); // 初始化一个列表，用于保存遍历序列 List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); // 队列出队 list.add(node.val); // 保存节点值 if (node.left != null) queue.offer(node.left); // 左子节点入队 if (node.right != null) queue.offer(node.right); // 右子节点入队 &#125; return list;&#125; 时间复杂度O(n)：所有节点被访问一次，使用 O(n) 时间，其中 n 为节点数量。空间复杂度O(n)：在最差情况下，即满二叉树时，遍历到最底层之前，队列中最多同时存在 (n+1)/2 个节点，占用 O(n) 空间。二叉树的层数越往下，每层的节点越多，所以 只有二叉树是满二叉树时，最底层的节点数会达到最大。此时，当最底层节点(叶子节点)全部放入队列时，也是队列占用空间最大时。此时叶子结点数量为 (n+1)/2 深度优先遍历 - 前、中、后 序遍历原理 “前序”、”中序”、”后序” 是基于遍历时 “根节点” 的顺序来说的。前序：根在前；中序：根在中；后序：根在后; 代码1234567891011121314151617181920212223242526272829/* 前序遍历 */void preOrder(TreeNode root) &#123; if (root == null) return; // 访问优先级：根节点 -&gt; 左子树 -&gt; 右子树 list.add(root.val); preOrder(root.left); preOrder(root.right);&#125;/* 中序遍历 */void inOrder(TreeNode root) &#123; if (root == null) return; // 访问优先级：左子树 -&gt; 根节点 -&gt; 右子树 inOrder(root.left); list.add(root.val); inOrder(root.right);&#125;/* 后序遍历 */void postOrder(TreeNode root) &#123; if (root == null) return; // 访问优先级：左子树 -&gt; 右子树 -&gt; 根节点 postOrder(root.left); postOrder(root.right); list.add(root.val);&#125; 时间复杂度 O(n)：所有节点被访问一次，使用 O(n) 时间。空间复杂度 O(n)：在最差情况下，即树退化为链表时，递归深度达到 n，系统占用 O(n) 栈帧空间。 lant:到目前为止，我们的二叉树都还只是自己手动将一些 数据节点 随意串连起来的，父子节点之间也没什么大小顺序之分，节点们的组合还没什么规律可言。我们也只是在串连时尽量保证它们连起来像一棵二叉树，尽量完全 或 完美。 但即便我们好手动连出了一棵完美二叉树，由于各节点之间并没有什么规则，这棵树貌似既不能帮我们完成排序，也无法帮我们完成某种快速检索。 貌似还没什么用…… 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」常见二叉树类型","date":"2020-10-27T13:23:19.000Z","path":"2020/10/27/data-structure-algorithm/10-2.binary-tree/","text":"「完美二叉树 perfect binary tree」所有层的节点都被完全填满。在完美二叉树中，叶节点的度为 0，其余所有节点的度都为 2；若树高度为 h，则节点总数为 $2^{h+1}-1$ 。呈现标准的指数级关系，反映了自然界中常见的细胞分裂现象。 「完全二叉树 complete binary tree」只有最底层的节点未被填满，且最底层节点尽量靠左填充。 「完满二叉树 full binary tree」除了叶节点之外，其余所有节点都有两个子节点 「平衡二叉树 balanced binary tree」任意节点的左子树和右子树的高度之差的绝对值不超过 1 二叉树的退化当二叉树的每层节点都被填满时，达到 完美二叉树，完美二叉树是理想情况，可以充分发挥二叉树“分治”的优势。而当所有节点都偏向一侧时，二叉树退化为 链表，链表则是另一个极端，各项操作都变为线性操作，时间复杂度退化至 O(n)。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」二叉树 binary tree","date":"2020-10-27T12:15:32.000Z","path":"2020/10/27/data-structure-algorithm/10-1.binary-tree/","text":"认识二叉树 「二叉树 binary tree」是一种非线性数据结构，体现着“一分为二”的分治逻辑。与链表类似，二叉树的基本单元是节点，每个节点包含：值、左子节点引用、右子节点引用。 常见术语12345678根节点 root node」：位于二叉树顶层的节点，没有父节点。「叶节点 leaf node」：没有子节点的节点，其两个指针均指向。「边 edge」：连接两个节点的线段，即节点引用（指针）。节点所在的「层 level」：从顶至底递增，根节点所在层为 1 。节点的「度 degree」：节点的子节点的数量。在二叉树中，度的取值范围是 0、1、2 。二叉树的「高度 height」：从根节点到最远叶节点所经过的边的数量。节点的「深度 depth」：从根节点到该节点所经过的边的数量。节点的「高度 height」：从距离该节点最远的叶节点到该节点所经过的边的数量。 二叉树 (链式存储) 基本操作初始化二叉树 从二叉树的结构图来看，它的节点和链表的节点非常像，因此用链表来存储二叉树也挺顺理成章的 😝。而且链式存储也比较简单、直观，很方便地通过节点的左右指针就能将整棵树串起来，大部分二叉树代码都是通过这种结构来实现的。 其实初始化二叉树的过程和初始化一个链表没什么区别(将一些节点用指针串联起来)。只不过串联的逻辑稍有不同。 1234567891011// 初始化节点TreeNode n1 = new TreeNode(1);TreeNode n2 = new TreeNode(2);TreeNode n3 = new TreeNode(3);TreeNode n4 = new TreeNode(4);TreeNode n5 = new TreeNode(5);// 构建引用指向（即指针）n1.left = n2;n1.right = n3;n2.left = n4;n2.right = n5; 这棵二叉树的逻辑结构如下： 当然，对于上面的多个节点，你有多种不同的连接方式，将它们连成多种不同的二叉树： 插入、删除 节点与链表类似， 在二叉树中 插入、删除节点 ，可以通过修改指针来实现 123456TreeNode P = new TreeNode(0);// 在 n1 -&gt; n2 中间插入节点 Pn1.left = P;P.left = n2;// 删除节点 Pn1.left = n2; 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」链表","date":"2020-10-15T13:39:13.000Z","path":"2020/10/15/data-structure-algorithm/2-2.linked-list/","text":"参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」数组","date":"2020-10-13T10:01:27.000Z","path":"2020/10/13/data-structure-algorithm/2-1.array/","text":"「数组 array」是一种线性数据结构，其将相同类型元素存储在连续的内存空间中。我们将元素在数组中的位置称为该元素的「索引 index」。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」数据结构分类","date":"2020-10-11T12:15:32.000Z","path":"2020/10/11/data-structure-algorithm/1-0.dataStructure-type/","text":"数据结构分类数据结构可以从两个维度分为： 逻辑结构 和 物理结构。 逻辑结构 揭示了数据元素之间的逻辑关系，是抽象意义上的结构（也是我们后面重点关注和讨论的）； 物理结构 则反映了 按一定逻辑结构组成的数据元素 在计算机内存中真正的存储结构；在算法运行过程中，相关数据都存储在内存中, 这些数据的存储方式可分为 连续空间存储（数组） 和 分散空间存储（链表） 逻辑结构 逻辑结构 又可被分为 线性 和 非线性 两大类 线性结构比较直观，指数据在逻辑关系上呈线性排列；如：数组、链表、栈、队列、哈希表。 非线性结构则相反，呈非线性排列。如：树、堆、图、哈希表。 所有数据结构都是基于 数组、链表 或二者的组合实现的，例如 基于数组可实现：栈、队列、哈希表、树、堆、图、矩阵、张量（维度&gt;&#x3D;3的数组）等。基于链表可实现：栈、队列、哈希表、树、堆、图等。 lant: 数组 和 链表这两种逻辑数据结构，对应了内存上的两个最基本的物理存储结构 连续存储、分散存储，因此 数组 和 链表是最基本的逻辑数据结构，其他更为复杂的逻辑数据结构要使用哪种物理结构进行存储时，都需要基于这两个最基础的逻辑数据结构进行选择。 可以简单认为，对于一组数据，无论它们逻辑上是用哪种结构组合起来的。它们最终在物理介质上都是两种存储方式 连续存储、分散存储。 而这两种物理存储方式对应了最基础的两个数据结构 数组、链表。 所以无论你的数据是哪种逻辑结构的组合，最终也要选择基于什么样的物理结构进行存储，而 数组 和 链表 这两种基础数据结构分别对应了不同的物理存储结构。 如，下图中对于 堆 这种数据结构(逻辑上的)，可以采用 链表 或 数组 两种不同的 数据结构(物理上的) 进行存储。 参考文献 hello-algo 《数据结构与算法之美》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」为什么要学习数据结构和算法","date":"2020-09-21T12:19:18.000Z","path":"2020/09/21/data-structure-algorithm/0-1.data-structure-algo/","text":"为什么要学习数据结构和算法你是不是觉得数据结构和算法，跟操作系统、计算机网络一样，是脱离实际工作的知识？可能除了面试，这辈子也用不着？尽管计算机相关专业的同学在大学都学过这门课程，甚至很多培训机构也会培训这方面的知识，但是据我了解，很多程序员对数据结构和算法依旧一窍不通。还有一些人也只听说过数组、链表、快排这些最最基本的数据结构和算法，稍微复杂一点的就完全没概念。当然，也有很多人说，自己实际工作中根本用不到数据结构和算法。所以，就算不懂这块知识，只要 Java API、开发框架用得熟练，照样可以把代码写得“飞”起来。事实真的是这样吗？今天我们就来详细聊一聊，为什么要学习数据结构和算法。 想要通关大厂面试，千万别让数据结构和算法拖了后腿 很多大公司，比如 BAT、Google、Facebook，面试的时候都喜欢考算法、让人现场写代码？对校招来说，参加面试的学生通常没有实际项目经验，公司只能考察他们的基础知识是否牢固。社招的话，越是厉害的公司，越是注重考察数据结构与算法这类基础知识。相比短期能力，他们更看中你的长期潜力。 业务开发工程师，你真的愿意做一辈子 CRUD boy 吗？对于大部分业务开发来说，平时可能更多的是利用已经封装好的现成的接口、类库来堆砌、翻译业务逻辑，很少需要自己实现数据结构和算法。但是，不需要自己实现，并不代表什么都不需要了解。 如果不知道这些类库背后的原理，不懂得时间、空间复杂度分析，你如何能用好、用对它们？存储某个业务数据的时候，你如何知道应该用 ArrayList，还是 Linked List 呢？调用了某个函数之后，你又该如何评估代码的性能和资源的消耗呢？ 作为业务开发，我们会用到各种框架、中间件和底层系统，比如 Spring、RPC 框架、消息中间件、Redis 等等。在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。比如，我们常用的 Key-Value 数据库 Redis 中，有序集合是用什么数据结构来实现的呢？为什么要用跳表来实现呢？为什么不用二叉树呢？如果你能弄明白这些底层原理，你就能更好地使用它们。即便出现问题，也很容易就能定位。因此，掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都是非常有用的。 基础架构研发工程师，写出达到开源水平的框架才是你的目标！不同的公司、不同的人做出的 RPC 框架，架构设计思路都差不多，最后实现的功能也都差不多。但是有的人做出来的框架，Bug 很多、性能一般、扩展性也不好，只能在自己公司仅有的几个项目里面用一下。而有的人做的框架可以开源到 GitHub 上给很多人用，甚至被 Apache 收录。为什么会有这么大的差距呢？ 高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。这些累积起来，决定了一个框架是不是优秀。所以，如果你还不懂数据结构和算法，没听说过大O复杂度分析，不知道怎么分析代码的时间复杂度和空间复杂度，那肯定说不过去了，赶紧来补一补吧！ 对编程还有追求？不想被行业淘汰？那就不要只会写凑合能用的代码！何为编程能力强？是代码的可读性好、健壮？还是扩展性好？我觉得没法列，也列不全。但是，在我看来，性能好坏起码是其中一个非常重要的评判标准。但是，如果你连代码的时间复杂度、空间复杂度都不知道怎么分析，怎么写出高性能的代码呢？ 有的人写代码的时候，从来都不考虑非功能性的需求，只是完成功能，凑合能用就好；我曾经面试过很多大龄候选人，简历能写十几页，经历的项目有几十个，但是细看下来，每个项目都是重复地堆砌业务逻辑而已，完全没有难度递进，看不出有能力提升。久而久之，十年的积累可能跟一年的积累没有任何区别。这样的人，怎么不会被行业淘汰呢？ 其实，我觉得，数据结构和算法这个东西，如果你不去学，可能真的这辈子都用不到，也感受不到它的好。但是一旦掌握，你就会常常被它的强大威力所折服。之前你可能需要费很大劲儿来优化的代码，需要花很多心思来设计的架构，用了数据结构和算法之后，很容易就可以解决了。 内容小结我们学习数据结构和算法，并不是为了死记硬背几个知识点。我们的目的是建立时间复杂度、空间复杂度意识，写出高质量的代码，能够设计基础架构，提升编程技能，训练逻辑思维，积攒人生经验，以此获得工作回报，实现你的价值，完善你的人生。 所以，不管你是业务开发工程师，还是基础架构工程师；不管你是初入职场的初级工程师，还是工作多年的资深架构师，又或者是想转人工智能、区块链这些热门领域的程序员，数据结构与算法作为计算机的基础知识、核心知识，都是必须要掌握的。 掌握了数据结构与算法，你看待问题的深度，解决问题的角度就会完全不一样。因为这样的你，就像是站在巨人的肩膀上，拿着生存利器行走世界。数据结构与算法，会为你的编程之路，甚至人生之路打开一扇通往新世界的大门。","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"「数据结构与算法」前言","date":"2020-09-21T04:50:01.000Z","path":"2020/09/21/data-structure-algorithm/0-0.data-structure-algo/","text":"若您是算法初学者，从未接触过算法，或者已经有一些刷题经验，对数据结构与算法有模糊的认识，在会与不会之间反复横跳，那么这本书正是为您量身定制！ 算法学习路线：从总体上看，我们可以将学习数据结构与算法的过程划分为三个阶段 （本书内容主要涵盖“第一阶段”，旨在帮助你更高效地展开第二和第三阶段的学习）算法入门：我们需要熟悉各种数据结构的特点和用法，学习不同算法的原理、流程、用途和效率等方面内容。刷算法题：建议从热门题目开刷，如 剑指 Offer 和 LeetCode Hot 100，先积累至少 100 道题目，熟悉主流的算法问题。初次刷题时，“知识遗忘”可能是一个挑战，但请放心，这是很正常的。我们可以按照“艾宾浩斯遗忘曲线”来复习题目，通常在进行 3-5 轮的重复后，就能将其牢记在心。搭建知识体系: 在学习方面，我们可以阅读算法专栏文章、解题框架和算法教材，以不断丰富知识体系。在刷题方面，可以尝试采用进阶刷题策略，如按专题分类、一题多解、一解多题等，相关的刷题心得可以在各个社区找到。 参考：hello-algo 工作十年间，我见过许多程序员。他们有着各种各样的背景，有很多既有潜力又非常努力，但始终无法在自己现有水平上更进一步。 在技术圈里，我们经常喜欢谈论高大上的架构，比如高可用、微服务、服务治理等等。鲜有人关注代码层面的编程能力，而愿意沉下心来，花几个月时间啃一啃计算机基础知识、认认真真夯实基础的人，简直就是凤毛麟角。基础知识就像是一座大楼的地基，它决定了我们的技术高度。而要想快速做出点事情，前提条件一定是基础能力过硬，“内功”要到位。技术人究竟都需要修炼哪些“内功”呢？无外乎就是大学里的那些基础课程，操作系统、计算机网络、编译原理 等等，当然还有数据结构和算法。 像《算法导论》这些经典书籍，虽然很全面，但是过于理论，学起来非常枯燥；而市面很多课程大多缺失真实的开发场景，费劲学完感觉好像还是用不上，过不了几天就忘了。 这怕是大多数人的无奈吧，面试必面，日常抛脑后 😓 通过不断学习《数据结构和算法》相关的知识，你至少也会在写代码时，不由自主地考虑很多性能方面的问题，这样久而久之， 时间复杂度高、空间复杂度高的垃圾代码在你得代码里会变得会越来越少。(比如你在用redis时，除了业务上的考虑，也会不由自主地关注所选api的 时间复杂度，仅仅这个入门的意识，你就能明显感觉到你和以往的不同)。 参考：《数据结构与算法之美 – 00开篇词》王争","tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://rymuscle.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]}]