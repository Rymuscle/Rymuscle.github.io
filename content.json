[{"title":"11. 连接的原理","date":"2021-11-09T14:10:12.000Z","path":"2021/11/09/MySQL知识点整理/11. 连接的原理/","text":"前言 搞数据库一个避不开的概念就是Join，翻译成中文就是连接。相信很多小伙伴在初学连接的时候都有些一脸懵逼，理解了连接的语义之后又可能不明白各个表中的记录到底是怎么连起来的，以至于在使用的时候常常陷入下边两种误区: 误区一:业务至上，管他三七二十一，再复杂的查询也用在一个连接语句中搞定。 误区二:敬而远之，上次 DBA 那给报过来的慢查询就是因为使用了连接导致的，以后再也不敢用了。所以本章就来扒一扒连接的原理。考虑到一部分小伙伴可能忘了连接是个啥或者压根儿就不知道，为了节省他们百度或者看其他书的宝贵时间以及为了我的书凑字数，我们先来介绍一下 MySQL 中支持的一些连接语法。 连接简介为了故事的顺利发展，我们先建立 t1、t2 两个简单的表并给它们填充一点数据，这两个表都有两个列，一个是INT类型的，一个是CHAR(1)类型的，填充好数据的两个表⻓这样: 12345678910111213141516171819mysql&gt; SELECT * FROM t1; +------+------+|m1 |n1 | +------+------+ |1|a| |2|b| |3|c| +------+------+3 rows in set (0.00 sec)mysql&gt; SELECT * FROM t2; +------+------+|m2 |n2 | +------+------+ |2|b| |3|c| |4|d| +------+------+3 rows in set (0.00 sec) 连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。所以我们把t1和t2两个表连接起来的过程如下图所示:这个过程看起来就是把t1表的记录和t2的记录连起来组成新的更大的记录，所以这个查询过程称之为 连接查询。连接查询的结果集中包含一个表中的每一条记录与另一个表中的每一条记录相互匹配的组合，像这样的结果集就可以称之为笛卡尔积。因为表t1中有3条记录，表t2中也有3条记录，所以这两个表连接之后的笛卡尔积就有3×3&#x3D;9行记录。在MySQL中，连接查询的语法也很随意，只要在FROM语句后边跟多个表名就好了，比如我们把t1表和t2表连接起来的查询语句可以写成这样: 123456789101112131415mysql&gt; SELECT * FROM t1, t2; +------+------+------+------+ |m1 |n1 |m2 |n2 | +------+------+------+------+ |1|a|2|b| |2|b|2|b| |3|c|2|b| |1|a|3|c| |2|b|3|c| |3|c|3|c| |1|a|4|d| |2|b|4|d| |3|c|4|d| +------+------+------+------+ 9 rows in set (0.00 sec) 连接过程简介如果我们乐意，我们可以连接任意数量张表，但是如果没有任何限制条件的话，这些表连接起来产生的笛卡尔积可能是非常巨大的。比方说3个100行记录的表连接起来产生的笛卡尔积就有 100×100×100&#x3D;1000000行数据!所以在连接的时候过滤掉特定记录组合是有必要的，在连接查询中的过滤条件可以分成两种: 涉及单表的条件这种只涉及单表的过滤条件我们之前都提到过一万遍了，我们之前也一直称为搜索条件，比如t1.m1 &gt; 1是只针对t1表的过滤条件，t2.n2 &lt; ‘d’是只针对t2表的过滤条件。 涉及两表的条件这种过滤条件我们之前没⻅过，比如t1.m1 &#x3D; t2.m2、t1.n1 &gt; t2.n2等，这些条件中涉及到了两个表，我们稍后会仔细分析这种过滤条件是如何使用的哈。 下边我们就要看一下携带过滤条件的连接查询的大致执行过程了，比 方说下边这个查询语句:SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &#39;d&#39;;在这个查询中我们指明了这三个过滤条件:t1.m1 &gt; 1t1.m1 = t2.m2t2.n2 &lt; &#39;d&#39; 那么这个连接查询的大致执行过程如下: 首先确定第一个需要查询的表，这个表称之为驱动表。怎样在 单表中执行查询语句我们在前一章都唠叨过了，只需要选取代 价最小的那种访问方法去执行单表查询语句就好了(就是说从 const、ref、ref_or_null、range、index、all这些执行方法 中选取代价最小的去执行查询)。此处假设使用t1作为驱动 表，那么就需要到t1表中找满足t1.m1 &gt; 1的记录，因为表 中的数据太少，我们也没在表上建立二级索引，所以此处查询 t1表的访问方法就设定为all吧，也就是采用全表扫描的方式 执行单表查询。关于如何提升连接查询的性能我们之后再说， 现在先把基本概念捋清楚哈。所以查询过程就如下图所示:我们可以看到，t1表中符合t1.m1 &gt; 1的记录有两条。 针对上一步骤中从驱动表产生的结果集中的每一条记录，分别 需要到t2表中查找匹配的记录，所谓匹配的记录，指的是符合 过滤条件的记录。因为是根据t1表中的记录去找t2表中的记 录，所以t2表也可以被称之为被驱动表。上一步骤从驱动表中 得到了2条记录，所以需要查询2次t2表。此时涉及两个表的列 的过滤条件t1.m1 &#x3D; t2.m2就派上用场了:当t1.m1 &#x3D; 2时，过滤条件t1.m1 &#x3D; t2.m2就相当于 t2.m2 &#x3D; 2，所以此时t2表相当于有了t1.m1 &#x3D; 2、t2.n2 &lt; ‘d’这两个过滤条件，然后到t2表中执行 单表查询。当t1.m1 &#x3D; 3时，过滤条件t1.m1 &#x3D; t2.m2就相当于 t2.m2 &#x3D; 3，所以此时t2表相当于有了t1.m1 &#x3D; 3、t2.n2 &lt; ‘d’这两个过滤条件，然后到t2表中执行 单表查询。所以整个连接查询的执行过程就如下图所示:也就是说整个连接查询最后的结果只有两条符合过滤条件的记录: 从上边两个步骤可以看出来，我们上边唠叨的这个两表连接查询共需 要查询1次t1表，2次t2表。当然这是在特定的过滤条件下的结果， 如果我们把t1.m1 &gt; 1这个条件去掉，那么从t1表中查出的记录就 有3条，就需要查询3次t3表了。也就是说在两表连接查询中，驱动 表只需要访问一次，被驱动表可能被访问多次。 内连接和外连接为了大家更好理解后边内容，我们先创建两个有现实意义的表， 12345678910CREATE TABLE student (number INT NOT NULL AUTO_INCREMENT COMMENT &#x27;学号&#x27;,name VARCHAR(5) COMMENT &#x27;姓名&#x27;, major VARCHAR(30) COMMENT &#x27;专业&#x27;, PRIMARY KEY (number)) Engine=InnoDB CHARSET=utf8 COMMENT &#x27;学生信息表&#x27;;CREATE TABLE score (number INT COMMENT &#x27;学号&#x27;,subject VARCHAR(30) COMMENT &#x27;科目&#x27;, score TINYINT COMMENT &#x27;成绩&#x27;, PRIMARY KEY (number, score)) Engine=InnoDB CHARSET=utf8 COMMENT &#x27;学生成绩表&#x27;; 我们新建了一个学生信息表，一个学生成绩表，然后我们向上述两个 表中插入一些数据，为节省篇幅，具体插入过程就不唠叨了，插入后 两表中的数据如下:","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"10. 单表访问方法","date":"2021-11-06T12:21:43.000Z","path":"2021/11/06/MySQL知识点整理/10.0 TODO 单表访问方法/","text":"前言 对于我们这些MySQL的使用者来说，MySQL其实就是一个软件，平时用的最多的就是查询功能。DBA时不时丢过来一些慢查询语句让优化，我们如果连查询是怎么执行的都不清楚还优化个毛线，所以是时候掌握真正的技术了。我们在第一章的时候就曾说过，MySQL Server有一个称为查询优化器的模块，一条查询语句进行语法解析之后就会被交给查询优化器来进行优化，优化的结果就是生成一个所谓的执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的，最后会按照执行计划中的步骤调用存储引擎提供的方法来真正的执行查询，并将查询结果返回给用户。不过查询优化这个主题有点儿大，在学会跑之前还得先学会走，所以本章先来瞅瞅MySQL怎么执行单表查询(就是FROM子句后边只有一个表，最简单的那种查询~)。 访问方法(access method)的概念我们平时写的查询语句本质上只是告诉MySQL我们要获取的数据符合哪些规则，至于MySQL背地里是怎么把查询结果搞出来的那是MySQL自己的事儿。对于单个表的查询来说，设计 MySQL 的大叔把查询的执行方式大致分为下边两种: 使用全表扫描进行查询这种执行方式很好理解，就是把表的每一行记录都扫一遍嘛， 把符合搜索条件的记录加入到结果集就完了。不管是啥查询都可以使用这种方式执行，当然，这种也是最笨的执行方式。 使用索引进行查询因为直接使用全表扫描的方式执行查询要遍历好多记录，所以代价可能太大了。如果查询语句中的搜索条件可以使用到某个索引，那直接使用索引来执行查询可能会加快查询执行的时间。 使用索引来执行查询的方式五花八⻔，又可以细分为许多 种类: 针对主键或唯一二级索引的等值查询 针对普通二级索引的等值查询 针对索引列的范围查询 直接扫描整个索引 设计MySQL的大叔把MySQL执行查询语句的方式称之为访问方法或者访问类型。同一个查询语句可能使用多种不同的访问方法来执行，虽然最后的查询结果都是一样的，但是执行的时间可能差老鼻子远了。下边细细道来各种访问方法的具体内容。 const有的时候我们可以通过主键列来定位一条记录，比方说这个查询: 1SELECT * FROM single_table WHERE id = 1438; MySQL会直接利用主键值在聚簇索引中定位对应的用户记录。对于的聚簇索引来说，它对应的B+树叶子节点中的记录就是按照id列排序的。B+树本来就是一个矮矮的大胖子，所以这样根据主键值定位一条记录的速度贼快。类似的，我们根据 唯一二级索引列 来定位一条记录的速度也是贼快的。比如下边这个查询: 1SELECT * FROM single_table WHERE key2 = 3841; 不过这个查询的执行会分两步，第一步先从idx_key2对应的B+树索引中根据key2列与常数的等值比较条件定位到一条二级索引记录，然后再根据该记录的id值到聚簇索引中获取到完整的用户记录。 设计MySQL的大叔认为通过主键或者唯一二级索引列与常数的等值比较 来定位一条记录是像坐火箭一样快的，所以他们把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为:const，意思是 常数级别 的，代价是可以忽略不计的。不过这种const访问方法 只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效 ， 如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个const访问方法才有效(这是因为只有该索引中全部列都采用等值比较才可以定位唯一的一条记录)。 对于唯一二级索引来说，查询该列为NULL值的情况比较特殊，比如 这样: 1SELECT * FROM single_table WHERE key2 IS NULL; 因为 唯一二级索引列并不限制NULL值的数量 ，所以上述语句可能访问到多条记录，也就是说上边这个语句不可以使用const访问方法来执行。 ref有时候我们对某个普通的二级索引列与常数进行等值比较，比如: 1SELECT * FROM single_table WHERE key1 = &#x27;abc&#x27;; 对于这个查询，我们当然可以选择全表扫描来逐一对比搜索条件是否满足要求，我们也可以先使用二级索引找到对应记录的id值，然后再回表到聚簇索引中查找完整的用户记录。由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，也就是说 使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数。如果匹配的记录较少，则回表的代价还是比较低的 (如果匹配到的记录太多…啧啧… MySQL可能会走全表扫描) ，所以MySQL可能选择使用索引而不是全表扫描的方式来执行查询。设计MySQL的大叔就把这种搜索条件为二级索引列与常数等值比较，采用二级索引来执行查询的访问方法称为:ref。 采用ref访问方法执行查询的图示: 从图示中可以看出，对于普通的二级索引来说，通过索引列进行等值比较后可能匹配到多条连续的记录，而不是像主键或者唯一二级索引那样最多只能匹配1条记录，所以这种ref访问方法比const差了那么一丢丢，但是在二级索引等值比较时匹配的记录数较少时的效率还是很高的(如果匹配的二级索引记录太多那么回表的成本就太大了)，跟坐高铁差不多。不过需要注意下边两种情况: 二级索引列值为NULL的情况 不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含NULL值的数量并不限制 ， 所以我们采用key IS NULL这种形式的搜索条件最多只能使用ref的访问方法，而不是const的访问方法 。 对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用ref的访问方法; 但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为ref了;比如：SELECT * FROM single_table WHERE key_part1 = &#39;god like&#39; AND key_part2 &gt; &#39;legendary&#39;; ref_or_null有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来，就像下边这个查询: 1SELECT * FROM single_demo WHERE key1 = &#x27;abc&#x27; OR key1 IS NULL; 当使用二级索引而不是全表扫描的方式执行该查询时，这种类型的查询使用的访问方法就称为 ref_or_null，这个ref_or_null访问方法的执行过程如下:可以看到，上边的查询相当于先分别从idx_key1索引对应的B+树中找出 key1 IS NULL和key1 = &#39;abc&#39;的两个连续的记录范围，然后根据这些二级索引记录中的id值再回表查找完整的用户记录。 range我们之前介绍的几种访问方法都是在对索引列与某一个常数进行等值比较的时候才可能使用到(ref_or_null比较奇特，还计算了值为NULL的情况)，但是有时候我们面对的搜索条件更复杂，比如下边这个查询: 1SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 &gt;= 38 AND key2 &lt;= 79); 我们当然还可以使用全表扫描的方式来执行这个查询，不过也可以使用 二级索引 + 回表 的方式执行。如果采用 二级索引 + 回表 的方式来执行的话，那么此时的搜索条件就不只是要求索引列与常数的等值匹配了，而是索引列需要匹配某个或某些范围的值，在本查询中 key2列的值只要匹配下列3个范围中的任何一个就算是匹配成功了: key2的值是1438； key2的值是6328 ； key2的值在38和79之间；设计MySQL的大叔把这种利用索引进行范围匹配的访问方法称之为: range。 小贴士:此处所说的使用索引进行范围匹配中的 索引 可以是聚簇索引， 也可以是二级索引。 如果把这几个所谓的key2列的值需要满足的范围在数轴上体现出来 的话，那应该是这个样子:也就是从数学的⻆度看，每一个所谓的范围都是数轴上的一个区间， 3个范围也就对应着3个区间:范围1:key2 &#x3D; 1438范围2:key2 &#x3D; 6328范围3:key2 ∈ [38, 79]，注意这里是闭区间。 我们可以把那种索引列等值匹配的情况称之为单点区间，上边所说的范围1和范围2都可以被称为单点区间；而像范围3这种的我们可以称为连续范围区间。 index (能直接遍历二级索引获取结果集)看下边这个查询: 1SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = &#x27;abc&#x27;; 由于key_part2并不是联合索引idx_key_part最左索引列，所以我们无法使用ref或者range访问方法来执行这个语句。 但是这个查询符合下边这两个条件: 它的查询列表只有3个列:key_part1, key_part2, key_part3，而索引idx_key_part又包含这三个列； 搜索条件中只有key_part2列。这个列也包含在索引idx_key_part中； 也就是说我们可以直接通过遍历idx_key_part索引的叶子节点的记录来比较key_part2 &#x3D; ‘abc’这个条件是否成立，把匹配成功的二级索引记录的key_part1, key_part2, key_part3列的值直接加到结果集中就行了。由于二级索引记录比聚簇索记录小的多(聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，而二级索引记录只需要存放索引列和主键)，而且这个过程也不用进行回表操作 ，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多 。设计MySQL的大叔就把这种采用 遍历二级索引记录 的执行方式称之为: index。 all (全表扫描, InnoDB为直接扫描聚簇索引)最直接的查询执行方式就是我们已经提了无数遍的全表扫描，对于 InnoDB表来说也就是直接扫描聚簇索引(lant:的叶子节点)，设计MySQL的大叔把这种使用全表扫描执行查询的方式称之为: all。 注意事项重温 二级索引 + 回表一般情况下只能利用单个二级索引执行查询，比方说下边的这个查询: 1SELECT * FROM single_table WHERE key1 = &#x27;abc&#x27; AND key2 &gt; 1000; 查询优化器会识别到这个查询中的两个搜索条件:key1 = &#39;abc&#39;、key2 &gt; 1000优化器一般会根据single_table表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少，然后选择那个扫描行数较少的条件到对应的二级索引中查询(关于如何比较的细节我们后边的章节中会唠叨)。然后将从该二级索引中查询到的结果经过回表得到完整的用户记录后 再根据其余的WHERE条件过滤记录 。一般来说，等值查找比范围查找需要扫描的行数更少(也就是ref的访问方法一般比range好，但这也不总是一定的，也可能采用ref访问方法的那个索引列的值为特定值的行数特别多)所以这里假设优化器决定使用idx_key1索引进行查询，那么整个查询过程可以分为两个步骤: 步骤1:使用二级索引定位记录的阶段，也就是根据条件key1 &#x3D; ‘abc’从idx_key1索引代表的B+树中找到对应的二级索引记录。 步骤2:回表阶段，也就是根据上一步骤中找到的记录的主键值进行回表操作，也就是到聚簇索引中找到对应的完整的用户记录，再根据条件key2 &gt; 1000到完整的用户记录继续过滤。将最终符合过滤条件的记录返回给用户。 这里需要特别提醒大家的一点是，因为二级索引的节点中的记录只包含索引列和主键，所以在步骤1中使用idx_key1索引进行查询时只会用到与key1列有关的搜索条件，其余条件，比如key2 &gt; 1000这个条件在步骤1中是用不到的，只有在步骤2完成回表操作后才能继续针对完整的用户记录中继续过滤。 明确range访问方法使用的范围区间其实对于B+树索引来说，只要索引列和常数使用&#x3D;、&lt;&#x3D;&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;&#x3D;、&lt;&#x3D;、BETWEEN、!&#x3D;(不等于也可以写成&lt;&gt;)或 者LIKE操作符连接起来，就可以产生一个所谓的区间。 小贴士:LIKE操作符比较特殊，只有在匹配完整字符串或者匹配字符串前缀时才可以利用索引，这里就不赘述了。IN操作符的效果和若干个等值匹配操作符=之间用OR连接起来是一样的，也就是说会产生多个单点区间，比如下边这两个语句的效果是一样的: 12SELECT * FROM single_table WHERE key2 IN (1438, 6328);SELECT * FROM single_table WHERE key2 = 1438 OR key2 = 6328; 不过在日常的工作中，一个查询的WHERE子句可能有很多个小的搜索条件，这些搜索条件需要使用AND或者OR操作符连接起来。当我们想使用range访问方法来执行一个查询语句时，重点就是找出该查询可用的索引以及这些索引对应的范围区间。下边分两种情况看一下怎么从由AND或OR组成的复杂搜索条件中提取出正确的范围区间。 所有搜索条件都可以使用某个索引的情况有时候每个搜索条件都可以使用到某个索引，比如下边这个查询语句: 1SELECT * FROM single_table WHERE key2 &gt; 100 AND key2 &gt; 200; 这个查询中的搜索条件都可以使用到key2，也就是说每个搜索条件都对应着一个idx_key2的范围区间。这两个小的搜索条件使用AND 连接起来，也就是要取两个范围区间的交集。在我们使用range访问方法执行查询时，key2 &gt; 100和key2 &gt; 200交集当然就是key2 &gt; 200了，也就是说上边这个查询使用idx_key2的范围区间就是(200, +∞)。 我们再看一下使用OR将 多个搜索条件连接在一起的情况: 1SELECT * FROM single_table WHERE key2 &gt; 100 OR key2 &gt; 200; OR意味着需要取各个范围区间的并集，所以上边这个查询在我们使用range访问方法执行查询时，使用的idx_key2索引的范围区间就是(100， +∞)。 有的搜索条件无法使用索引的情况比如下边这个查询: 1SELECT * FROM single_table WHERE key2 &gt; 100 AND common_field = &#x27;abc&#x27;; 请注意，这个查询语句中能利用的索引只有idx_key2一个， 而idx_key2这个二级索引的记录中又不包含common_field这个字段，所以在使用二级索引idx_key2定位定位记录的阶段用不到common_field &#x3D; ‘abc’这个条件，这个条件是在回表获取了完整的用户记录后才使用的。而 范围区间是为了 到索引中取记录 中提出的概念 ，所以在确定范围区间的时候不需要考虑common_field &#x3D; ‘abc’这个条件，我们在为某个索引确定范围区间的时候只需要把用 不到相关索引的搜索条件替换为TRUE就好了。 也就是说最上边那个查询使用idx_key2的范围区间就是:(100, +∞)。 再来看一下使用OR的情况: 1SELECT * FROM single_table WHERE key2 &gt; 100 OR common_field = &#x27;abc&#x27;; 同理，我们把使用不到idx_key2索引的搜索条件替换为TRUE: 1SELECT * FROM single_table WHERE key2 &gt; 100 OR TRUE; 接着化简: 1SELECT * FROM single_table WHERE TRUE; 额，这也就说说明如果我们强制使用idx_key2执行查询的话，对应的范围区间就是(-∞, +∞)，也就是 需要将全部二级索引的记录进行回表 ，这个代价肯定比直接全表扫描都大了 。也就是说 一个使用到索引的搜索条件和没有使用该索引的搜索条件使用OR连接起来后是无法使用该索引的 。 复杂搜索条件下找出范围匹配的区间有的查询的搜索条件可能特别复杂，光是找出范围匹配的各个区间就挺烦的，比方说下边这个: 123SELECT * FROM single_table WHERE(key1 &gt; &#x27;xyz&#x27; AND key2 = 748 ) OR (key1 &lt; &#x27;abc&#x27; AND key1 &gt; &#x27;lmn&#x27;) OR (key1 LIKE &#x27;%suf&#x27; AND key1 &gt; &#x27;zzz&#x27; AND(key2 &lt; 8000 OR common_field = &#x27;abc&#x27;)) ; 我滴个神，这个搜索条件真是绝了，不过大家不要被复杂的表象迷住了双眼，按着下边这个套路分析一下: 首先查看WHERE子句中的搜索条件都涉及到了哪些列，哪些列可能使用到索引。 这个查询的搜索条件涉及到了key1、key2、common_field 这3个列，然后key1列有普通的二级索引idx_key1，key2列有唯一二级索引idx_key2。 对于那些可能用到的索引，分析它们的范围区间。 假设我们使用idx_key1执行查询 我们需要把那些用不到该索引的搜索条件暂时移除掉，移除方法也简单，直接把它们替换为TRUE就好了。上边的查询中除了有关key2和 common_field列不能使用到idx_key1索引外，key1 LIKE ‘%suf’也使用不到索引，所以把这些搜索条件替换为TRUE之后的样子就是这样:(key1 &gt; &#39;xyz&#39; AND TRUE ) OR (key1 &lt; &#39;abc&#39; AND key1 &gt; &#39;lmn&#39;) OR (TRUE AND key1 &gt; &#39;zzz&#39; AND (TRUE OR TRUE))化简一下上边的搜索条件就是:(key1 &gt; &#39;xyz&#39;) OR (key1 &lt; &#39;abc&#39; AND key1 &gt; &#39;lmn&#39;) OR (key1 &gt; &#39;zzz&#39;) 替换掉永远为TRUE或FALSE的条件 因为符合key1 &lt; ‘abc’ AND key1 &gt; ‘lmn’永远为FALSE，所以上边的搜索条件可以被写成: (key1 &gt; &#39;xyz&#39;) OR (key1 &gt; &#39;zzz&#39;) 继续化简区间 key1 &gt; ‘xyz’和key1 &gt; ‘zzz’之间使用OR操作符连接起来的，意味着要取并集，所以最终的结果化简的到的区间就是:key1 &gt; xyz。也就是说:上边那个有一坨搜索条件的查询语句如果使用 idx_key1 索引执行查询的话，需要把满足key1 &gt; xyz的二级索引记录都取出来，然后拿着这些记录的id再进行回表，得到完整的用户记录之后再使用其他的搜索条件进行过滤。 假设我们使用idx_key2执行查询 我们需要把那些用不到该索引的搜索条件暂时使用TRUE条件替换掉，其中有关key1和 common_field的搜索条件都需要被替换掉，替换 结果就是:(TRUE AND key2 = 748 ) OR (TRUE AND TRUE) OR (TRUE AND TRUE AND (key2 &lt; 8000 OR TRUE))key2 &lt; 8000 OR TRUE的结果肯定是TRUE呀，也就是说化简之后的搜索条件成了:key2 = 748 OR TRUE这个化简之后的结果就更简单了: TRUE 这个结果也就意味着如果我们要使用idx_key2索引执行查询语句的话，需要扫描idx_key2二级索引的所有记录，然后再回表，这不是得不偿失么，所以这种情况下不会使用idx_key2索引的。 索引合并 index merge我们前边说过MySQL在一般情况下执行一个查询时最多只会用到单个二级索引，但不是还有特殊情况么，在这些特殊情况下也可能在一个查询中使用到多个二级索引，设计MySQL的大叔把这种使用到多个索引来完成一次查询的执行方法称之为:index merge，具体的索引合并算法有下边三种。 Intersection合并Intersection翻译过来的意思是交集。这里是说某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集，比方说下边这个查询: 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;; 假设这个查询使用Intersection合并的方式执行的话，那这个过 程就是这样的: 从idx_key1二级索引对应的B+树中取出key1 &#x3D; ‘a’的相关 记录。 从idx_key3二级索引对应的B+树中取出key3 &#x3D; ‘b’的相关 记录。二级索引的记录都是由 索引列 + 主键 构成的，所以我们可以计算出这两个结果集中id值的交集。按照上一步生成的id值列表进行回表操作，也就是从聚簇索引中把指定id值的完整用户记录取出来，返回给用户。 MySQL在某些特定的情况下才可能会使用到 Intersection索引合并: 情况一: 二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配 且 不能出现只出现匹配部分列的情况。 情况二:主键列可以是范围匹配 比方说下边这个查询可能用到主键和idx_key_part进行Intersection索引合并的操作: 1SELECT * FROM single_table WHERE id &gt; 100 AND key1 = &#x27;a&#x27;; 为啥呢?凭啥呀?突然冒出这么两个规定让大家一脸懵逼，下边我们 慢慢品一品这里头的玄机。这话还得从InnoDB的索引结构说起，你 要是记不清麻烦再回头看看。对于InnoDB的二级索引来说，记录先 是按照索引列进行排序，如果该二级索引是一个联合索引，那么会按 照联合索引中的各个列依次排序。而二级索引的用户记录是由索引列 + 主键构成的，二级索引列的值相同的记录可能会有好多条，这些 索引列的值相同的记录又是按照主键的值进行排序的。所以重点来 了，之所以在二级索引列都是等值匹配的情况下才可能使 用Intersection索引合并，是因为只有在这种情况下根据二级索 引查询出的结果集是按照主键值排序的。so?还是没看懂根据二级索引查询出的结果集是按照主键值排序的 对使用Intersection索引合并有啥好处?小伙子，别忘了 Intersection索引合并会把从多个二级索引中查询出的主键值求 交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主 键排好序的，那么求交集的过程就很easy啦。假设某个查询使 用Intersection索引合并的方式从idx_key1和idx_key2这两个 二级索引中获取到的主键值分别是:从idx_key1中获取到已经排好序的主键值:1、3、5从idx_key2中获取到已经排好序的主键值:2、3、4那么求交集的过程就是这样:逐个取出这两个结果集中最小的主键 值，如果两个值相等，则加入最后的交集结果中，否则丢弃当前较小 的主键值，再取该丢弃的主键值所在结果集的后一个主键值来比较，直到某个结果集中的主键值用完了，如果还是觉得不太明白那继续往 下看:先取出这两个结果集中较小的主键值做比较，因为1 &lt; 2，所 以把idx_key1的结果集的主键值1丢弃，取出后边的3来比 较。因为3 &gt; 2，所以把idx_key2的结果集的主键值2丢弃，取出 后边的3来比较。因为3 &#x3D; 3，所以把3加入到最后的交集结果中，继续两个结 果集后边的主键值来比较。后边的主键值也不相等，所以最后的交集结果中只包含主键 值3。 别看我们写的啰嗦，这个过程其实可快了，时间复杂度是O(n)，但 是如果从各个二级索引中查询出的结果集并不是按照主键排序的话， 那就要先把结果集中的主键值排序完再来做上边的那个过程，就比较 耗时了。 小贴士:按照有序的主键值去回表取记录有个专有名词儿，叫:Rowid Ordered Retrieval，简称ROR，以后大家在某些地方⻅到这个 名词儿就眼熟了。 另外，不仅是多个二级索引之间可以采用Intersection索引合 并，索引合并也可以有聚簇索引参加，也就是我们上边写的情况二: 在搜索条件中有主键的范围匹配的情况下也可以使 用Intersection索引合并索引合并。为啥主键这就可以范围匹配 了?还是得回到应用场景里，比如看下边这个查询: 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND id &gt; 100; 假设这个查询可以采用Intersection索引合并，我们理所当然的 以为这个查询会分别按照id &gt; 100这个条件从聚簇索引中获取一些 记录，在通过key1 &#x3D; ‘a’这个条件从idx_key1二级索引中获取一 些记录，然后再求交集，其实这样就把问题复杂化了，没必要从聚簇 索引中获取一次记录。别忘了二级索引的记录中都带有主键值的，所 以可以在从idx_key1中获取到的主键值上直接运用条件id &gt; 100 过滤就行了，这样多简单。所以涉及主键的搜索条件只不过是为了从 别的二级索引得到的结果集中过滤记录罢了，是不是等值匹配不重 要。当然，上边说的情况一和情况二只是发生Intersection索引合并 的必要条件，不是充分条件。也就是说即使情况一、情况二成立，也 不一定发生Intersection索引合并，这得看优化器的心情。优化 器在下边两个条件满足的情况下才趋向于使用Intersection索引 合并: 单独根据搜索条件从某个二级索引中获取的记录数太多，导致 回表开销太大 通过Intersection索引合并后需要回表的记录数大大减少 Union合并我们在写查询语句时经常想把既符合某个搜索条件的记录取出来，也把符合另外的某个搜索条件的记录取出来，我们说这些不同的搜索条 件之间是OR关系。有时候OR关系的不同搜索条件会使用到同一个索引，比方说这样: 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR key3 = &#x27;b&#x27; Intersection是交集的意思，这适用于使用不同索引的搜索条件 之间使用AND连接起来的情况;Union是并集的意思，适用于使用不 同索引的搜索条件之间使用OR连接起来的情况。与Intersection索引合并类似，MySQL在某些特定的情况下才可能会使用到Union索 引合并: 情况一:二级索引列是等值匹配的情况，对于联合索引来说， 在联合索引中的每个列都必须等值匹配，不能出现只出现匹配 部分列的情况。比方说下边这个查询可能用到idx_key1和idx_key_part这 两个二级索引进行Union索引合并的操作:1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR ( key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;); 而下边这两个查询就不能进行Union索引合并:12SELECT * FROM single_table WHERE key1 &gt; &#x27;a&#x27; OR (key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;);SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR key_part1 = &#x27;a&#x27;; 第一个查询是因为对key1进行了范围匹配，第二个查询是因为 联合索引idx_key_part中的key_part2列并没有出现在搜 索条件中，所以这两个查询不能进行Union索引合并。 情况二:主键列可以是范围匹配 情况三:使用Intersection索引合并的搜索条件这种情况其实也挺好理解，就是搜索条件的某些部分使 用Intersection索引合并的方式得到的主键集合和其他方式 得到的主键集合取交集，比方说这个查询:1SELECT * FROM single_table WHERE key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27; OR (key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;); 优化器可能采用这样的方式来执行这个查询: 先按照搜索条件key1 &#x3D; ‘a’ AND key3 &#x3D; ‘b’从索 引idx_key1和idx_key3中使用Intersection索引合 并的方式得到一个主键集合。 再按照搜索条件key_part1 &#x3D; ‘a’ AND key_part2 &#x3D; ‘b’ AND key_part3 &#x3D; ‘c’从联合索 引idx_key_part中得到另一个主键集合。 采用Union索引合并的方式把上述两个主键集合取并集， 然后进行回表操作，将结果返回给用户。 当然，查询条件符合了这些情况也不一定就会采用Union索引合并， 也得看优化器的心情。优化器在下边两个条件满足的情况下才趋向于 使用Union索引合并: 单独根据搜索条件从某个二级索引中获取的记录数比较少 通过Intersection索引合并后需要回表的记录数大大减少 Sort-Union合并Union索引合并的使用条件太苛刻，必须保证各个二级索引列在进行 等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用 到Union索引合并: 1SELECT * FROM single_table WHERE key1 &lt; &#x27;a&#x27; OR key3 &gt; &#x27;z&#x27; 这是因为根据key1 &lt; ‘a’从idx_key1索引中获取的二级索引记录 的主键值不是排好序的，根据key3 &gt; ‘z’从idx_key3索引中获取 的二级索引记录的主键值也不是排好序的，但是key1 &lt; ‘a’和 key3 &gt; ‘z’这两个条件又特别让我们动心，所以我们可以这样: 先根据key1 &lt; ‘a’条件从idx_key1二级索引总获取记录， 并按照记录的主键值进行排序 再根据key3 &gt; ‘z’条件从idx_key3二级索引总获取记录， 并按照记录的主键值进行排序 因为上述的两个二级索引主键值都是排好序的，剩下的操作和 Union索引合并方式就一样了。 我们把上述这种先按照二级索引记录的主键值进行排序，之后按 照Union索引合并方式执行的方式称之为Sort-Union索引合并，很 显然，这种Sort-Union索引合并比单纯的Union索引合并多了一步 对二级索引记录的主键值排序的过程。 小贴士:为啥有Sort-Union索引合并，就没有Sort-Intersection索引 合并么?是的，的确没有Sort-Intersection索引合并这么一 说，Sort-Union的适用场景是单独根据搜索条件从某个二级索引中获 取的记录数比较少，这样即使对这些二级索引记录按照主键值进行 排序的成本也不会太高而Intersection索引合并的适用场景是单独根据搜索条件从某个 二级索引中获取的记录数太多，导致回表开销太大，合并后可以明 显降低回表开销，但是如果加入Sort-Intersection后，就需要 为大量的二级索引记录按照主键值进行排序，这个成本可能比回表 查询都高了，所以也就没有引入Sort-Intersection这个玩意 儿。 索引合并注意事项联合索引替代Intersection索引合并1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;; 这个查询之所以可能使用Intersection索引合并的方式执行，还 不是因为idx_key1和idx_key2是两个单独的B+树索引，你要是把 这两个列搞一个联合索引，那直接使用这个联合索引就把事情搞定 了，何必用啥索引合并呢，就像这样: 1ALTER TABLE single_table drop index idx_key1, idx_key3, add index idx_key1_key3(key1, key3); 这样我们把没用的idx_key1、idx_key3都干掉，再添加一个联合 索引idx_key1_key3，使用这个联合索引进行查询简直是又快又 好，既不用多读一棵B+树，也不用合并结果，何乐而不为? 小贴士:不过小心有单独对key3列进行查询的业务场景，这样子不得不再把 key3列的单独索引给加上。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.6 InnoDB的表空间 之 系统表空间","date":"2021-11-04T14:15:17.000Z","path":"2021/11/04/MySQL知识点整理/9.6 TODO 存放页面的大池子--InnoDB的表空间/","text":"了解完了独立表空间的基本结构，系统表空间的结构也就好理解多 了，系统表空间的结构和独立表空间基本类似，只不过由于整个 MySQL进程只有一个系统表空间，在系统表空间中会额外记录一些 有关整个系统信息的⻚面，所以会比独立表空间多出一些记录这些信 息的⻚面。因为这个系统表空间最牛逼，相当于是表空间之首，所以 它的表空间 ID(Space ID)是0。 系统表空间的整体结构系统表空间与独立表空间的一个非常明显的不同之处就是在表空间开头有许多记录整个系统属性的⻚面，如图:可以看到，系统表空间和独立表空间的前三个⻚面(⻚号分别 为0、1、2，类型分别是FSP_HDR、IBUF_BITMAP、INODE)的类 型是一致的，只是⻚号为37的⻚面是系统表空间特有的，我们来 看一下这些多出来的⻚面都是干啥使的:除了这几个记录系统属性的⻚面之外，系统表空间的extent 1和 extent 2这两个区，也就是⻚号从64127这128个⻚面被称 为Doublewrite buffer，也就是双写缓冲区。不过上述的大部分 知识都涉及到了事务和多版本控制的问题，这些问题我们会放在后边 的章节集中唠叨，现在讲述太影响用户体验，所以现在我们只唠叨一 下有关InnoDB数据字典的知识，其余的概念在后边再看。 InnoDB数据字典我们平时使用INSERT语句向表中插入的那些记录称之为用户数据， MySQL只是作为一个软件来为我们来保管这些数据，提供方便的增 删改查接口而已。但是每当我们向一个表中插入一条记录的时候， MySQL先要校验一下插入语句对应的表存不存在，插入的列和表中 的列是否符合，如果语法没有问题的话，还需要知道该表的聚簇索引 和所有二级索引对应的根⻚面是哪个表空间的哪个⻚面，然后把记录 插入对应索引的B+树中。所以说，MySQL除了保存着我们插入的用 户数据之外，还需要保存许多额外的信息，比方说: 某个表属于哪个表空间，表里边有多少列 表对应的每一个列的类型是什么 该表有多少索引，每个索引对应哪几个字段，该索引对应的根 ⻚面在哪个表空间的哪个⻚面 该表有哪些外键，外键对应哪个表的哪些列 某个表空间对应文件系统上文件路径是什么 balabala … 还有好多，不一一列举了 上述这些数据并不是我们使用INSERT语句插入的用户数据，实际上 是为了更好的管理我们这些用户数据而不得已引入的一些额外数据， 这些数据也称为元数据。InnoDB存储引擎特意定义了一些列的内部 系统表(internal system table)来记录这些这些元数据:这些系统表也被称为数据字典，它们都是以B+树的形式保存在系统 表空间的某些⻚面中，其中 SYS_TABLES、SYS_COLUMNS、SYS_INDEXES、SYS_FIELDS这 四个表尤其重要，称之为基本系统表(basic system tables)，我 们先看看这4个表的结构:这个SYS_TABLES表有两个索引: 以NAME列为主键的聚簇索引 以ID列建立的二级索引","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.5 InnoDB独立表空间结构 之 各类型⻚面详细情况","date":"2021-10-29T14:11:32.000Z","path":"2021/10/29/MySQL知识点整理/9.5 InnoDB的表空间 之 独立表空间结构(5)/","text":"到现在为止我们已经大概清楚了表空间、段、区、XDES Entry、 各种以XDES Enty为节点的链表、List Base Node、INODE Entry 等概念了。可是总有一种不踏实的感觉： 每个区对应的 XDES Entry结构 到底存储在表空间的什么地方? 直属于 表空间的 FREE、FREE_FRAG、FULL_FRAG 链表的基节点到底存储在表空间的什么地方? (其实上一篇我们已经知道 段的3种链表的基节点都在INODE Entry结构中，只不过不知道 INODE Entry到底在表空间哪个位置罢了) 每个段对应的INODE Entry结构到底存在表空间的什么地方? 我们前边介绍了每256个连续的区算是一个组，想解决刚才提出来的这些个疑问还得从每个组开头的一些类型相同的⻚面说起，接下来我们一个⻚面一个⻚面的分析，真相⻢上就要浮出水面了。 FSP_HDR类型的页首先看表空间-&gt;第一个组-&gt;第一个区-&gt;第一个⻚面(⻚号为0)，这个⻚面的类型是FSP_HDR，它存储了表空间的一些整体属性以及第一个组内256个区的对应的XDES Entry结构，直接看这个类型的⻚面的示意图:从图中可以看出，一个完整的FSP_HDR类型的⻚面大致由5个部分组成，各个部分的具体释义如下表:File Header ： 文件头部； 38字节； ⻚的一些通用信息；File Space Header： 表空间头部；112字节； 表空间的一些整体属性信息；XDES Entry：区描述信息；10240字节；存储本组256个区对应的属性信息；Empty Space：尚未使用空间；5986字节；用于⻚结构的填充，没啥实际意义；File Trailer：文件尾部；8字节； 校验⻚是否完整； File Header和File Trailer就不再强调了，另外的几个部分中，Empty Space是尚未使用的空间，我们不用管它，重点来看看File Space Header和XDES Entry这两个部分。 File Space Header部分从名字就可以看出来，这个部分是用来存储表空间的一些整体属性的: Space ID : 4字节；表空间ID；Not Used : 4字节；这四个字节未被使用，可以忽略；Size : 4字节；当前表空间占有的页面数；FREE Limit : 4字节；尚未被初始化的最小页号，大于或等于这个页号的区对应的XDES Entry结构都没有被加入FREE链表；Space Flags : 4字节；表空间的一些占用存储空间比较小的属性；FRAG_N_USED : 4字节；FREE_FRAG链表中已使用的⻚面数量；List Base Node for Free List: 16字节；FREE链表的基节点；List Base Node for FREE_FRAG List : 16字节；FREE_FRAG链表的基节点；List Base Node for FULL_FRAG List : 415字节；FULL_FRAG链表的基节点；Next Unused Segment ID: 8字节； 当前表空间中下一个未使用的 Segment ID;List Base Node for SEG_INNODES_FULL List：16字节；SEG_INODES_FULL链表的基节点；List Base Node for SEG_INNODES_FREE List：16字节；SEG_INODES_FREE链表的基节点； 这里头的Space ID、Not Used、Size 这三个字段大家肯定一看就懂，其他的字段我们再详细瞅瞅。 📌 List Base Node for FREE List、List Base Node for FREE_FRAG List、List Base Node for FULL_FRAG List这三个大家看着太亲切了，分别是直属于表空间的FREE链表的基节点、FREE_FRAG链表的基节点、FULL_FRAG链表的基节点， 这三个链表的基节点在表空间的位置是固定的，就在表空间的第一个⻚面 (也就是FSP_HDR类型的⻚面)的File Space Header部分。所以之后定位这几个链表就so easy 啦。 📌 FRAG_N_USED这个字段表明在 FREE_FRAG链表 中已经使用的⻚面数量，方便之后在链表中查找空闲的⻚面。 FREE Limit 我们知道表空间都对应着具体的磁盘文件，一开始我们创建表空间的时候对应的磁盘文件中都没有数据，所以我们需要对表空间完成一个初始化操作，包括为表空间中的区建立XDES Entry结构，为各个段建立INODE Entry结构，建立各种链表&#96;吧啦吧啦的各种操作。我们可以一开始就为表空间申请一个特别大的空间，但是实际上有绝大部分的区是空闲的，我们可以选择把所有的这些空闲区对应的XDES Entry结构加入FREE链表，也可以选择只把一部分的空闲区加入FREE链表，等啥时候空闲链表中的XDES Entry结构对应的区不够使了，再把之前没有加入FREE链表的空闲区对应的XDES Entry结构加入FREE链表，中心思想就是啥时候用到啥时候初始化，设计InnoDB的大叔采用的就是后者，他们为表空间定义了FREE Limit这个字段，在该字段表示的⻚号之前的区都被初始化了，之后的区尚未被初始化。 Next Unused Segment ID表中每个索引都对应2个段，每个段都有一个唯一的ID，那当我们为某个表新创建一个索引的时候，就意味着要创建两个新的段。那怎么为这个新创建的段找一个唯一的ID呢?去遍历现在表空间中所有的段么?我们说过，遍历是不可能遍历的，这辈子都不可能遍历，所以设计InnoDB的大叔们提出了这个名叫Next Unused Segment ID的字段，该字段表明当前表空间中最大的段ID的下一个ID，这样在创建新段的时候赋予新段一个唯一的ID值就so easy啦，直接使用这个字段的值就好了。 Space Flags表空间对于一些布尔类型的属性，或者只需要寥寥几个比特位搞定的属性都放在了这个Space Flags中存储，虽然它只有4个字节，32个比特位大小，却存储了好多表空间的属性，详细情况如下表: Tips: 不同MySQL版本里 SPACE_FLAGS 代表的属性可能有些差异，这里列举的是5.7.21版本。不过大家现在不必深究它们的意思，因为我们一旦把这些概念展开，就需要非常大的篇幅，主要怕大家受不了。我们还是先挑重要的看，把主要的表空间结构了解完，这些 SPACE_FLAGS 里的属性的细节就暂时不深究了。 List Base Node for SEG_INODES_FULL List 和 List Base Node for SEG_INODES_FREE List每个段对应的INODE Entry结构会集中存放到一个类型为INODE的⻚中，如果表空间中的段特别多，则会有多个INODE Entry结构，可能一个⻚放不下，这些INODE类型的⻚会组成两种列表:SEG_INODES_FULL链表，该链表中的INODE类型的⻚面都已经被INODE Entry结构填充满了，没空闲空间存放额外的INODE Entry了。SEG_INODES_FREE链表，该链表中的INODE类型的⻚面都已经仍有空闲空间来存放INODE Entry结构。由于我们现在还没有详细唠叨INODE类型⻚，所以等会说过INODE类型的⻚之后再回过头来看这两个链表。 XDES Entry部分紧接着 File Space Header部分 的就是 XDES Entry部分。我们唠叨过无数次但却一直未见真身的XDES Entry就存储在表空间的第一个页面中。一个XDES Entry结构的大小是 40字节，由于一个⻚面的大小有限，只能存放有限个XDES Entry 结构，所以我们才把256个区划分成一组，在每组的第一个⻚面中存放256个XDES Entry结构。大家回看那个FSP_HDR类型⻚面的示意图，XDES Entry 0就对应着extent 0，XDES Entry 1就对 应着extent 1… 依此类推，XDES Entry255就对应着extent 255。 因为每个区对应的XDES Entry结构的地址是固定的，所以我们可以很轻松地访问它们。 XDES类型的页面我们说过，每一个XDES Entry结构对应表空间的一个区，虽然一个XDES Entry结构只占用40字节，但抵不住表空间区的数量也多啊。 在区的数量非常多时，一个单独的⻚可能就不够存放足够多的XDES Entry结构，所以我们把表空间的区分为了若干个组，每组开头的一个⻚面记录着本组内所有的区对应的XDES Entry结构。 由于第一个组的第一个⻚面有些特殊，因为它也是整个表空间的第一个⻚面，所以除了记录本组中的所有区对应的XDES Entry结构以外， 还记录着表空间的一些整体属性，这个⻚面的类型就是我们刚刚说完的FSP_HDR类型，整个表空间里只有一个这个类型的⻚面。 除去第一个分组以外，之后的每个分组的第一个⻚面只需要记录本组内所有的区对应的XDES Entry结构即可，不需要再记录表空间的属性了， 为了和FSP_HDR类型做区别，我们把之后每个分组的第一个⻚面的类型定义为XDES，它的结构和FSP_HDR类型是非常相似的:与FSP_HDR类型的⻚面对比，除了少了File Space Header部分之外(少了记录表空间整体属性的部分)，其余的部分是一样一样的。由于上边唠叨FSP_HDR类型的页面时已经够仔细了，对于XDES类型的⻚面也就不重复唠叨了。 IBUF_BITMAP类型的页面对比前边介绍表空间的图，每个分组的第二个⻚面的类型都是IBUF_BITMAP，这种类型的⻚里边记录了一些有关Change Buffer的东东。 INODE类型的页面再次对比前边介绍表空间的图，第一个分组的第三个⻚面的类型是INODE。我们前边说过设计InnoDB的大叔为每个索引定义了两个段，而且为某些特殊功能定义了些特殊的段。为了方便管理，他们又为每个段设计了一个INODE Entry结构，这个结构中记录了关于这个段的相关属性。我们将要介绍的这个INODE类型的⻚就是为了存储INODE Entry结构而存在的。 直接看图:从图中可以看出，一个INODE类型的⻚面是由这几部分构成的: 除了File Header、Empty Space、File Trailer这几个老朋友外，我们重点关注 List Node for INODE Page List 和 INODE Entry 这两个部分。 INODE Entry部分我们前边已经详细介绍过这个结构的组成了，主要包括对应的段内零散⻚面的地址以及附属于该段的FREE、NOT_FULL和FULL链表的基节点。每个INODE Entry结构占用192字节，一个⻚面里可以存储84个这样的结构。 List Node for INODE Page List结构重点看一下这个，因为一个表空间中可能存在超过84个段，所以可能一个INODE类型的⻚面不足以存储所有的段对应的INODE Entry结构，所以就需要额外的INODE类型的⻚面来存储这些结构。还是为了方便管理这些INODE类型的⻚面，设计InnoDB的大叔们将这些INODE类型的⻚面串联成两个不同的链表: SEG_INODES_FULL链表: 该链表中的INODE类型的⻚面中已经没有空闲空间来存储额外的INODE Entry结构了。 SEG_INODES_FREE链表: 该链表中的INODE类型的⻚面中还有空闲空间来存储额外的INODE Entry结构了。 想必大家已经认出这两个链表了，我们前边提到过这两个链表的基节点就存储在File Space Header里边，也就是说这两个链表的基节点的位置是固定的，所以我们可以很轻松的访问到这两个链表。 以后每当我们新创建一个段(创建索引时就会创建段)时，都会创建一个INODE Entry结构与之对应，存储INODE Entry的大致过程就是这样的: 先看看SEG_INODES_FREE链表是否为空，如果不为空，直接从该链表中获取一个节点，也就相当于获取到一个仍有空闲空间的INODE类型的⻚面，然后把该INODE Entry结构放到该⻚面中。当该⻚面中无剩余空间时，就把该⻚放到SEG_INODES_FULL链表中。 如果SEG_INODES_FREE链表为空，则需要从表空间的FREE_FRAG链表中申请一个⻚面，修改该⻚面的类型为INODE，把该⻚面放到SEG_INODES_FREE链表中，与此同时把该INODE Entry结构放入该⻚面。 Segment Header 结构我们知道一个索引会产生两个段，分别是叶子节点段和非叶子节点段，而每个段都会对应一个INODE Entry结构，那我们怎么知道某个段对应哪个INODE Entry结构呢? 所以得找个地方记下来这个对应关系。希望你还记得我们在唠叨数据⻚，也就是INDEX类型的⻚时有一个Page Header部分，当然我不能指望你记住，所以把Page Header部分再抄一遍给你看:其中的PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP都占用10个字 节，它们其实对应一个叫Segment Header的结构，该结构图示如 下:各个部分的具体释义如下:这样子就很清晰了，PAGE_BTR_SEG_LEAF记录着叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个⻚面的哪个偏移量；PAGE_BTR_SEG_TOP记录着非叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个⻚面的哪个偏移量。这样子索引和其对应的段的关系就建立起来了。不过需要注意的一点是，因为一个索引只对应两个段，所以只需要在索引的根⻚面中记录这两个结构即可。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.4 InnoDB的表空间 之 独立表空间结构(4)","date":"2021-10-28T12:57:09.000Z","path":"2021/10/28/MySQL知识点整理/9.4 InnoDB的表空间 之 独立表空间结构(4)/","text":"段的结构(INODE Entry结构)我们前边说过，段其实不对应表空间中某一个连续的物理区域，而是一个 逻辑上的概念 ，由若干个零散的⻚面以及一些完整的区组成。 像每个区都有对应的 XDES Entry结构 来记录这个区中的属性一样，设计 InnoDB的大叔也为每个段都定义了一个INODE Entry结构来记录段中的属性。示意图如下: Segment ID : 就是指这个 INODE Entry结构 对应的段的编号(ID)。 NOT_FULL_N_USED这个字段指在 NOT_FULL链表中已经使用了多少⻚面。有了这个字段之后就可以快速定位空闲⻚面。 List Base Node ：段的3个链表对应的基节点分别为段的FREE链表、NOT_FULL链表、FULL链表 定义了 List Base Node。这样我们想查找某个段的某个链表的头节点和尾节点的时候，就可以直接到这个部分找到对应链表的 List Base Node。so easy! Magic Number这个值是用来标记这个 INODE Entry 是否已经被初始化了(初始化的意思就是把各个字段的值都填进去了)。如果这个数字是值的97937874，表明该INODE Entry已经初始化，否则没有被初始化。(不用纠结这个值有啥特殊含义，人家规定的)。 Fragment Array Entry我们前边强调过无数次段是一些零散⻚面和一些完整的区的集合，每个Fragment Array Entry结构都对应着一个零散的⻚面，这个结构一共4个字节，表示一个零散⻚面的⻚号。 结合着这个INODE Entry结构，大家可能对段是一些零散⻚面和一些完整的区的集合的理解再次深刻一些。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"📌 9.3 InnoDB的表空间 之 独立表空间结构(3)","date":"2021-10-27T14:19:17.000Z","path":"2021/10/27/MySQL知识点整理/9.3 InnoDB的表空间 之 独立表空间结构(3)/","text":"到现在为止，我们已经提出的概念五花八⻔(像 区、碎片区、段、附属于段的区、区对应的XDES Entry结构)。我们把事情搞这么麻烦，初心仅仅是 想减少随机IO，而又不至于数据量少的表浪费空间 。 现在我们知道向表中插入数据本质上就是向表中各个索引的 叶子节点段、非叶子节点段 插入数据，也知道了不同的区有不同的状态。再回到最初的起点，捋一捋向某个段中插入数据时，申请新页面的过程; 先从直接隶属于表空间的碎片区中申请页一开始，当段中数据较少时，首先会查看表空间中是否有状态为FREE_FRAG的区，也就是找还空闲页的碎片区 如果找到了，则从该区中取一些零碎的⻚把数据插进去; 如果没找到，则到表空间下申请一个状态为FREE的区(也就是空闲的区)，把该区的状态变为FREE_FRAG，(lant:相当于从表空间中新拿了个FREE空闲区作为 新的FREE_FRAG空闲碎片区)，然后从 新的FREE_FRAG空闲碎片区 中取一些零碎的⻚把数据插进去。之后不同的段使用零碎⻚的时候都从该区中取，直到该区中没有空闲页面，然后该区的状态就变成了FULL_FRAG 。 引出 XDES Entry 链表：(lant: 3种区状态链表)现在的问题是你怎么知道表空间里的哪些区是FREE的，哪些区的状态是FREE_FRAG的，哪些区是FULL_FRAG的?要知道表空间的大小是可以不断增大的，当增⻓到GB级别的时候，区的数量也就上千了，我们总不能每次都遍历这些区对应的 XDES Entry结构(查看其 state状态) 吧? 这时候就是 XDES Entry结构 中的List Node部分发挥奇效的时候了，我们可以通过List Node中的指针做下面三件事: 把 状态为FREE的区 对应的 XDES Entry结构 通过 List Node 连接成一个链表，称之为 FREE链表； 把 状态为FREE_FRAG的区 对应的 XDES Entry结构 通过 List Node 连接成一个链表，称之为 FREE_FRAG链表； 把 状态为FULL_FRAG的区 对应的 XDES Entry结构 通过 List Node 连接成一个链表，称之为 FULL_FRAG链表； 这样每当我们想找一个FREE_FRAG状态的区时，就直接把 FREE_FRAG链表 的头节点拿出来，从这个节点对应的区中取一些零碎的⻚来插入数据，当这个节点对应的区用完时，就修改一下这个节点的State字段的值，然后从FREE_FRAG链表中移到FULL_FRAG链表中。同理，如果 FREE_FRAG链表 中一个节点都没有，那么就直接从 FREE链表 中取一个节点移动到 FREE_FRAG链表 的状态，并修改该节点的STATE字段值为FREE_FRAG，然后从这个节点对应的区中获取零碎的⻚就好了。当段中数据已经占满了32个零散的⻚后，就直接申请完整的区来插入数据了。 lant小结:我这里给 XDES Entry 链表 叫 XDES Entry 状态链表其实 3种XDES Entry 链表 就是根据区的状态，将 相同状态的区 对应的 XDES Entry 结构 连起来组成的三种状态链表。这样，无论我们需要哪种状态的区，直接找到对应的状态链表，就能快速地拿到处于该状态的区，而不用遍历表空间的所有区才能拿到你想要的那个装态的区。 申请完整的区在段中数据已经占满32个零碎的页后，我们就可以申请完整的区来插入数据了。 引出 段状态链表：(每个段下都有3类状态链表)还是那个问题，那么多区，我们怎么知道哪些区已经是属于哪个段的了呢?lant: 毕竟你不能随便拿个有空闲页的区就去用了，因为该区可能已经被别的段使用了(属于别的段了)，你肯定要保证每个段使用的区都是属于自己的段(这样段中的数据才会尽可能在物理上连续，减少随机IO)；其次，即便你取到的区属于当前段，但也可能已经没有空闲页了。那咋办？再遍历各个XDES Entry结构，查看区状态和区所属的段ID1? 遍历是不可能的，这辈子都不可能遍历的，有链表还遍历个毛线啊。 所以我们这里可以根据段号(也就 是Segment ID)来建立链表，有多少个段就建多少个链表?因为一个段中可以有好多个区，有的区是完全空闲的，有的区还有一些⻚面可以用，有的区已经没有空闲⻚面可以用了，所以设计InnoDB的大叔们为每个段中的区对应的XDES Entry结构建立了三个链表: FREE (段)链表: 同一个段中，所有⻚面都是空闲的区 对应的 XDES Entry结构 会被加入到这个链表。注意和直属于表空间的FREE链表区别开了，此处的FREE链表是附属于某个段的。 NOT_FULL (段)链表: 同一个段中，仍有空闲空间的区 对应的 XDES Entry结构 会被加入到这个链表。 FULL (段)链表: 同一个段中，已经没有空闲空间的区 对应的 XDES Entry结构 会被加入到这个链表。 再次强调一遍，每一个索引都对应两个段，每个段都会维护上述的3个链表。 假设表t共有两个索引，一个聚簇索引，一个二级索引idx_c2，每个索引都有 叶子节点段 和 非叶子节点段 2个段，所以这个表共有4个段，每个段都会维护上述3个链表，所以这个表共需要维护12个链表。 所以段在数据量比较大时插入数据的话，会先获取NOT_FULL链表的头节点，直接把数据插入这个头节点对应的区中即可，如果该区的空间已经被用完，就把该节点移到FULL链表中。 Tiplant: 当然，无论是直属于 表空间 的链表 还是 属于 段 的链表, 我估计一开始都是从 Free状态链表那里取直属于表空间的Free状态的区 新的空闲区的。 链表基节点 List Base Node上边介绍了一堆链表，可我们怎么在表空间中找到这些链表呢，或者说怎么找到某个链表的头节点或者尾节点在表空间中的位置呢?设计 InnoDB的大叔当然考虑了这个问题，他们设计了一个叫List Base Node的结构，翻译成中文就是链表的基节点。这个结构中包含了链表的头节点和尾节点的指针以及这个链表中包含了多少节点的信息，示意图如下: 我们上边介绍的 每个链表都对应这么一个 List Base Node结构 ， 其中: List Length表明该链表一共有多少节点； First Node Page Number 和 First Node Offset 表明该链表的头节点在表空间中的位置； Last Node Page Number 和 Last Node Offset 表明该链表的尾节点在表空间中的位置。 一般我们把某个链表对应的 List Base Node结构 放置在表空间中固定的位置(后面会介绍)，这样想找定位某个链表就变得so easy啦。 链表小结 📌 综上所述，表空间 是由若干个区 组成的，每个区都对应一个XDES Entry的结构； 直属于表空间的区对应的XDES Entry结构可以分成FREE、FREE_FRAG和FULL_FRAG这3个链表； 每个段可以拥有若干个区，每个段中的区对应的XDES Entry结构可以分成 FREE、NOT_FULL 和 FULL 这3个链表； 上面每个链表都对应一个List Base Node的结构，这个结构里记录了链表的头、尾节点的位置以及该链表中包含的节点数； 正是因为这些链表的存在，管理这些区才变成了一件so easy的事情。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.2 InnoDB的表空间 之 独立表空间结构(2)","date":"2021-10-26T10:42:11.000Z","path":"2021/10/26/MySQL知识点整理/9.2 InnoDB的表空间 之 独立表空间结构(2)/","text":"区的分类通过上边一通唠叨，大家知道了表空间的是由若干个区组成的，这些区大体上可以分为4种类型: 有剩余空间的碎片区: 表示碎片区中还有可用的⻚面; 没有剩余空间的碎片区: 表示碎片区中的所有⻚面都被使用，没有空闲⻚面; 空闲的区: 区中⻚面还没有被使用过; 附属于某个段的区: 每一个索引都可以分为叶子节点段和非叶子节点段，在这些段中的数据量很大时 就会使用区来作为基本的分配单位。这些区中的页面完全用来存储该段中的数据。 这4种类型的区也可以被称为区的4种状态(State)，设计InnoDB 的大叔们为这4种状态的区定义了特定的名词儿: FREE_FRAG 有剩余空间的碎片区 FULL_FRAG 没有剩余空间的碎片区 FREE 空闲的区（有空闲页就行） FSEG 附属于某个段的区 需要再次强调一遍的是，处于FREE、FREE_FRAG以及FULL_FRAG 这三种状态的区都是独立直属于表空间的; 而处于FSEG状态的区是附属于某个段的。 Tips:如果把表空间比作是一个集团军，段就相当于师，区就相当于团。一般的团都是隶属于某个师的，就像是处于FSEG的区全都隶属于某个段，而处于FREE、FREE_FRAG以及FULL_FRAG这三种状态的区却直接隶属于表空间，就像独立团直接听命于军部一样。 区对应的 XDES Entry 结构为了方便管理这些区，设计InnoDB的大叔设计了一个称为 XDES Entry的结构(全称是Extent Descriptor Entry)。每一个区都对应着一个XDES Entry结构 ，这个结构记录了对应的区的一些属性。 先通过下图对这个结构有个大致的了解: Segment ID(8字节): 表示该区所在的段(每一个段都有一个唯一ID)。当然前提是该区已经被分配给某个段了，不然的话该字段的值没啥意义。 List Node(12字节):这个部分可以将若干个 XDES Entry结构 串联成一个链表，大家看一下这个List Node的结构: 把一些XDES Entry结构连成一个链表有啥用?稍安勿躁，我们稍后唠叨XDES Entry结构组成的链表问题。 State(4字节):这个字段表明区的状态。可选的值就是我们前边说过的那4个，分别是:FREE、FREE_FRAG、FULL_FRAG和FSEG。 Page State Bitmap(16字节):这个部分共占用16个字节(128个比特位)。我们说一个区默认有64个⻚，这128个比特位被划分为64个部分，每个部分2个比特位，对应区中的一个⻚。 比如Page State Bitmap部分的第1和第2个比特位对应着区中的第1个⻚面，第3和第4个比特位对应着区中的第2个⻚面，依此类推，这两个比特位的第一个位表示对应的⻚是否是空闲的，第二个比特位还没有用。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.1 InnoDB的表空间 之 独立表空间结构(1)","date":"2021-10-26T05:19:37.000Z","path":"2021/10/26/MySQL知识点整理/9.1 InnoDB的表空间 之 独立表空间结构(1)/","text":"我们知道InnoDB支持许多种类型的表空间，本章重点关注 独立表空间 和 系统表空间 的结构。它们的结构比较相似，但是由于 系统表空间 中额外包含了一些关于整个系统的信息，所以我们先挑简单一点的 独立表空间 来聊，稍后再说系统表空间的结构。 区(extent)的概念：为了顺序IO 表空间 中的 ⻚ 实在是太多了，为了更好的管理这些⻚，设计InnoDB的大叔们提出了区(extent)的概念。对于16KB的⻚来说，连续的64个⻚ 就是一个区，也就是说一个区默认占用1MB空间大小。 为啥好端端地提出一个区的概念呢？ 我们以前学到的InnoDB存储结构的相关知识大致是:表中的记录存储到⻚里，然后⻚作为节点组成B+树，这个B+树就是索引，然后吧啦吧啦一堆聚簇索引和二级索引的区别。这套路也没啥不妥的呀~ 是的，如果我们表中数据量很少的话，比如说你的表中只有几十条、几百条数据的话，的确用不到区的概念，因为简单的几个⻚就能把对应的数据存储起来。但是你架不住表里的记录越来越多呀。 我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的B+树的节点中插入数据。而 B+树的每一层中的⻚都会形成一个双向链表 ， 如果是以⻚为单位来分配存储空间的话， 双向链表相邻的两个⻚之间的物理位置可能离得非常远 。 我们介绍B+树索引的适用场景的时候特别提到 范围查询只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了 。 而如果双向链表中相邻的两个⻚的物理位置不连续，对于传统机械硬盘来说，需要重新定位磁头的位置，就是所谓的随机I&#x2F;O，这样会影响磁盘的性能。随机I/O是非常慢的。 所以 我们应该尽量让链表中相邻的⻚的物理位置也相邻 ，这样进行范围查询时，扫描叶子节点中大量记录时才可以使用顺序I/O。 所以才引入了区(extent)的概念，一个区就是在物理位置上连续的64个⻚。在表中数据量大的时候，为某个索引分配空间的时候就 不再按照⻚为单位分配了 ，而是 按照区为单位分配，甚至在表中的数据十分非常特别多的时候，可以 一次性分配多个连续的区。虽然可能造成一点点空间的浪费(数据不足填充满整个区)，但是从性能⻆度看，可以消除很多的随机I/O，功大于过嘛! 独立表空间的结构不论是系统表空间还是独立表空间，都可以看成是由若干个区组成的，每256个区被划分成一组 , 示意图如下： 每个组里的头几个⻚面(lant:自然也是位于该组的第一个区里)的类型都是类似的: 第一个组中的最开始的3个⻚面(也就是说extent 0这个区最开始的3个⻚面)的类型是固定的，分别是: FSP_HDR类型的页: 这个类型的⻚面是用来登记 整个表空间的一些整体属性 以及 本组256个区的属性，稍后详细唠叨。 需要注意的一点是，整个表空间只有一个FSP_HDR类型的⻚面。 IBUF_BITMAP类型的页: 这个类型的⻚面是存储本组所有区的所有⻚面关于 INSERT BUFFER 的信息。当然，你现在不用知道啥是个INSERT BUFFER。 INODE类型的页: 这个类型的⻚面存储了许多称为INODE的数据结构，还是那句话，现在你不需要知道啥是个INODE， 后边儿会说到你吐。 其余各组最开始的2个⻚面的类型是固定的，分别是: XDES类型:全称是extent descriptor，用来登记本组256个区的属性;上边介绍的FSP_HDR类型的⻚面其实和XDES类型的⻚面的作用类似，只不过FSP_HDR类型的⻚面还会额外存储一些表空间的属性。 ❓IBUF_BITMAP类型:上边介绍过了。 好了，宏观的结构介绍完了，里边儿的名词大家也不用记清楚，只要大致记得: 表空间被划分为许多连续的区，每个区默认由64个⻚组成 每256个区又被划分为一组，每个组的最开始的几个⻚面类型是固定的就好了。 段(segment) 的概念：还是为了顺序IO 😁然而事情到这里并没有结束，因为我们之前提到的范围查询是对B+树叶子节点中的记录进行顺序扫描 。而如果你在以页为单位存储记录时，如果不区分普通记录页和目录页(也就是不区分叶子节点和非叶子节点) ，无论什么类型的节点都统统放到申请到的区中的话，那范围扫描的效果就大打折扣了。 (lant: 提出区的概念本来就是为了让存放叶子节点的页在物理上尽量连续，减少随机IO，结果现在存放叶子节点的页和存放非叶子节点的页是混在一起在存到申请的区中的，这样存放叶子节点的页在物理上又不是顺序了)。 所以设计InnoDB的大叔们对B+树的叶子节点和非叶子节点进行了区别对待，也就是说 叶子节点有自己独有的区 ， 非叶子节点也有自己独有的区 。(lant: 这样，存放叶子节点的页在物理上就会尽量被连续存放起来，毕竟申请的区里的页都会用来存储叶子节点)。存放叶子节点的区的集合 和 存放非叶子节点的区的集合 都被称为 段。 也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段 。 碎片区 的概念默认情况下，InnoDB引擎的表只有一个聚簇索引，会生成2个段。而段是以区为单位申请存储空间的，一个区默认占用1M存储空间，所以默认情况下一个只存了几条记录的小表也需要2M的存储空间么? 以后每次添加一个索引都要申请2M的存储空间么? 这对于存储记录比较少的表简直是天大的浪费。 设计InnoDB 的大叔们都挺节俭的，当然也考虑到了这种情况。这个问题的症结在于 到现在为止我们都是认为 区是被整个分配给某一个段 的(即使段的数据填不满区中所有的⻚面)。 但是为了考虑 以完整的区为单位分配给某个段 对于数据量较小的表太浪费存储空间的这种情况，设计InnoDB的大叔们提出了一个碎片(fragment)区的概念。在一个碎片区中的⻚，不一定会全部分配给某个段；碎片区中的⻚可以用于不同的目的，比如有些⻚用于段A，有些⻚用于段B，有些⻚甚至哪个段都不属于 。 碎片区` 直属于 `表空间`，并不属于任何一个`段`。所以此后为某个`段`分配存储空间的策略是这样的: 在刚开始向表中插入数据的时候，`段`是从某个`碎片区`以`单个⻚面为单位`来分配存储空间的； 当某个段已经占用了32个碎片区⻚面之后，就会以完整的区为单位来分配存储空间； 所以现在 段 不能仅定义为是 某些区的集合，更精确的应该是 某些零散的⻚面以及 一些完整的区 的集合。 另外，除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为存储一些特殊的数据而定义的段，比如 回滚段，当然我们现在并不关心别的类型的段，现在只需要知道段是一些零散的⻚面以及一些完整的区的集合就好了。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.0 InnoDB的表空间 之 页相关知识回顾","date":"2021-10-23T13:16:21.000Z","path":"2021/10/23/MySQL知识点整理/9.0 InnoDB的表空间 之 页相关知识回顾/","text":"表空间 回顾通过前边的学习，大家知道， 表空间是一个抽象的概念 ，对于 系统表空间 来说，对应着文件系统中一个或多个实际文件;对于 每个独立表空间 来说，对应着文件系统中一个名为 表名.ibd 的实际文件(InnoDB)。 (lant: 其实可以认为 表空间就是个抽象出来的概念，它代表的其实就是 数据目录(真实存在)下与数据库名同名的子目录(真实存在)下的 表名.ibd文件 / 表名.MYD+表名.MYI文件(真实存在)) 大家可以把表空间想象成被切分为许许多多个⻚的池子，当我们想为某个表插入一条记录的时候，就从池子中捞出一个对应的⻚来把数据写进去。 ⻚面类型 回顾可参考 5.5 通用页 结构 之 File Header(文件头)部分再一次强调，InnoDB 是以⻚为单位管理存储空间的，我们的聚簇索引(也就是完整的表数据)和其他的二级索引都是以B+树的形式保存到表空间的，而B+树的节点就是数据⻚。我们前边说过，这个数据⻚的类型名其实是:FIL_PAGE_INDEX，除了这种存放索引数据的⻚面类型之外，InnoDB 也为了不同的目的设计了若干种不同类型的⻚面，为了唤醒大家的记忆，我们再一次把各种常用的⻚面类型(FIL_PAGE_TYPE)提出来: 因为⻚面类型前边都有个FIL_PAGE或者FIL_PAGE_TYPE的前缀， 为简便起⻅我们后边唠叨⻚面类型的时候就把这些前缀省略掉了，比方说FIL_PAGE_TYPE_ALLOCATED类型称为ALLOCATED类型，FIL_PAGE_INDEX类型称为INDEX类型。 ⻚面通用部分 回顾我们前边说过数据⻚，也就是INDEX类型的⻚由7个部分组成，其中的两个部分是所有类型的⻚面都通用的。在这里重新强调一遍，任何类型的⻚面都有下边这种通用的结构:从上图中可以看出，任何类型的⻚都会包含这两个部分: File Header: 记录⻚面的一些通用信息 File Trailer: 校验⻚是否完整，保证从内存到磁盘刷新时内容的一致性。 对于File Trailer我们不再做过多强调，全部忘记了的话可以到数据⻚的那一章回顾一下。我们这里再强调一遍File Header的各个组成部分:现在除了名称里边儿带有LSN的两个字段大家可能看不懂以外，其他的字段肯定都是倍儿熟了，不过我们仍要强调这么几点: 表空间中的每一个⻚都对应着一个⻚号，也就是FIL_PAGE_OFFSET，这个⻚号由4个字节组成，也就是32个比特位，所以页号最大也就到 2^32，所以一个表空间最多可以拥有2^32个⻚。如果按照⻚的默认大小16KB来算，一个表空间最多支持64TB的数据。(表空间的第一个⻚的⻚号为0，之后的⻚号分别是1，2，3…依此类推) 某些类型的⻚可以组成链表，链表中的⻚可以不按照物理顺序存储，而是根据FIL_PAGE_PREV和FIL_PAGE_NEXT来存储上一个⻚和下一个⻚的⻚号。需要注意的是，这两个字段主要是为了INDEX类型的⻚，也就是我们之前一直说的数据⻚建立B+树后，为每层节点建立双向链表用的，一般类型的⻚是不使用这两个字段的。 每个⻚的类型由FIL_PAGE_TYPE表示，比如像数据⻚的该字段的值就是0x45BF，我们后边会介绍各种不同类型的⻚，不同类型的⻚在该字段上的值是不同的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"8.0 数据的家--MySQL的数据目录","date":"2021-10-22T11:11:32.000Z","path":"2021/10/22/MySQL知识点整理/8.0 数据的家--MySQL的数据目录/","text":"数据库和文件系统的关系 我们知道像 InnoDB、MyISAM 这样的存储引擎都是把表数据存储在磁盘上的，而操作系统用来管理磁盘的那个东东又被称为文件系统，所以直接点来说就是: 像 InnoDB 、 MyISAM 这样的存储引擎都是把表存储在文件系统上的。当我们想读取数据时，这些存储引擎会从文件系统中把数据读出来返回给我们，当我们想写入数据时，这些存储引擎会把这些数据又写回文件系统。 所以，接下来就是要聊一下InnoDB和MyISAM这两个存储引擎的数据是如何在文件系统中存储的。 MySQL数据目录 MySQL服务器程序在启动时会到文件系统的某个目录下加载一些文件，之后在运行过程中产生的数据也都会存储到这个目录下的某些文件中，这个目录就称为数据目录，我们下边就要详细唠唠这个目录下具体都有哪些重要的东⻄。 数据目录和安装目录的区别 我们之前只接触过 MySQL的安装目录，而且重点强调过这个安装目录下非常重要的bin目录，它里边存储了许多关于控制客户端程序和服务器程序的命令(许多可执行文件，比如mysql，mysqld，mysqld_safe等等好几十个)。 而数据目录是用来存储MySQL在运行过程中产生的数据，一定要和安装目录区别开! MySQL中的数据目录在哪儿？ 那说了半天，MySQL中的数据目录到底在哪儿(数据到底被它存储到哪个目录了)？其实数据目录对应着一个系统变量 datadir，我们在使用客户端与服务器建立连接之后查看这个系统变量的值就可以了: 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;datadir&#x27;; +---------------+-----------------------+ | Variable_name | Value | +---------------+-----------------------+ | datadir | /usr/local/mysql/var | +---------------+-----------------------+ 1 row in set (0.00 sec) 从结果中可以看出，在我的计算机上MySQL的数据目录就是 /usr/local/mysql/var，你用你的计算机试试呗~ MySQL运行过程中会产生哪些数据? 首先，它当然会包含我们创建的 数据库、表、视图、 触发器、用户数据 … 除了这些用户数据， 为了程序更好的运行，MySQL也会创建一些其他的额外数据，我们接下来细细的品味一下这个数据目录下的内容。 数据库在文件系统中的表示每当我们使用 CREATE DATABASE 数据库名 创建一个数据库时，在文件系统上实际发生了什么呢?其实很简单， 每个数据库都对应数据目录下的一个子目录 。 每当我们新建一个数据库时，MySQL会帮我们做这两件事儿: 在数据目录下创建一个和数据库名同名的子目录(或者说是文件夹); 在与该数据库名同名的子目录下创建一个名为 db.opt的文件，这个文件中包含了该数据库的各种属性，比方说该数据库的字符集和比较规则是个啥。 比方说我们查看一下在我的计算机上当前有哪些数据库: 123456789101112mysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || jm_taxi || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec)mysql&gt; 可以看到在我的计算机上当前有5个数据库，其中 jm_taxi 数据库是我们自定义的，其余4个数据库是属于MySQL自带的系统数据库。我们再看一下我的计算机上的数据目录下的内容:当前MySQL服务器上的数据目录下的文件和子目录比较多哈，不过仍然能看到我们创建的数据库 jm_taxi 在数据目录下是有对应的子目录的。数据目录下的其他的文件和子目录，我们暂时先忽略它们的存在就好了。 表在文件系统中的表示每个表的信息其实可以分为两种: 表结构信息 表结构 就是该表的名称是啥，表里边有多少列，每个列的数据类型是啥，有啥约束条件和索引，用的是啥字符集和比较规则吧啦吧啦的各种信息，这些信息都体现在了我们的建表语句中了。为了保存这些信息，InnoDB和MyISAM这两种存储引擎都在数据目录下对应的数据库子目录下创建了一个专⻔用于描述表结构的文件，文件名是 表名.frm (这个后缀名为.frm是以二进制格式存储的，直接打开会是乱码的~);(值得注意的是：MySQL8版本中的innodb存储引擎的表没有.frm文件。MySQL8开始删除了原来的frm文件，并采用 Serialized Dictionary Information (SDI),SDI信息源记录保存在ibd文件中。) 表中的数据 描述表结构的文件我们知道了，那表中的数据被存到什么文件中了呢?在这个问题上，不同的存储引擎就产生了分歧了，下边我们分别看一下InnoDB和MyISAM是用什么文件来保存表中数据的。 InnoDB是如何存储表数据的 我们前边重点唠叨过InnoDB的一些实现原理，到现在为止我们应该熟悉下边这些东东: InnoDB 是使用⻚为基本单位来管理存储空间的，默认的⻚大小为16KB。 对于InnoDB存储引擎来说，每个索引都对应着一棵B+树，该B+树的每个节点都是一个数据⻚，数据⻚之间不必要是物理连续的 ，因为数据⻚之间有双向链表来维护着这些⻚的顺序。 InnoDB的聚簇索引的叶子节点存储了完整的用户记录，也就是所谓的 索引即数据，数据即索引 。 表空间 的概念 不过，为了更好的管理这些⻚，设计InnoDB的大叔们又提出了一个表空间或者文件空间(英文名:table space或者file space)的概念。其实 表空间 是一个抽象的概念，它可以对应文件系统上一个或多个真实文件(不同表空间对应的文件数量可能不同);每一个表空间可以被划分为很多很多很多个⻚，我们的表数据就存放在某个表空间下的某些⻚里 ; 设计InnoDB的大叔还将表空间划分为几种不同的类型，我们一个一个看一下。 系统表空间(system tablespace)这个所谓的系统表空间可以对应文件系统上一个或多个实际的文件。默认情况下，InnoDB会在 数据目录 下创建一个名为 ibdata1、大小为12M的文件，这个文件就是对应的系统表空间在文件系统上的表示。之所以只有12M，那是因为这个文件是所谓的自扩展文件，也就是当不够用的时候它会自己增加文件大小~ 当然，如果你想让系统表空间对应文件系统上多个实际文件，或者仅仅觉得原来的ibdata1这个文件名难听，那可以在MySQL启动时配置对应的文件路径以及它们的大小，比如我们这样修改一下配置文件: 12[server] innodb_data_file_path=data1:512M;data2:512M:autoextend 这样在MySQL启动之后就会创建这两个512M大小的文件作为系统表空间，其中的autoextend表明这两个文件如果不够用会自动扩展data2文件的大小。 我们也可以把系统表空间对应的文件路径不配置到数据目录下，甚至可以配置到单独的磁盘分区上，涉及到的启动参数就是innodb_data_file_path和innodb_data_home_dir，具体的配置逻辑挺绕的，就不多唠叨了，知道改哪个参数可以修改系统表空间对应的文件，有需要的时候到官方文档里一查就好了。 需要注意的一点是，在一个MySQL服务器中，系统表空间只有一份 (可以配置 系统表空间 对应多个实际文件) 。从MySQL5.5.7到MySQL5.6.6之间的各个版本中，我们表中的数据都会被默认存储到这个系统表空间。 独立表空间(file-per-table tablespace)在MySQL5.6.6以及之后的版本中，InnoDB并不会默认的把各个表的数据存储到系统表空间中，而是为每一个表建立一个独立表空间，也就是说我们 创建了多少个表，就有多少个独立表空间 。 使用独立表空间 来存储表数据的话，会在该表所属数据库对应的子目录下创建一个表示该独立表空间的文件，文件名和表名相同，只不过添加了一个.ibd的扩展名而已，所以完整的文件名称就是: 表名.ibd 比方说假如我们使用了独立表空间去存储 jm_taxi数据库下的 jm_member 表的话，那么在该表所在数据库对应的jm_taxi目录下会为jm_member表创建这两个文件: jm_member.frm、 jm_member.ibd其中 jm_member.ibd文件 就用来存储jm_member表中的数据和索引 (索引和数据在一起的哦，正所谓 索引即数据，数据即索引)。 当然我们也可以自己指定使用系统表空间还是独立表空间来存储数据，这个功能由启动参数innodb_file_per_table控制。 比如说我们想刻意将表数据都存储到系统表空间时，可以在启动MySQL服务器的时候这样配置: 12[server] innodb_file_per_table=0 // 0:代表使用系统表空间;1:代表使用独立表空间。 不过innodb_file_per_table参数只对新建的表起作用，对于已经分配了表空间的表并不起作用。 如果我们想把已经存在系统表空间中的表转移到独立表空间，可以使用下边的语法: 1ALTER TABLE 表名 TABLESPACE [=] innodb_file_per_table; //其中中括号扩起来的=可有可无 或者把已经存在独立表空间的表转移到系统表空间，可以使用下边的语法: 1ALTER TABLE 表名 TABLESPACE [=] innodb_system; // 其中中括号扩起来的=可有可无 其他类型的表空间 随着MySQL的发展，除了上述两种老牌表空间之外，现在还新提出了一些不同类型的表空间比如 通用表空间(general tablespace)、undo表空间(undo tablespace)、临时表空间 (temporary tablespace) …… 等等具体情况我们等用到的时候再提 MyISAM是如何存储表数据的好了，唠叨完了InnoDB的系统表空间和独立表空间，现在轮到MyISAM了。 我们知道，和InnoDB的索引和数据是一个东东不同。MyISAM中的索引全部都是二级索引，该存储引擎的数据和索引是分开存放的。所以MyISAM在文件系统中也是使用不同的文件来存储数据和索引的。而且和InnoDB不同的是，MyISAM并没有什么所谓的表空间一说，表数据都存放到对应的数据库子目录下。 假如 jm_member表 使用MyISAM存储引擎的话，那么在它所在数据库对应的 jm_taxi目录下会为 jm_member表 创建这三个文件: jm_member.frm、jm_member.MYD、jm_member.MYI 其中 jm_member.MYD 代表表的数据文件，也就是我们插入的用户记录; jm_member.MYI 代表表的索引文件，我们为该表创建的索引都会放到这个文件中。 视图在文件系统中的表示 我们知道MySQL中的视图其实是虚拟的表，也就是某个查询语句的一个别名而已，所以在存储视图的时候是不需要存储真实的数据的，只需要把它的结构存储起来就行了。和表一样，描述视图结构的文件也会被存储到所属数据库对应的子目录下边，只会存储一个 视图名.frm 的文件。 其他的文件除了我们上边说的这些用户自己存储的数据以外，数据目录 下还包括为了更好运行程序的一些额外文件，主要包括这几种类型的文件: 服务器进程文件 我们知道每运行一个MySQL服务器程序，都意味着启动一个进程。MySQL服务器会把自己的进程ID写入到一个文件中。 服务器日志文件 在服务器运行过程中，会产生各种各样的日志, 比如常规的 查询日志、错误日志、二进制日志、redo日志… 等 各种日志，这些日志各有各的用途，现在暂时先了解一下就可以了。 默认&#x2F;自动生成的SSL和RSA证书和密钥文件 主要是为了客户端和服务器安全通信而创建的一些文件， 大家看不懂可以忽略~ 文件系统对数据库的影响因为MySQL的数据都是存在文件系统中的，就不得不受到文件系统的一些制约，这在数据库和表的命名、表的大小和性能方面体现的比较明显，比如下边这些方面: 数据库名称和表名称不得超过文件系统所允许的最大⻓度。 每个数据库都对应数据目录的一个子目录;每个表都会在数据库子目录下产生一个和表名同名的.frm文件(如果是InnoDB的独立表空间或者使用MyISAM引擎还会有别的文件名称与表名一致)。 特殊字符的问题 为了避免因为数据库名和表名出现某些特殊字符而造成文件系统不支持的情况，MySQL会把数据库名和表名中所有除数字和拉丁字母以外的所有字符在文件名里都映射成 @+编码值的形式 作为文件名。 文件⻓度受文件系统最大⻓度限制 对于InnoDB的独立表空间来说，每个表的数据都会被存储到一个与表名同名的.ibd文件中;对于MyISAM存储引擎来说，数据和索引会分别存放到与表同名的.MYD和.MYI文件中。这些文件会随着表中记录的增加而增大，它们的大小受限于文件系统支持的最大文件大小。 MySQL系统数据库简介我们前边提到了MySQL的几个系统数据库，这几个数据库包含了 MySQL服务器运行过程中所需的一些信息以及一些运行状态信息， 我们现在稍微了解一下。 mysql 这个数据库贼核心，它存储了MySQL的用户账户和权限信息， 一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。 information_schema 这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。 performance_schema 这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多⻓时间，内存的使用情况等等信息。 sys 这个数据库主要是通过视图的形式把information_schema 和performance_schema结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。啥?这四个系统数据库这就介绍完了? 是的，这里只是因为介绍数据目录里遇到了，为了内容的完整性跟大家提一下，具体如何使用还是要参照文档~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.4 主键自增","date":"2021-10-20T09:03:19.000Z","path":"2021/10/20/MySQL知识点整理/7.4 主键自增/","text":"我们知道，对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据⻚中的，数据⻚和记录又是按照记录主键值从小到大的顺序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满一个数据⻚就换到下一个数据⻚继续插。 而如果我们插入的主键值忽大忽小的话，这就比较麻烦了，假设某个数据⻚存储的记录已经满了，它存储的主键值在1~100之间, 如果此时再插入一条主键值为9的记录，那它插入的位置就如下图::可这个数据⻚已经满了啊，再插进来咋办呢?我们需要把当前⻚面分裂成两个⻚面，把本⻚中的一些记录移动到新创建的这个⻚中。⻚面分裂和记录移位意味着什么?意味着: 性能损耗! 所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会发生这样的性能损耗了。所以我们建议:让主键具有AUTO_INCREMENT，让存储引擎自己为表生成主键，而不是我们手动插入。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.3 如何选择索引","date":"2021-10-20T07:21:31.000Z","path":"2021/10/20/MySQL知识点整理/7.3 如何选择索引/","text":"上边我们以 idx_name_birthday_phone_number索引 为例对索引的适用条件进行了详细的唠叨，下边看一下我们在建立索引时或者编写查询语句时就应该注意的一些事项。 考虑列的基数 列的基数指的是某一列中不重复数据的个数，比方说某个列包含值2, 5, 8, 2, 5, 8, 2, 5, 8，虽然有9条记录，但该列的基数却是3。也就是说，在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。这个列的基数指标非常重要，直接影响我们是否能有效的利用索引。 假设某个列的基数为1，也就是所有记录在该列中的值都一样，那为该列建立索引是没有用的，因为所有值都一样就无法排序，无法进行快速查找了~而且如果某个建立了二级索引的列的重复值特别多，那么使用这个二级索引查出的记录还可能要做回表操作，这样性能损耗就更大了。所以结论就是:最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好。 索引列的类型尽量小 我们在定义表结构的时候要显式的指定列的类型，以整数类型为例，有TINYINT、MEDIUMINT、INT、BIGINT这么几种，它们占用的存储空间依次递增，我们这里所说的类型大小指的就是该类型表示的数据范围的大小。如果我们想要对某个整数列建立索引的话，在表示的整数范围允许的情况下，尽量让索引列使用较小的类型，比如我们能使用INT就不要使用BIGINT，能使用MEDIUMINT就不要使用INT~这是因为: 数据类型越小，在查询时进行的比较操作越快(这是CPU层次 的东东) 数据类型越小，索引占用的存储空间就越少，在一个数据⻚内就可以放下更多的记录，从而减少磁盘I&#x2F;O带来的性能损耗， 也就意味着可以把更多的数据⻚缓存在内存中，从而加快读写效率。 这个建议对于表的主键来说更加适用，因为不仅是聚簇索引中会存储主键值，其他所有的二级索引的节点处都会存储一份记录的主键值， 如果主键适用更小的数据类型，也就意味着节省更多的存储空间和更高效的I&#x2F;O。 索引字符串值的前缀 当我们的字符串很⻓时，存储一个字符串就需要占用很大的存储空间。在我们需要为这个字符串列建立索引时，那就意味着在对应的B+树中有这么两个问题: B+树索引中的记录需要把该列的完整字符串存储起来，而且字符串越⻓，在索引中占用的存储空间越大。 如果B+树索引中索引列存储的字符串很⻓，那在做字符串比较时会占用更多的时间。 我们前边儿说过索引列的字符串前缀其实也是排好序的，所以索引的设计者提出了个方案 – 只对字符串的前几个字符进行索引，也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时, 虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。这样只在B+树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，还大概能解决排序的问题，何乐而不为，比方说我们在建表语句中只对name列的前10个字符进行索引可以这么写: 1234567CREATE TABLE person_info(name VARCHAR(100) NOT NULL,birthday DATE NOT NULL,phone_number CHAR(11) NOT NULL,country varchar(100) NOT NULL,KEY idx_name_birthday_phone_number (name(10),birthday, phone_number) ); name(10)就表示在建立的B+树索引中只保留记录的前10个字符的编码，这种只索引字符串值的前缀的策略是我们非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候。 索引列前缀对排序的影响 如果使用了 索引列前缀，比方说前边只把name列的前10个字符放到了二级索引中, 下边这个查询可能就有点儿尴尬了:SELECT * FROM person_info ORDER BY name LIMIT 10;因为二级索引中不包含完整的name列信息，所以无法对前十个字符相同，后边的字符不同的记录进行排序，也就是使用索引列前缀的方式无法支持使用索引排序，只好乖乖的用文件排序喽 。 让索引列在比较表达式中单独出现 假设表中有一个整数列my_col，我们为这个列建立了索引。下边的两个WHERE子句虽然语义是一致的，但是在效率上却有差别:WHERE my_col * 2 &lt; 4WHERE my_col &lt; 4/2第1个WHERE子句中my_col列并不是以单独列的形式出现的，而是以my_col * 2这样的表达式的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于4，所以这种情况下是使用不到为my_col列建立的B+树索引的。而第2个WHERE子句中my_col列是以单独列的形式出现的，这样的情况可以直接使用B+树索引。 所以结论就是:如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.2 回表的代价与覆盖索引","date":"2021-10-16T15:01:19.000Z","path":"2021/10/16/MySQL知识点整理/7.2 回表的代价与覆盖索引/","text":"之前我们在谈到回表这个词时，多是一带而过，可能大家没啥深刻的体会，下边我们详细唠叨下。还是用idx_name_birthday_phone_number索引为例，看下边这个查询: 1SELECT * FROM person_info WHERE name &gt; &#x27;Asa&#x27; AND name &lt; &#x27;Barlow&#x27;; 在使用idx_name_birthday_phone_number索引进行查询时大致可以分为这两个步骤: 从索引idx_name_birthday_phone_number对应的B+树中取出name值在Asa~Barlow之间的用户记录。 由于索引idx_name_birthday_phone_number对应的B+树用户记录中只包含name、age、birthday、id这4个字段， 而查询列表是*，意味着要查询表中所有字段，也就是还要包括country字段。这时需要把从上一步中获取到的每一条记录的id字段都到聚簇索引对应的B+树中找到完整的用户记录，也就是我们通常所说的回表，然后把完整的用户记录返回给查询用户。 由于索引idx_name_birthday_phone_number对应的B+树中的记录首先会按照name列的值进行排序，所以值在Asa~Barlow之间的记录在磁盘中的存储是相连的，集中分布在一个或几个数据⻚中， 我们可以很快的把这些连着的记录从磁盘中读出来，这种读取方式我们也可以称为顺序I&#x2F;O。根据第1步中获取到的记录的id字段的值可能并不相连，而在聚簇索引中记录是根据id(也就是主键)的顺序排列的，所以根据这些并不连续的id值到聚簇索引中访问完整的用户记录可能分布在不同的数据⻚中，这样读取完整的用户记录可能要访问更多的数据⻚，这种读取方式我们也可以称为随机I&#x2F;O。一般情 况下，顺序I&#x2F;O比随机I&#x2F;O的性能高很多，所以步骤1的执行可能很快，而步骤2就慢一些。所以这个使用索 引idx_name_birthday_phone_number的查询有这么两个特点: 会使用到两个B+树索引，一个二级索引，一个聚簇索引。 访问二级索引使用顺序I&#x2F;O，访问聚簇索引使用随机I&#x2F;O。 需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。比方说name值在Asa ~Barlow之间的用户记录数量占全部记录数量90%以上，那么如果使用idx_name_birthday_phone_number索引的话，有90%多的id值需要回表，这不是吃力不讨好么，还不如直接去扫描聚簇索引 (也就是全表扫描)。 那什么时候采用全表扫描的方式，什么使用采用 二级索引 + 回表 的方式去执行查询呢?这个就是传说中的查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表 的方式。当然优化器做的分析工作不仅仅是这么简单，但是大致上是个这个过程。一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用 二级索引 + 回表 的方式进行查询，因为回表的记录越少，性能提升就越高，比方说上边的查询可以改写成这样:SELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39; LIMIT 10;添加了LIMIT 10的查询更容易让优化器采用二级索引 + 回表的方 式进行查询。 对于有排序需求的查询，上边讨论的采用 全表扫描 还是 二级索引 + 回表 的方式进行查询的条件也是成立的，比方说下边这个查询:SELECT * FROM person_info ORDER BY name, birthday, phone_number;由于查询列表是*，所以如果使用二级索引进行排序的话，需要把排序完的二级索引记录全部进行回表操作，这样操作的成本还不如直接遍历聚簇索引然后再进行文件排序(filesort)低，所以优化器会倾向于使用全表扫描的方式执行查询。如果我们加了LIMIT子句，比如这样:SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;这样需要回表的记录特别少，优化器就会倾向于使用 二级索引 + 回表 的方式执行查询。 覆盖索引 为了彻底告别回表操作带来的性能损耗，我们建议: 最好在查询列表里只包含索引列，比如这样:SELECT name, birthday, phone_number FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;因为我们只查询name, birthday, phone_number这三个索引列的值，所以在通过idx_name_birthday_phone_number索引得到结果后就不必到聚簇索引中再查找记录的剩余列，也就是country列的值了，这样就省去了回表操作带来的性能损耗。我们把这种只需要用到索引的查询方式称为索引覆盖。 排序操作也优先使用覆盖索引的 方式进行查询，比方说这个查询:SELECT name, birthday, phone_number FROM person_info ORDER BY name, birthday, phone_number;虽然这个查询中没有LIMIT子句，但是采用了覆盖索引，所以查询优化器就会直接使用idx_name_birthday_phone_number索引进行排序而不需要回表操作了。 当然，如果业务需要查询出索引以外的列，那还是以保证业务需求为重。但是我们很不鼓励用*号作为查询列表，最好把我们需要查询的列依次标明。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.1 索引的使用及注意事项","date":"2021-10-16T13:05:37.000Z","path":"2021/10/16/MySQL知识点整理/7.1 索引的使用及注意事项/","text":"测试数据表准备B+树索引并不是万能的，并不是所有的查询语句都能用到我们建立的索引。 为了故事的顺利发展，我们需要先创建一个 用户基本信息 表: 123456789CREATE TABLE person_info(id INT NOT NULL auto_increment,name VARCHAR(100) NOT NULL,birthday DATE NOT NULL,phone_number CHAR(11) NOT NULL,country varchar(100) NOT NULL,PRIMARY KEY (id),KEY idx_name_birthday_phone_number (name,birthday, phone_number) ); 对于这个person_info表我们需要注意两点: 表中的主键是id列，它存储一个自动递增的整数。所以InnoDB存储引擎会自动为id列建立聚簇索引。 我们额外定义了一个二级索引 idx_name_birthday_phone_number，它是由3个列组成的联合索引。 所以在这个索引对应的B+树的叶子节点处存储的用户记录只保留name、birthday、phone_number这三个列的值以及主键id的值，并不会保存country列的值。 person_info表会为 聚簇索引 和 idx_name_birthday_phone_number索引 建立2棵B+树下边我们画一下索引idx_name_birthday_phone_number的示意图，不过既然我们已经掌握了InnoDB的B+树索引原理，那我们在画图的时候为了让图更加清晰，所以在省略一些不必要的部分，比如记录的额外信息，各⻚面的⻚号等等，其中内节点中目录项记录的⻚号信息我们用箭头来代替，在记录结构中只保 留name、birthday、phone_number、id这四个列的真实数据值，所以示意图就⻓这样:为了方便大家理解，我们特意标明了哪些是内节点，哪些是叶子节点。再次强调一下，内节点中存储的是目录项记录，叶子节点中存储的是用户记录(由于不是聚簇索引，所以用户记录是不完整的，缺少country列的值)。 从图中可以看出，这个 idx_name_birthday_phone_number 索引对应的B+树中⻚面和记录的排序方式就是这样的: 先按照name列的值进行排序。 如果name列的值相同，则按照birthday列的值进行排序。 如果birthday列的值也相同，则按照phone_number的值进行排序。这个排序方式十分、特别、非常、巨、very very very重要，因为只要⻚面和记录是排好序的，我们就可以通过二分法来快速定位查找。 下边的内容都仰仗这个图了，大家对照着图理解。 全值匹配当我们的 where搜索条件 中的列和 索引列 一致的话，这种情况就称为全值匹配，比方说下边这个查找语句: 1SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27; AND birthday = &#x27;1990-09-27&#x27; AND phone_number = &#x27;15123983239&#x27;; 我们建立的 idx_name_birthday_phone_number索引 包含的3个列在这个查询语句中都展现出来了。 大家可以想象一下这个查询过程: 因为B+树的数据⻚和记录先是按照name列的值进行排序的， 所以先可以很快定位name列的值是Ashburn的记录位置。 在name列相同的记录里又是按照birthday列的值进行排序的，所以在name列的值是Ashburn的记录里又可以快速定位birthday列的值是’1990-09-27’的记录。 如果很不幸，name和birthday列的值都是相同的，那记录是按照phone_number列的值排序的，所以联合索引中的三个列都可能被用到。 有的同学也许有个疑问，如果调换WHERE子句中的几个搜索条件的顺序对查询结果有啥影响么? 比方说写成下边这样: 1SELECT * FROM person_info WHERE birthday = &#x27;1990- 09-27&#x27; AND phone_number = &#x27;15123983239&#x27; AND name = &#x27;Ashburn&#x27;; 答案是: 没影响哈。MySQL有一个叫查询优化器的东东，会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件。我们后边儿会有专⻔的章节来介绍查询 优化器，敬请期待。 匹配左边的列 其实在我们的搜索语句中也可以不用包含全部联合索引中的列，只包含左边 的就行，比方说下边的查询语句: 1234SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27;;或者SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27; AND birthday = &#x27;1990-09-27&#x27;; 那为什么搜索条件中必须出现左边的列才可以使用到这个B+树索引呢? 比如下边的语句就用不到这个B+树索引么? 1SELECT * FROM person_info WHERE birthday = &#x27;1990-09-27&#x27;; 是的，的确用不到，因为B+树的数据⻚和记录先是按照name列的值排序的，在name列的值相同的情况下才使用birthday列进行排序，也就是说name列的值不同的记录中birthday的值可能是无序的。而现在你跳过name列直接根据birthday的值去查找，臣妾做 不到呀~ 那如果我就想在只使用birthday的值去通过B+树索引进行查找咋办呢?这好办，你再对birthday列建一个B+树索引就行了。 但是需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。比方说联合索引idx_name_birthday_phone_number中列的定义顺序是name、birthday、phone_number，如果我们的搜索条件中只有name和phone_number，而没有中间的birthday，比方说这样: 1SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27; AND phone_number = &#x27;15123983239&#x27;; 这样只能用到name列的索引，birthday和phone_number的索引就用不上了，因为name值相同的记录先按照birthday的值进行排序，birthday值相同的记录才按照phone_number值进行排序。 匹配列前缀 我们前边说过为某个列建立索引的意思其实就是 在对应的B+树的记录中使用该列的值进行排序比方说person_info表上建立的联合索引idx_name_birthday_phone_number会先用name列的值进行排序，所以这个联合索引对应的B+树中的记录的name列的排列就是这样的: 123456789101112AaronAaron...AaronAsaAshburn...AshburnBairdBarlow...Barlow 字符串排序的本质就是比较哪个字符串大一点儿，一般的比较规则都是逐个比较字符的大小，也就是说我们比较两个字符串的大小的过程其实是这样的: 先比较字符串的第一个字符，第一个字符小的那个字符串就比较小。 如果两个字符串的第一个字符相同，那就再比较第二个字符， 第二个字符比较小的那个字符串就比较小。 如果两个字符串的第二个字符也相同，那就接着比较第三个字符，依此类推。 也就是说这些字符串的前n个字符，也就是前缀都是排好序的， 所以对于字符串类型的索引列来说，我们只匹配它的前缀也是可以快速定位记录的 。 比方说我们想查询名字以’As’开头的记录，那就可以这么写查询语句:SELECT * FROM person_info WHERE name LIKE ‘As%’;但是需要注意的是，如果只给出后缀或者中间的某个字符串，比如这样:SELECT * FROM person_info WHERE name LIKE ‘%As%’;MySQL就无法快速定位记录位置了，因为字符串中间有’As’的字符串并没有排好序， 所以只能全表扫描了 。 匹配范围值 回头看我们idx_name_birthday_phone_number索引的B+树示意图，所有记录都是按照索引列的值从小到大的顺序排好序的，所以这极大的方便我们查找索引列的值在某个范围内的记录。 比方说查询语句: SELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;;由于B+树中的数据⻚和记录是先按name列排序的，所以我们上边的查询过程其实是这样的:找到name值为Asa的记录。找到name值为Barlow的记录。哦啦，由于所有记录都是由链表连起来的(记录之间用单链表，数据⻚之间用双链表)，所以他们之间的记录都可以很容易的取出来喽~找到这些记录的主键值，再到聚簇索引中回表查找完整的记录。 不过在使用联合索引进行范围查找的时候需要注意，如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到B+树索引，比方说这样:SELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39; AND birthday &gt; &#39;1980-01-01&#39;;上边这个查询可以分成两个部分: 通过条件name &gt; ‘Asa’ AND name &lt; ‘Barlow’来对name进行范围，查找的结果可能有多条name值不同的记录 对这些name值不同的记录继续通过 birthday &gt; ‘1980-01-01’条件继续过滤 这样子对于联合索引idx_name_birthday_phone_number来说，只能用到name列的部分，而用不到birthday列的部分，因为只有name值相同的情况下才能用birthday列的值进行排序，而这个查询中通过name进行范围查找的记录中可能并不是按照birthday列进行排序的，所以在搜索条件中继续以birthday列进行查找时是用不到这个B+树索引的。 精确匹配某一列并范围匹配另外一列 对于同一个联合索引来说，虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找，比方说这样:SELECT * FROM person_info WHERE name = &#39;Ashburn&#39; AND birthday &gt; &#39;1980-01-01&#39; AND birthday &lt; &#39;2000- 12-31&#39; AND phone_number &gt; &#39;15100000000&#39;;name &#x3D; ‘Ashburn’，对name列进行精确查找，当然可以使用B+树索引了。birthday &gt; ‘1980-01-01’ AND birthday &lt; ‘2000- 12-31’，由于name列是精确查找，所以通过name &#x3D; ‘Ashburn’条件查找后得到的结果的name值都是相同的，它们会再按照birthday的值进行排序。所以此时对birthday 列进行范围查找是可以用到B+树索引的。phone_number &gt; ‘15100000000’，通过birthday的范围查找的记录的birthday的值可能不同，所以这个条件无法再利用B+树索引了，只能遍历上一步查询得到的记录。 用于排序 （注意 文件排序(英文名:filesort)） 我们在写查询语句的时候经常需要对查询出来的记录通过 ORDER BY 子句按照某种规则进行排序。 一般情况下，我们只能把记录都加载到内存中，再用一些排序算法，比如快速排序、归并排序、吧啦吧啦排序…… 在内存中对这些记录进行排序，有的时候可能查询的结果集太大以至于不能在内存中进行排序的话，还可能暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端。 在MySQL中，把这种在内存中或者磁盘上进行排序的方式统称为 文件排序(英文名:filesort)，跟文件这个词儿一沾边儿，就显得这些排序操作非常慢了。但是如果ORDER BY子句里使用到了我们的索引列，就有可能省去在内存或文件中排序的步骤，比如下边这个简单的查询语句:SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;这个查询的结果集需要先按照name值排序，如果记录的name值相同，则需要按照birthday来排序，如果birthday的值相同，则需要按照phone_number排序。大家可以回过头去看我们建立的 idx_name_birthday_phone_number 索引的示意图，因为这个B+树索引本身就是按照上述规则排好序的，所以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了。简单吧? 是的，索引就是这么牛逼。 （lant:如果用到索引，你就不用再次排序了。） Tips:请注意，本例的查询语句中加了limit子句，这是因为如果不限制需要获取的记录数量，会导致为大量二级索引记录执行回表操作，这样会影响整体的查询性能。关于回表操作造成的影响，我们后续再聊。 使用联合索引进行排序注意事项 对于联合索引有个问题需要注意，ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY phone_number, birthday, name的顺序，那也是用不了B+树索引，这种颠倒顺序就不能使用索引的原因我们上边详细说过了，这就不赘述了。 当联合索引左边列的值为常量，也可以使用后边的列进行排序，比如这样:SELECT * FROM person_info WHERE name = &#39;A&#39; ORDER BY birthday, phone_number LIMIT 10;这个查询能使用联合索引进行排序是因为name列的值相同的记录是按照birthday, phone_number排序的，说了好多遍了都。 不可以使用索引进行排序的几种情况ASC、DESC混用 对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC规则排序，要么都是DESC规则排序。为啥会有这种奇葩规定呢? 这个还得回头想想这个idx_name_birthday_phone_number联合索引中记录的结构: 先按照记录的name列的值进行升序排列。 如果记录的name列的值相同，再按照birthday列的值进行升序排列。 如果记录的birthday列的值相同，再按照phone_number列的值进行升序排列。 如果查询中的各个排序列的排序顺序是一致的，比方说下边这两种情况:ORDER BY name, birthday LIMIT 10 : 这种情况直接从索引的最左边开始往右读10行记录就可以了。ORDER BY name DESC, birthday DESC LIMIT 10: 这种情况直接从索引的最右边开始往左读10行记录就可以了。 但是如果我们查询的需求是先按照name列进行升序排列，再按照birthday列进行降序排列的话，比如说这样的查询语句:SELECT * FROM person_info ORDER BY name ASC, birthday DESC LIMIT 10;这样就不能高效使用索引，而要采取更复杂的算法去从索引中取数据，设计MySQL的大叔觉得这样还不如直接文件排序来的快，所以就规定使用联合索引的各个排序列的排序顺序必须是一致的。 WHERE子句中出现非排序使用到的索引列 如果WHERE子句中出现了非排序使用到的索引列，那么排序依然是使用不到索引的，比方说这样:SELECT * FROM person_info WHERE country = &#39;China&#39; ORDER BY name LIMIT 10;这个查询只能先把符合搜索条件country &#x3D; ‘China’的记录提取出来(这个筛选本身就用不到索引)后再进行排序。注意和下边这个查询作区别:SELECT * FROM person_info WHERE name = &#39;A&#39; ORDER BY birthday, phone_number LIMIT 10;虽然这个查询也有搜索条件，但是name &#x3D; ‘A’可以使用到索引 idx_name_birthday_phone_number，而且过滤剩下的记录还是按照birthday、phone_number列排序的，所以还是可以使用索引进行排序的。 排序列包含非同一个索引的列 有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序，比方说:SELECT * FROM person_info ORDER BY name, country LIMIT 10;name和country并不属于一个联合索引中的列，所以无法使用索引进行排序，至于为啥我就不想再唠叨了，自己用前边的理论自己捋一捋把~ &#x2F;&#x2F; TODO: 为什么不能先用 order by name 索引先拿出10条记录，然后用这10条记录的主键id再去回表取到country列，然后再在内存中做 order by country 呢？&#x2F;&#x2F; 哦： 这样在内存中进行排序，其实就是 文件排序了，也就是说还要你重新再排序，并没有使用到现成排好序的索引。 排序列使用了复杂的表达式 要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式，比方说这样:SELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;使用了UPPER函数修饰过的列就不是单独的列啦，这样就无法使用索引进行排序啦。 用于分组 有时候我们为了方便统计表中的一些信息，会把表中的记录按照某些列进行分组。比如下边这个分组查询:SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number 这个查询语句相当于做了3次分组操作: 先把记录按照name值进行分组，所有name值相同的记录划分为一组。 将每个name值相同的分组里的记录再按照birthday的值进行分组，将birthday值相同的记录放到一个小分组里，所以看起来就像在一个大分组里又化分了好多小分组。 再将上一步中产生的小分组按照phone_number的值分成更小的分组，所以整体上看起来就像是先把记录分成一个大分组，然后把大分组分成若干个小分组，然后把若干个小分组再细分成更多的小小分组。 然后针对那些小小分组进行统计，比如在我们这个查询语句中就是统计每个小小分组包含的记录条数。 如果没有索引的话，这个分组过程全部需要在内存里实现，而如果有了索引的话，恰巧这个分组顺序又和我们的B+树中的索引列的顺序是一致的，而我们的B+树索引又是按照索引列排好序的，这不正好么，所以可以直接使用B+树索引进行分组。 和使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.0 回顾B+树索引的本质","date":"2021-10-16T11:15:21.000Z","path":"2021/10/16/MySQL知识点整理/7.0 回顾B+树索引的本质/","text":"回顾 B+树的索引本质我们前边非常详细地唠叨了InnoDB存储引擎的B+树索引， 我们必须熟悉下边这些结论: 每个索引都对应一棵B+树，B+树分为好多层，最下边一层是叶子节点，其余的是内节点。 所有用户记录都存储在B+树的叶子节点，所有目录项记录都存储在内节点。 InnoDB存储引擎会自动为主键(如果没有它会自动帮我们添加)建立聚簇索引，聚簇索引的叶子节点包含完整的用户记录。 我们可以为自己感兴趣的列建立二级索引，二级索引的叶子节点包含的用户记录由 索引列+主键 组成，所以如果想通过二级索引来查找完整的用户记录的话，需要通过回表操作，也就是在通过二级索引找到主键值之后再到聚簇索引中查找完整的用户记录。 B+树中每层节点(页)都是按照索引列值从小到大的顺序排序而组成了双向链表；而且每个⻚内的记录(不论是用户记录还是目录项记录)都是按照索引列的值从小到大的顺序而形成了一个单链表。 如果是联合索引的话，则⻚面和记录先按照联合索引前边的列排序，如果该列值相同，再按照联合索引后边的列排序。 通过索引查找记录是从B+树的根节点开始，一层一层向下搜索。由于每个⻚面都按照索引列的值建立了 Page Directory(⻚目录)，所以在这些⻚面内的查找非常快。 如果你读上边的几点结论有些任何一点点疑惑的话，那下边的内容不适合你，回过头先去看前边的内容去。 索引的代价在熟悉了B+树索引原理之后，本篇文章的主题是唠叨如何更好的使用索引，虽然索引是个好东⻄，可不能乱建，在介绍如何更好的使用索引之前先要了解一下使用这玩意儿的代价，它在空间和时间上都会拖后腿: 空间上的代价 这个是显而易⻅的，每建立一个索引都要为它建立一棵B+树， 每一棵B+树的每一个节点都是一个数据⻚，一个⻚默认会占用16KB的存储空间，一棵很大的B+树由许多数据⻚组成，那可是很大的一片存储空间呢。 时间上的代价 每次对表中的数据进行增、删、改操作时，都需要去修改各个B+树索引。因为B+树每层节点都是按照索引列的值从小到大的顺序排序而组成了双向链表。不论是叶子节点中的记录，还是内节点中的记录(也就是不论是用户记录还是目录项记录)都是按照索引列的值从小到大的顺序而形成了一个单向链表。 而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，⻚面分裂、⻚面回收啥的操作来维护好节点和记录的排序。 如果我们建了许多索引，每个索引对应的B+树都要进行相关的维护操作，这还能不给性能拖后腿么? 所以说，一个表上索引建的越多，就会占用越多的存储空间，在增删改记录的时候性能就越差。为了能建立又好又少的索引，我们先得学学这些索引在哪些条件下起作用的。 B+树索引适用的条件接下来将唠叨许多种让B+树索引发挥最大效能的技巧和注意事项。不过大家要清楚，所有的技巧都是源自你对B+树索引本质的理解，所以如果你还不能保证对B+树索引充分的理解，那么再次建议回过头把前边的内容看完了再来，要不然读文章对你来说是一种折磨。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.8 索引基本操作","date":"2021-10-14T12:29:53.000Z","path":"2021/10/14/MySQL知识点整理/6.8 索引基本操作/","text":"小结: InnoDB和MyISAM会自动为主键或者声明为UNIQUE的列去自动建立B+树索引。 但是如果我们想为其他的列建立索引就需要我们显式的去指明。 为啥不自动为每个列都建立个索引呢?别忘了，每建立一个索引都会建立一棵B+树，每插入一条记录都要维护各个记录、数据⻚的排序关系，这是很费性能和存储空间的。 创建、修改、删除 索引: 我们可以在创建表的时候指定需要建立索引的单个列或者建立联合索引的多个列: 12CREATE TALBE 表名 ( 各种列的信息 ··· ,[KEY|INDEX] 索引名 (需要被索引的单个列或多个列) ) 其中的KEY和INDEX是同义词，任意选用一个就可以。 我们也可以在 修改表结构的时候添加索引 1ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的 单个列或多个列); 也可以在修改表结构的时候删除索引: 1ALTER TABLE 表名 DROP [INDEX|KEY] 索引名; 我们创建的索引名名称可以随便起，不过我们还是建议以idx_为前缀，后边跟着需要建立索引的列名，多个列名之间用下划线_分隔开。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.7 MyISAM中的索引方案简单介绍","date":"2021-10-14T12:19:26.000Z","path":"2021/10/14/MySQL知识点整理/6.7 MyISAM中的索引方案简单介绍/","text":"前面我们介绍的都是InnoDB存储引擎中的索引方案，为了内容的完整性以及各位可能在面试时遇到这类的问题，我们有必要再简单介绍一下MyISAM存储引擎中的索引方案。 我们知道InnoDB中 索引即数据 ，也就是聚簇索引的那棵B+树的叶子节点中已经把所有完整的用户记录都包含了。而MyISAM的索引方案虽然也使用树形结构，但是却将索引和数据分开存储: MyISAM的数据文件： 它将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个数据⻚，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。 MyISAM的索引文件： 使用MyISAM存储引擎的表, 会把索引信息另外存储到一个称为 索引文件 的另一个文件中MyISAM会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是 主键值+行号 的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录!这一点和InnoDB是完全不相同的，在InnoDB存储引擎中，如果是根据主键查找数据，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录；而在MyISAM中却需要进行一次回表操作，意味着MyISAM中建立的索引相当于全部都是二级索引! 如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和InnoDB中的索引差不多，不过在叶子节点处存储的是 相应的列+行号。这些索引也全部都是二级索引。 Tips:小贴士:MyISAM的行格式有定长记录格式(Static)、变长记录格式 (Dynamic)、压缩记录格式(Compressed)。如果数据表采用的市定长记录格式，也就是一条记录占用存储空间的大小是固定的，这样就可以轻松算出某条记录在数据文件中的 地址偏移量。但是变长记录格式就不行了，MyISAM会直接在索引叶子节点处存储该条记录在数据文件中的地址偏移量。通过这个可以看出， MyISAM的回表操作是十分快速的 ，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里边儿找记录，虽然说也不慢，但还是比不上直接用地址去访问。 此处我们只是非常简要的介绍了一下MyISAM的索引，具体细节全拿出来又可以写一篇文章了。这里只是希望大家理解InnoDB中的索引即数据，数据即索引，而MyISAM中却是索引是索引、数据是数据。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.6 InnoDB B+树索引 注意事项","date":"2021-10-13T14:21:36.000Z","path":"2021/10/13/MySQL知识点整理/6.6 InnoDB B+树索引 注意事项/","text":"根⻚面万年不动窝我们前边介绍B+树索引时，为了大家理解上的方便，先把 存储用户记录的叶子节点都画出来，然后接着画 存储目录项记录 的内节点，实际上B+树的形成过程是这样的: 每当为某个表创建一个B+树索引(聚簇索引不是人为创建的， 默认就有)时，都会为这个索引创建一个根节点⻚面。 最开始表中没有数据时，每个B+树索引对应的根节点中既没有用户记录，也没有目录项记录。 随后向表中插入用户记录时，先把用户记录存储到这个 根节点 中。 当 根节点 中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的⻚，比如⻚a中，然后对这个新⻚进行⻚分裂(lant:这个算是正常的页分裂)的操作，得到另一个新⻚，比如⻚b。这时新插入的记录根据键值(也就是聚簇索引中的主键值，二级索引中对应的索引列的值)的大小就会被分配到⻚a或者⻚b中，**而根节点便升级为存储目录项记录的⻚**。 这个过程需要大家特别注意的是: 一个B+树索引的根节点自诞生之日起，便不会再移动 。 这样只要我们对某个表建立一个索引，那么 它的根节点的⻚号便会被记录到某个地方，然后凡是InnoDB存储引擎需要用到这个索引的时候，都会从那个固定的地方取出根节点的⻚号，从而来访问这个索引 。 内节点中目录项记录的唯一性我们知道B+树索引的 内节点 中 目录项记录的内容是 索引列+⻚号 的搭配，但是这个搭配对于二级索引来说有点儿不严谨。 还拿index_demo表为例，假设这个表中的数据是这样的:c1 c2 c31 1 ‘u’3 1 ‘d’5 1 ‘y’7 1 ‘a’如果二级索引中目录项记录的内容只是 索引列 + ⻚号 的搭配的话， 那么为c2列建立索引后的B+树应该⻓这样: 如果我们想新插入一行记录(其中c1、c2、c3的值分别是:9、1、’c’)，那么在修改这个为c2列建立的二级索引对应的B+树时便碰到了个大问题: 由于⻚3中存储的目录项记录是由 c2列+⻚号的值 构成的，⻚3中的两条目录项记录对应的c2列的值都是1，而我们新插入的这条记录的c2列的值也是1，那我们这条新插入的记录到底应该放到⻚4中，还是⻚5中啊? 答案是: 对不起，懵逼了。 为了让新插入记录能找到自己在哪个⻚里，我们需要保证 在B+树的同一层 内节点 的 目录项记录 除⻚号这个字段外，其他字段(作为一个整体)应该是唯一的 。所以其实二级索引的内节点(目录项记录页)中的目录项记录的内容实际上是由三个部分构成的: 索引列的值 主键值 ⻚号 也就是我们把主键值也添加到二级索引的内节点中的目录项记录了，这样就能保证 **在B+树的同一层 内节点 的 目录项记录 除⻚号这个字段外，其他字段(作为一个整体)应该是唯一的**，所以我们为c2列建立二级索引后的示意图实际上应该是:这样我们再插入记录(9, 1, ‘c’)时，由于⻚3中存储的目录项记录是由 c2列 + 主键 + ⻚号 的值构成的，可以先把新记录的c2列的值和⻚3中各目录项记录的c2列的值作比较，如果c2列的值相同的话，可以接着比较主键值，因为B+树同一层中不同目录项记录的 c2 列 + 主键 的值肯定是不一样的，所以最后肯定能定位唯一的一条目录项记录，在本例中最后确定新记录应该被插入到⻚5中。 一个⻚面最少存储2条记录","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.5 InnoDB 的联合索引","date":"2021-10-13T13:19:37.000Z","path":"2021/10/13/MySQL知识点整理/6.5 InnoDB 的联合索引/","text":"我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引。比方说我们想让B+树按照c2和c3列的大小进行排序,这个包含两层含义: 先把各个记录和⻚按照c2列进行排序； 在记录的c2列相同的情况下，采用c3列进行排序； 为c2和c3列建立的联合索引的示意图如下： 如图所示，我们需要注意以下几点: 每条目录项记录都由 c2、c3、⻚号 这三个部分组成，各条记录先按照c2列的值进行排序，如果记录的c2列相同，则按照c3列的值进行排序。 B+树叶子节点处的用户记录由 c2、c3、主键c1列组成。 千万要注意一点，以c2和c3列的大小为排序规则建立的B+树称为联合索引，本质上也是一个二级索引。它的意思与分别为c2和c3列分别建立索引的表述是不同的，建立联合索引只会建立如上图一样的1棵B+树。而为c2和c3列分别建立索引会分别以c2和c3列的大小为排序规则建立2棵B+树","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.4 InnoDB 的 二级索引及其回表操作","date":"2021-10-06T14:04:19.000Z","path":"2021/10/06/MySQL知识点整理/6.4 InnoDB 的 二级索引及其回表操作/","text":"之前介绍的 聚簇索引 只能在搜索条件是主键值时才能发挥作用 😓，因为B+树中的记录都是按照主键进行排序的。 二级索引 如果我们想以别的列作为搜索条件该咋办呢? 难道只能从头到尾沿着链表依次遍历记录么? 🤔 不，我们可以多建几棵B+树，不同的B+树中的数据采用不同的排序规则 ✅。 比方说我们用c2列的大小作为数据⻚、⻚中记录的排序规则，再建一棵B+树，效果如下图所示:这个B+树与上边介绍的聚簇索引有几处不同: 使用记录c2列的大小进行 记录 和 ⻚ 的排序，这包括三个方面的含义: ⻚内的记录是按照c2列的大小顺序排成一个单向链表； 存放用户记录的⻚之间也是根据⻚中记录的c2列大小顺序排成一个双向链表； 存放目录项记录的⻚分为不同的层次，在同一层次中的⻚也是根据⻚中目录项记录的c2列大小顺序排成一个双向链表。 B+树的叶子节点存储的并不是完整的用户记录，而只是 c2列 +主键 这两个列的值； 目录项记录中不再是主键+⻚号的搭配，而变成了 c2列+⻚号的 搭配； 所以如果我们现在想通过c2列的值查找某些记录的话就可以使用我们刚刚建好的这个B+树了。 以查找c2列的值为4的记录为例，查找过程如下: 确定目录项记录⻚根据根⻚面，也就是⻚44，可以快速定位到目录项记录所在的⻚为⻚42(因为2 &lt; 4 &lt; 9)。 通过目录项记录⻚确定用户记录真实所在的⻚。在⻚42中可以快速定位到实际存储用户记录的⻚，但是由于c2列并没有唯一性约束，所以c2列值为4的记录可能分布在多个数据⻚中，又因为2 &lt; 4 ≤ 4，所以确定实际存储用户记录的⻚在⻚34和⻚35中。在真实存储用户记录的⻚中定位到具体的记录。 到⻚34和⻚35中定位到具体的记录。 但是这个B+树的叶子节点中的记录只存储了c2和c1(也就是主键)两个列，所以我们必须再根据主键值去聚簇索引中再查找一遍完整的用户记录。 二级索引需要回表哦 各位看到上面步骤4的操作了么?我们根据这个以c2列大小排序的B+树只能确定我们要查找记录的主键值，所以如果我们想根据c2列的值查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍， 这个过程也被称为回表。 也就是根据c2列的值查询一条完整的用户记录需要使用到2棵B+树!!! 为什么我们还需要一次回表操作呢?直接把完整的用户记录放到叶子节点不就好了么? 你说的对，如果把完整的用户记录放到叶子节点是可以不用回表，但是太占地方了呀~相当于每建立一棵B+树都需要把所有的用户记录再都拷⻉一遍，这就有点太浪费存储空间了。 因为 这种按照非主键列建立的B+树需要一次回表操作才可以定位到完整的用户记录，所以这种B+树也被称为二级索引(英文名secondary index)，或者辅助索引。由于我们使用的是c2列的大小作为B+树 的排序规则，所以我们也称这个B+树为为c2列建立的索引。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.3 InnoDB 的 聚簇索引 - 索引即数据","date":"2021-10-06T10:21:31.000Z","path":"2021/10/06/MySQL知识点整理/6.3 InnoDB 的 聚簇索引 - 索引即数据/","text":"我们上边介绍的B+树索有两个特点: 使用记录主键值的大小进行记录和⻚的排序，这包括三个方面 的含义: ⻚内的记录是按照主键的大小顺序排成一个单向链表； 存放用户记录的⻚之间也是根据⻚中用户记录的主键大小顺序排成一个双向链表； 存放目录项记录的⻚分为不同的层次，在同一层次中的⻚也是根据⻚中目录项记录的主键大小顺序排成一个双向链表。 B+树的叶子节点存储的是完整的用户记录，所谓完整的用户记录，就是指这个记录中存储了所有列的值 (包括隐藏列)。 我们把具有这两种特性的B+树称为聚簇索引， 所有完整的用户记录都存放在这个聚簇索引的叶子节点处 。这种聚簇索引并不需要我们在MySQL语句中显式的使用INDEX语句去创建(后边会介绍索引相关的语句)，InnoDB存储引擎会自动的为我们创建聚簇索引。 另外有趣的一点是，在InnoDB存储引擎中， 聚簇索引就是数据的存储方式 (所有的用户记录都存储在了叶子节点)，也就是所谓的 索引即数据，数据即索引。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.2 快速查询的秘籍 - B+树索引 之 `InnoDB中的索引方案 B+树`","date":"2021-10-04T14:09:13.000Z","path":"2021/10/04/MySQL知识点整理/6.2 快速查询的秘籍 - B+树索引 之 `InnoDB中的索引方: B+树`/","text":"普通用户记录 vs 目录项记录 设计InnoDB的大叔们为了灵活管理所有目录项。他们发现这些目录项其实跟我们的用户记录也差不多，只不过目录项中的两个列是主键和⻚号而已。所以大叔们复用了之前存储用户记录的数据⻚来存储目录项，为了和用户记录做一下区分，我们把这些用来表示目录项的记录称为目录项记录。 为了区分一条记录是普通用户记录还是目录项记录呢，InnoDB 就用到了记录头信息里的record_type属性(0:普通的用户记录、1:目录项记录、2:最小记录、3:最大记录) 所以我们把前面使用到的目录项放到数据⻚中的样子就是这样: 从图中可以看出来，我们新分配了一个编号为30的⻚来专⻔存储 目录项记录。 Tips:目录项记录和普通的用户记录 除了 内容不同、记录头信息 里的 record_type 不同，还有个不同点(可参考 5.2 回顾: 行格式 之 记录头信息 的秘密) :我们之前在唠叨记录头信息时提到过一个叫 min_rec_mask的，只有在存储目录项记录的⻚中的主键值最小的目录项记录的min_rec_mask值为1，其他别的记录的min_rec_mask值都是0。 除了上述几点外，这两者就没啥差别了，它们用的是一样的数据⻚。⻚的组成结构也是一样一样的。 只有单个存储目录项记录的数据⻚时的查找 现在以查找主键为20的记录为例，查找记录的步骤就可以大致拆分成下边两步: 先到存储目录项记录的数据⻚(也就是⻚30)中，通过二分法快速定位到对应目录项 (因为12 &lt; 20 &lt; 209，所以定位到对应的记录所在的⻚就是⻚9)； 再到存储用户记录的⻚9中定位到主键值为20的用户记录。(之前多次提到的页内查找方法：O(log n) + O(1)) 大量存储目录项记录的数据⻚时的查找 虽然说目录项记录中只存储主键值和对应的⻚号，比用户记录需要的存储空间小多了，但是不论怎么说一个⻚只有16KB大小，能存放的目录项记录也是有限的，如果表中的数据太多，以至于一个数据⻚不足以存放所有的目录项记录，该咋办呢?当然是再多整一个存储目录项记录的⻚喽~ 为了大家更好的理解新分配一个目录项记录⻚的过程，我们假设一个存储目录项记录的⻚最多只能存放4条目录项记录，所以如果此时我们再向上图中插入一条主键值为320的用户记录的话，那就需要分配一个新的存储目录项记录的⻚喽:从图中可以看出，我们插入了一条主键值为320的用户记录之后需要两个新的数据⻚: 为存储该用户记录而新生成了⻚31。 因为原先存储目录项记录的⻚30的容量已满(我们前边假设只能存储4条目录项记录)，所以不得不需要一个新的⻚32来存放⻚31对应的目录项。 现在因为存储目录项记录的⻚不止一个，所以如果我们想根据主键值查找一条用户记录大致需要3个步骤，以查找主键值为20的记录为例: 确定目录项记录⻚ 我们现在的存储目录项记录的⻚有两个，即⻚30和⻚32，又因为⻚30表示的目录项的主键值的范围是[1, 320)，⻚32表示的目录项的主键值不小于320，所以主键值为20的记录对应的目录项记录在⻚30中。 在一个存储目录项记录的⻚中通过主键值定位一条目录项记录的方式说过了，不赘述了~ 在真实存储用户记录的⻚中定位到具体的记录。 也多次提过了，不赘述了~ B+树 那么问题又来了:在这个查询步骤的第1步中我们需要定位 存储目录项记录的⻚，但是这些⻚在存储空间中也可能不挨着，如果我们表中的数据非常多则会产生很多存储目录项记录的⻚，那我们怎么根据主键值快速定位一个存储目录项记录的⻚呢?其实也简单， 为这些存储目录项记录的⻚再生成一个更高级的目录 ，所以现在各个⻚的 示意图就是这样子:如图，我们生成了一个存储更高级目录项的⻚33，这个⻚中的两条记录分别代表⻚30和⻚32，如果用户记录的主键值在[1, 320)之间，则到⻚30中查找更详细的目录项记录，如果主键值不小于320的话，就到⻚32中查找更详细的目录项记录。 不过，随着表中记录的增加，这个目录的层级会继续增加，如果简化一下，这玩意儿就像一个倒过来的树，上头是树根，下头是树叶! 这种组织数据的形式，或者说是一种数据结构，它的名称是B+树。 不论是存放用户记录的数据⻚，还是存放目录项记录的数据⻚，我们都把它们存放到B+树这个数据结构中了，所以我们也称这些数据⻚为节点。从图中可以看出来，我们的实际用户记录其实都存放在B+树的最底层的节点上，这些节点也被称为叶子节点或叶节点，其余用来存放目录项记录的节点称为非叶子节点或者内节点，其中B+树最上边的那个节点也称为根节点。 从图中可以看出来，一个B+树的节点其实可以分成好多层，设计InnoDB的大叔们为了讨论方便，规定最下边的那层，也就是存放我们用户记录的那层为第0层，之后依次往上加。 之前的讨论我们做了一个非常极端的假设:存放用户记录的⻚最多存放3条记录，存放目录项记录的⻚最多存放4条记录。其实真实环境中一个⻚存放的记录数量是非常大的 假设，假设，假设所有存放用户记录的叶子节点代表的数据⻚可以存放100条用户记录，所有存放目录项记录的内节点代表的数据⻚可以存放1000条目录项记录，那么: 如果B+树只有1层，也就是只有1个用于存放用户记录的节点，最多能存放100条记录。 如果B+树有2层，最多能存放1000×100&#x3D;100000条记录。 如果B+树有3层，最多能存放1000×1000×100&#x3D;100000000 条记录。 如果B+树有4层，最多能存放1000×1000×1000×100&#x3D;100000000000条记录。 你的表里能存放100000000000条记录么?所以一般情况下，我们用到的B+树都不会超过4层，那我们通过主键值去查找某条记录最多只需要做4个⻚面内的查找(查找3个目录项⻚和1个用户记录⻚)，又因为在每个⻚面内有所谓的Page Directory(⻚目录)，所以在⻚面内也可以通过二分法实现快速定位记录，这不是很牛么，哈哈!","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.1 快速查询的秘籍 - B+树索引 之 简易目录(索引的雏形)","date":"2021-10-04T12:17:57.000Z","path":"2021/10/04/MySQL知识点整理/6.1 快速查询的秘籍 - B+树索引 之 简易目录(索引的雏形)/","text":"Demo表 为了故事的顺利发展，我们先建一个表:mysql&gt; CREATE TABLE index_demo( c1 INT,-&gt; c2 INT,-&gt; c3 CHAR(1),-&gt; PRIMARY KEY(c1)-&gt; ) ROW_FORMAT = Compact;-&gt; Query OK, 0 rows affected (0.03 sec) 这个新建的index_demo表中有2个INT类型的列，1个CHAR(1)类型的列，而且我们规定了c1列为主键。 这个表是使用Compact行格式来实际存储记录的。为了我们理解上的方便，我们简化了一下 index_demo表 的行格式示意图: record_type: 记录头信息的一个属性，表示记录的类型：0 表示普通记录、2表示最小记录、3表示最大记录、1我们还没用过，等会再说~ next_record: 记录头信息的一个属性，表示下一条地址相对于本条记录的地址偏移量，为了方便大家理解，我们都会用箭头来表明下一条记录是谁。 各个列的值: 这里只记录在index_demo表中的三个列，分别是c1、c2和c3。 其他信息:除了上述3种信息以外的所有信息，包括其他隐藏列的值以及记录的额外信息。 我们之后的示意图中会把 记录的其他信息 这个部分省略掉，因为它占地方并且不会有什么观赏效果: 把一些记录放到⻚里边的示意图就是: 一个简单的索引方案 现在我们已经知道，当我们根据某个搜索条件查找一些记录时，首先需要遍历所有的数据⻚ O(n)，然后再在每个数据页内利用 pagedirectory二分法定位槽 O(logn) + 组内遍历单链表 O(1) 进行记录的匹配。 所以… 效率问题目前是出在第一步，也就是在所有数据页中快速定位我们需要的页。还记得我们 通过主键 在 页内查找 时为了快速定位一条记录在⻚中的位置而设立的 ⻚目录 么?我们也可以想办法为快速定位记录所在的 数据⻚ 而建立一个别的目录，不过，要建这个目录必须完成下边的事儿； 数据页可以像页内记录那样也按主键顺序排列下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值。 页分裂问题： 😱 为了故事的顺利发展，我们这里需要做一个假设: 假设我们的每个数据⻚最多能存放3条记录(实际上一个数据⻚非常大，可以存放下好多记录)。 有了这个假设之后，如果我们向index_demo表插入4条记录，因为⻚10最多只能放3条记录，所以我们不得不再分配一个新⻚:你可以看到，新分配的数据页的页号并不是11，而是28这是因为我们使用的这些⻚在存储空间里可能并不挨着。它们只是通过维护着上一个⻚和下一个⻚的编号而建立了链表关系。另外，⻚10中用户记录最大的主键值是5，而⻚28中有一条记录的主键值是4，因为5 &gt; 4，所以不符合下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值的要求，**所以在插入主键值为4的记录时需要伴随着一次记录移动**，也就是把主键值为5的记录移动到⻚28中，然后再把主键值为4的记录插入到⻚10中，这个过程的示意图如下: 这个过程表明了在对⻚中的记录进行增删改操作的过程中， 我们必须通过一些诸如 记录移动的操作 来始终保证这个状态一直成立 : 下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值。这个过程我们也可以称为 **⻚分裂**。(lant:所以，所以这也说明了，主键为什么我们一般设置自增的，最好不要乱动主键，因为如果要保证“下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值”的要求，逐渐最好自增，不然就会经常出现页分裂，这显然是个低效的动作。即便要删除记录，我们最好也是给记录标记一个删除状态即可。) 数据页也可以像页内记录那样也有一个 Page Directory 页目录 由于数据⻚的编号可能并不是连续的，所以在向index_demo 表中插入许多条记录后，可能是这样的效果: 如果想从更大量的⻚中根据主键值快速定位某些记录所在的⻚，我们也可以给这些页做个目录，每个⻚对应一个目录项，每个目录项包括下边两个部分: ⻚的用户记录中最小的主键值，我们用key来表示。 ⻚号，我们用page_no表示。所以我们为上边几个⻚做好的目录就像这样子: 以⻚28为例，它对应目录项2，这个目录项中包含着该⻚的⻚号28以及该⻚中用户记录的最小主键值5。比方说我们想找主键值为20的记录，具体查找过程分两步: 先从目录项中根据二分法快速确定出主键值为20的记录在目录项3中，它对应的⻚是 ⻚9。 再根据前边说的在⻚中查找记录的方式去⻚9中定位具体的记录。 由一个个的目录项组成的类似书籍中的简易目录，其实就是索引的雏形 至此，针对数据⻚做的简易目录就搞定了。不过忘了说了，这个目录有一个别名，称为索引。 所以：上一篇讲的，数据页内，为许多记录设计的目录，叫 页目录；本篇讲的，为许多数据页设计的目录，叫 索引；","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.0 没有索引时，如何查找数据？","date":"2021-10-04T11:53:21.000Z","path":"2021/10/04/MySQL知识点整理/6.0 没有索引时，如何查找数据？/","text":"没有索引的查找本集的主题是索引，在正式介绍索引之前，我们需要了解一下没有索引时是怎么查找记录的。为了方便理解，下边先只唠叨搜索条件为对某个列精确匹配的情况，如：SELECT [列名列表] FROM 表名 WHERE 列名 = xxx; 在单个数据页中的查找 假设目前表中的记录比较少，所有的记录都可以被存放到一个⻚中。在查找记录的时候可以根据搜索条件的不同分为两种情况: 以主键为搜索条件 (😄 O(log n) + O(1) &#x3D; O(log n))可参考 5. 7 前情回顾: 数据页、目录页、槽、(页内)分组、记录 以其他列作为搜索条件 (😭 O(n))对非主键列的查找的过程可就不这么幸运了，因为在数据⻚中并没有对非主键列建立所谓的⻚目录，所以我们无法通过二分法快速定位相应的槽。这种情况下只能从最小记录开始依次遍历单链表中的每条记录，然后对比每条记录是不是符合搜索条件。很显然，这种查找的效率是非常低的。 所以结论就是：在单个数据页内 主键查找可以使用 “二分找槽 + 页内遍历”；(😄 O(log n) + O(1) &#x3D; O(log n)) 非主键查找还无法做到快速查找；(😭 O(n)) 在很多⻚中查找 大部分情况下我们表中存放的记录都是非常多的，需要好多的 数据⻚ 来存储这些记录。在很多⻚中查找记录的话可以分为两个步骤: 定位到记录所在的⻚； ⻚内查找； (这个前面已经多次提过了) 现在问题就是第1步了，如何定位记录所在的页?由于目前我们还没有讲什么方法去快速的定位到记录所在的⻚，所以只能从第一个⻚沿着双向链表一直往下找; 这种遍历所有数据⻚的方式显然是超级耗时的，如果一个表有一亿条记录，使用这种方式去查找记录那要等到猴年⻢月才能等到查找结果。（定位页的操作，时间复杂度此时成了 O(n)，显然很低效 ）所以祖国和人⺠都在期盼一种能高效完成搜索的方法，索引同志就要亮相登台了。 小结lant: 所以…… 到了这里，我们应该清楚： 索引 这个方案 是为了：当数据量很大时(InnoDB会用到大量的数据页)，在 大量的 数据页 中高效定位到 某个数据页； Page Directory、槽(对应分组) 是为了：在页内高效定位到某行记录（在页的目录页中通过二分法定位槽(页内分组) + 分组内遍历）。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.7 前情回顾 数据页、目录页、槽、(页内)分组、记录","date":"2021-10-02T02:21:43.000Z","path":"2021/10/02/MySQL知识点整理/5.7 前情回顾 数据页、目录页、槽、(页内)分组、记录/","text":"前情回顾: 数据页、目录页、槽、(页内)分组、记录 之间的关系 前边我们详细唠叨了InnoDB数据⻚的7个组成部分，知道了: 各个数据⻚ 可能在物理结构上并不相连，而是通过双向链表相关联； 而每个数据⻚中的记录会按照主键值从小到大的顺序组成一个单向链表； 数据页、目录页、槽、(页内)分组、记录 之间的关系 回顾: 每个数据页内的记录，会被分成一个个的(页内)分组； 每个分组中的记录也都是按照主键值从小到大由单链表串联起来的(页内记录本来就是这样串联的)； 每个分组中的最大记录的地址偏移量被叫做槽 （由于槽就是分组中最大那条记录的地址偏移量，所以槽其实也就指向(代表)了对应分组中的最大那条记录的主键值）； 每个分组对应的槽都被放到了页内一个叫页目录的地方； 在某个页中 通过主键查找某条记录的时候: 可以先在⻚目录中使用二分法快速定位到对应的槽 (O(log n)) 然后再遍历该槽对应分组中的记录，即可快速找到指定的记录(O(1))。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.6 `通用页`结构 之 File Trailer(文件尾)部分","date":"2021-09-29T13:37:31.000Z","path":"2021/09/29/MySQL知识点整理/5.6 通用页结构 之 File Trailer(文件尾)部分/","text":"通用页结构 之 File Trailer(文件尾)部分 File Trailer(文件尾) 部分和 File Header 部分 一样，都是所有类型的⻚通用的。 我们知道InnoDB存储引擎会把数据存储到磁盘上，但是磁盘速度太慢，需要以⻚为单位把数据加载到内存中处理，如果该⻚中的数据在内存中被修改了，那么在修改后的某个时间需要把数据同步到磁盘中。**但是在同步了一半的时候中断电了咋办，这不是莫名尴尬么?** 为了检测一个⻚是否完整(也就是在同步的时候有没有发生只同步一半的尴尬情况)，设计InnoDB的大叔们在每个⻚的尾部都加了一个File Trailer部分，这个部分由8个字节组成，可以分成2个小部分: **前4个字节代表⻚的校验和**：这个部分是和 File Header 中的校验和相对应的。每当一个⻚在内存中修改了，在同步之前就要把它的校验和算出来，因为File Header在⻚面的前边，所以校验和会被首先同步到磁盘，当完全写完时，校验和也会被写到⻚的尾部，如果完全同步成功，则⻚的首部和尾部的校验和应该是一致的。如果写了一半儿断电了，那么在File Header中的校验和就代表着已经修改过的⻚，而在File Trialer中的校验和代表着原先的⻚，二者不同则意味着同步中间出了错。 后4个字节代表⻚面被最后修改时对应的日志序列位置(LSN)这个部分也是为了校验⻚的完整性的，只不过我们目前还没说LSN是个什么意思，所以大家可以先不用管这个属性。 这个File Trailer与FILE Header类似，都是所有类型的⻚通用的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.5 `通用页`结构 之 File Header(文件头)部分","date":"2021-09-28T14:07:14.000Z","path":"2021/09/28/MySQL知识点整理/5.5 通用页结构 之 File Header(文件头)部分/","text":"通用页结构 之 File Header(文件头)部分 上一篇讲的 数据页结构的Page Header部分 是 专⻔针对 页类型为 数据⻚ 的这种页。 它的各个属性描述了 数据页 中的记录的各种状态信息，比方说⻚里头有多少个记录了呀，有多少个槽了呀。 而我们现在讲到的 页结构的File Header部分 是属于各种类型的⻚都通用的部分，它描述了一些针对各种⻚都通用的一些信息，比方说 这个⻚的编号是多少，它的上一个⻚、下一个⻚是谁 ……这个部分占用固定的38个字节，是由下边这些内容组成的: 名称 占用空间 描述 📌 FIL_PAGE_SPACE_OR_CHKSUM 4字节 页的校验和(checksum值) ✅ FIL_PAGE_OFFSET 4字节 页号 ✅ FIL_PAGE_PREV 4字节 上一个页的页号 ✅ FIL_PAGE_NEXT 4字节 下一个页的页号 FIL_PAGE_LSN 8字节 页面被最后修改时对应的日志序列(LSN)位置(log sequence number) ✅ FIL_PAGE_TYPE 2字节 该⻚的类型 FIL_PAGE_FILE_FLUSH_LSN 8字节 仅在系统表空间的一个⻚中定义，代表文件至少被刷新到了对应的LSN值 FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID 4字 ⻚属于哪个表空间 对照着这个表格，我们看几个目前比较重要的部分:FIL_PAGE_SPACE_OR_CHKSUM:这个属性代表当前⻚面的校验和(checksum)。啥是校验和?就是对于一个很⻓很⻓的字节串来说，我们会通过某种算法计算出一个比较短的值来代表这个很⻓的字节串，这个比较短的值就称为校验和。**这样在比较两个很⻓的字节串之前先比较这两个⻓字节串的校验和，如果校验和都不一样两个⻓字节串肯定是不同的，所以省去了直接比较两个比较⻓的字节串的时间损耗**。 FIL_PAGE_OFFSET:每一个⻚都有一个单独的⻚号，InnoDB通过⻚号来可以唯一定位一个⻚。 FIL_PAGE_TYPE:这个代表当前⻚的类型，我们前边说过，InnoDB为了不同的目的而把⻚分为不同的类型，我们上边介绍的其实都是存储记录的数据⻚，其实还有很多别的类型的⻚。(我们存放记录的数据⻚的类型其实是FIL_PAGE_INDEX，也就是所谓的索引⻚。至于啥是个索引，且听下回分解~) FIL_PAGE_PREV 和 FIL_PAGE_NEXT:我们前边强调过，InnoDB是以⻚为单位存放数据的，有时候我们存放的数据占用的空间非常大(比如一张表中可以有成千上万条记录)，InnoDB可能不可以一次性为这么多数据分配一个非常大的存储空间，如果分散到多个不连续的⻚中存储的话需要把这些⻚关联起来，FIL_PAGE_PREV和 FIL_PAGE_NEXT就分别代表本⻚的上一个和下一个⻚的⻚号。这样**通过建立一个双向链表把许许多多的⻚就都串联起来 了**，而无需这些⻚在物理上真正连着。(Tips: 也不是所有类型的⻚都有上一个和下一个⻚的属性，不过我们本集中唠叨的数据⻚(也就是类型为FIL_PAGE_INDEX的⻚)是有这两个属性的）。所以所有的数据⻚其实是一个双链表，就像这样: 关于File Header的其他属性我们暂时用不到，等用到的时候再提~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.4 `数据页`结构 之 Page Header(页面头部)部分","date":"2021-09-26T13:46:53.000Z","path":"2021/09/26/MySQL知识点整理/5.4 数据页结构 之 Page Header(页面头部)部分/","text":"数据页结构 之 Page Header(页面头部)部分 设计InnoDB的大叔们为了能得到某个数据⻚中存储的记录的状态信息，比如 本⻚中已经存储了多少条记录、第一条记录的地址是什么、⻚目录中存储了多少个槽(通过页目录中的槽的数量，其实也就能知道本页面被分出了多少个分组) 等信息……。大叔们特意在⻚中定义了一个叫 Page Header的部分，页结构的这个部分占用固定的56个字节，通过多个属性专⻔来存储各种状态信息: 名称 占用空间 描述 ✅ PAGE_N_DIR_SLOTS 2字节 页目录中槽的数量 ✅ PAGE_HEAP_TOP 2字节 还未使用空间的起始地址，你自然能明白，该地址之后就是 页结构的 Free Space 部分了 ✅ PAGE_N_HEAP 2字节 本⻚中的记录数量(包括最小和最大记录以及标记为删除的记录) ✅ PAGE_FREE 2字节 第一个已经标记为删除的记录地址(各个已删除的记录通过next_record也会组成一个单链表) ✅ PAGE_GARBAGE 2字节 已删除记录占用的字节数 ✅ PAGE_LAST_INSERT 2字节 最后插入记录的位置 PAGE_DIRECTION 2字节 记录插入的方向 PAGE_N_DIRECTION 2字节 一个方向连续插入的记录数量 ✅ PAGE_N_RECS 2字节 本⻚中的记录数量(不包括最小和最大记录以及被标记为删除的记录) PAGE_MAX_TRX_ID 8字节 修改当前⻚的最大事务ID，该值仅在二级索引中定义 📌 PAGE_LEVEL 2字节 当前⻚在B+树中所处的层级 PAGE_INDEX_ID 8字节 索引ID，表示当前页属于哪个索引 PAGE_BTR_SEG_LEAF 10字节 B+树叶子节点段的头部信息，尽在B+树的Root页定义 PAGE_BTR_SEG_TOP 10字节 B+树非叶子节点段的头部信息，尽在B+树的Root页定义 如果大家认真看过前边的文章，从 PAGE_N_DIR_SLOTS 到 PAGE_LAST_INSERT 以及 PAGE_N_RECS 的意思大家一定是清楚的。⚠️ 如果不清楚，对不起，你应该回头再看一遍前边的文章。⚠️ 剩下的状态信息看不明白不要着急，饭要一口一口吃，东⻄要一点一点学 (一定要稍安勿躁哦，不要被这些名词吓到)。 接下来我们先唠叨一下 PAGE_DIRECTION 和 PAGE_N_DIRECTION 的意思: PAGE_DIRECTION:假如新插入的一条记录的主键值比上一条记录的主键值大，我们说这条记录的插入方向是右边，反之则是左边。用来表示最后一条记录插入方向的状态就PAGE_DIRECTION。 PAGE_N_DIRECTION:假设连续几次插入新记录的方向都是一致的，InnoDB会把沿着同一个方向插入记录的条数记下来，这个条数就用 PAGE_N_DIRECTION 这个状态表示。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。(🤔TODO :目前是能读懂意思，至于用途嘛…暂时还不明白) 至于上面还没提到的那些状态属性，现在大家还不需要知道。不要着急，当我们学完了后边的内容，你再回头看，一切都是那么清晰。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.3 `数据页`结构 之 Page Directory(⻚目录) 部分","date":"2021-09-25T06:36:09.000Z","path":"2021/09/25/MySQL知识点整理/5.3 数据页结构 之 Page Directory(⻚目录) 部分/","text":"数据页结构 之 Page Directory&#96;(⻚目录) 部分单链表存储数据记录的低效问题现在我们已经知道， 记录在⻚中是按照主键值由小到大顺序串联成一个单链表放在 UserRecords 部分的 。 那如果我们想根据主键值查找⻚中的某条记录该咋办? 最笨的办法: 从 Infimum记录(最小记录)开始，沿着链表一直往后找，总有一天会找到(或者找不到)，在找的时候还能投机取巧，因为链表中各个记录的值是按照从小到大顺序排列的，所以当链表的某个节点代表的记录的主键值大于你想要查找的主键值时，你就可以停止查找了。 这个方法在⻚中存储的记录数量比较少的情况用起来也没啥问题，但是如果一个⻚中存储了非常多的记录，这么查找对性能来说还是有损耗的，所以我们说这种遍历查找这是一个笨办法。（ 时间复杂度很显然是 O(n) ） 索引页结构 之 Page Directory 设计InnoDB的大叔们自然不会用上面那种笨办法，他们从现实中的书籍目录中找到了灵感。他们为我们的记录也制作了一个类似的目录，他们的制作过程是这样的: 将所有正常的记录(包括页内的最大和最小记录，不包括标记为已删除的记录) 划分为几个组 ； 每个组的最后一条记录(也就是组内最大的那条记录)的头信息中的n_owned属性表示该组内共有几条记录； 将每个组内最后一条记录的地址偏移量单独提取出来并且还按主键顺序存储到靠近⻚的尾部的地方，这个地方就是所谓的 Page Directory，也就是⻚目录。⻚目录中的这些地址偏移量被称为槽(英文 名:Slot)，所以这个⻚目录就是由槽组成的。 比方说现在的page_demo表中正常的记录共有6条，InnoDB会把它们分成两组，第一组中只有一个最小记录，第二组中是剩余的5条记录，看下边的示意图:现在⻚目录部分中有两个槽，也就意味着我们的记录被分成了两个组:槽1中的值是112，代表最大记录(组内最后一条记录)的地址偏移量(就是从⻚面的0字节开始数，数112个字节);槽0中的值是99，代表最小记录(组内最后一条记录)的地址偏移量。 注意上面两个分组中最后一条记录的头信息中的 n_owned 属性：在第一个分组中，只有最小记录这一条记录，它的记录头信息的n_owned属性值为1，这就代表着以最小记录结尾的这个分组中只有1条记录；在第二个分组中，最后一条记录(此处是最大记录)的n_owned值为5，这就代表着以最大记录结尾的这个分组中有5条记录。 99和112这样的地址偏移量很不直观，我们用箭头指向的方式替代数字，这样更易于我们理解，所以修改后的示意图就是这样:不过上面的图看上去还是怪不好看的，我们就单纯从逻辑上对图做点改动:这样看就顺眼多了。 还有个问题，那就是为什么最小记录的n_owned值为1，而最大记录的n_owned值为5呢，这里头有什么猫腻么?这是因为，设计InnoDB的大叔们对每个分组中的记录条数是有规定的: 对于最小记录所在的分组只能有 1 条记录； 最大记录所在的分组拥有的记录条数只能在 1~8 条之间； 其他的分组中记录的条数范围只能在是 4~8 条之间。 所以分组是按照下边的步骤进行的: 初始情况下一个数据⻚里只有最小记录和最大记录两条记录，它们分属于两个分组。 之后每插入一条记录，都会从⻚目录中找到主键值比本记录的主键值大并且差值最小的槽（页目录中哪儿有主键值？页目录中不是 每个分组的最后一条记录的偏移量 即 槽 么？ 这是因为从本质上来说，通过槽就可以直接找到某个组内最后一条记录的主键 ），然后把该槽对应的记录的n_owned值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。 在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录。这个过程会在⻚目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。 由于现在page_demo表中的记录太少，无法演示添加了⻚目录之后加快查找速度的过程，所以我们一口气又往表中添加了12条记录，现在⻚里边就一共有18 条记录了(包括最小和最大记录)，这些记录被分成了5个组，如图 所示:因为把16条记录的全部信息都画在一张图里太占地方，图中只保留了用户记录头信息中的n_owned和next_record属性，也省略了各个记录之间的箭头! 现在看怎么使用⻚目录来查找记录因为各个槽代表的是每个分组中最后一条记录的主键值，也就是说 槽 代表的主键当然也是从小到大排序的(分组内的记录不必多说，肯定是按照主键从小到大排序的)，所以我们可以在页目录中使用二分法快速定位我们要查找的记录的主键在哪个分组中。 4个槽的编号分别是:0、1、2、3、4，所以初始情况下最低的槽就是low&#x3D;0，最高的槽就是high&#x3D;4。比方说我们想找主键值为6的记录，过程是这样的: 计算中间槽的位置:(0+4)&#x2F;2&#x3D;2，所以查看槽2对应记录的主键值为8，又因为8 &gt; 6，所以设置high&#x3D;2，low保持不变。 重新计算中间槽的位置:(0+2)&#x2F;2&#x3D;1，所以查看槽1对应的主键值为4，又因为4 &lt; 6，所以设置low&#x3D;1，high保持不变。 因为high - low的值为1，所以确定主键值为5的记录在槽2对应的组中。 此刻我们需要找到槽2中主键值最小的那条记录，然后沿着单向链表遍历槽2中的记录。但是我们前边又说过，每个槽对应的记录都是该组中主键值最大的记录，这里槽2对应的记录是主键值为8的记录，怎么定位一个组中最小的记录呢?别忘了各个槽都是挨着的，我们可以很轻易的拿到槽1对应的记录(主键值为4)，该条记录的下一条记录就是槽2中主键值最小的记录，该记录的主键值为5。所以我们可以从这条主键值为5的记录出发，遍历槽2中的各条记录，直到找到主键值为6的那条记录即可。由于一个组中包含的记录条数只能是1~8条，所以遍历一个组中的记录的代价是很小的。 所以在一个数据⻚中查找指定主键值的记录的过程分为两步:**通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录**。(时间复杂度是 O(log n))通过记录的 记录头信息中的next_record属性遍历该槽所在的组中的各个记录 （每个分组中的记录数比较少，属于常量级别，所以时间复杂度是 O(1) ）。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.2 回顾 行格式 之 记录头信息 的秘密","date":"2021-09-24T05:31:16.000Z","path":"2021/09/24/MySQL知识点整理/5.2 回顾: 行格式 之 记录头信息 的秘密/","text":"为了故事的顺利发展，我们先创建一个表:mysql&gt; CREATE TABLE page_demo( -&gt; c1 INT, -&gt; c2 INT, -&gt; c3 VARCHAR(10000), -&gt; PRIMARY KEY (c1) -&gt; ) CHARSET=ascii ROW_FORMAT=Compact; Query OK, 0 rows affected (0.03 sec) 这个新创建的page_demo表有3个列，其中c1和c2列是用来存储整数的，c3列是用来存储字符串的。需要注意的是，我们把 c1 列指定为主键，所以在具体的行格式中InnoDB就没必要为我们去创建那个所谓的 row_id 隐藏列了。而且我们为这个表指定了ascii字符集以及Compact的行格式。所以这个表中记录的行格式示意图就是这样的: 我们再次先把这些记录头信息中各个属性的大体意思浏览一下(这里仍然使用Compact行格式进行演示): 为了进一步方便大家分析这些记录在⻚的User Records部分中是怎么表示的，我把记录中头信息和实际的列数据都用十进制表示出来了(其实是一堆二进制位)，这些记录的示意图如下:我们对照着这个图来看看记录头信息中的各个属性是啥意思。 delete_mask 这个属性标记着当前记录是否被删除，占用1个二进制位，值为0的时候代表记录并没有被删除，为1的时候代表记录被删除掉了。 这些被删除的记录之所以不立即从磁盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗，所以只是打一个删除标记，所有被删除的记录会组成一个所谓的垃圾链表，在这个链表中的记录占用的空间称之为可重用空间，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。 Tips：将这个delete_mask位设置为1 和 将被删除的记录加入到垃圾 链表中 其实是两个阶段，我们后边在介绍事务的时候会详细唠叨删除操作的详细过程，稍安勿躁。 min_rec_mask B+树的每层非叶子节点中的最小记录都会添加该标记。 什么是个B+树? 什么是个非叶子节点?好吧，别着急，等会儿再聊这个问题。 反正我们自己插入的四条记录的min_rec_mask值都是0，意味着它们都不是B+树的非叶子节点中的最小记录。 n_owned这个暂时保密，稍后它是主⻆~ heap_no 这个属性表示当前记录在本⻚中的位置。 从图中可以看出来， 我们插入的4条记录在本⻚中的位置分别是: 2、3、4、5。可怎么不⻅heap_no值为0和1的记录呢?这其实是设计InnoDB的大叔们玩的一个小把戏，他们自动给每个⻚里加了两个记录，由于这两个记录并不是我们自己插入的，所以有时候也称为伪记录或者虚拟记录。这两个伪记录一个代表最小记录，一个代表最大记录。 等一下哈~，记录可以比大小么?是的，记录也可以比大小，对于一条完整的记录来说，比较记录的大小就是比较主键的大小。比方说我们插入的4行记录的主键值分别是:1、2、3、4，这也就意味着这4条记录是从小到大依次递增。 但是不管我们向⻚中插入了多少自己的记录，设计InnoDB的大叔们都规定他们定义的两条伪记录分别为最小记录与最大记录。这两条记录的构造十分简单，都是由5字节大小的记录头信息和8字节大小的一个固定的部分组成的，如图所示： 由于这两条记录不是我们自己定义的记录，所以它们并不存放在⻚的User Records部分，他们被单独放在一个称为 Infimum + Supremum的部分，如下图所示: record_type 这个属性表示当前记录的类型，一共有4种类型的记录：0表示：普通记录1表示：B+树非叶节点记录2表示：最小记录3表示：最大记录 从图中我们也可以看出来，我们自己插入的记录就是普通记录，它们的record_type值都是0，而最小记录和最大记录的record_type值分别为2和3。至于record_type为1的情况，我们之后在说索引的时候会重点强调的。 next_record 这玩意儿非常重要，它表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。比方说第一条记录的 next_record 值为32，意味着从第一条记录的真实数据的地址处向后找32个字节便是下一条记录的真实数据。如果你熟悉数据结构的话，就立即明白了，这其实是个链表，可以通过一条记录找到它的下一条记录。 但是需要注意注意再注意的一点是，下一条记录指得并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。而且规定Infimum记录(也就是最小记录) 的下一条记录就是本⻚中主键值最小的用户记录，而本⻚中主键值最大的用户记录的下一条记录就是 Supremum记录(也就是最大记录) 。为了更形象的表示一下这个next_record起到的作用，我们用箭头来替代一下next_record中的地址偏移量: 从图中可以看出来，我们的记录按照主键从小到大的顺序形成了一个单链表。最大记录的next_record的值为0，这也就是说最大记录是没有下一条记录了，它是这个单链表中的最后一个节点。 如果从中删除掉一条记录，这个链表也是会跟着变化的，比如我们把第2条记录删掉后的示意图就是:从图中可以看出来，删除第2条记录前后主要发生了这些变化: 第2条记录并没有从存储空间中移除，而是把该条记录的delete_mask值设置为1。 第2条记录的next_record值变为了0，意味着该记录没有下一条记录了。 第1条记录的next_record指向了第3条记录。 还有一点你可能忽略了，就是最大记录的n_owned值从5变成了4，关于这一点的变化我们稍后会详细说明的。 再来看一个有意思的事儿，因为主键值为2的记录被我们删掉了，但是存储空间却没有回收，如果我们再次把这条记录插入到表中，会发生什么事呢? InnoDB并没有因为新记录的插入而为它申请新的存储空间，而是直接复用了原来被删除记录的存储空间。 所以，不论我们怎么对⻚中的记录做增删改操作，InnoDB始终会维护一条 由记录组成的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.1 `数据页` 结构 之 User Records、Free Space 部分","date":"2021-09-23T15:12:10.000Z","path":"2021/09/23/MySQL知识点整理/5.1 数据页结构 之 User Records、Free Space 部分/","text":"数据页 结构 之 User Records、Free Space 部分 在索引⻚的7个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到 User Records 部分。 但是在一开始生成⻚的时候，其实并没有 User Records 这个部分，每当我们插入一条记录，都会从 Free Space 部分(也就是尚未使用的存储空间中)申请一个记录大小的空间划分到 User Records 部分，当 Free Space 部分的空间全部被 User Records 部分替代掉之后，也就意味着这个⻚使用完了，如果还有新的记录插入的话，就需要去申请新的⻚了，这个过程的图示如下: 为了更好的管理 User Records中的这些记录，InnoDB可费了一番力气呢，在哪费力气了呢? 不就是把记录按照指定的行格式一条一条摆在User Records部分么? 其实这话还得从记录行格式的记录头信息中说起。(回顾：4.1 compact 行格式，当时在提到 记录头信息 时，只是简单地了解了 记录头信息 的基本构成)，下面就着重看下之前学的行格式的知识中的记录头信息部分的秘密吧。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.0 盛放记录的大盒子 - InnoDB的数据页结构","date":"2021-09-23T13:25:09.000Z","path":"2021/09/23/MySQL知识点整理/5.0 盛放记录的大盒子 - InnoDB的数据页结构/","text":"不同类型的页简介 前边已经简单提到过 ⻚ 的概念了， 它是InnoDB管理存储空间的基本单位 ，一个⻚的大小一般是16KB。 InnoDB为了不同的目的而设计了许多种不同类型的⻚，比如 存放 表空间头部信息 的⻚、存放 Insert Buffer信息 的⻚、存放 INODE信息 的⻚、存放 undo日志信息 的⻚ 等等…… 当然，如果这些名词你一个都没有听过也无所谓~~~目前暂时还不准备说这些类型的⻚。我们聚焦的是那些存放我们表中记录的那种类型的⻚，官方称这种存放记录的⻚为索引(INDEX)⻚，鉴于我们还没有了解过索引是个什么东⻄，而这些表中的记录就是我们日常口中所称的数据，所以目前还是叫这种存放记录的⻚为数据⻚吧。 索引(INDEX)⻚的结构概括 数据⻚的16KB存储空间可以被划分为多个部分，不同部分有不同的功能: 可以看出，一个InnoDB数据⻚的存储空间大致被划分成了7个部分，有的部分占用的字节数是确定的，有的部分占用的字节数是不确定的。 下边我们用表格的方式来大致描述一下这7个部分都存储一些啥内容(快速的瞅一眼就行了，后边会详细唠叨的): 名称 中文名 占用空间大小 简单描述 👌 File Header 文件头部 38字节 ⻚的一些通用信息(所有类型的页都有这个不分) ✅ Page Header ⻚面头部 56字节 数据⻚这种页类型专有的一些信息 ✅ Infimum + Supremum 最小记录和最大记录 26字节 两个虚拟的行记录 ✅ *User Records 用户记录 不确定 实际存储的行记录内容 ✅ Free Space 空闲空间 不确定 ⻚中尚未使用的空间 ✅ Page Directory ⻚面目录 不确定 ⻚中的某些记录的相对位置 👌 File Trailer 文件尾部 8字节 校验⻚是否完整 不过，我们接下来并不打算按照⻚中各个部分的出现顺序来依次介绍它们，因为各个部分中会出现很多大家目前不理解的概念，这会打击 各位读文章的信心与兴趣，希望各位能接受这种拍摄手法~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.4 CHAR(M)中的M值过大的情况","date":"2021-09-21T11:51:16.000Z","path":"2021/09/21/MySQL知识点整理/4.4 CHAR(M)中的M值过大的情况/","text":"CHAR(M)中的M值过大的情况 CHAR(M)类型的列所占用的最大字节⻓度等于 该列使用的字符集表示一个字符需要的最大字节数和M的乘积。 如果某个列使用的是CHAR(M)类型，并且它存储的最大字节⻓度超过768字节，那么不论我们使用的是之前讲过的4种行格式中的哪种，InnoDB都会把该列当成变⻓字段看待。比方说采用utf8mb4的CHAR(255)类型的列将会被当作变⻓字段看待，因为 4×255 &gt; 768。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.3 Dynamic 和 Compressed 行格式","date":"2021-09-21T11:11:27.000Z","path":"2021/09/21/MySQL知识点整理/4.3 Dynamic 和 Compressed 行格式/","text":"Dynamic 和 Compressed 行格式 我现在使用的MySQL版本是5.7，它的默认行格式就是Dynamic，这俩行格式和Compact行格式挺像，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储字段真实数据的前768个字节，而是把所有的字节都存储到其他⻚面中，只在记录的真实数据处存储其他⻚面的地址，就像这样: Compressed行格式和Dynamic不同的一点是，Compressed行格式会采用压缩算法对⻚面进行压缩，以节省空间。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.2 行溢出数据 与 溢出页","date":"2021-09-19T14:01:52.000Z","path":"2021/09/19/MySQL知识点整理/4.2 行溢出数据 与 溢出页/","text":"VARCHAR(M)最多能存储的数据 我们知道，对于VARCHAR(M)类型的列最多可以占用65535个字节。(lant: 因为在变长字段长度列表中，每个变长字段实际存储的数据的长度值最多占2个字节，而2个字节最大能表示的数就是65535了)。而之前我们也说过，VARCHAR(M)的M代表该类型最多存储的字符数量 使用ascii定长字符集 如果我们使用ascii字符集的话，一个字符就代表一个字节，我们看看VARCHAR(65535)是否可用: mysql&gt; CREATE TABLE varchar_size_demo(-&gt; c VARCHAR(65535)-&gt; ) CHARSET=ascii ROW_FORMAT=Compact; ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to change some columns to TEXT or BLOBs mysql&gt; 从报错信息里可以看出，MySQL对一条记录占用的最大存储空间是有限制的，除了BLOB或者TEXT类型的列之外， 其他所有的列(不包括隐藏列和记录头信息)占用的字节⻓度加起来不能超过65535个字节 。所以上面可以看到MySQL服务器建议我们把存储类型改为TEXT或者BLOB的类型。 这65535个字节除了列本身的数据外，还包括一些其他数据，比如说为了存储一个VARCHAR(M)类型的列，其实需要占用3部分存储空间: 真实数据、真实数据的⻓度占用的字节、NULL值标识(如果该列有NOT NULL属性则可以没有这部分存 储空间)…如果该VARCHAR类型的列没有NOT NULL属性，那最多只能存储65532个字节的数据，因为真实数据的⻓度在变长字段列表中会占2个字节，NULL 值标识需要占用1个字节，再次尝试，果然成功了mysql&gt; CREATE TABLE varchar_size_demo(-&gt; c VARCHAR(65532)-&gt; ) CHARSET=ascii ROW_FORMAT=Compact;Query OK, 0 rows affected (0.02 sec) 使用变长字符集如果VARCHAR(M)类型的列使用的不是ascii字符集，那会怎么样呢? mysql&gt; CREATE TABLE varchar_size_demo( -&gt; c VARCHAR(65532)-&gt; ) CHARSET=gbk ROW_FORMAT=Compact;ERROR 1074 (42000): Column length too big for column &#39;c&#39; (max = 32767); use BLOB or TEXT instead mysql&gt; CREATE TABLE varchar_size_demo(-&gt; c VARCHAR(65532)-&gt; ) CHARSET=utf8 ROW_FORMAT=Compact;ERROR 1074 (42000): Column length too big for column &#39;c&#39; (max = 21845); use BLOB or TEXT instead 从执行结果中可以看出，如果VARCHAR(M)类型的列使用的不是ascii字符集，那M的最大取值取决于该字符集表示一个字符最多需要的字节数。gbk字符集表示一个字符最多需要2个字符，在列的值允许为NULL的情况下，M的最大取值就是32766(也就是: 65535-2(变长字段列表占2字节)-1(null列表占1字节) &#x3D; 65532)，也就是说最多能存储32766(65532&#x2F;2)个字符;utf8字符集表示一个字符最多需要3个字符，那在该字符集下，M的最大取值就是21844，就是说最多能存储21844(也就是: (65535-2-1)&#x2F;3)个字符。 Tips:上述所言在列的值允许为NULL的情况下，gbk字符集下M的最大取值就是32766，utf8字符集下M的最大取值就是21844， 这都是在表中只有一个字段的情况下说的 ， 一定要记住一个行中的所有列(不包括隐藏列和记录头信息)占用的字节⻓度加起来不能超过65535个字节 ! 记录中的数据太多产生的溢出 前边说过， MySQL中磁盘和内存交互的基本单位是⻚，也就是说MySQL是以⻚为基本单位来管理存储空间的，我们的记录都会被分配到某个⻚中存储 。 而一个⻚的大小一般是16KB，也就是16384字节，而一个VARCHAR(M)类型的列就最多可以存储65532个字节，这样就可能造成一个⻚存放不了一条记录的尴尬情况。 在Compact和Reduntant行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，而剩余的数据则会被分散存储在几个其他的⻚中，然后记录的真实数据处用20个字节存储指向这些⻚的地址(当然这20个字节中还包括这些分散在其他⻚面中的数据的占用的字节数)，从而可以找到剩余数据所在的⻚。 从图中可以看出来，对于Compact和Reduntant行格式来说，如果 某一列中的数据非常多的话，在本记录的真实数据处只会存储该列的 前768个字节的数据和一个指向其他⻚的地址，然后把剩下的数据存 放到其他⻚中，这个过程也叫做行溢出，存储超出768字节的那些⻚面也被称为溢出⻚。简图如下：最后需要注意的是，不只是 VARCHAR(M) 类型的列，其他的 TEXT、BLOB 类型的列在存储数据非常多的时候也会发生行溢出。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.1 compact 行格式","date":"2021-09-18T12:41:09.000Z","path":"2021/09/18/MySQL知识点整理/4.1 compact 行格式/","text":"COMPACT行格式 直接看图:从图中可以看出来，一条完整的记录其实可以被分为 记录的额外信息 和 记录的真实数据 两大部分，下边我们详细看一下这两部分的组成。 记录的额外信息这部分信息是 服务器为了描述这条记录而不得不额外添加的一些信息 。这些额外信息分为3部分，分别是 变⻓字段⻓度列表、NULL值列表 和 记录头信息，我们分别看一下 记录的额外信息 之 变⻓字段⻓度列表 我们知道MySQL支持一些变⻓的数据类型，比如 VARCHAR(M)、VARBINARY(M)、各种TEXT类型，各种BLOB类型，我们可以把被设置为这些数据类型的列称为变⻓字段；变⻓字段中存储多少字节的数据是不固定的，所以我们在存储真实数据时，InnoDB引擎会顺便把这些数据实际占用的字节数也存起来，这样才不至于把MySQL服务器搞懵，所以这些变⻓字段占用的存储空间分为两部分: 真正的数据内容、数据内容占用的字节数。 在Compact行格式中，把所有变⻓字段的真实数据所占用的字节数都存放在记录的开头部位，从而形成一个变⻓字段⻓度列表。各变⻓字段的真实数据所占用的字节数，按照列的顺序逆序存放。 示例:拿 record_format_demo 示例表中的 第一条记录 来举例: 因为record_format_demo表的c1、c2、c4字段都是 VARCHAR(10)类型(变⻓数据类型)， 所以这三个列的所存储的真实数据的⻓度值都需要保存在当前记录的 变⻓字段⻓度列表中 ； 又因为record_format_demo表中的各个列都使用的是ascii字符集(每个字符只需要1个字节来进行编码);来看一下第一条记录各变⻓字段的 实际内容 的⻓度: 又因为这些⻓度值需要按照列的逆序存放，所以最后这条记录的变⻓字段⻓度列表 的字节串用十六进制表示的效果就是： 第一行记录中，c1、c2、c4 每列中的真实数据所占的字节长度的数值比较小(4，3，1这些小数字)，用1个字节就可以表示；但是如果变⻓列的数据占用的字节数比较多，可能就需要用2个字节来表示 。(如果某行记录的c1变长字段的真实数据长度是300字节，300这个数值用一个字节就无法表示了，因为一个字节是8位，最大只能表示的数字是255)每个变长字段在 变长字段列表中 具体用1个还是2个字节来表示真实数据所占用的字节数，InnoDB有它的一套规则，我们首先声明一下W、M和L的意思。 W:假设一个字符集中表示一个字符最多需要使用的字节数为W，也就是使用 SHOW CHARSET 语句的结果中的Maxlen列。(比方说utf8字符集中的W就是3，utf8mb4字符集中的W就是4)。 M:对于变⻓类型VARCHAR(M)来说， 这种类型表示能存储最多M个字符 (注意是字符不是字节)，所以这个类型能表示的字符串最多占用的字节数就是 M×W。 L:假设该变长实际存储的字符串占用的字节数是 L; 所以确定使用1个字节还是2个字节表示真正字符串占用的字节数的规则就是: 如果 M×W &lt;= 255，那么使用1个字节来表示真正字符串占用的字节数； (一个字节能表示的最大数值就是255) 如果M×W &gt; 255，则分为两种情况: 如果 L &lt;= 127，则用1个字节来表示真正字符串占用的字节数。 如果 L &gt; 127，则用2个字节来表示真正字符串占用的字节数。 对于一些占用字节数非常多的字段，比方说某个字段⻓度大于了16KB，即 该记录在单个⻚面中都存储不下时，InnoDB 会把一部分数据存放到所谓的溢出⻚中(我们后边会唠叨)，在变⻓字段⻓度列表处只存储留在本⻚面中的⻓度，所以使用两个字节也可以存放下来。 总结一下就是说: 如果该变长字段允许存储的最大字节数(M×W)超过255字节并且真实存储的字节数(L)超过127字节，则使用2个字节，否则使用1个字节。 另外需要注意的一点是，变⻓字段⻓度列表中只存储实际内容为非NULL的列数据占用的字节数，值为NULL的列的⻓度是不储存的也就是 说对于第二条记录来说，因为c4列的值为NULL，所以第二条记录的变⻓字段⻓度列表只需要存储c1和c2列的⻓度即可（其中c1列存储的值为’eeee’，占用的实际字节数为4，c2列存储的值为’fff’，占用的实际字节数为3。数字4可以用1个字节表示，3也可以用1个字节表示， 所以整个变⻓字段⻓度列表共需2个字节）。填充完变⻓字段⻓度列表 的两条记录的对比图如下: Tips:并不是所有记录都有这个 变⻓字段⻓度列表 部分，比方说表中所有的列都不是变⻓的数据类型的话，这一部分就不需要有。 记录的额外信息 之 NULL值列表我们知道表中的某些列可能存储NULL值，如果把这些NULL值都放到记录的真实数据中存储，那就会很占地方，所以Compact行格式把这些值为NULL的列统一管理起来，存储到了 记录的额外信息 中的 NULL值列表 中，它的处理过程是这样的: 首先统计表中允许存储NULL的列有哪些像 主键列、被NOT NULL修饰的列 都是不可以存储NULL值的，所以在统计时不会把这些列算进去。 如果表中没有允许存储 NULL 的列，则NULL值列表也不存在。否则 将每个允许存储NULL的列对应一个二进制位 ，二进制位按照列的顺序逆序排列，二进制位的值为1时，代表该列的值为NULL。二进制位的值为0时，代表该列的值不为NULL。 MySQL规定NULL值列表必须用整数个字节的位表示，如果可以为NULL的字段数 达不到整数个字节，则在字节的高位补0。表record_format_demo只有3个值允许为NULL的列，对应3个二进制位，不足一个字节，所以在字节的高位补0，效果就是这样: 对于第一条记录来说，c1、c3、c4 这3个列的值都不为NULL，所以它们对应的二进制位都是0: 对于第二条记录来说，c1、c3、c4 这3个列中c3和c4的值都为NULL，所以这3个列对应的二进制位的情况就是: 所以这两条记录在填充了NULL值列表后的示意图就是这样: 记录的额外信息 之 记录头信息 除了 变⻓字段⻓度列表、NULL值列表 之外，还有一个 用于描述记录的 记录头信息。 记录头信息 由固定的5个字节组成(也就是40个二进制位，不同的位代表不同的意思)，如图: 这些二进制位代表的详细信息如下表:现在暂时也没必要把它们的意思都记住，只需要看一遍混个脸熟，等之后用到这些属性的时候我们再回过头来看 现在我们并不清楚这些属性详细的用法，所以这里就不分析各个属性值是怎么产生的了，之后我们遇到会详细看的。 所以我们现在直接看一下record_format_demo 表中的两条记录的头信息分别是什么:目前，你只需要对这两条记录的 记录头信息部分 有个印象就行。 记录的真实数据 对于record_format_demo表来说，记录的真实数据除了 c1、c2、c3、c4 这几个我们自己定义的列的数据以外， MySQL会为每个记录默认的添加一些列(也称为隐藏列) ，具体的列如下: 列名 是否必须 占用空间 描述 row_id 否 6字节 行ID，唯一标识一条记录 transaction_id 是 6字节 事务ID roll_pointer 是 7字节 回滚指针 Tips: 实际上这几个列的真正名称其实是: DB_ROW_ID、DB_TRX_ID、 DB_ROLL_PTR，我们为了美观才写成了row_id、 transaction_id和roll_pointer。 这里需要提一下 InnoDB表对主键的生成策略: 优先使用用户自定义的主键作为主键; 如果用户没有定义主键，则选取一个Unique键作为主键; 如果表中连Unique键都没有定义的话，则InnoDB会为表默认添加一个名为row_id 的隐藏列作为主键。 所以我们可以看出: InnoDB存储引擎会为每条记录都添加 transaction_id 和 roll_pointer 这两个列，但是 row_id 是可选的(在没有自定义主键及Unique键的情况下才会添加该列)。这些隐藏列的值不用我们操心，InnoDB存储引擎会自己帮我们生成的。 因为表record_format_demo示例表并没有定义主键，所以MySQL服务器会为每条记录增加上述的3个列。现在看一下加上记录的真实数据的、两个记录⻓什么样吧:看这个图的时候我们需要注意几点:表record_format_demo使用的是ascii字符集，所以0x61616161就表示字符串’aaaa’，0x626262就表示字符 串’bbb’，以此类推; 注意第1条记录中c3列的值，它是CHAR(10)类型的，虽然它实际存储的字符串是:’cc’(ascii字符集的字节表示是’0x6363’)，虽然表示这个字符串只需要用2个字节，但整个c3列仍然占用了10个字节的空间，除真实数据以外的8个字节的统统都用空格字符填充，空格字符在ascii字符集的表示就是0x20。 注意第2条记录中c3和c4列的值都为NULL，它们被存储在了前边的NULL值列表处，在记录的真实数据处就不再冗余存储，从而节省存储空间 。 字符集对 COMPACT 行格式的影响COMPACT行格式会受字符集的影响。 以 CHAR(M)列的存储格式 为例尽管我们说在 Compact行格式 下只会把变⻓字段存储的实际数据的⻓度逆序存到 变⻓字段⻓度列表中。 但其实除了考虑字段本身的类型是否是变长字段，还需要考虑字符集的影响 。 对于record_format_demo示例表的c1,c2,c4列来说，它们是变长字段，这个没毛病，但此时我们的表采用的是ascii字符集(这个字符集是一个定⻓字符集，一个字符采用固定的一个字节)。如果采用变⻓的字符集(也就是表示一个字符需要的字节数不确定，比如gbk表示一个字符要12个字节、utf8表示一个字符要13个字节等)的话， 此时c3列虽然是char(10)这种定长字段，但它的数据⻓度也会被存储到变⻓字段⻓度列表中 。 假如我们将record_format_demo表的字符集修改为utf8,修改该列字符集后记录的变⻓字段⻓度列表也发生了变化: 这就意味着: 对于 CHAR(M) 类型的列来说，当采用的是定⻓字符集时，该列实际数据占用的字节数不会被加到变⻓字段⻓度列表中; 而如果采用的是变⻓字符集时，该列实际数据占用的字节数也会被加到变⻓字段⻓度列表 。 Tips:另外有一点还需要注意， 变⻓字符集的CHAR(M)类型的列要求至少占用M个字节 （utf8表示一个字符要1~3个字节），而VARCHAR(M)却没有这个要求。 比方说对于使用utf8字符集的CHAR(10)的列来说，该列存储的数据字节⻓度的范围是10~30个字节。即使我们向该列中存储一个空字符串也会占用10个字节。这样的话，将来更新该列的值时，如果字节⻓度小于10个字节时，可以在该记录处直接更新，而不是在存储空间中重新分配一个新的记录空间，导致原有的记录空间成为所谓的碎片。(这里你感受到设计Compact行格式的大叔既想节省存储空间，又不想更新CHAR(M)类型的列产生碎片时的纠结心情了吧。) Redundant行格式 其实知道了Compact行格式之后，其他的行格式就是依葫芦画瓢了。我们现在要介绍的Redundant行格式是MySQL5.0之前用的一种行格式，也就是说它已经非常老了，大家乐呵乐呵的看就好。 …… Redundant行格式: CHAR(M) 不会产生碎片我们知道Compact行格式在CHAR(M)类型的列中存储数据的时候还挺麻烦，分 变⻓字符集 和 定⻓字符集 的情况，而在Redundant行格式中十分干脆，不管该列使用的字符集是啥，只要是使用CHAR(M)类型，占用的真实数据空间就是该字符集表示一个字符最多需要的字节数和M的乘积。比方说使用utf8字符集的CHAR(10)类型的列占用的真实数据空间始终为30个字节，使用gbk字符集的CHAR(10)类型的列占用的真实数据空间始终为20个字节。由此可以看出来，使用Redundant行格式的CHAR(M)类型的列是不会产生碎片的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.0 InnoDB记录存储结构 之 页的概念、行格式的概念","date":"2021-09-18T12:01:19.000Z","path":"2021/09/18/MySQL知识点整理/4.0 InnoDB记录存储结构 之 页的概念、行格式的概念/","text":"前言 到现在为止，MySQL对于我们来说还是一个黑盒。我们只是简单使用客户端发送请求并等待服务器返回结果。至于 表中的数据到底存到了哪里? 以什么格式存放的? MySQL是以什么方式来访问的这些数据? 这些问题我们统统不知道。 不过前面已经多次提到， MySQL服务器上负责对表中数据的读取和写入工作的部分是存储引擎 。MySQL服务器支持多种不同类型的存储引擎(如InnoDB、MyISAM、Memory……)，不同的存储引擎一般是由不同的人为实现不同的特性而开发的，真实数据在不同存储引擎中存放的方式一般是不同的，甚至有的存储引擎比如Memory都不用磁盘来存储数据。 由于InnoDB是MySQL默认的存储引擎，也是我们最常用到的存储引擎，我们也没有那么多时间去把各个存储引擎的内部实现都看一遍，所以本集要唠叨的是使用InnoDB作为存储引擎时的数据存储结构，了解了一个存储引擎的数据存储结构之后，其他的存储引擎都是依葫芦画瓢，等以后用到了再说~ InnoDB存储引擎中⻚的概念 InnoDB是一个将表中的数据存储到磁盘上的存储引擎，所以即使关机后重启我们的数据还是存在的。 不过，尽管InnoDB是将数据存储到磁盘上的存储引擎，但真正处理数据的过程却是发生在内存中的，所以需要把磁盘中的数据加载到内存中，如果是处理写入或修改请求的话，还需要把内存中的内容刷新到磁盘上。 而我们知道读写磁盘的速度非常慢，和内存读写差了几个数量级，所以当我们想从表中获取某些记录时，InnoDB存储引擎需要一条一条的把记录从磁盘上读出来么?不，那样会慢死，InnoDB采取的方式是: 将数据划分为若干个⻚，以⻚作为磁盘和内存之间交互的基本单位，InnoDB 中⻚的大小一般为16KB。也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。 InnoDB引擎的行格式(记录格式) 我们平时是以行(也叫记录)为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为行格式或者记录格式。 设计InnoDB存储引擎的大叔们到现在为止设计了4种不同类型的行格式，分别是 Compact、Redundant、Dynamic 和 Compressed 行格式，随着时间的推移，他们可能会设计出更多的行格式，但是不管怎么变，在原理上大体都是相同的。 如何指定表的行格式？我们可以在创建或修改表的语句中指定行格式:&#x2F;&#x2F; 语法如下CREATE TABLE 表名 ( 列的信息) ROW_FORMAT=行格式名称 ALTER TABLE 表名 ROW_FORMAT=行格式名称","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"3. 字符集和比较规则","date":"2021-09-14T14:53:41.000Z","path":"2021/09/14/MySQL知识点整理/3. 字符集和比较规则/","text":"字符集的概念 我们知道在计算机中只能存储二进制数据，那该怎么存储字符串呢? 当然是建立字符与二进制数据的映射关系了 ，建立这个关系最起码要搞清楚两件事儿: 你要把哪些字符映射成二进制数据? (其实就是字符集要包含的 字符范围) 怎么映射? (其实就是 编码规则)将一个字符映射成一个二进制数据的过程也叫做编码，将一个二进制数据映射到一个字符的过程叫做解码。 为此，人们抽象出了一个叫 字符集 的概念来描述某个字符范围的编码规则。 比方说，我们现在可以自定义一个名称为 xiaohaizi 的字符集，它包含的 字符范围 和 编码规则 如下: 字符范围: 包含字符：’a’、’b’、’A’、’B’ ； 编码规则是：采用1个字节编码一个字符，字符和字节的映射关系如下:‘a’ -&gt; 00000001 (十六进制:0x01)‘b’ -&gt; 00000010 (十六进制:0x02)‘A’ -&gt; 00000011 (十六进制:0x03)‘B’ -&gt; 00000100 (十六进制:0x04) 有了 xiaohaizi 这个字符集后，我们就可以用二进制形式表示一些字符串了，下边是一些字符串用 xiaohaizi 这个字符集编码后的二进制表示:bA’ -&gt; 00000010 00000011 (十六进制:0x0203)‘baB’ -&gt; 00000010 00000001 00000100 (十六进 制:0x020104)‘cd’ -&gt; 无法表示，因为字符集xiaohaizi不包含字符’c’和’d’ 所以，字符集 其实就是通过制定 字符范围 和 编码规则 来将日常字符数据映射到计算机能存储的二进制数据的一套规则。 比较规则的概念 在我们确定了xiaohaizi字符集表示字符的范围以及编码规则后，怎么比较两个字符的大小呢? 最容易想到的就是直接比较这两个字符对应的二进制编码的大小，比方说字符’a’的编码为0x01，字符’b’的编码为0x02，所以’a’小于’b’，这种简单的比较规则也可以被称为二进制比较规则，英文名为binary collation。 二进制比较规则 非常简单，但有时候并不符合现实需求，比如在很多场合对于英文字符我们都是不区分大小写的，也就是说’a’和’A’是相等的，在这种场合下就不能简单粗暴的使用二进制比较规则了，这时候我们可以这样指定比较规则: 将两个大小写不同的字符全都转为大写或者小写。 然后再比较这两个字符对应的二进制数据。 这是一种稍微复杂一点点的比较规则，但是实际生活中的字符不止英文字符一种，比如我们的汉字有几万几十万之多，即便对于某一种字符集来说，比较两个字符大小的规则也可以制定出很多种。后面会介绍各种现实生活中用的字符集以及它们的一些比较规则。 一些重要的字符集不幸的是，这个世界太大了，不同的人制定出了好多种字符集，每个字符集表示的字符范围和用到的编码规则可能都不一样。我们看一下一些常用字符集的情况: ASCII字符集 字符范围：共收录128个字符包括空格、标点符号、数字、大小写字母 和一些不可⻅字符。 编码规则：由于总共才128个字符，所以可以使用1个字节来进行编码，我们简单看一下该字符集的编码方式:‘L’ -&gt; 01001100(十六进制:0x4C，十进制:76)‘M’ -&gt; 01001101(十六进制:0x4D，十进制:77) ISO 8859-1字符集这个字符集有一个别名 latin1 字符范围：共收录256个字符，是在ASCII字符集的基础上又扩充了128个⻄欧常用字符(包括德法两国的字母); 编码 方式/规则/方案：它也是使用1个字节来进行编码。 GB2312字符集 字符范围：收录了汉字以及拉丁字母、希腊字母、日文平假名及片假名字母、俄语⻄里尔字母。其中收录汉字6763个，其他文字符号682个。 编码规则：同时这种字符集又兼容ASCII字符集，所以在编码方式上显得有些奇怪: 如果该字符在ASCII字符集中，则采用1字节编码。 否则采用2字节编码。 这种表示一个字符需要的字节数可能不同的编码方式称为变⻓编码方式。比方说字符串’爱u’，其中’爱’需要用2个字节进行编码，编码后的十六进制表示为0xCED2;而’u’只需要用1个字节进行编码，编码后的十六进制表示为0x75;所以拼合起来就是0xCED275。 ⚠️ Tips:我们怎么区分某个字节代表一个单独的字符还是代表某个字符的一部分呢?别忘了ASCII字符集只收录128个字符，使用0127就可以表示全部字符(只用到了01111111 一个字节的前7位)，所以如果某个字节是在0127之内的(如果第8个字节是0)，就意味着一个字节代表一个单独的字符，否则就是两个字节代表一个单独的字符。 GBK字符集 字符范围： GBK字符集只是在收录字符范围上对GB2312字符集作了扩充； 编码方式: 兼容GB2312； utf8字符集 字符范围: 收录地球上能想到的所有字符，而且还在不断扩充。 编码方式: 这种字符集兼容ASCII字符集，采用变⻓编码方式，编码一个字符需要使用1~4个字节，比方说这样:‘L’ -&gt; 01001100(十六进制:0x4C)‘啊’ -&gt; 111001011001010110001010(十六进 制:0xE5958A) ⚠️ Tips:其实准确的说，utf8并不是一个字符集，它只是Unicode字符集的一种编码方案。Unicode字符集可以采用utf8、utf16、utf32这几种编码方案： utf8使用1~4个字节编码一个字符； utf16使用2个或4个字节编码一个字符； utf32使用4个字节编码一个字符。 更详细的Unicode和其编码方案的知识不是本书的重点，大家上网查查哈~ 虽然 编码方案 只是 字符集 内包含的一部分功能，但 MySQL中并不区分字符集和编码方案的概念，所以后边唠叨的时候把utf8、utf16、utf32都当作一种字符集对待。 小结字符集的概念包括字符范围和编码规则两部分功能；可以对字符集制定多种不同的比较规则； utf8并不是一个字符集，它只是Unicode字符集的一种编码方案； MySQL中并不区分字符集和编码方案的概念，所以后边唠叨的时候把 utf8、utf16、utf32都当作一种字符集&#96;对待。 MySQL中支持的字符集和排序规则MySQL中的 utf8 和 utf8mb4 我们上边说utf8字符集表示一个字符需要使用1~4个字节，但是我们常用的一些字符使用1~3个字节就可以表示了。而在MySQL中字符集表示一个字符所用最大字节⻓度在某些方面会影响系统的存储和性能，所以设计MySQL的大叔偷偷的定义了两个概念: utf8mb3: 阉割过的utf8字符集，只使用1~3个字节表示字符。 utf8mb4: 正宗的utf8字符集，使用1~4个字节表示字符。 有一点需要大家十分的注意，在MySQL中utf8是utf8mb3的别名，所以之后在MySQL中提到utf8就意味着使用1~3个字节来表示一个字符， 如果大家有使用4字节编码一个字符的情况，比如存储一些emoji表情啥的，那请使用utf8mb4 。 字符集的查看 MySQL支持好多好多种字符集，查看当前MySQL中支持的字符集可以用 SHOW (CHARSET) [LIKE 匹配的模式]; 这个语句:我们查询一下(支持的字符集太多了，我们省略了一些)，为了让大家的印象更深刻，下面把几个常用到的字符集的Maxlen列摘抄下来，大家务必记住: 字符集名称 Maxlen ascii 1 latin1 1 gb2312 2 gbk 2 utf8 3 utf8mb4 4 比较规则的查看 查看MySQL中支持的比较规则的命令为: SHOW COLLATION [LIKE 匹配的模式]; 我们前边说过一种字符集可能对应着若干种比较规则，MySQL支持的字符集就已经非常多了，所以支持的比较规则更多，我们先只查看一下utf8字符集下的比较规则:SHOW COLLATION LIKE &#39;utf8%&#39;; 每种字符集对应若干种比较规则，每种字符集都有一种默认的比较规则，SHOW COLLATION的返回结果中的Default列的值为YES的就是该字符集的默认比较规则，比方说utf8字符集默认的比较规则就是utf8_general_ci。 各级别的字符集和比较规则MySQL有4个级别的字符集和比较规则，分别是: 服务器级别 MySQL提供了两个系统变量来表示服务器级别的字符集和比较规则character_set_server 服务器级别的字符集 collation_server 服务器级别的比较规则 我们可以在启动服务器程序时通过启动选项或者在服务器程序运行过程中使用SET语句修改这两个变量的值。比如我们可以在配置文件中这样写:[server]character_set_server=gbkcollation_server=gbk_chinese_ci 数据库级别 我们在创建和修改数据库时可以指定该数据库的字符集和比较规则；如果想查看当前数据库使用的字符集和比较规则，可以查看下面两个系统变量的值；character_set_database 和 collation_database 这两个系统变量是只读的，我们不能通过修改这两个变量的值而改变当前数据库的 字符集和比较规则数据库的创建语句中也可以不指定字符集和比较规则，这样的话将使用服务器级别的字符集和比较规则作为数据库的字符集和比较规则； 表级别 我们也可以在创建和修改表的时候指定表的字符集和比较规则如果创建和修改表的语句中没有指明字符集和比较规则，将使用该表所在数据库的字符集和比较规则作为该表的字符集和比较规则 列级别 需要注意的是，对于存储字符串的列，同一个表中的不同的列也可以 有不同的字符集和比较规则。对于某个列来说，如果在创建和修改的语句中没有指明字符集和比较 规则，将使用该列所在表的字符集和比较规则作为该列的字符集和比 较规则。 客户端和服务器通信中的字符集 如果对于同一个字符串编码和解码使用的字符集不一样，会产生意想不到的结果，作为人类的我们看上去就像是产生了乱码一样。 我们知道从客户端发往服务器的请求本质上就是一个字符串，服务器向客户端返回的结果本质上也是一个字符串，而字符串其实是使用某种字符集编码的二进制数据。这个字符串可不是使用一种字符集的编码方式一条道走到黑的，从发送请求到返回结果这个过程中伴随着多次字符集的转换，在这个过程中会用到3个系统变量，我们先把它们写出来看一下: 系统变量 描述 character_set_client 服务器解码请求时使用的字符集 character_set_connection 服务器运行过程中使用的字符集 character_set_results 服务器向客户端返回数据时使用的字符集 我们通常都把 character_set_client 、character_set_connection、character_set_results 这三个 系统变量设置成和客户端使用的字符集一致的情况，这样减少了很多无谓的字符集转换。 为了方便我们设置，MySQL提供了一条非常简便的语句: SET NAMES 字符集名; 这一条语句产生的效果和下面这3条的效果是一样的:SET character_set_client = 字符集名;SET character_set_connection = 字符集名;SET character_set_results = 字符集名; 另外，如果你想在启动客户端的时候就把这三个系统变量的值设置成一样的，那我们可以在启动客户端的时候指定一个叫default-character-set的启动选项，比如在配置文件里可以这么写:[client]default-character-set=utf8它起到的效果和执行一遍 SET NAMES utf8 是一样一样的，都会将那三个系统变量的值设置成utf8。lant: 这怪方便，只用设置这个，mysql启动后，所有的客户端都连接上来都会先设置这三个系统变量…. 妥妥的无乱码喽","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"2. MySQL的启动选项和配置文件、系统变量、状态变量","date":"2021-09-14T13:17:21.000Z","path":"2021/09/14/MySQL知识点整理/2. MySQL的启动选项和配置文件、系统变量、状态变量/","text":"MySQL的启动选项 MySQL的 服务器程序 和 客户端程序 都有很多的设置项: 比如 MySQL服务器程序 可以指定像 允许同时连入的客户端数量、客户端和服务器通信方式、表的默认存储引擎、查询缓存的大小…等 设置项。 对于MySQL客户端程序，则可以指定像 需要连接的服务器程序所在主机的主机名或IP地址、用户名及密码等信息。 这些设置项一般都有各自的默认值，比方说服务器允许同时连入的客户端的默认数量是151，表的默认存储引擎是InnoDB。 我们可以在程序启动的时候去修改这些默认值，对于这种在程序启动时指定的设置项也称之为启动选项(startup options)，这些选项控制着程序启动后的行为。 在MySQL安装目录下的bin目录中的各种可执行文件，不论是服务器相关的程序(比如mysqld、mysqld_safe)还是客户端相关的程序(比如mysql、mysqladmin)， 在启动时基本都可以指定启动参数 。 这些启动参数可以放在命令行中指定，也可以把它们放在配置文件中指定。 下面会以`mysqld`为例，来详细唠叨如何指定`启动选项`。下边出现的`启动选项不`论大家认不认识，先不用去纠结每个选项具体的作用是啥，之后我们会对一些重要的启动选项详细唠叨。 在命令行上设置启动选项 通过上一篇的学习，我们已经知道，如果我们在启动客户端程序时在-h参数后边紧跟服务器的IP地址，这就意味着客户端和服务器之间需要通过TCP/IP网络进行通信（当然，如果ip指定的是 127.0.0.1，那也可能是通过 unix套接字进行通信）。 如果我们在启动服务器程序时，想禁止各客户端使用TCP&#x2F;IP网络与服务器程序进行通信，则可以在启动服务器程序的命令行里添加 skip-networking 启动选项，如: mysqld --skip-networking Tips：在命令行中指定启动选项时需要在选项名前加上 --前缀。如果选项名是由多个单词构成的，它们之间可以由短划线-连接起来，也可以使用下划线_连接起来，也就是说 skip-networking 和 skip_networking 表示的含义是相同的。 在按照上述命令启动服务器程序后，如果我们再使用mysql来启动客户端程序时，仍把服务器主机名指定为127.0.0.1(IP地址的形式)的话，就会显示连接失败。这就意味着我们指定的启动选项 skip-networking 生效了! 再举一个例子，我们前边说过如果在创建表的语句中没有显式指定表的存储引擎的话，则会默认使用InnoDB作为表的存储引擎。如果我们想改变表的默认存储引擎的话，可以这样写启动服务器的命令行: mysqld --default-storage-engine=MyISAM。这下，你再次建表时即便没有明确指定表的存储引擎，建表成功后通过 SHOW CREATE TABLE 表名\\G 会发现表已经是 MyISAM 引擎了。 小结：在启动服务器程序的命令行后边指定启动选项的通用格式是 --启动选项1[=值1] --启动选项2[=值2] ... --启动选项n[= 值n] 即，我们可以将多个启动选项写到一行，各个启动选项间用空白字符隔开，在每个启动选项名称前边添加--。对于不需要值的启动选项，比方说 skip-networking，它们就不需要指定对应的值。对于需要指定值的启动选项，比如default-storage-engine,我们在指定这个设置项的时候需要显式的指定它的值。 在命令行上指定有值的启动选项时，需要注意，选项名、=、选项值之间不可以有空白字符。 每个MySQL程序都有许多不同的启动选项。大多数程序提供了一个 --help 选项来查看该程序支持的全部启动选项以及它们的默认值。例如，使用 mysql --help 可以看到mysql程序支持的启动选项，mysqld_safe --help 可以看mysqld_safe程序支持的启动选项。查看mysqld支持的启动选项有些特别，需要使用 mysqld --verbose --help。 启动选项的⻓形式和短形式 我们前边提到的 skip-networking、default-storage-engine称之为⻓形式的选项，设计MySQL的大叔为了我们使用的方便，对于一些常用的选项提供了短形式，我们列举一些具有短形式的启动选项来瞅瞅(MySQL支持的短形式选项太多了，全列出来会刷屏的) ⻓形式 短形式 含义 host -h 主机名 –user -u 用户名 –password -p 密码 –port -P 端口 –version -V 版本信息 …… …… …… 短形式的选项名只有一个字母，与使用⻓形式选项时需要在选项名前加--前缀不同的是，使用短形式选项时在选项名前只加一个短划线-前缀。 使用短形式指定启动选项时，选项名和选项值之间可以无间隙，也可以用空白字符隔开(-p选项有些特殊，-p和密码值之间不能有空白字符)。(得了，无论 短形式 还是 长形式，选项名和选项值之间都别有空格就行了) 在配置文件中设置启动选项 在命令行中设置启动选项只对当次启动生效，下次重启程序时还得在启动命令行中加这些启动选项! 于是设计MySQL的大叔们提出 配置文件(也称为选项文件)的概念，我们把需要设置的启动选项都写在这个配置文件中，每次启动服务器时都从这个文件里加载相应的启动选项。由于这个配置文件可以⻓久的保存在计算机的硬盘里，所以只需我们配置一次，以后就都不用显式的把启动选项都写在启动命令行中了， 所以我们推荐使用配置文件的方式来设置启动选项 。 配置文件的路径: MySQL程序在启动时会寻找多个路径下的配置文件，这些路径有的是固定的，有的是可以在命令行指定的。根据操作系统的不同，配置文件的路径也有所不同，这里重点看下类unix系统。 在类UNIX操作系统中，MySQL会按照下列路径来寻找配置文件: 路径名 备注 说明 &#x2F;etc&#x2F;my.cnf &#x2F;etc&#x2F;mysql&#x2F;my.cnf SYSCONFDIR&#x2F;my.cnf SYSCONFDIR 表示在使用CMake构建MySQL时使用SYSCONFDIR选项指定的目录。默认情况下，这是位于编译安装目录下的etc目录。 $MYSQL_HOME&#x2F;my.cnf 特定于服务器的选项(仅限服务器) MYSQL_HOME是一个环境变量，该变量的值是我们自己设置的，我们想设置就设置，不想设置就不设置。该变量的值代表一个路径，我们可以在该路径下创建一个my.cnf配置文件。这个配置文件中只能放置关于启动服务器程序相关的选项(言外之意就是其他的配置文件既能存放服务器相关的选项也 能存放客户端相关的选项，.mylogin.cnf除外，它只能存放客户端相关的一些选项)。 defaults-extra-file 命令行指定的额外配置文件路径 ~&#x2F;.my.cnf 用户特定选项 ~&#x2F;.mylogin.cnf 用户特定的登录路径选项(仅限客户端) .mylogin.cnf 不是纯文本文件，只能使用mysql_config_editor实用程序去创建或修改，用于存放客户端登陆服务器时的相关选 项。 这也就是说，在我的计算机中这几个路径中的任意一个都可以当作配置文件来使用，如果它们不存在，你可以手动创建一个。 另外，我们在唠叨如何启动MySQL服务器程序的时候说过，使用mysqld_safe程序启动服务器时，会间接调用mysqld，所以对于传递给mysqld_safe的启动选项来说，如果mysqld_safe程序不处理，会接着传递给mysqld程序处理。比方说skip-networking选项是由mysqld处理的，mysqld_safe并不处理。 配置文件的内容:与在命令行中指定启动选项不同的是，配置文件中的启动选项被划分为若干个组，每个组有一个组名，用中括号[]扩起来，像这样: [server] (具体的启动选项...)[mysqld] (具体的启动选项...)[mysqld_safe] (具体的启动选项...)[client] (具体的启动选项...)[mysql] (具体的启动选项...)[mysqladmin] (具体的启动选项...) 每个组下边可以定义若干个启动选项，我们以[server]组为例来看一下填写启动选项的形式[server]option1 #这是option1，该选项不需要选项值option2 = value2 #这是option2，该选项需要选项值 ... 在配置文件中指定启动选项的语法类似于命令行语法，但是配置文件中只能使用⻓形式的选项。在配置文件中指定的启动选项不允许加--前缀，并且每行只指定一个选项，而且&#x3D;周围可以有空白字符。另外，在配置文件中，我们可以使用#来添加注释，从#出现直到行尾的内容都属于注释内容，读取配置文件时会忽略这些注释内容。 配置文件中不同的选项组是给不同的启动命令使用的，如果选项组名称与程序名称相同，则组中的选项将专⻔应用于该程序。例如，[mysqld] 和 [mysql] 组分别应用于mysqld服务器程序 和 mysql客户端程序。不过有两个选项组比较特别: [server]组下边的启动选项将作用于所有的服务器程序。 [client]组下边的启动选项将作用于所有的客户端程序。 不过， 需要注意的一点是，mysqld_safe和mysql.server这两个程序在启动时都会读取[mysqld]选项组中的内容。 为了直观感受一下，我们挑一些启动命令来看一下它们能读取的选项组都有哪些: 启动命令 类别 能读取的组 mysqld 启动服务器 [mysqld]、[server] mysqld_safe 启动服务 [mysqld]、[server]、[mysqld_safe] mysql.server 启动服务 [mysqld]、[server]、[mysql.server] mysql 启动客户端 [mysql]、[client] mysqladmin 启动客户端 [mysqladmin]、[client] mysqldump 启动客户端 [mysqldump]、[client] 特定MySQL版本的专用选项组我们可以在选项组的名称后加上特定的MySQL版本号，比如对于 [mysqld]选项组 来说，我们可以定义一个 [mysqld-5.7] 的选项组，它的含义和 [mysqld] 一样，只不过只有版本号为5.7的 mysqld程序才能使用这个选项组中的选项。 配置文件的优先级我们前边唠叨过MySQL将在某些固定的路径下搜索配置文件，我们也可以通过在命令行上指定defaults-extra-file启动选项 来指定额外的配置文件路径。MySQL将按照我们在上表中给定的顺序依次读取各个配置文件，如果该文件不存在则忽略。值得注意的是，如果我们在多个配置文件中设置了相同的启动选项，那以最后一个配置文件中的为准。 同一个配置文件中多个组的优先级我们说同一个命令可以访问配置文件中的多个组，比如mysqld可以访问[mysqld]、[server]组，如果在同一个配置文件中的这些组里出现了同样的配置项，比如:[server]default-storage-engine=InnoDB[mysqld]default-storage-engine=MyISAM那么，将以最后一个出现的组中的启动选项为准，因为[mysqld]组在[server]组后边，就以 [mysqld]组中的配置项为准。 defaults-file的使用如果我们不想让MySQL到默认的路径下搜索配置文件(就是上表中列出的那些)，则可以在命令行指定defaults-file选项比如：mysqld --defaults-file=/tmp/myconfig.txt，在程序启动的时候将只在&#x2F;tmp&#x2F;myconfig.txt路径下搜索配置文件。如果文件不存在或无法访问，则会发生错误。 Tips: 注意defaults-extra-file和defaults-file的区别使用defaults-extra-file可以指定额外的配置文件搜索路径 (也就是说那些固定的配置文件路径也会被搜索)。 命令行和配置文件中启动选项的区别在命令行上指定的绝大部分启动选项都可以放到配置文件中，但是有一些选项是专⻔为命令行设计的，比方说defaults-extra-file、defaults-file这样的选项本身就是为了指定配置文件路径的，再放在配置文件中使用就没啥意义了。剩下的一些只能用在命令行上而不能用到配置文件中的启动选项就不一一列举了，用到的时候再提。 另外有一点需要特别注意，如果同一个启动选项既出现在命令行中，又出现在配置文件中，那么以命令行中的启动选项为准! 系统变量简介 MySQL服务器程序运行过程中会用到许多影响程序行为的变量，它们被称为MySQL系统变量。 比如允许同时连入的客户端数量用系统变量 max_connections 表示 表的默认存储引擎用系统变量 default_storage_engine 表示 查询缓存的大小用系统变量 query_cache_size 表示 MySQL服务器程序的系统变量有好几百条，我们就不一一列举了。每个系统变量都有一个默认值，我们可以使用命令行或者配置文件中的选项在启动服务器时改变它们。 不过，大多数的系统变量的值也可以在程序运行过程中修改，而无需停止并重新启动它。 查看系统变量 可以使用 SHOW VARIABLES [LIKE 匹配的模式]; 命令查看MySQL服务器程序支持的系统变量以及它们的当前值:不过，由于系统变量实在太多了，如果我们直接使用 SHOW VARIABLES 查看的话就直接刷屏了，所以通常都会带一个LIKE过滤条件来查看我们需要的系统变量的值，比如:mysql&gt; SHOW VARIABLES LIKE ‘default_storage_engine’;+————————+——–+| Variable_name | Value |+————————+——–+| default_storage_engine | InnoDB |+————————+——–+1 row in set (0.01 sec) mysql&gt; SHOW VARIABLES like ‘max_connections’;+—————–+——-+| Variable_name | Value |+—————–+——-+| max_connections | 151 |+—————–+——-+1 row in set (0.00 sec) mysql&gt; 设置系统变量通过启动选项设置系统变量 大部分的系统变量都可以通过启动服务器时传送启动选项的方式来进行设置。如何填写启动选项我们上边已经花了大篇幅来唠叨了，就是下边两种方式: 通过命令行添加启动选项:比方说我们在启动服务器程序时用命令: mysqld --default-storage-engine=MyISAM --max-connections=10 通过配置文件添加启动选项:[server] default-storage-engine=MyISAM max-connections=10 有一点需要注意的是，对于启动选项来说，如果启动选项名由多个单词组成，各个单词之间用短划线-或者下划线_连接起来都可以，但是对应的 系统变量 之间必须使用下划线_连接起来。 服务器程序运行过程中设置系统变量 系统变量比较牛逼的一点就是，对于大部分系统变量来说，它们的值可以在服务器程序运行过程中进行动态修改而无需停止并重启服务器。不过系统变量有作用范围之分，下边详细唠叨下。 系统变量的不同作用范围我们前边说过，多个客户端程序可以同时连接到一个服务器程序。对于同一个系统变量，我们有时想让不同的客户端有不同的值。 比方说狗哥使用客户端A，他想让当前客户端对应的默认存储引擎为InnoDB，所以他可以把系统变量default_storage_engine的值设置为InnoDB; 猫爷使用客户端B，他想让当前客户端对应的默认存储引擎为MyISAM，所以他可以把系统变量default_storage_engine的值设置为MyISAM。这样可以使狗哥和猫爷的的客户端拥有不同的默认存储引擎，使用时互不影响，十分方便。但是这样各个客户端都私有一份系统变量会产生这么两个问题: 有一些系统变量并不是针对单个客户端的，比如允许同时连接到服务器的客户端数量max_connections，查询缓存的大小query_cache_size，这些公有的系统变量让某个客户端私有显然不合适。 一个新连接到服务器的客户端对应的系统变量的值该怎么设置? 为了解决这两个问题，设计MySQL的大叔提出了系统变量的作用范围的概念，具体来说作用范围分为这两种: GLOBAL:全局变量，影响服务器的整体操作。 SESSION:会话变量，影响某个客户端连接的操作。(注:SESSION有个别名叫LOCAL) 在服务器启动时，会将每个全局变量初始化为其默认值(可以通过命令行或配置文件中指定的选项更改这些默认值)。然后服务器还为每个连接的客户端维护一组会话变量，客户端的会话变量在连接时使用相应全局变量的当前值初始化。以default_storage_engine举例，在服务器启动时会初始化一个名为default_storage_engine，作用范围为GLOBAL的系统变量。之后每当有一个客户端连接到该服务器时，服务器都会单独为该客户端分配一个名为default_storage_engine，作用范围为SESSION的系统变量，该作用范围为SESSION的系统变量值按照当前作用范围为GLOBAL的同名系统变量值进行初始化。 服务器程序运行过程中设置系统变量了解了系统变量的GLOBAL和SESSION作用范围之后，我们再看一下在服务器程序运行期间通过客户端程序设置系统变量的语法:SET [GLOBAL|SESSION] 系统变量名 = 值;或者SET [@@(GLOBAL|SESSION).]var_name = XXX; 如果在设置系统变量的语句中省略了作用范围，默认的作用范围就是SESSION 查看不同作用范围的系统变量 既然系统变量有作用范围之分，那我们的SHOW VARIABLES语句查看的是什么作用范围的系统变量呢?答:默认查看的是SESSION作用范围的系统变量。 当然我们也可以在查看系统变量的语句上加上要查看哪个作用范围的系统变量，就像这样:SHOW [GLOBAL|SESSION] VARIABLES [LIKE 匹配的模式]; 如果某个客户端改变了某个系统变量在GLOBAL作用范围的值，并不会影响该系统变量在当前已经连接的客户端作用范围为 SESSION的值，只会影响后续连入的客户端在作用范围为 SESSION的值。 注意事项 并不是所有系统变量都具有GLOBAL和SESSION的作用范围 有一些系统变量只具有GLOBAL作用范围，比方说 max_connections，表示服务器程序支持同时最多有多少个客户端程序进行连接。 有一些系统变量只具有SESSION作用范围，比如 insert_id，表示插入值时使用的AUTO_INCREMENT修饰的列的值。 有一些系统变量的值既具有GLOBAL作用范围，也具有SESSION作用范围，比如我们前边用到的 default_storage_engine，而且其实大部分的系统变量都是这样的。 有些系统变量是只读的，并不能设置值。 比方说version，表示当前MySQL的版本，我们客户端是不能设置它的值的，只能在SHOW VARIABLES语句里查看。 启动选项和系统变量的区别启动选项是在程序启动时我们程序员传递的一些参数，而系统变量是影响服务器程序运行行为的变量，它们之间的关系如下: 大部分的系统变量都可以被当作启动选项传入; 有些系统变量是在程序运行过程中自动生成的，是不可以当作启动选项来设置，比如 auto_increment_offset、character_set_client啥的。 有些启动选项也不是系统变量，比如defaults-file。 状态变量为了让我们更好的了解服务器程序的运行情况，MySQL服务器程序中维护了好多关于程序运行状态的变量，它们被称为状态变量。比方说 Threads_connected 表示当前有多少客户端与服务器建立了连接，Handler_update表示已经更新了多少行记录吧啦吧啦，像这样显示服务器程序状态信息的状态变量还有好几百个，我们就不一一唠叨了，等遇到了会详细说它们的作用的。 由于状态变量是用来显示服务器程序运行状况的，所以它们的值只能由服务器程序自己来设置，我们程序员是不能设置的。与系统变量类似，状态变量也有GLOBAL和SESSION两个作用范围的，所以查看状态变量的语句可以这么写: 123456789101112131415SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];// 类似的，如果我们不写明作用范围，默认的作用范围是SESSION// 如下， 所有以Thread开头的SESSION作用范围的状态变量就都被展示出来 了。mysql&gt; SHOW STATUS LIKE &#x27;thread%&#x27;;+-------------------+-------+| Variable_name | Value |+-------------------+-------+| Threads_cached | 1 || Threads_connected | 1 || Threads_created | 2 || Threads_running | 2 |+-------------------+-------+4 rows in set (0.00 sec)mysql&gt;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"1. 重新认识MySQL","date":"2021-09-12T05:01:09.000Z","path":"2021/09/12/MySQL知识点整理/1. 重新认识MySQL/","text":"MySQL的 客户端&#x2F;服务器架构我们日常使用MySQL的情景一般是: 启动 MySQL服务器程序； 启动 MySQL客户端程序 并连接到 MySQL服务器程序； 在 MySQL客户端程序 中输入一些 命令语句 作为请求发送到 MySQL服务器程序； MySQL服务器程序 收到这些请求后，会根据请求的内容来操作具体的数据并向 MySQL客户端程序 返回操作结果。 MySQL服务器程序 和 MySQL客户端程序 本质上都算是计算机上的一个进程，代表 MySQL服务器程序 的进程也被称为 MySQL数据库实例(简称数据库实例)； 每个进程都有一个唯一的编号，称为 进程ID，英文名叫PID， 这个编号是在我们启动程序的时候由操作系统 随机分配的，操作系统会保证在某一时刻同一台机器上的进程号不重复。 比如你打开了计算机中的QQ程序，那么操作系统会为它分配一个唯一的进程号；如果你把这个程序关掉了，那操作系统就会把这个进程号回收，之后可能会重新分配给别的进程。当我们下一次再启动QQ程序的时候分配的就可能是另一个编号。 每个进程都有一个名称，这个名称是编写程序的人自己定义的，比如我们启动的 MySQL服务器进程 的默认名称是 mysqld，而我们常用的MySQL客户端进程的默认名称为 mysql。 MySQL安装 小须知首先你要知道：无论我们通过 下载源代码自行编译安装的方式 还是 直接使用官方提供的安装包进行安装的方式。之后，MySQL的服务器程序和MySQL的客户端程序 都会被安装到我们的机器上。 Tips:MySQL的大部分安装包都包含了服务器程序和客户端程序，不过在Linux下使用 RPM包 安装时会有单独的 服务器RPM包 和 客户端RPM包，需要分别安装。 不论使用上述两者的哪种安装方式，一定要记住你的 MySQL的安装目录 。 在 MySQL的安装目录 下有一个特别特别重要的目录 bin目录 ，这个目录下存放着许多可执行文件。 启动MySQL服务器程序在 类UNIX系统 中，用来 启动MySQL服务器程序 的可执行文件有很多，大多都在 MySQL安装目录 的 bin目录 下。 mysqldmysqld 这个可执行文件就代表着 MySQL服务器程序，运行这个可执行文件就可以直接启动一个服务器进程。 但这个命令不常用，我们继续往下看更牛逼的启动命令。 mysqld_safemysqld_safe 是一个启动脚本: 它会间接的调用 mysqld ; 而且还顺便启动了另外一个 监控进程；这个 监控进程 在服务器进程挂了的时候，可以帮助重启它; 另外，它会将服务器程序的出错信息和其他诊断信息重定向到某个文件中，产生错误日志，方便我们找出发生错误的原因。 mysql.servermysql.server 也是一个启动脚本，它会间接的调用 mysqld_safe； 命令用法如下： 启动服务器程序 ：mysq.server start 停止服务器程序：mysq.server stop 需要注意的是，这个 mysql.server 文件其实是一个链接文件，它的实际文件是 ../support-files/mysql.server 。 我使用的macOS操作系统会帮我在bin目录下自动创建一个指向实际文件的链接文件，如果你的操作系统没有帮你自动创建这个链接文件，那就自己创建一个呗~ mysqld_multi 其实我们一台计算机上也可以运行多个MYSQL数据库实例。mysql_multi可执行文件 可以对每一个服务器进程的启动或停止进行监控。这个命令的使用比较复杂，本书主要是为了讲清楚MySQL服务器和客户端运行的过程，不会对启动多个服务器程序进行过多唠叨。 启动MySQL客户端程序 在成功启动MySQL服务器程序后，就可以接着启动MySQL客户端程序来连接到这个服务器。 bin目录下有许多客户端程序，比方说 mysqladmin、mysqldump、mysqlcheck 等等 (好多呢，就不一一列举了)。 这里我们重点要关注的是 可执行文件 mysql： 通过这个可执行文件可以让我们和服务器程序进程交互(也就是发送请求，接受服务器的处理结果)。 命令用法：&#x2F;&#x2F; 启动这个可执行文件时一般需要一些参数，格式如下:mysql -h主机名 -u用户名 -p密码 &#x2F;&#x2F; 如果我们想断开客户端与服务器的连接并且关闭客户端的话，&gt; 可以在 mysql&gt; 提示符后输入下边任意一个命令: quit exit \\q Tips:像 h、u、p 这样只有一个英文字母的参数称为 短形式的参数，使用时前边需要加单短划线;而像 host、user、password 这样大于一个英文字母的参数称为⻓形式的参数，使用时前边需要加 双短划线。 如果你愿意，你可以多打开几个终端窗口(每个黑框框都使用 mysql -hlocalhost -uroot -p123456)来运行多个 客户端程序，每个客户端程序 其实都是互不影响的。如果你有多个电脑，也可以试试把它们用局域网连起来，在一个电脑上启动 MySQL服务器程序，在另一个电脑上执行 mysql命令 使用IP地址作为主机名来连接到服务器。 客户端与服务器连接的过程我们现在已经知道如何启动 MySQL的服务器程序，以及如何启动 MySQL的客户端程序来连接到这个服务器程序。 运行着的服务器程序和客户端程序本质上都是计算机上的一个进程，所以客户端进程向服务器进程发送请求并得到回复的过程本质上是一个进程间通信的过程! MySQL支持下边三种客户端进程和服务器进程的通信方式: TCP&#x2F;IP真实环境中，数据库服务器进程 和 客户端进程 可能运行在不同的主机中，它们之间必须通过网络来进行通讯。 MySQL采用 TCP 作为服务器和客户端 之间的网络通信协议: 在网络环境下，每台计算机都有一个唯一的IP地址，如果某个进程有需要采用TCP协议进行网络通信方面的需求，可以向操作系统申请一个端口号，这是一个整数值，它的取值范围是0~65535。这样在网络中的其他进程就可以通过 IP地址 + 端口号的方式来与这个进程连接，这样进程之间就可以通过网络进行通信了。 MySQL服务器启动时会默认申请3306端口号(即，MySQL服务器会默认监听3306端口)，之后就在这个端口号上等待客户端进程进行连接。 Tips:&#x2F;&#x2F; 如果3306端口号已经被别的进程占用了或者我们单纯的想自定义该 数据库实例监听的端口号，那我们可以在启动服务器程序的命令行里添加 -P参数 来明确指定一下端口号，比如这样: mysqld -P3307&#x2F;&#x2F; 这样MySQL服务器在启动时就会去监听我们指定的端口号3307。 命名管道和共享内存如果你是一个Windows用户，那么客户端进程和服务器进程之间可以考虑使用命名管道或共享内存进行通信。 Unix域套接字文件如果我们的服务器进程和客户端进程都运行在 同一台 操作系统为 类Unix的机器上的话，我们可以使用Unix域套接字文件来进行进程间通信。 如果我们在启动客户端程序时指定的主机名为localhost，或者指定了--protocal=socket的启动参数，那服务器程序和客户端程序之间就可以通过Unix域套接字文件来进行通信了。 MySQL服务器程序默认监听的Unix域套接字文件路径为/tmp/mysql.sock，客户端程序也默认连接到这个Unix域套接字文件。 如果我们想改变这个默认路径，可以在启动服务器程序时指定socket参数，就像这样: mysqld --socket=/tmp/a.txt，这样服务器启动后便会监听/tmp/a.txt。 在服务器改变了默认的UNIX域套接字文件后，如果客户端程序想通过UNIX域套接字文件进行通信的话，也需要显式的指定连接到的UNIX域套接字文件路径，就像这样:mysql -hlocalhost -uroot --socket=/tmp/a.txt -p 这样该客户端进程和服务器进程就可以通过路径为/tmp/a.txt的Unix域套接字文件进行通信了。 服务器处理客户端请求 其实不论客户端进程和服务器进程是采用哪种方式进行通信，最后实现的效果都是:客户端进程向服务器进程发送一段文本(MySQL语句)，服务器进程处理后再向客户端进程返回一段文本(处理结果)。 那服务器进程对客户端进程发送的请求做了什么处理，才能产生最后的处理结果呢? 客户端可以向服务器发送增删改查各类请求，我们这里以比较复杂的查询请求为例来画个图展示一下大致的过程: 从图中可以看出，服务器程序处理来自客户端的查询请求大致需要经过三个部分，分别是 连接管理、解析与优化、 存储引擎 。下边我们来详细看一下这三个部分都干了什么。 📌连接管理 客户端进程 可以采用我们上边介绍的 TCP/IP、命名管道或共享内存、Unix域套接字 这几种方式之一来与 服务器进 程建立连接。 每当有一个客户端进程连接到服务器进程时，服务器进程都会创建一个线程来专⻔处理与这个客户端的交互； 当该客户端退出时会与服务器断开连接，服务器并不会立即把与该客户端交互的线程销毁掉，而是把它缓存起来； 在另一个新的客户端再进行连接时，服务器会把这个缓存的线程重新分配给该新客户端。 这样就起到了不频繁创建和销毁线程的效果，从而节省开销 。 从这一点大家也能看出， MySQL服务器会为每一个连接进来的客户端分配一个线程，但是线程分配的太多了会严重影响系统性能，所以我们也需要限制一下可以同时连接到服务器的客户端数量 ，至于怎么限制我们后边再说哈~ 在客户端程序发起连接的时候，需要携带 主机信息、用户名、密码，服务器程序会对客户端程序提供的这些信息进行认证，如果认证失败，服务器程序会拒绝连接。另外，如果客户端程序和服务器程序不运行在一台计算机上，我们还可以采用使用了SSL(安全套接字)的网络连接进行通信，来保证数据传输的安全性。 当连接建立后，与该客户端关联的服务器线程会一直等待客户端发送过来的请求，MySQL服务器接收到的请求只是一个文本消息，该文本消息还要经过各种处理，预知后事如何，继续往下看哈~ 解析与优化到现在为止，MySQL服务器已经获得了文本形式的请求，接着还要经过九九八十一难的处理，其中的几个比较重要的部分分别是 查询缓存、语法解析 和 查询优化，下边我们详细来看。 查询缓存 如果我问你 9+8×16-3×2×17 的值是多少，你可能会用计算器去算一下，或者牛逼一点用心算，最终得到了结果35，如果我再问你一遍 9+8×16-3×2×17 的值是多少，你还用再傻呵呵的算一遍么?我们 刚刚已经算过了，直接说答案就好了。 MySQL服务器程序处理查询请求的过程也是这样，会把刚刚处理过的查询请求和结果缓存起来，如果下一次有一模一样的请求过来，直接从缓存中查找结果就好了，就 不用再傻呵呵的去底层的表中查找了。 并且 这个查询缓存可以在不同客户端之间共享 ，也就是说如果客户端A刚刚查询了一个语句，而客户端B之后发送了同样的查询请求，那么客户端B的这次查询就可以直接使用查询缓存中的数据。 当然，MySQL服务器并没有人聪明: 如果两个查询请求在任何字符上的不同(例如:空格、注释、大小写)，都会导致缓存不会命中。 另外，如果查询请求中包含某些系统函数、用户自定义变量和函数、一些系统表，如 mysql 、information_schema、 performance_schema 数据库中的表，那这个请求就不会被缓存。 以某些系统函数举例，可能同样的函数的两次调用会产生不一样的结果，比如 函数NOW，每次调用都会产生最新的当前时间，如果在一个查询请求中调用了这个函数，那即使查询请求的文本信息都一样，那不同时间的两次查询也应该得到不同的结果，如果在第一次查询时就缓存了，那第二次查询的时候直接使用第一次查询的结果就是错误的! 而且，既然是缓存，那就有它缓存失效的时候。MySQL的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了INSERT、 UPDATE、DELETE、TRUNCATE TABLE、ALTER TABLE、DROP TABLE或 DROP DATABASE 语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除! 所以，虽然查询缓存有时可以提升系统性能，但也不得不因维护这块缓存而造成一些开销，比如每次都要去查询缓存中检索，查询请求处理完需要更新查询缓存，维护该查询缓存对应的内存区域。从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 语法解析 如果 查询缓存 没有命中，接下来就需要进入正式的 查询阶段 了。 但由于客户端程序 发送过来的请求只是一段文本而已，所以MySQL服务器程序首先要对这段文本做分析，判断请求的语法是否正确，然后从文本中将 要查询的表、各种查询条件 … 等信息都提取出来放到MySQL服务器内部使用的一些数据结构上来。⚠️ Tips:这个从指定的文本中提取出我们需要的信息本质上算是一个编译过程，涉及 词法解析、语法分析、语义分析 等阶段，这些问题不属于我们讨论的范畴，大家只要了解在处理请求的过程中需要这个步骤就好了。 📌 查询优化 语法解析之后，服务器程序获得到了需要的信息，比如 要查询的列是哪些，表是哪个，搜索条件是什么 等等…，但光有这些是不够的，因为我们写的MySQL语句执行起来效率可能并不是很高，MySQL的优化程序会对我们的语句做一些优化，如外连接转换为内连接、表达式简化、子查询转为连接吧啦吧啦的一堆东⻄。 优化的结果会 生成一个执行计划 ，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的。我们可以使用EXPLAIN语句来查看某个语句的执行计划，关于查询优化这部分的详细内容我们后边会仔细唠叨，现在你只需要知道在MySQL服务器程序处理请求的过程中有这么一个步骤就好了。 📌 存储引擎截止到服务器程序完成了查询优化为止，还没有真正的去访问真实的数据表。 MySQL服务器把数据的存储和提取操作都封装到了一个叫 存储引擎 的模块里 。 我们知道表是由一行一行的记录组成的， 但这只是一个逻辑上的概念，物理上如何表示 记录，怎么从表中读取数据，怎么把数据写入具体的物理存储器上? 这都是 存储引擎 负责的事情。 为了实现不同的功能，MySQL提供了各式各样的存储引擎，不同存储引擎管理的表具体的存储结构可能不同，采用的存取算法也可能不同 。 为了管理方便，人们把 连接管理、查询缓存、语法解析、查询优化 这些并不涉及真实数据存储的功能划分为MySQL server的功能。 而把真实存取数据的功能划分为存储引擎的功能。（各种不同的 存储引擎 向上边的 MySQL server层 提供统一的调用接口(也就是存储引擎 API)，包含了几十个底层函数，像”读取索引第一条内容”、”读取索引下一条内容”、”插入记录”等等。所以在MySQL server完成了查询优化后，只需按照生成的执行计划 调用 底层存储引擎 提供的API，获取到数据后返回给客户端就好了。 常用存储引擎MySQL支持非常多种存储引擎，我这先列举一些: 存储引擎 描述 ARCHIVE 用于数据存档(行被插入后不能再修改) BLACKHOLE 丢弃写操作，读操作会返回空内容 CSV 在存储数据时，以逗号分隔各个数据项 FEDERATED 用来访问远程表 InnoDB 具备外键支持功能的事务存储引擎 MEMORY 置于内存的表 MERGE 用来管理多个MyISAM表构成的表集合 MyISAM 主要的非事务处理存储引擎 NDB MySQL集群专用存储引 这么多我们怎么挑啊，哈哈，你多虑了，其实我们最常用的就是InnoDB 和 MyISAM，有时会提一下 Memory。其中InnoDB是MySQL默认的存储引擎，我们之后会详细唠叨这个存储引擎的各种功能。现在先看一下一些存储引擎对于某些功能的支持情况: Feature MyISAM Memory InnoDB Archive NDB B-tree indexes yes yes yes no no Clustered indexes no no yes no no Full-text search indexes yes no yes no no MVCC no no yes no no …… …… …… …… …… …… Hash indexes no yes no no yes 密密麻麻列了这么多，看的头皮都发麻了，达到的效果就是告诉你: 这玩意儿很复杂。其实这些东⻄大家没必要立即就给记住，列出来的目的就是想让大家明白不同的存储引擎支持不同的功能，有些重要的功能我们会在后边的唠叨中慢慢让大家理解的~ 查看、设置 存储引擎 我们可以用SHOW ENGINES;命令来查看当前服务器程序支持的存储引擎: Support列 表示该存储引擎是否可用; DEFAULT值 代表是当前服务器程序的默认存储引擎; Comment列 是对存储引擎的一个描述; Transactions列 代表该存储引擎是否支持事务处理; XA列 代表着该存储引擎是否支持分布式事务; (也许你并不知道什么是个事务、更别提分布式事务了，这些内容在后边的章节会详细唠叨，现在看个新鲜就得了) Savepoints列 代表着该列是否支持部分事务回滚。 设置表的存储引擎前边说过， 存储引擎是负责对表中的数据进行提取和写入工作的 ，我们可以为不同的表设置不同的存储引擎，也就是说 不同的表可以有不同的物理存储结构，不同的提取和写入方式 。 创建表时指定存储引擎 我们之前创建表的语句都没有指定表的存储引擎，那就会使用默认的存储引擎InnoDB。(查看表结构可以使用:show create tables 表名\\G)如果我们想显式的指定一下表的存储引擎，那可以这么写:CREATE TABLE 表名( 建表语句;) ENGINE = 存储引擎名称; 如果表已经建好了，我们也可以使用 ALTER TABLE 表名 ENGINE = 存储引擎名称; 这个语句来修改表的存储引擎。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"0. 初阶需要重点关注 InnoDB存储引擎 存储结构 的相关知识","date":"2021-09-11T11:43:20.000Z","path":"2021/09/11/MySQL知识点整理/0. 初阶需要重点关注 InnoDB存储引擎 存储结构 的相关知识/","text":"开篇需要提醒你的是，在MySQL中， InnoDB存储引擎 的 存储结构 的相关知识(比如 记录结构、⻚结构、索引结构、表空间结构 等等)，是所有后续知识的基础，也是 重中之重，一定要重点掌握。 Jeremy Cole 已经使用 Ruby 开发了一个简易的工具来解析这些基础结构（innodb_ruby的github地址），你可以按照说明安装上这个工具，从而更好的理解 InnoDB 中的一些存储结构(此工具虽然是针对MySQL 5.6 的，但是幸好MySQL的基础存储结构基本没多大变化 ，所以大部分场景下这个innodb_ruby工具还是可以使用的)。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"HTTP 之 method","date":"2017-11-27T11:43:20.000Z","path":"2017/11/27/HTTP/4. method/","text":"PUT vs POST PUT: 替换资源; PUT 和 POST的区别: 在HTTP中, PUT被定义为 idempotent(幂等性) 的方法, POST则不是, 这是一个很重要的区别 应该用 PUT 还是 POST? 取决于这个REST服务的行为是否是idempotent(幂等)的 假如发送两个请求, 希望服务器端是产生两个新数据，那就说明这个服务不是idempotent的, 因为多次使用产生了副作用了, 那就应该使用 POST 方法; 但如果是希望后一个请求把第一个请求覆盖掉(这不正是修改么), 那这个服务就是idempotent的, 那就应该使用 PUT 方法; 虽然 POST 和 PUT 差别不大, 用错了也没关系, 但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦; POST POST: 上面已经提过了, POST是非幂等的; POST 和 PUT 都可以上传文件或者创建新信息, 但主要看你的REST服务行为是否是幂等的; PATCHPATCH不是HTTP标准方法的，服务端需要考虑客户端是否能够支持的问题; 对已有资源的操作: 用于对资源的 部分内容 进行更新 (例如更新某一个字段, 具体比如说只更新用户信息的电话号码字段); 而 PUT 则用于更新某个资源较完整的内容, 比如说用户要重填完整表单更新所有信息, 后台处理更新时可能只是保留内部记录ID不变; HEAD HEAD和 GET 本质是一样的, 区别在于如果使用HEAD, 响应体将不会被返回, 而仅仅返回HTTP头信息;比如: 欲判断某个资源是否存在, 我们通常使用GET, 但这里用HEAD则意义更加明确; GET比较简单, 直接获取资源; OPTIONS这个方法使用比较少, 它用于获取当前URL所支持的方法;若请求成功, 则它会在HTTP头中包含一个名为 Allow 的头, 值是服务器所支持的方法, 如 GET, POST;之前跨域相关博文 CORS方案 not-so-simple request 中的”预检”请求用的请求方法就是 OPTIONS; CONNECT要求用隧道协议连接代理, 如使用SSL TRACE~~未完待续 DELETE参考 PURGE非规范中定义的方法","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]},{"title":"认证与授权","date":"2017-11-25T13:12:54.000Z","path":"2017/11/25/HTTP/3. 认证与授权/","text":"认证 (Authentication) 和 授权 (Authorization) 的区别？这是一个绝大多数人都会混淆的问题。简单点说： 认证 (Authentication)： 你是谁 是验证您的身份的凭据（例如用户名&#x2F;用户ID和密码），通过这个凭据，系统得以知道你就是你，也就是说系统是否存在你这个用户。所以，Authentication 被称为身份&#x2F;用户验证。 401 Unauthorized : 表示 认证(Authentication) 类型的错误比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 授权 (Authorization)： 你有权限干什么 Authorization（授权） 发生在 Authentication（认证） 之后。它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。 403 Forbidden : 经常和401状态码混淆; 其实403表示的是 授权(Authotization) 类型的错误, 授权和认证的不同之处是: 小结通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限”这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。 Cookie Session 身份验证 Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 用户成功登陆系统，然后返回给客户端具有 SessionID 的 Cookie，只有用户向再后端发起请求的时候会把 SessionID 带上，这样后端就知道你的身份状态了。 使用 Session 的时候需要注意下面几个点： 依赖Session的关键业务一定要确保客户端开启了Cookie 注意Session的过期时间 如果没有Cookie的话Session还能用吗？一般是通过 Cookie 来保存 SessionID，假如你使用了 Cookie 保存 SessionID的方案的话，如果客户端禁用了Cookie，那么 Session就无法正常工作。但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将SessionID放在请求的 url 里面 https://javaguide.cn/?session_id=xxx 。这种方案可行，但是安全性和用户体验感降低。当然，你也可以对 SessionID 进行一次加密之后再传入后端。 Cookie 无法防止CSRF攻击，而token可以CSRF（Cross Site Request Forgery）一般被翻译为 跨站请求伪造 。简单来说就是用你的身份去发送一些对你不友好的请求。举个简单的例子： 小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了10000元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。&lt;a src&#x3D;http://www.mybank.com/Transfer?bankId=11&amp;money=10000&gt;科学理财，年盈利率过万&lt;&#x2F;&gt;上面也提到过，进行Session 认证的时候，我们一般使用 Cookie 来存储 SessionId, 当我们登陆后，后端生成一个SessionId放在Cookie中返回给客户端，服务端通过Redis或者其他存储工具记录保存着这个Sessionid，客户端登录以后每次请求都会带上这个SessionId，服务端通过这个SessionId来标识你这个人。如果别人通过 cookie拿到了 SessionId ，那他就可以代替你的身份访问系统了。而 Session 认证中，Cookie 中的 SessionId是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。 但是，我们使用 token 的话就不会存在这个问题，在我们登录成功获得 token 后，然后我们在前端通过某些方式会给每个发到后端的请求加上这个 token,这样就不会出现 CSRF 漏洞的问题。因为，即使你点击了某个非法链接发送请求到服务端，这个非法请求是无法自动携带 token 的，所以这个请求将是非法的。 ** 其实CSRF主要是利用浏览器会携带已登录的用户标识，来达到冒充用户的目的，从而对被攻击的网站执行某项操作。** 无论 Cookie 还是 token 都无法避免 跨站脚本攻击（Cross Site Scripting）XSS跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为XSS。XSS中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如cookie。 推荐阅读：如何防止CSRF攻击？—美团技术团队CSRF的特点： 攻击一般发起在第三方网站，而不是被攻击的网站。 攻击利用受害者在被攻击网站的登录凭证，冒充受害者提交操作；而不是直接窃取数据。 整个过程攻击者并不能获取到受害者的登录凭证，仅仅是“冒用”。 跨站请求可以用各种方式：图片URL、超链接、CORS、Form提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪。CSRF通常是跨域的，因为外域通常更容易被攻击者掌控(lant:也就是说，如果你的站点是跨域的，这个域最好有个一级域名的限制，否则其他网站都能钓鱼了)。但是如果本域下有容易被利用的功能，比如可以发图和链接的论坛和评论区，攻击可以直接在本域下进行，而且这种攻击更加危险。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]},{"title":"03. HTTP状态码详解","date":"2017-11-25T05:30:12.000Z","path":"2017/11/25/HTTP/2. status_code/","text":"1xx 101: 参考博文WebSocket简单示例分析 (做协议升级, 还会响应: Connection: Upgrade) 2xx Web API的设计与开发 P109 200 OK : 200码非常出名, 似乎没有对它进一步说明的必要; 201 Created : 当在服务器端创建数据成功时, 会返回201状态码; 也就是使用 POST 请求方法的场景 (如:用户登录后添加了新用户, 上传了图片等新创建数据的场景) 202 Accepted : 在异步处理客户端请求时, 它用来表示服务器端已经接受了来自客户端的请求, 但处理尚未结束; 在文件格式转换, 处理远程通知(Apple Push Notification等)这类很耗时的场景中, 如果等到所有处理都结束后才向客户端返回响应消息, 就会花费相当长的时间, 造成应用可用性不高; 这时采用的方法是服务器向客户端返回一次响应消息, 然后立刻开始异步处理。 202状态码就被用于告知客户端服务器端已经开始处理请求, 但整个处理过程尚未结束; 比如: 以LinkedIn的参与讨论的API为例如果成功参与讨论并发表意见, 服务器端通常会返回201状态码;但如果需要得到群主的确认, 那么所发表的意见就无法立即在页面显示出来, 这时服务器端就需要返回202状态码; 从广义上来看, 该场景也属于异步处理, 但和程序设计里的异步执行当然不同; 204 No Content : 正如其字面意思, 当响应消息为空时会返回该状态码。 其实就是告诉浏览器, 服务端执行成功了, 但是没什么数据返回给你, 所以你不用刷新页面, 也不用导向新的页面; 在用 DELETE 方法删除数据时, 服务器端通常会返回204状态码(阮一峰博文也提到过, 对DELETE适用); 除此之外, 也有人认为在使用 PUT或PATCH 方法更新数据时, 因为只是更新已有数据, 所以返回204状态码更加自然;书中建议 DELETE 返回204; PUT或PATCH返回200并返回该方法所操作的数据; 关于204状态码的讨论可以参考 p111; 205 Reset Content : 告诉浏览器, 页面表单需要被重置; 205的意思是服务端在接收了浏览器POST请求以后, 处理成功以后, 告诉浏览器, 执行成功了, 请清空用户填写的Form表单, 方便用户再次填写; 206 Partial Content : 成功执行了一个部分或Range(范围)的请求; 206响应中, 必须包含 Content-Range, Date 以及 ETag或Content-Location首部; 3xx300 Multiple Choices : 客户端驱动方式进行内容协商时, 服务器可能返回多个连接供客户端进行选择 (比如多语言网站可能会出现); 301 Moved Permanently : 在请求的URL已经被移除时使用, 响应的Location首部中应该包含资源现在所处的URL; (比较适合永久重定向) 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是301; 则即便稍后取消了location.php中的跳转(或者修改了跳转地址), 由于浏览器还是会认为你之前的跳转是永久性的, 再次访问www.test.com/location.php仍然会跳转到之前的跳转链接(除非清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 302 Found: 与301类似, 但是客户端应该使用Location首部给出的URL来进行临时定位资源, 将来的请求仍应该使用老的URL; 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是302; 如果稍后取消了location.php中的跳转, 再次访问www.test.com/location.php, 会发现不会进行跳转, 而是访问到 location.php 修改后的代码 (不用清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 303 See Other : HTTP&#x2F;1.1使用303来实现和302一样的临时重定向; 307 Temporary Redirect HTTP&#x2F;1.1规范要求用307来取代302进行临时重定向; (302临时重定向留给HTTP&#x2F;1.0) 所以他也具备302临时重定向的特点; 但是, 与 302, 303 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 308 Permanent Redirect 貌似不是rfc2616的标准 具备和301永久重定向的特点, 需要清除浏览器缓存才行; 但是, 与 301 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 304 Not Modified : 参考博文缓存相关 4xx Web API的设计与开发 P1134字头状态码主要用于描述因客户端请求的问题而引发的错误。也就是说, 服务器端不存在问题, 但服务器端无法理解客户端发送的请求, 或虽然服务器端能够理解但请求却没有被执行, 当遇到这些情况引发的错误时, 服务器端便会向客户端返回这一类别的状态码。因此, 当服务器端返回4字头的状态码时, 就表示客户端的访问方式发生了问题, 用户需要检查一下客户端的访问方式或访问的目标资源等。 400 Bad Request : 表示其他错误的意思, 即其他4字头状态码都无法描述的错误类型; 401 Unauthorized : 表示认证(Authentication)类型的错误 比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 403 Forbidden : 和401状态码比较相似, 所以也经常被混淆; 其实403表示的是授权(Authotization)类型的错误, 授权和认证的不同之处是: 认证表示”识别前来访问的是谁”, 而授权则表示”赋予特定用户执行特定操作的权限” 通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限” 404 Not Found : 表示访问的数据不存在, 但是 例如当客户端湿度获取不存在的用户信息时, 或者试图访问原本就不存在的端点时, 服务器就会返回404状态码; 所以, 如果客户端想要获取用户信息, 却得到服务器端返回的404状态码, 客户端仅凭”404 Not Found”将难以区分究竟是用户不存在, 还是端点URI错误导致访问了原本不存在的URI; 405 Method Not Allowed : 表示虽然访问的端点存在, 但客户端使用的HTTP方法不被服务器端允许; 比如客户端使用了POST方法来访问只支持GET方法的信息检索专用的API; 又比如客户端用了GET方法来访问更新数据专用的API等; 406 Not Acceptable : 服务器端API不支持客户端指定的数据格式时, 服务器端所返回的状态码; 比如, 服务器端只支持JSON和XML输出的API被客户端指定返回YAML的数据格式时, 服务器端就会返回406状态码; 408 Request Timeout : 当客户端发送请求至服务器端所需的时间过长时, 就会触发服务器端的超时处理, 从而使服务器端返回该状态码; 409 Conflict: 用于表示资源发生冲突时的错误 (es中就会有该错误码) 比如通过指定ID等唯一键值信息来调用注册功能的API时, 倘若已有相同ID的数据存在, 就会导致服务器端返回409状态码; 在使用邮箱地址及Facebook ID等信息进行新用户注册时, 如果该邮箱地址或者ID已经被其他用户注册, 就会引起冲突, 这时服务器端就会返回409状态码告知客户端该邮箱地址或ID已被使用; 410 Gone : 和 404状态码 相同, 都表示访问资源不存在, 只是410状态码不单表示资源不存在, 还进一步告知资源曾经存在, 只是目前已经消失了; 因此服务器端常在访问被删除的数据时返回该状态码, 但是为了返回该状态码, 服务器必须保存该数据已被删除的信息, 而且客户端也应该知晓服务器端保存了这样的信息; 但是在通过邮箱地址搜索用户信息的API中, 从保护个人信息的角度来说, 返回410状态码的做法也会受到质疑; (所以在此种资源不存在的情况下, 为了稍微安全一些, 返回410状态码需要慎重) 413 Request Entity Too Large : 413也是比较容易出现的一种状态码, 表示请求实体过大而引发的错误 请求消息体过长是指, 比如在上传文件这样的API中, 如果发送的数据超过了所允许的最大值, 就会引发这样的错误; 414 Request-URI Too Large : 414是表示请求首部过长而引发的错误 如果在进行GET请求时, 查询参数被指定了过长的数据, 就会导致服务器端返回414状态码 415 Unsupported Media Type : 和406比较相似 406我们知道是表示服务器端不支持客户端想要接收的数据格式 而415表示的是服务器端不支持客户端请求首部 Content-Type 里指定的数据格式, 也就是说, 当客户端通过POST,PUT,PATCH等方法发送的请求消息体的数据格式不被服务器支持时, 服务器端就会返回415状态码; 例如在只接收JSON格式的API里, 如果客户端请求时发送的是XML格式的数据去请求服务器端, 或者在 Content-Type 首部指定 application/xml, 都会导致该类型错误; 429 Too Many Requests : 是2012年RFC6585文档中新定义的状态码, 表示访问次数超过了所允许的范围; 例如某API存在一小时内只允许访问100次的访问限制, 这种情况下入股哦客户端视图进行第101次访问, 服务器便会返回该状态码; 表示在一定的时间内用户发送了太多的请求, 即超出了”频次限制”, 在响应中，可以提供一个 Retry-After 首部来提示用户需要等待多长时间之后再发送新的请求; 5xx 5字头状态码表示错误不发生在客户端, 而是由服务器自身问题引发的。 500 Internal Server Error : 是web应用程序开发里非常常见的错误, 当服务器代码里存在bug, 输出错误信息并停止运行等情况下, 就会返回该类型的错误; 因此, 不仅限于API, 对于5字头状态码的错误, 都要认真监视错误日志, 使系统在出错时及时告知管理员, 以便在错误发生时做好应对措施, 防止再次发生。 501 Not Implemented : ??? 502 Bad GateWay : ??? 503 Service Unavaliable : 用来表示服务器当前处于暂不可用状态 可以回送:响应首部 Retry-After 表示多久恢复; 不同的客户端与服务器端应用对于 Retry-After 首部的支持依然不太一致; 不过，一些爬虫程序，比如谷歌的爬虫程序Googlebot, 会遵循Retry-After响应首部的规则, 将其与503(Service Unavailable,当前服务不存在)响应一起发送有助于互联网引擎做出判断,在宕机结束之后继续对网站构建索引。 参考:https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Retry-After 504 Gateway Time-out: 复现这个错误码比较简单, 让你的php程序模拟耗时请求, 如下代码 123&lt;?phpsleep(70);//模拟耗时，睡70秒echo &quot;睡醒了&quot;; 就会返回 12504 Gateway Time-outnginx/1.11.4505 HTTP Version Not Supported: 服务器收到的请求, 使用的是它无法支持的HTTP协议版本; 参考:《HTTP权威指南》、《Web API的设计与开发》","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]},{"title":"HTTP 之 同源策略SOP","date":"2017-11-24T15:01:19.000Z","path":"2017/11/24/HTTP/1. 同源策略/","text":"同源策略SOP浏览器安全的基石是”同源政策”（same-origin policy） 1995年，同源政策由 Netscape 公司引入浏览器。目前所有浏览器都实行这个政策; 简单来说，A站点设置的Cookie，B站点不能打开，除非这两个站点属同源，所谓同源指的是 “三个相同”: 协议相同http://blog.renyimin.com 和 https://blog.renyimin.com 就不是同一个源 ； 域名完全相同http://blog.renyimin.com/test/index.php 和 http://blog.renyimin.com/welcome/index.html 就是同一个源;但是 http://www.renyimin.com/test/index.php 和 http://blog.renyimin.com/test/index.php 就不是同一个源 ；localhost 和 127.0.0.1 也不是同一个源 ; 端口相同http://www.renyimin.com:8080/test/index.php 和 http://www.renyimin.com:80/test/index.php 就不是同一个源 ; 同源策略的限制随着互联网的发展, “同源政策”越来越严格, 目前, 如果非同源, 共有三种行为受到限制: Cookie、LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求不能发送 同源策略目的为了保证用户信息的安全，防止恶意的网站窃取并利用数据 比如用户登录一家银行网站后，又去浏览其他站点, 如果没有同源策略限制, 其他站点就也能读取银行网站的 Cookie, 这样的话，如果 Cookie 包含用户的私密信息，泄漏给第三方站点就比较危险, 当然, Cookie中包含的敏感信息通常经过加密，很难将其反向破解, 但这并不意味着绝对安全;虽然第三方无法通过解密获取cookie中的信息, 但它可以不解密,而是直接使用Cookie去骗取银行网站的信任;由此可见，”同源政策” 是必需的，否则, 各站点的 Cookie 可以随便共享，那互联网就毫无安全可言了; 同源策略和CSRF安全问题需要注意一点: 同源策略的限制, 并没有限制住CSRF攻击 假如你当前已经登录了邮箱，或bbs，同时你又访问了另外一个站点，假设这就是一个钓鱼网站(站点中伪装了很多诱导用户去点击的超链接, 而这些超链接都是其他站点的一些敏感操作, 就这样放好诱饵等待曾经登陆过那些站点的用户去点击, 等鱼儿上钩);假设这个网站上面可能因为某个图片吸引你，你去点击一下，而这个点击正是去往你的bbs站点进行一个发帖操作，由于当前你的浏览器状态已经是登陆了bbs站点，此时你点击这个钓鱼网站的连接是就会使用你之前登陆bbs站点在浏览器cookie罐中保存的信息, 就和正常的请求一样。于是钓鱼站点就纯天然的利用了其他站点的登陆状态，让用户在不知情的情况下，帮“它们”发帖或干其他更多危险的事情; 这也就是我们通常所说的CSRF攻击, CSRF攻击的主要目的是用户在不知情的情况下无辜使用自己在某个已登录系统的cookie信息，执行一个对自己有害的操作; 引出跨域问题由于同源策略的这些限制都是为了安全考虑, 自然是必要的; 但是有时很不方便, 可能会导致合理的用途也受到影响, 接下来将详细介绍如何在需要的时候合理地去 规避”同源政策”的限制; 参考https://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html 认证 (Authentication) 和 授权 (Authorization) 的区别？这是一个绝大多数人都会混淆的问题。简单点说：认证 (Authentication)： 你是谁是验证您的身份的凭据（例如用户名&#x2F;用户ID和密码），通过这个凭据，系统得以知道你就是你，也就是说系统是否存在你这个用户。所以，Authentication 被称为身份&#x2F;用户验证。 401 Unauthorized : 表示 认证(Authentication) 类型的错误比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 授权 (Authorization)： 你有权限干什么Authorization（授权） 发生在 Authentication（认证） 之后。它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。 403 Forbidden : 经常和401状态码混淆; 其实403表示的是 授权(Authotization) 类型的错误, 授权和认证的不同之处是:通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限” 这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。 Cookie Session 身份验证Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 用户成功登陆系统，然后返回给客户端具有 SessionID 的 Cookie，只有用户向再后端发起请求的时候会把 SessionID 带上，这样后端就知道你的身份状态了。 使用 Session 的时候需要注意下面几个点：依赖Session的关键业务一定要确保客户端开启了Cookie注意Session的过期时间 如果没有Cookie的话Session还能用吗？一般是通过 Cookie 来保存 SessionID，假如你使用了 Cookie 保存 SessionID的方案的话，如果客户端禁用了Cookie，那么 Session就无法正常工作。但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将SessionID放在请求的 url 里面 https://javaguide.cn/?session_id=xxx 。这种方案可行，但是安全性和用户体验感降低。当然，你也可以对 SessionID 进行一次加密之后再传入后端。 Cookie 无法防止CSRF攻击，而token可以CSRF（Cross Site Request Forgery）一般被翻译为 跨站请求伪造 。简单来说就是用你的身份去发送一些对你不友好的请求。举个简单的例子：小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了10000元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。&lt;a src&#x3D;http://www.mybank.com/Transfer?bankId=11&amp;money=10000&gt;科学理财，年盈利率过万&lt;&#x2F;&gt;上面也提到过，进行Session 认证的时候，我们一般使用 Cookie 来存储 SessionId, 当我们登陆后后端生成一个SessionId放在Cookie中返回给客户端，服务端通过Redis或者其他存储工具记录保存着这个Sessionid，客户端登录以后每次请求都会带上这个SessionId，服务端通过这个SessionId来标识你这个人。如果别人通过 cookie拿到了 SessionId ，那他就可以代替你的身份访问系统了。而 Session 认证中，Cookie 中的 SessionId是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。 但是，我们使用 token 的话就不会存在这个问题，在我们登录成功获得 token 之后，一般会选择存放在 local storage 中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 token,这样就不会出现 CSRF 漏洞的问题。因为，即使你点击了某个非法链接发送请求到服务端，这个非法请求是无法自动携带 token 的，所以这个请求将是非法的。 其实CSRF主要是利用浏览器会携带已登录的用户标识，来达到冒充用户的目的，从而对被攻击的网站执行某项操作。 无论 Cookie 还是 token 都无法避免 跨站脚本攻击（Cross Site Scripting）XSS跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为XSS。XSS中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如cookie。 推荐阅读：如何防止CSRF攻击？—美团技术团队CSRF的特点： 攻击一般发起在第三方网站，而不是被攻击的网站。被攻击的网站无法防止攻击发生。 攻击利用受害者在被攻击网站的登录凭证，冒充受害者提交操作；而不是直接窃取数据。 整个过程攻击者并不能获取到受害者的登录凭证，仅仅是“冒用”。 跨站请求可以用各种方式：图片URL、超链接、CORS、Form提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪。CSRF通常是跨域的，因为外域通常更容易被攻击者掌控。但是如果本域下有容易被利用的功能，比如可以发图和链接的论坛和评论区，攻击可以直接在本域下进行，而且这种攻击更加危险。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]}]