[{"title":"05.支撑 TCP 协议的基石 —— 剖析首部字段","date":"2022-01-25T14:03:16.000Z","path":"2022/01/25/TCP/05.支撑TCP协议的基石--剖析首部字段/","text":"这篇文章来讲讲 TCP 报文首部相关的概念，这些头部是支撑 TCP 复杂功能的基石。 完整的 TCP 头部如下图所示我们用一次访问百度网页抓包的例子来开始。curl -v www.baidu.com完整的抓包文件可以来 github 下载：curl_baidu.pcapng 源端口号、目标端口号在第一个包的详情中，首先看到的高亮部分的源端口号（Src Port）和目标端口号（Dst Port)，这个例子中本地源端口号为 61024，百度目标端口号是 80。TCP 报文头部里没有源 ip 和目标 ip 地址，只有源端口号和目标端口号 这也是初学 wireshark 抓包时很多人会有的一个疑问：过滤 ip 地址为 172.19.214.24 包的条件为什么不是 “tcp.addr &#x3D;&#x3D; 172.19.214.24”，而是 “ip.addr &#x3D;&#x3D; 172.19.214.24”TCP 的报文里是没有源 ip 和目标 ip 的，因为那是 IP 层协议的事情，TCP 层只有源端口和目标端口。 源 IP、源端口、目标 IP、目标端口构成了 TCP 连接的「四元组」。一个四元组可以唯一标识一个连接。 后面文章中专门有一节是用来介绍端口号相关的知识。 接下来，我们看到的是序列号，如截图中 2 的标识。 序列号（Sequence number）TCP 是面向字节流的协议，通过 TCP 传输的字节流的每个字节都分配了序列号，序列号（Sequence number）指的是本报文段第一个字节的序列号。序列号加上报文的长度，就可以确定传输的是哪一段数据。序列号是一个 32 位的无符号整数，达到 2^32-1 后循环到 0。 在 SYN 报文中，序列号用于交换彼此的初始序列号，在其它报文中，序列号用于保证包的顺序。 因为网络层（IP 层）不保证包的顺序，TCP 协议利用序列号来解决网络包乱序、重复的问题，以保证数据包以正确的顺序组装传递给上层应用。 如果发送方发送的是四个报文序列号分别是1、2、3、4，但到达接收方的顺序是 2、4、3、1，接收方就可以通过序列号的大小顺序组装出原始的数据。","tags":[{"name":"TCP","slug":"TCP","permalink":"http://rymuscle.github.io/tags/TCP/"}]},{"title":"04.来自 Google 的协议栈测试神器 —— packetdrill","date":"2022-01-24T13:17:36.000Z","path":"2022/01/24/TCP/04.来自 Google 的协议栈测试神器 packetdrill/","text":"从大学开始懵懵懂懂粗略学习（死记硬背）了一些 TCP 协议的内容，到工作多年以后，一直没有找到顺手的网络协议栈调试工具，对于纷繁复杂 TCP 协议。业界流行的 scapy 不是很好用，有很多局限性。直到前段时间看到了 Google 开源的 packetdrill，真有一种相见恨晚的感觉。这篇文章讲介绍 packetdrill 的基本原理和用法。 packetdrill 在 2013 年开源，在 Google 内部久经考验，Google 用它发现了 10 余个 Linux 内核 bug，同时用测试驱动开发的方式开发新的网络特性和进行回归测试，确保新功能的添加不影响网络协议栈的可用性。 安装以 centos7 为例 首先从 github 上 clone 最新的源码 github.com/google/pack… 进入源码目录 cd gtests/net/packetdrill 安装 bison 和 flex 库：sudo yum install -y bison flex 为避免 offload 机制对包大小的影响，修改 netdev.c 注释掉 set_device_offload_flags 函数所有内容 执行 .&#x2F;configure 修改 Makefile，去掉第一行的末尾的 -static 执行 make 命令编译 确认编译无误地生成了 packetdrill 可执行文件 初体验packetdrill 脚本采用 c 语言和 tcpdump 混合的语法。脚本文件名一般以 .pkt 为后缀，执行脚本的方式为 sudo ./packetdrill test.pkt 脚本的每一行可以由以下几种类型的语句构成： 执行系统调用（system call），对比返回值是否符合预期 把数据包（packet）注入到内核协议栈，模拟协议栈收到包 比较内核协议栈发出的包与预期是否相符 执行 shell 命令 执行 python 命令 脚本每一行都有一个时间参数用来表明执行的时间或者预期事件发生的时间，packetdrill 支持绝对时间和相对时间。绝对时间就是一个简单的数字，相对时间会在数字前面添加一个+号。比如下面这两个例子 12345// 300ms 时执行 accept 调用0.300 accept(3, ..., ...) = 4// 在上一行语句执行结束 10ms 以后执行+.010 write(4, ..., 1000) = 1000` 如果预期的事件在指定的时间没有发生，脚本执行会抛出异常，由于不同机器的响应时间不同，所以 packetdrill 提供了参数（–tolerance_usecs）用来设置误差范围，默认值是 4000us（微秒），也即 4ms。这个参数默认值在 config.c 的 set_default_config 函数里进行设置config-&gt;tolerance_usecs &#x3D; 4000; 我们以一个最简单的 demo 来演示 packetdrill 的用法。乍一看很懵，容我慢慢道来 123456789101112131 0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 32 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 03 +0 bind(3, ..., ...) = 04 +0 listen(3, 1) = 0567 +0 &lt; S 0:0(0) win 4000 &lt;mss 1000&gt;8 +0 &gt; S. 0:0(0) ack 1 &lt;...&gt;9 +.1 &lt; . 1:1(0) ack 1 win 10001011 +0 accept(3, ..., ...) = 412 +0 &lt; P. 1:201(200) win 400013 +0 &gt; . 1:1(0) ack 201 第 1 行：0 socket(…, SOCK_STREAM, IPPROTO_TCP) &#x3D; 3在脚本执行的第 0s 创建一个 socket，使用的是系统调用的方式，socket 函数的签名和用法如下 12345#include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol);成功时返回文件描述符，失败时返回 -1int socket_fd = socket(AF_INET, SOCK_STREAM, 0); domain 表示套接字使用的协议族信息，IPv4、IPv6等。AF_INET 表示 IPv4 协议族，AF_INET6 表示 IPv6 协议族。绝大部分使用场景下都是用 AF_INET，即 IPv4 协议族 type 表示套接字数据传输类型信息，主要分为两种：面向连接的套接字（SOCK_STREAM）和面向无连接报文的套接字（SOCK_DGRAM）。众所周知，SOCK_STREAM 默认协议是 TCP，SOCK_DGRAM 的默认协议是 UDP。 protocol 这个参数通常是 0，表示为给定的协议族和套接字类型选择默认协议。 在 packetdrill 脚本中用 … 来表示当前参数省略不相关的细节信息，使用 packetdrill 程序的默认值。 脚本返回新建的 socket 文件句柄，这里用&#x3D;来断言会返回3，因为linux 在每个程序开始的时刻，都会有 3 个已经打开的文件句柄，分别是：标准输入stdin(0)、标准输出stdout(1)、错误输出stderr(2) 默认的，其它新建的文件句柄则排在之后，从 3 开始。 1232 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 03 +0 bind(3, ..., ...) = 04 +0 listen(3, 1) = 0 第 2 行：调用 setsockopt 函数设置端口重用。 第 3 行：调用 bind 函数，这里的 socket 地址省略会使用默认的端口 8080，第一个参数 3 是套接字的 fd 第 4 行：调用 listen 函数，第一个参数 3 也是套接字 fd 到此为止，socket 已经可以接受客户端的 tcp 连接了。 第 7 ~ 9 行是经典的三次握手，packetdrill 的语法非常类似 tcpdump 的语法 &lt; 表示输入的数据包（input packets)， packetdrill 会构造一个真实的数据包，注入到内核协议栈。比如： 1234// 构造 SYN 包注入到协议栈+0 &lt; S 0:0(0) win 32792 &lt;mss 1000,sackOK,nop,nop,nop,wscale 7&gt;// 构造 icmp echo_reply 包注入到协议栈0.400 &lt; icmp echo_reply &gt; 表示预期协议栈会响应的包（outbound packets），这个包不是 packetdrill 构造的，是由协议栈发出的，packetdrill 会检查协议栈是不是真的发出了这个包，如果没有，则脚本报错停止执行。比如 1234567// 调用 write 函数调用以后，检查协议栈是否真正发出了 PSH+ACK 包+0 write(4, ..., 1000) = 1000+0 &gt; P. 1:1001(1000) ack 1// 三次握手中过程向协议栈注入 SYN 包以后，检查协议栈是否发出了 SYN+ACK 包以及 ack 是否等于 10.100 &lt; S 0:0(0) win 32792 &lt;mss 1000,nop,wscale 7&gt;0.100 &gt; S. 0:0(0) ack 1 &lt;mss 1460,nop,wscale 6&gt; 第 7 行：+0 &lt; S 0:0(0) win 1000 &lt;mss 1000&gt; packetdrill 构造一个 SYN 包发送到协议栈，它使用与 tcpdump 类似的相对 sequence 序号，S 后面的三个 0 ，分别表示发送包的起始 seq、结束 seq、包的长度。比如P. 1:1001(1000)表示发送的包起始序号为 1，结束 seq 为 1001，长度为1000。紧随其后的 win 表示发送端的接收窗口大小 1000。依据 TCP 协议，SYN 包也必须带上自身的 MSS 选项，这里的 MSS 大小为 1000 第 8 行：+0 &gt; S. 0:0(0) ack 1 &lt;…&gt; 预期协议栈会立刻回复 SYN+ACK 包，因为还没有发送数据，所以包的 seq开始值、结束值、长度都为 0，ack 为上次 seq + 1，表示第一个 SYN 包已收到。 第 9 行：+.1 &lt; . 1:1(0) ack 1 win 1000 0.1s 以后注入一个 ACK 包到协议栈，没有携带数据，包的长度为 0，至此三次握手完成，过程如下图 +0 accept(3, …, …) &#x3D; 4 accept 系统调用返回了一个值为 4 的新的文件 fd，这时 packetdrill 可以往这个 fd 里面写数据了 +0 write(4, …, 10)&#x3D;10+0 &gt; P. 1:11(10) ack 1+.1 &lt; . 1:1(0) ack 11 win 1000packetdrill 调用 write 函数往 socket 里写了 10 字节的数据，协议栈立刻发出这 10 个字节数据包，同时把 PSH 标记置为 1。这个包的起始 seq 为 1，结束 seq 为 10，长度为 10。100ms 以后注入 ACK 包，模拟协议栈收到 ACK 包。 整个过程如下采用 tcpdump 对 8080 端口进行抓包，结果如下 sudo tcpdump -i any port 8080 -nn10:02:36.591911 IP 192.0.2.1.37786 &gt; 192.168.31.139.8080: Flags [S], seq 0, win 4000, options [mss 1000], length 010:02:36.591961 IP 192.168.31.139.8080 &gt; 192.0.2.1.37786: Flags [S.], seq 2327356581, ack 1, win 29200, options [mss 1460], length 010:02:36.693785 IP 192.0.2.1.37786 &gt; 192.168.31.139.8080: Flags [.], ack 1, win 1000, length 010:02:36.693926 IP 192.168.31.139.8080 &gt; 192.0.2.1.37786: Flags [P.], seq 1:11, ack 1, win 29200, length 1010:02:36.801092 IP 192.0.2.1.37786 &gt; 192.168.31.139.8080: Flags [.], ack 11, win 1000, length 0 packetdrill 原理简述在脚本的最后一行，加上+0 sleep 1000000让脚本执行完不要退出，执行 ifconfig 可以看到，比没有执行脚本之前多了一个虚拟的网卡 tun0。packetdrill 就是在执行脚本前创建了一个名为 tun0 的虚拟网卡，脚本执行完，tun0 会被销毁。该虚拟网卡对应于操作系统中&#x2F;dev&#x2F;net&#x2F;tun文件，每次程序通过 write 等系统调用将数据写入到这个文件 fd 时，这些数据会经过 tun0 这个虚拟网卡，将数据写入到内核协议栈，read 系统调用读取数据的过程类似。协议栈可以向操作普通网卡一样操作虚拟网卡 tun0。 关于 linux 下 tun 的详细使用介绍，可以参考 IBM 的文章 www.ibm.com/developerwo… 把 packetdrill 命令加到环境变量里把 packetdrill 加入到环境变量里以便于可以在任意目录可以执行。第一步是修改&#x2F;etc&#x2F;profile或者.zshrc（如果你用的是最好用的 zsh 的话）等可以修改环境变量的文件。 export PATH&#x3D;&#x2F;path_to_packetdrill&#x2F;:$PATH source ~&#x2F;.zshrc在命令行中输入 packetdrill 如果有输出 packetdrill 的 usage 文档说明第一步成功啦。 但是 packetdrill 命令是需要 sudo 权限执行的，如果现在我们在命令行中输入sudo packetdrill，会提示找不到 packetdrill 命令 sudo：packetdrill：找不到命令这是因为 sudo 命令为了安全性的考虑，覆盖了用户自己 PATH 环境变量，我们可以用sudo sudo -V | grep PATH 来看 sudo sudo -V | grep PATH覆盖用户的 $PATH 变量的值：&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin可以看到 sudo 命令覆盖了用户的 PATH 变量。这些初始值是在&#x2F;etc&#x2F;sudoers中定义的 sudo cat &#x2F;etc&#x2F;sudoers | grep -i PATHDefaults secure_path &#x3D; &#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin一个最简单的办法是在sudo 启动时重新赋值它的 PATH 变量：sudo env PATH&#x3D;”$PATH” cmd_x，可以用sudo env PATH&#x3D;”$PATH” env | grep PATH与sudo env | grep PATH做前后对比 对于本文中的 packetdrill，可以用sudo env PATH&#x3D;$PATH packetdrill delay_ack.pkt来执行，当然你可以做一个 sudo 的 alias alias sudo&#x3D;’sudo env PATH&#x3D;”$PATH”‘这样就可以在任意地方执行sudo packetdrill了 小结packetdrill 上手的难度有一点大，但是熟悉了以后用起来特别顺手，后面很多 TCP 包超时重传、快速重传、滑动窗口、nagle 算法都是会用这个工具来进行测试，希望你可以熟练掌握。","tags":[{"name":"TCP","slug":"TCP","permalink":"http://rymuscle.github.io/tags/TCP/"}]},{"title":"03.TCP概述 -- 可靠的、面向连接的、基于字节流、全双工的协议","date":"2022-01-23T11:43:20.000Z","path":"2022/01/23/TCP/03.TCP概述 -- 可靠的、面向连接的、基于字节流、全双工的协议/","text":"如果要用一句话来描述 TCP 协议，我想应该是：TCP 是一个可靠的(reliable)、面向连接的(connection-oriented)、基于字节流(byte-stream)、全双工的(full-duplex) 协议。 TCP 是面向连接的协议一开始学习 TCP 的时候，我们就被告知 TCP 是面向连接的协议，那什么是面向连接，什么是无连接呢？ 面向连接(connection-oriented)：面向连接的协议要求正式发送数据之前需要通过「握手」建立一个逻辑连接，结束通信时也是通过有序的四次挥手来断开连接。 无连接(connectionless)：无连接的协议则不需要 三次握手建立连接的过程是通过「三次握手」来完成的，顾名思义，通过三次数据交换建立一个连接。 通过三次握手协商好双方后续通信的起始序列号、窗口缩放大小等信息。 TCP 协议是可靠的IP 是一种无连接、不可靠的协议：它尽最大可能将数据报从发送者传输给接收者，但并不保证包到达的顺序会与它们被传输的顺序一致，也不保证包是否重复，甚至都不保证包是否会达到接收者。 TCP 要想在 IP 基础上构建可靠的传输层协议，必须有一个复杂的机制来保障可靠性。 主要有下面几个方面： 对每个包提供校验和 包的序列号解决了接收数据的乱序、重复问题 超时重传 流量控制、拥塞控制 校验和（checksum）每个 TCP 包首部中都有两字节用来表示校验和，防止在传输过程中有损坏。如果收到一个校验和有差错的报文，TCP 不会发送任何确认直接丢弃它，等待发送端重传。 包的序列号保证了接收数据的乱序和重复问题假设我们往 TCP 套接字里写 3000 字节的数据导致 TCP发送了 3 个数据包，每个数据包大小为 1000 字节：第一个包序列号为[11001)，第二个包序列号为 [10012001)，第三个包序号为[2001~3001)假如因为网络的原因导致第二个、第三个包先到接收端，第一个包最后才到，接收端也不会因为他们到达的顺序不一致把包弄错，TCP 会根据他们的序号进行重新的排列然后把结果传递给上层应用程序。如果 TCP 接收到重复的数据，可能的原因是超时重传了两次但这个包并没有丢失，接收端会收到两次同样的数据，它能够根据包序号丢弃重复的数据。 超时重传TCP 发送数据后会启动一个定时器，等待对端确认收到这个数据包。如果在指定的时间内没有收到 ACK 确认，就会重传数据包，然后等待更长时间，如果还没有收到就再重传，在多次重传仍然失败以后，TCP 会放弃这个包。后面我们讲到超时重传模块的时候会详细介绍这部分内容。 流量控制、拥塞控制这部分内容较复杂，后面有专门的文章进行讲解，这里先不展开。 TCP 是面向字节流的协议TCP 是一种字节流（byte-stream）协议，流的含义是没有固定的报文边界。 假设你调用 2 次 write 函数往 socket 里依次写 500 字节、800 字节。write 函数只是把字节拷贝到内核缓冲区，最终会以多少条报文发送出去是不确定的，如下图所示情况 1：分为两条报文依次发出去 500 字节 和 800 字节数据情况 2：两部分数据合并为一个长度为 1300 字节的报文，一次发送情况 3：第一部分的 500 字节与第二部分的 500 字节合并为一个长度为 1000 字节的报文，第二部分剩下的 300 字节单独作为一个报文发送情况 4：第一部分的 400 字节单独发送，剩下100字节与第二部分的 800 字节合并为一个 900 字节的包一起发送情况 N：还有更多可能的拆分组合 上面出现的情况取决于诸多因素：路径最大传输单元 MTU、发送窗口大小、拥塞窗口大小等。 当接收方从 TCP 套接字读数据时，它是没法得知对方每次写入的字节是多少的。接收端可能分2次每次 650 字节读取，也有可能先分三次，一次 100 字节，一次 200 字节，一次 1000 字节进行读取。 TCP 是全双工的协议在 TCP 中发送端和接收端可以是客户端&#x2F;服务端，也可以是服务器&#x2F;客户端，通信的双方在任意时刻既可以是接收数据也可以是发送数据，每个方向的数据流都独立管理序列号、滑动窗口大小、MSS 等信息。 小结与思考TCP 是一个可靠的（reliable）、面向连接的（connection-oriented）、基于字节流（byte-stream）、全双工（full-duplex）的协议。发送端在发送数据以后启动一个定时器，如果超时没有收到对端确认会进行重传，接收端利用序列号对收到的包进行排序、丢弃重复数据，TCP 还提供了流量控制、拥塞控制等机制保证了稳定性。","tags":[{"name":"TCP","slug":"TCP","permalink":"http://rymuscle.github.io/tags/TCP/"}]},{"title":"02.TCP/IP 历史与分层模型","date":"2022-01-22T11:43:20.000Z","path":"2022/01/22/TCP/02.TCP、IP 历史与分层模型/","text":"","tags":[{"name":"TCP","slug":"TCP","permalink":"http://rymuscle.github.io/tags/TCP/"}]},{"title":"01. 环境","date":"2022-01-21T11:43:20.000Z","path":"2022/01/21/TCP/01.环境/","text":"","tags":[{"name":"TCP","slug":"TCP","permalink":"http://rymuscle.github.io/tags/TCP/"}]},{"title":"23. 锁","date":"2021-12-19T14:08:18.000Z","path":"2021/12/19/MySQL知识点整理/23.锁/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"22. undo日志(上)","date":"2021-12-15T13:19:56.000Z","path":"2021/12/15/MySQL知识点整理/22.undo日志(上)/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"22. undo日志","date":"2021-12-15T13:19:56.000Z","path":"2021/12/15/MySQL知识点整理/22.undo日志(下)/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"21.2 redo日志后续知识点","date":"2021-12-13T05:10:27.000Z","path":"2021/12/13/MySQL知识点整理/21.2 redo日志 后续知识点/","text":"checkpoint有一个很不幸的事实就是我们的redo日志文件组容量是有限的，我们不得不选择循环使用redo日志文件组中的文件，但是这会造成最后写的redo日志与最开始写的redo日志追尾。 这时应该想到: redo日志只是为了在系统奔溃后恢复脏⻚用的，如果对应的脏⻚已经刷新到了磁盘，那么即使现在系统奔溃，那么在重启后也用不着使用redo日志恢复该⻚面了，所以该redo日志也就没有存在的必要了，那么它占用的磁盘空间就可以被后续的redo日志所重用。也就是说: 判断某些redo日志占用的磁盘空间是否可以覆盖的依据就是它对应的脏⻚是否已经刷新到磁盘里。 我们看一下前边一直唠叨的那个例子: 如图，虽然mtr_1和mtr_2生成的redo日志都已经被写到了磁盘上，但是它们修改的脏⻚仍然留在Buffer Pool中，所以它们生成的redo日志在磁盘上的空间是不可以被覆盖的。 之后随着系统的运行，如果⻚a被刷新到了磁盘，那么它对应的控制块就会从flush链表中移除，就像这样子:这样mtr_1生成的redo日志就没有用了，这些redo日志占用的磁盘空间就可以被覆盖掉了。 设计InnoDB的大叔提出了一个全局变量 checkpoint_lsn 来代表当前系统中可以被覆盖的redo日志总量是多少，这个变量初始值也是8704。比方说现在⻚a被刷新到了磁盘，mtr_1生成的redo日志就可以被覆盖了，所以我们需要进行一个增加checkpoint_lsn的操作，我们把这个过程称为执行一次checkpoint。执行一次checkpoint其实可 以分为两个步骤: 步骤一:计算一下当前系统中可以被覆盖的redo日志对应的lsn值最大是多少。redo日志可以被覆盖，意味着它对应的脏⻚被刷到了磁盘，只要我们计算出当前系统中被最早修改的脏⻚对应的 oldest_modification 值，那凡是在系统lsn值小于该节点的oldest_modification值时产生的redo日志都是可以被覆盖掉的，我们就把该脏⻚的oldest_modification赋值给 checkpoint_lsn。比方说当前系统中⻚a已经被刷新到磁盘，那么flush链表的尾节点就是⻚c，该节点就是当前系统中最早修改的脏⻚了， 它的oldest_modification值为8404，我们就把8404赋值给checkpoint_lsn(也就是说在redo日志对应的lsn值小于8404时就可以被覆盖掉)。 步骤二:将checkpoint_lsn和对应的redo日志文件组偏移量以及此次checkpint的编号写到日志文件的管理信息(就是checkpoint1或者checkpoint2)中。设计InnoDB的大叔维护了一个目前系统做了多少次checkpoint的变量checkpoint_no，每做一次checkpoint，该变量的值就加1。我们前边说过计算一个lsn值对应的redo日志文件组偏移量是很容易的，所以可以计算得到该checkpoint_lsn在redo日志文件组中对应的偏移量checkpoint_offset，然后把这三个值都写到redo日志文件组的管理信息中。 我们说过，每一个redo日志文件都有2048个字节的管理信息，但是上述关于checkpoint的信息只会被写到日志文件组的第一个日志文件的管理信息中。不过它们应该存储到checkpoint1中还是checkpoint2中呢? 设计InnoDB的大叔规定，当checkpoint_no的值是偶数时，就写到checkpoint1中，是奇数时，就写到checkpoint2中。 记录完checkpoint的信息之后，redo日志文件组中各个lsn值的关系就像这样: 批量从flush链表中刷出脏⻚我们在介绍Buffer Pool的时候说过，一般情况下都是后台的线程在对LRU链表和flush链表进行刷脏操作，这主要因为刷脏操作比较慢，不想影响用户线程处理请求。但是如果当前系统修改⻚面的操作十分频繁，这样就导致写日志操作十分频繁，系统lsn值增⻓过快。 如果后台的刷脏操作不能将脏⻚刷出，那么系统无法及时做checkpoint，可能就需要用户线程同步的从flush链表中把那些最早修改的脏⻚(oldest_modification最小的脏⻚)刷新到磁盘，这样这些脏⻚对应的redo日志就没用了，然后就可以去做checkpoint了。 查看系统中的各种LSN值我们可以使用SHOW ENGINE INNODB STATUS命令查看当前InnoDB存储引擎中的各种LSN值的情况，比如: 12345678910mysql&gt; SHOW ENGINE INNODB STATUS\\G(...省略前边的许多状态)LOG---Log sequence number 124476971Log flushed up to 124099769Pages flushed up to 124052503Last checkpoint at 1240524940 pending log flushes, 0 pending chkp writes 24 log i/o&#x27;s done, 2.00 log i/o&#x27;s/second ----------------------(...省略后边的许多状态) 其中:Log sequence number: 代表系统中的lsn值，也就是当前 系统已经写入的redo日志量，包括写入log buffer中的日 志。Log flushed up to: 代表flushed_to_disk_lsn的 值，也就是当前系统已经写入磁盘的redo日志量。Pages flushed up to: 代表flush链表中被最早修改的那 个⻚面对应的oldest_modification属性值。Last checkpoint at: 当前系统的checkpoint_lsn值。 innodb_flush_log_at_trx_commit的用法我们前边说为了保证事务的持久性，用户线程在事务提交时需要将该事务执行过程中产生的所有redo日志都刷新到磁盘上。这一条要求太狠了，会很明显的降低数据库性能。 如果有的同学对事务的持久性要求不是那么强烈的话，可以选择修改一个名为innodb_flush_log_at_trx_commit的系统变量的值，该变量有3个可选的值: 0: 当该系统变量值为0时，表示在事务提交时不立即向磁盘中同步redo日志，这个任务是交给后台线程做的。这样很明显会加快请求处理速度，但是如果事务提交后服务器挂了，后台线程没有及时将redo日志刷新到磁盘，那么该事务对⻚面的修改会丢失。 1: 当该系统变量值为0时，表示在事务提交时需要将redo日志同步到磁盘，可以保证事务的持久性。1也是默认值。 2: 当该系统变量值为0时，表示在事务提交时需要将redo日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘。这种情况下如果数据库挂了，操作系统没挂的话，事务的持久性还是可以保证的，但是操作系统也挂了的话，那就不能保证持久性了。 崩溃恢复在服务器不挂的情况下，redo日志简直就是个大累赘，不仅没用，反而让性能变得更差。但是万一数据库挂了，那redo日志可是个宝了，我们就可以在重启时根据redo日志中的记录就可以将⻚面恢复到系统奔溃前的状态。接下来大致看一下恢复过程是个啥样。 确定恢复的起点我们前边说过，checkpoint_lsn之前的redo日志都可以被覆盖， 也就是说这些redo日志对应的脏⻚都已经被刷新到磁盘中了，既然它们已经被刷盘，我们就没必要恢复它们了。对于 checkpoint_lsn 之后的redo日志，它们对应的脏⻚可能没被刷盘，也可能被刷盘了，我们不能确定，所以需要从 checkpoint_lsn 开始读取redo日志来恢复⻚面。当然，redo日志文件组的第一个文件的管理信息中有两个block都存储了checkpoint_lsn的信息，我们当然是要选取最近发生的那次checkpoint的信息。衡量checkpoint发生时间早晚的信息就是所谓的checkpoint_no，我们只要把checkpoint1和checkpoint2这两个block中的checkpoint_no值读出来比一下大小，哪个的 checkpoint_no值更大，说明哪个block存储的就是最近的一次checkpoint信息。这样我们就能拿到最近发生的checkpoint对应的checkpoint_lsn值以及它在redo日志文件组中的偏移量 checkpoint_offset。 确定恢复的终点redo日志恢复的起点确定了，那终点是哪个呢?这个还得从block的结构说起。我们说在写redo日志的时候都是顺序写的，写满了一个 block之后会再往下一个block中写: 普通block的`log block header`部分有一个名为`LOG_BLOCK_HDR_DATA_LEN`的属性，该属性值记录了当前block里使用了多少字节的空间。对于被填满的block来说，该值永远为512。如果该属性的值不为512，那么就是它了，它就是此次奔溃恢复中需要扫描的最后一个block。 怎么恢复确定了需要扫描哪些redo日志进行奔溃恢复之后，接下来就是怎么进行恢复了。假设现在的redo日志文件中有5条redo日志，如图: 由于redo 0在checkpoint_lsn后边，恢复时可以不管它。我们现在可以按照redo日志的顺序依次扫描checkpoint_lsn之后的各条redo日志，按照日志中记载的内容将对应的⻚面恢复出来。这样没什么问题，不过设计InnoDB的大叔还是想了一些办法加快这个恢复的过程: 使用哈希表根据redo日志的space ID和page number属性计算出散列值，把space ID和page number相同的redo日志放到哈希表的同一个槽里，如果有多个space ID和page number都相同的redo日志，那么它们之间使用链表连接起来，按照生成的先后顺序链接起来的，如图所示: 之后就可以遍历哈希表，因为对同一个⻚面进行修改的redo日志都放在了一个槽里，所以可以一次性将一个⻚面修复好(避免了很多读取⻚面的随机IO)，这样可以加快恢复速度。另外需要注意一点的是，同一个⻚面的redo日志是按照生成时间顺序进行排序的，所以恢复的时候也是按照这个顺序进行恢复， 如果不按照生成时间顺序进行排序的话，那么可能出现错误。 比如原先的修改操作是先插入一条记录，再删除该条记录，如果恢复时不按照这个顺序来，就可能变成先删除一条记录，再插入一条记录，这显然是错误的。 跳过已经刷新到磁盘的⻚面我们前边说过，checkpoint_lsn之前的redo日志对应的脏⻚确定都已经刷到磁盘了，但是checkpoint_lsn之后的redo日志我们不能确定是否已经刷到磁盘，主要是因为在最近做的一次checkpoint后，可能后台线程又不断的从LRU链表和flush链表中将一些脏⻚刷出Buffer Pool。这些在checkpoint_lsn之后的redo日志，如果它们对应的脏⻚在奔溃发生时已经刷新到磁盘，那在恢复时也就没有必要根据redo日志的内容修改该⻚面了。 那在恢复时怎么知道某个redo日志对应的脏⻚是否在奔溃发生时已经刷新到磁盘了呢?这还得从⻚面的结构说起，我们前边说过每个⻚面都有一个称之为File Header的部分，在File Header里有一个称之为FIL_PAGE_LSN的属性，该属性记载了最近一次修改⻚面时对应的lsn值(其实就是⻚面控制块中 的newest_modification值)。如果在做了某次checkpoint之后有脏⻚被刷新到磁盘中，那么该⻚对应的 FIL_PAGE_LSN代表的lsn值肯定大于checkpoint_lsn的值，凡是符合这种情况的⻚面就不需要做恢复操作了，所以更进一步提升了奔溃恢复的速度。 遗漏的问题:LOG_BLOCK_HDR_NO是如何计算的我们前边说过，对于实际存储redo日志的普通的log block来说， 在log block header处有一个称之为LOG_BLOCK_HDR_NO的属 性(忘记了的话回头再看看哈)，我们说这个属性代表一个唯一的标 号。这个属性是初次使用该block时分配的，跟当时的系统lsn值有 关。使用下边的公式计算该block的LOG_BLOCK_HDR_NO值:((lsn / 512) &amp; 0x3FFFFFFFUL) + 1 这个公式里的0x3FFFFFFFUL可能让大家有点困惑，其实它的二进 制表示可能更亲切一点: 从图中可以看出，0x3FFFFFFFUL对应的二进制数的前2位为0，后 30位的值都为1。我们刚开始学计算机的时候就学过，一个二进制位 与0做与运算(&)的结果肯定是0，一个二进制位与1做与运算 (&)的结果就是原值。让一个数和0x3FFFFFFFUL做与运算的意思 就是要将该值的前2个比特位的值置为0，这样该值就肯定小于或等 于0x3FFFFFFFUL了。这也就说明了，不论lsn多大，((lsn / 512) & 0x3FFFFFFFUL)的值肯定在0~0x3FFFFFFFUL之间，再 加1的话肯定在1~0x40000000UL之间。而0x40000000UL这个值 大家应该很熟悉，这个值就代表着1GB。也就是说系统最多能产生不 重复的LOG_BLOCK_HDR_NO值只有1GB个。设计InnoDB的大叔规定 redo日志文件组中包含的所有文件大小总和不得超过512GB，一个 block大小是512字节，也就是说redo日志文件组中包含的block块 最多为1GB个，所以有1GB个不重复的编号值也就够用了。 另外，LOG_BLOCK_HDR_NO值的第一个比特位比较特殊，称之 为flush bit，如果该值为1，代表着本block是在某次将log buffer中的block刷新到磁盘的操作中的第一个被刷入的block。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"21.1 Log Sequeue Number","date":"2021-12-12T14:19:04.000Z","path":"2021/12/12/MySQL知识点整理/21.1 Log Sequeue Number/","text":"Log Sequeue Number自系统开始运行，就在不断地修改⻚面，这也就意味着会不断的生成redo日志。redo日志的量在不断的递增，就像人的年龄一样，自打出生起就不断递增，永远不可能缩减。 设计InnoDB的大叔设计了一个名为Log Sequeue Number的全局变量(日志序列号，简称lsn)，用来记录当前总共已经写入的redo日志量。 不过不像人一出生的年龄是0岁，设计InnoDB的大叔规定初始的lsn值为8704(人家就这么规定的,也就是一条redo日志也没写入时，lsn的值就是8704)。 我们知道在向log buffer中写入redo日志时不是一条一条写入的，而是以mtr生成的一组redo日志为单位进行写入的。而且实际上是把日志内容写在了log blcok body处。但是在统计lsn的增⻓量时，是按照实际写入的日志量加上占用的log block header和log block trailer来计算的。我们来看一个例子: 系统第一次启动后初始化log buffer时，buf_free(就是标记下一条redo日志应该写入到log buffer的位置的变量) 就会指向第一个block的偏移量为12字节(log block header的大小)的地方，那么lsn值也会跟着增加12: 如果某个mtr产生的一组redo日志占用的存储空间比较小，也就是待插入的block剩余空闲空间能容纳这个mtr提交的日志时，lsn增⻓的量就是该mtr生成的redo日志占用的字节数， 就像这样 我们假设上图中mtr_1产生的redo日志量为200字节，那么lsn就要在8716的基础上增加200，变为8916。 如果某个mtr产生的一组redo日志占用的存储空间比较大，也就是待插入的block剩余空闲空间不足以容纳这个mtr提交的日志时，lsn增⻓的量就是该mtr生成的redo日志占用的字节数加上额外占用的log block header和log block trailer的字节数，就像这样: 我们假设上图中mtr_2产生的redo日志量为1000字节，为了将mtr_2产生的redo日志写入log buffer，我们不得不额外多分配两个block，所以lsn的值需要在8916的基础上增加 1000 + 12×2 + 4 × 2 = 1032。 从上边的描述中可以看出来，每一组由mtr生成的redo日志都有一个唯一的LSN值与其对应，LSN值越小，说明redo日志产生的越早。 flushed_to_disk_lsnredo日志是先写到Log buffer中，之后才会被刷新到磁盘的redo日志文件中。所以设计InnoDB的大叔提出了一个名为buf_next_to_write的全局变量，用来标记当前log buffer中已经有哪些日志被刷新到磁盘中了。如下图: 我们前边说lsn是表示当前系统中写入的redo日志量，这包括了写到log buffer而没有刷新到磁盘的日志。相应的，设计InnoDB的大叔提出了一个表示刷新到磁盘中的redo日志量的全局变量，名为flushed_to_disk_lsn。 系统第一次启动时，该变量的值和初始的lsn值是相同的，都是8704。随着系统的运行，redo日志被不断写入log buffer，但是并不会立即刷新到磁盘，lsn的值 就和 flushed_to_disk_lsn 的值拉开了差距。我们演示一下: 系统第一次启动后，向log buffer中写入了 mtr_1、mtr_2、mtr_3这三个mtr产生的redo日志，假设这三个mtr开始和结束时对应的lsn值分别是: mtr_1:8716 ~ 8916、 mtr_2:8916 ~ 9948、 mtr_3:9948 ~ 10000此时的lsn已经增⻓到了10000，但是由于没有刷新操作，所以此时flushed_to_disk_lsn的值仍为8704，如图: 随后进行将log buffer中的block刷新到redo日志文件的操作，假设将mtr_1和mtr_2的日志刷新到磁盘，那么flushed_to_disk_lsn就应该增⻓mtr_1和mtr_2写入的日志量，所以flushed_to_disk_lsn的值增⻓到了9948， 如图: 综上所述，当有新的redo日志写入到log buffer时，首先lsn的值会增⻓，但flushed_to_disk_lsn不变，随后随着不断有log buffer中的日志被刷新到磁盘上，flushed_to_disk_lsn的值也跟着增⻓。如果两者的值相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了。 lsn值和redo日志文件偏移量的对应关系因为lsn的值是代表系统写入的redo日志量的一个总和，一个mtr中产生多少日志，lsn的值就增加多少(当然有时候要加上log block header和log block trailer的大小)，这样mtr产生的日志写到磁盘中时，很容易计算某一个lsn值在redo日志文件组中的偏移量，如图: 初始时的LSN值是8704，对应文件偏移量2048，之后每个mtr向磁盘中写入多少字节日志，lsn的值就增⻓多少。 flush链表中的LSN我们知道一个mtr代表一次对底层⻚面的原子访问，在访问过程中可能会产生一组不可分割的redo日志，在mtr结束时，会把这一组redo日志写入到log buffer中。除此之外，在mtr结束时还有一件非常重要的事情要做，就是把在mtr执行过程中可能修改过的⻚面加入到Buffer Pool的flush链表。 为了防止大家早已忘记flush链表是个啥，我们再看一下图:当第一次修改某个缓存在Buffer Pool中的⻚面时，就会把这个⻚面对应的控制块插入到flush链表的头部，之后再修改该⻚面时由于 它已经在flush链表中了，就不再次插入了。也就是说flush链表中的脏⻚是按照⻚面的第一次修改时间从大到小进行排序的。在这个过程中会在缓存⻚对应的控制块中记录两个关于⻚面何时修改的属性: oldest_modification：如果某个⻚面被加载到Buffer Pool后进行第一次修改，那么就将修改该⻚面的mtr开始时对应的lsn值写入这个属性。 newest_modification：每修改一次⻚面，都会将修改该⻚面的mtr结束时对应的lsn值写入这个属性。也就是说该属性表示⻚面最近一次修改后对应的系统lsn值。 我们接着上边唠叨flushed_to_disk_lsn的例子看一下: 假设mtr_1执行过程中修改了⻚a，那么在mtr_1执行结束时，就会将⻚a对应的控制块加入到flush链表的头部。并且将mtr_1开始时对应的lsn，也就是8716写入⻚a对应的控制块的oldest_modification属性中，把mtr_1结束时对应的lsn，也就是8404写入⻚a对应的控制块的newest_modification属性中。画个图表示一下(为了让图 片美观一些，我们把oldest_modification缩写成了o_m， 把newest_modification缩写成了n_m): 接着假设mtr_2执行过程中又修改了⻚b和⻚c两个⻚面，那么在mtr_2执行结束时，就会将⻚b和⻚c对应的控制块都加入到flush链表的头部。并且将mtr_2开始时对应的lsn，也就是8404写入⻚b和⻚c对应的控制块的oldest_modification属性中，把mtr_2结束时对应的lsn，也就是9436写入⻚b和⻚c对应的控制块的newest_modification属性中。画个图表示一下: 从图中可以看出来，每次新插入到flush链表中的节点都是被放在了头部，也就是说flush链表中前边的脏⻚修改的时间比较晚，后边的脏⻚修改时间比较早。 接着假设mtr_3执行过程中修改了⻚b和⻚d，不过⻚b之前已经被修改过了，所以它对应的控制块已经被插入到了flush链表，所以在mtr_3执行结束时，只需要将⻚d对应的控制块都加入到flush链表的头部即可。所以需要将mtr_3开始时对应的lsn，也就是9436写入⻚c对应的控制块的oldest_modification属性中，把mtr_3结束时对应的lsn，也就是10000写入⻚c对应的控制块的newest_modification属性中。另外，由于⻚b在mtr_3执行过程中又发生了一次修改，所以需要更新⻚b对应的控制块中newest_modification的值为10000。画个图表示一下: 总结一下上边说的，就是:flush链表中的脏⻚按照修改发生的时间顺序进行排序，也就是按照oldest_modification代表的LSN值进行排序，被多次更新的⻚面不会重复插入到flush链表中，但是会更新newest_modification属性的值。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"21.0 redo日志文件","date":"2021-12-12T12:23:11.000Z","path":"2021/12/12/MySQL知识点整理/21.0 redo日志文件/","text":"redo日志刷盘时机前边说过，MTR 运行过程中产生的一组redo日志在mtr结束时会被复制到log buffer中。可这些日志总在内存里呆着也不是个办法，在一些情况下它们会被刷新到磁盘里，比如: log buffer空间不足时log buffer的大小是有限的(通过系统变量 innodb_log_buffer_size 指定)，如果不停的往这个有限大小的log buffer里塞入日志，很快它就会被填满。设计 InnoDB的大叔认为，如果当前写入log buffer的redo日志量已经占满了log buffer总容量的50%左右，就需要把这些日志刷新到磁盘中。 事务提交时我们前边说过之所以使用redo日志主要是因为它占用的空间少，还是顺序写，在事务提交时可以不把修改过的Buffer Pool⻚面刷新到磁盘，但是为了保证持久性，必须要把修改这些⻚面对应的redo日志刷新到磁盘 。 否则系统崩溃后，无法将该事务对页面所做的修改恢复过来。 后台有一个线程，大约以每秒一次的频率将log buffer中的redo日志刷新到磁盘。 正常关闭服务器时。 做所谓的checkpoint时(我们现在没介绍过checkpoint的概念，稍后会仔细唠叨，稍安勿躁) redo日志文件组MySQL的数据目录(使用 SHOW VARIABLES LIKE &#39;datadir&#39;查看)下默认有两个名为ib_logfile0和ib_logfile1的文件，log buffer中的日志默认情况下就是刷新到这两个磁盘文件中。 如果我们对默认的redo日志文件不满意，可以通过下边几个启动参数来调节: innodb_log_group_home_dir：该参数指定了redo日志文件所在的目录，默认值就是当前的数据目录。 innodb_log_file_size：该参数指定了每个redo日志文件的大小，在MySQL 5.7.21 这个版本中的默认值为48MB。 innodb_log_files_in_group：该参数指定redo日志文件的个数，默认值为2，最大值为 100。 从上边的描述中可以看到，磁盘上的redo日志文件不只一个，而是以一个日志文件组的形式出现的。 这些文件以ib_logfile[数字] (数字可以是0、1、2…)的形式进行命名。在将redo日志写入日志文件组时，是从ib_logfile0开始写，如果ib_logfile0写满了，就接着ib_logfile1写，同理，ib_logfile1写满了就去写ib_logfile2，依此类推。 如果写到最后一个文件该咋办? 那就重新转到ib_logfile0继续写，所以整个过程如下图所示:总共的redo日志文件大小其实就是：innodb_log_file_size × innodb_log_files_in_group。 Tips: 如果采用循环使用的方式向redo日志文件组里写数据的话，那岂不是要追尾，也就是后写入的redo日志覆盖掉前边写的redo日志? 当然可能了! 所以设计InnoDB的大叔提出了checkpoint的概念，稍后我们重点唠叨。 redo日志的文件格式我们前边说过log buffer本质上是一片连续的内存空间，被划分成了若干个512字节大小的block。将log buffer中的redo日志刷新到磁盘的本质就是把block的镜像写入日志文件中，所以redo日志文件其实也是由若干个512字节大小的block组成。 redo日志文件组中的每个文件大小都一样，格式也一样，都是由两部分组成: 前2048个字节，也就是前4个block是用来存储一些管理信息的； 从第2048字节往后是用来存储log buffer中的block镜像的； 所以我们前边所说的循环使用redo日志文件，其实是从每个日志文件的第2048个字节开始算，示意图就是: 普通block的格式我们在唠叨log buffer时都说过了，就是log block header、log block body、log block trialer这三个部分，就不重复介绍了。 这里需要介绍一下每个redo日志文件前2048个字节，也就是前4个特殊block的格式都是干嘛的，先看图:从图中可以看出来，这4个block分别是: log file header:描述该redo日志文件的一些整体属性，它的结构: LOG_HEADER_FORMAT: 4字节，redo日志的版本，在MySQL 5.7.21中该值永远为1LOG_HEADER_PAD1： 4字节，做字节填充用的，没什么实际意义，忽略~LOG_HEADER_START_LSN: 8字节，标记本redo日志文件开始的LSN值，也就是文件偏移量为2048字节初对应的LSN值(关于什么是LSN我们稍后再看哈，看不懂的先忽略)。LOG_HEADER_CREATOR：32字节，一个字符串标记本redo日志文件的创建者是谁。正常运行时该值为MySQL的版本号，比如:”MySQL 5.7.21”，使用mysqlbackup命令创建的redo日志文件的该值为”ibbackup”和创建时间。LOG_BLOCK_CHECKSUM: 4字节，本block的校验值，所有block都有，我们不关心 Tips: 设计InnoDB的大叔对redo日志的block格式做了很多次修改，如果你阅读的其他书籍中发现上述的属性和你阅读书籍中的属性有些出入，不要慌，正常现象，忘记以前的版本吧。另外，LSN值我们后边才会介绍，现在千万别纠结LSN是个啥。 checkpoint1: 记录关于checkpoint的一些属性，看一下它的结构: LOG_CHECKPOINT_NO：8字节，服务器执行checkpoint的编号，每执行一次checkpoint，该值就加1。LOG_CHECKPOINT_LSN：8字节，服务器在结束checkpoint时对应的LSN值；系统在奔溃恢复时将从该值开始。LOG_CHECKPOINT_OFFSET：8字节，上个属性中的LSN值在redo日志文件组中的偏移量LOG_CHECKPOINT_LOG_BUF_SIZE：8字节，服务器在执行checkpoint操作时对应的log buffer的大小LOG_BLOCK_CHECKSUM：4字节，本block的校验值，所有block都有该值，我们不用关心 Tips: 小贴士:现在看不懂上边这些关于checkpoint和LSN的属性的释义是很正常的，我就是想让大家对上边这些属性混个脸熟，后边我们后详细唠叨的。 第三个block未使用，忽略~ checkpoint2: 结构和checkpoint1一样。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"20.3 redo日志的写入过程","date":"2021-12-11T15:15:21.000Z","path":"2021/12/11/MySQL知识点整理/20.3 redo日志的写入过程/","text":"redo log block(页)设计InnoDB的大叔为了更好的进行系统奔溃恢复，他们把通过MTR生成的redo日志都放在了大小为512字节的⻚中。 为了和我们前边提到的表空间中的⻚做区别，我们这里把用来存储redo日志的⻚称为 block (你心里清楚⻚和block的意思其实差不多就行了)。 一个 redo log block 的示意图如下:真正的redo日志都是存储到占用496字节大小的log block body中，图中的log block header和log block trailer存储的是一些管理信息。我们来看看这些所谓的管理信息都是啥: 其中log block header的几个属性的意思分别如下: LOG_BLOCK_HDR_NO: 每一个block都有一个大于0的唯一标号，本属性就表示该标号值。 LOG_BLOCK_HDR_DATA_LEN: 表示block中已经使用了多少字节，初始值为12(因为log block body从第12个字节处开始)。随着往block中写入的redo日志越来也多，本属性值也跟着增⻓。如果log block body已经被全部写满，那么本属性的值被设置为512。 LOG_BLOCK_FIRST_REC_GROUP: 一条redo日志也可以称为一条redo日志记录(redo log record)。一个mtr会生产多条redo日志记录，这个MTR生成的这些redo日志记录被称为一个redo日志记录组(redo log record group)。LOG_BLOCK_FIRST_REC_GROUP就代表该block中第一个mtr生成的redo日志记录组的偏移量(其实也就是这个block里第一个mtr生成的第一条redo日志的偏移量)。如果一个MTR生成的redo日志横跨了好多个block,那么最后一个block中的LOG_BLOCK_FIRST_REC_GROUP属性就表示这个MTR对应的redo日志结束的地方，也就是下一个MTR生成redo日志开始的地方。 LOG_BLOCK_CHECKPOINT_NO: 表示所谓的checkpoint的序号，checkpoint是我们后续内容的重点，现在先不用清楚它的意思，稍安勿躁。 log block trailer 中属性的意思如下: LOG_BLOCK_CHECKSUM:表示block的校验值，用于正确性校验，我们暂时不关心它。 redo日志缓冲区我们前边说过，设计InnoDB的大叔为了解决磁盘速度过慢的问题而引入了 Buffer Pool。同理，写入redo日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为 redo log buffer(redo日志缓冲区) 的连续内存空间，也可以简称为log buffer。这片内存空间被划分成若干个连续的redo log block，就像这样:我们可以通过启动参数innodb_log_buffer_size来指定log buffer的大小，在MySQL 5.7.21这个版本中，该启动参数的默认值为16MB。 redo日志写入log buffer向log buffer中写入redo日志的过程是顺序写入的，也就是先往前边的block中写，当该block的空闲空间用完之后再往下一个block中写。当想往log buffer中写入redo日志时，第一个遇到的问题就是应该写在哪个block的哪个偏移量处。设计InnoDB的大叔特意提供了一个称之为buf_free的全局变量，该变量指明后续写入的redo日志应该写入到log buffer中的哪个位置，如图所示: 我们前边说过一个mtr执行过程中可能产生若干条redo日志，这些redo日志是一个不可分割的组，所以并不是每生成一条redo日志就将其插入到log buffer中，而是每个mtr运行过程中产生的日志先暂时存到一个地方；当该mtr结束的时候，再将过程中产生的一组redo日志全部复制到log buffer中。 我们现在假设有两个名为T1、T2的事务，每个事务都包含2个mtr，我们给这几个mtr命名一下: 事务T1的两个mtr分别称为mtr_T1_1和mtr_T1_2； 事务T2的两个mtr分别称为mtr_T2_1和mtr_T2_2； 每个mtr都会产生一组redo日志，用示意图来描述一下这些mtr产生的日志情况: 不同的事务可能是并发执行的，所以T1、T2之间的mtr可能是交替执行的。每当一个mtr执行完成时，伴随该mtr生成的一组redo日志就需要被复制到log buffer中，也就是说不同事务的mtr可能是交替写入log buffer的，我们画个示意图(为了美观，我们把一个mtr中产生的所有的redo日志当作一个整体来画):从示意图中我们可以看出来，不同的mtr产生的一组redo日志占用的存储空间可能不一样 有的mtr产生的redo日志量很少，比如 mtr_t1_1、mtr_t2_1就被放到同一个block中存储 有的mtr产生的redo日志量非常大，比如 mtr_t1_2 产生的redo日志甚至占用了3个block来存储。 Tips:对照着上图，自己分析一下每个block的 LOG_BLOCK_HDR_DATA_LEN、LOG_BLOCK_FIRST_REC_GROUP 属性值都是什么哈","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"20.2 Mini-Transcation","date":"2021-12-11T14:46:19.000Z","path":"2021/12/11/MySQL知识点整理/20.2 Mini-Transcation/","text":"以组的形式写入redo日志语句在执行过程中可能修改若干个⻚面。比如我们前边说的一条INSERT语句可能修改 系统表空间⻚号为7的⻚面的Max Row ID 属性 (当然也可能更新别的系统⻚面，只不过我们没有都列举出来而已)，还会更新聚簇索引和二级索引对应B+树中的⻚面。 由于对这些⻚面的更改都发生在Buffer Pool中，所以在修改完⻚面之后，需要记录一下相应的redo日志。 在执行语句的过程中产生的redo日志被设计InnoDB的大叔人为的划分成了若干个不可分割的组，比如: 更新Max Row ID属性时产生的redo日志是不可分割的。 向聚簇索引对应B+树的⻚面中插入一条记录时产生的redo日志是不可分割的。 向某个二级索引对应B+树的⻚面中插入一条记录时产生的redo日志是不可分割的。 还有其他的一些对⻚面的访问操作时产生的redo日志是不可分割的。。。 怎么理解这个不可分割的意思呢? 我们以向某个索引对应的B+树插入一条记录为例，在向B+树中插入这条记录之前，需要先定位到这条记录应该被插入到哪个叶子节点代表的数据⻚中，定位到具体的数据⻚之后，有两种可能的情况: 情况一: 该数据⻚的剩余的空闲空间充足，足够容纳这一条待插入记录，那么事情很简单，直接把记录插入到这个数据⻚中，记录一条类型为MLOG_COMP_REC_INSERT的redo日志就好了，我们把这种情况称之为乐观插入。 情况二: 该数据⻚剩余的空闲空间不足，那么事情就悲剧了， 我们前边说过，遇到这种情况要进行所谓的⻚分裂操作，也就是新建一个叶子节点，然后把原先数据⻚中的一部分记录复制到这个新的数据⻚中，然后再把记录插入进去，把这个叶子节点插入到叶子节点链表中，最后还要在内节点中添加一条目录项记录指向这个新创建的⻚面。很显然，这个过程要对多个⻚面进行修改，也就意味着会产生多条redo日志，我们把这种情况称之为悲观插入。如果作为内节点的⻚a的剩余空闲空间也不足以容纳增加一条目录项记录，那需要继续做内节点⻚a的分裂操作，也就意味 着会修改更多的⻚面，从而产生更多的redo日志。另外，对于 悲观插入 来说，由于需要新申请数据⻚，还需要改动一些系统⻚面，比方说要修改各种段、区的统计信息信息，各种链表的统计信息(比如什么FREE链表、FSP_FREE_FRAG链表吧啦吧啦，我们在唠叨表空间那一章中介绍过的各种东东)等等等等， 反正总共需要记录的redo日志有二、三十条。 设计InnoDB的大叔们认为向某个索引对应的B+树中插入一条记录的这个过程必须是原子的，不能说插了一半之后就停止了。 比方说在悲观插入过程中，新的⻚面已经分配好了，数据也复制过去了，新的记录也插入到⻚面中了，可是没有向内节点中插入一条目录项记录，这个插入过程就是不完整的，这样会形成一棵不正确的B+树。 而redo日志是为了在系统奔溃重启时恢复崩溃前的状态，如果在悲观插入的过程中只记录了一部分redo日志，那么在系统奔溃重启时会将索引对应的B+树恢复成一种不正确的状态 ，这是设计InnoDB的大叔们所不能忍受的。 所以他们规定在执行这些需要保证原子性的操作时必须以组的形式来记录的redo日志，在进行系统奔溃重启恢复时，针对某个组中的redo日志，要么把全部的日志都恢复掉，要么一条也不恢复。 怎么做到的呢? 这得分情况讨论: 有的需要保证原子性的操作会生成多条redo日志，比如向某个索引对应的B+树中进行一次悲观插入就需要生成许多条redo日志。如何把这些redo日志划分到一个组里边儿呢? 设计InnoDB的大叔做了一个很简单的小把戏，就是在该组中的最后一条redo日志后边加上一条特殊类型的redo日志，该类型名称为 MLOG_MULTI_REC_END，type字段对应的十进制数字为31，该类型的redo日志结构很简单，只有一个type字段。所以某个需要保证原子性的操作产生的一系列redo日志必须要以一个类型为MLOG_MULTI_REC_END结尾，就像这样: 这样在系统奔溃重启进行恢复时，只有当解析到类型为 `MLOG_MULTI_REC_END` 的redo日志，才认为解析到了一组完整的redo日志，才会进行恢复。否则的话直接放弃前边解析到的redo日志。 有的需要保证原子性的操作只生成一条redo日志，比如更新 Max Row ID属性的操作就只会生成一条redo日志。其实在一条日志后边跟一个类型为MLOG_MULTI_REC_END的redo日志也是可以的，不过设计InnoDB的大叔比较勤俭节约，它们不想浪费一个比特位。别忘了虽然redo日志的类型比较多，但撑死了也就是几十种，是小于127这个数字的，也就是说我们用7个比特位就足以包括所有的redo日志类型，而type字段其实是占用1个字节的，也就是说我们可以省出来一个比特位用来表示该需要保证原子性的操作只产生单一的一条redo日志，示意图如下: 如果type字段的第一个比特为为1，代表该需要保证原子性的操作只产生了单一的一条redo日志，否则表示该需要保证原子性的操作产生了一系列的redo日志。 Mini-Transaction的概念设计MySQL的大叔把对底层⻚面中的一次原子访问的过程称之为一个Mini-Transaction，简称mtr，比如上边所说的修改一次Max Row ID的值算是一个Mini-Transaction，向某个索引对应的B+树中插入一条记录的过程也算是一个Mini-Transaction。 通过上边的叙述我们也知道，一个所谓的mtr可以包含一组redo日志 ， 在进行奔溃恢复时这一组redo日志作为一个不可分割的整体。 一个事务可以包含若干条语句，每一条语句其实是由若干个mtr组成 ，每一个mtr又可以包含若干条redo日志 ，画个图表示它们的关系就是这样:","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"20.1 redo日志格式","date":"2021-12-11T14:16:41.000Z","path":"2021/12/11/MySQL知识点整理/20.1 redo日志格式和类型/","text":"redo 日志格式通过上边的内容我们知道，redo日志本质上只是记录了一下事务对数据库做了哪些修改。 设计InnoDB的大叔们针对 事务对数据库的不同修改场景 定义了多种类型的redo日志，但大部分类型都有下边这种通用的结构:type: 该条redo日志的类型 (在MySQL 5.7.21中，设计InnoDB的大叔一共为redo日志设计了53种不同的类型，稍后会详细介绍不同类型的redo日志。)space ID: 表空间IDpage number: ⻚号data: 该条redo日志的具体内容 简单的redo日志类型 前边介绍InnoDB的记录行格式时说过，如果我们没有为某个表显式的定义主键，并且表中也没有定义Unique键，InnoDB会自动的为表添加一个称之为row_id的隐藏列作为主键。 这个row_id隐藏列的赋值方式如下: 服务器会在内存中维护一个全局变量，每当向某个包含隐藏的row_id列的表中插入一条记录时，就会把该全局变量的值当作新记录的row_id列的值，并且把该全局变量自增1。 每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的⻚号为7的⻚面中一个称之为Max Row ID的属性处(前边介绍表空间结构时详细说过)。 当系统启动时，会将上边提到的Max Row ID属性加载到内存中，将该值加上256之后赋值给我们前边提到的全局变量(因为在上次关机时该全局变量的值可能大于Max Row ID属性值(lant: 关机时，全局变量可能会没即时刷到表空间的⻚号为7的⻚面中的Max Row ID属性 😝))。 这个Max Row ID属性占用的存储空间是8个字节，当某个事务向某个包含row_id隐藏列的表插入一条记录，并且为该记录分配的row_id值为256的倍数时，就会向系统表空间⻚号为7的⻚面的相应偏移量处写入8个字节的值。但是我们要知道，这个写入实际上是在 Buffer Pool 中完成的，我们需要为这个⻚面的修改记录一条redo日志，以便在系统奔溃后能将已经提交的该事务对该⻚面所做的修改恢复出来。这种情况下对⻚面的修改是极其简单的，redo日志中只需要记录一下在某个⻚面的某个偏移量处修改了几个字节的值，具体被修改的内容是啥就好了，设计InnoDB的大叔把这种极其简单的redo日志称之为 物理日志，并且根据在⻚面中写入数据的多少划分了几种不同的redo日志类型: MLOG_1BYTE(type字段对应的十进制数字为1): 表示在⻚面的某个偏移量处写入1个字节的redo日志类型。 MLOG_2BYTE(type字段对应的十进制数字为2): 表示在⻚面的某个偏移量处写入2个字节的redo日志类型。 MLOG_4BYTE(type字段对应的十进制数字为4): 表示在⻚面的某个偏移量处写入4个字节的redo日志类型。 MLOG_8BYTE(type字段对应的十进制数字为8): 表示在⻚面的某个偏移量处写入8个字节的redo日志类型。 MLOG_WRITE_STRING(type字段对应的十进制数字 为30): 表示在⻚面的某个偏移量处写入一串数据。 我们上边提到的 Max Row ID 属性实际占用8个字节的存储空间，所以在修改⻚面中的该属性时，会记录一条类型为 MLOG_8BYTE 的redo日志，MLOG_8BYTE的redo日志结构如下所示:其余 MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE类型的redo日志结构和MLOG_8BYTE的类似，只不过具体数据中包含对应个字节的数据罢了。 MLOG_WRITE_STRING类型的redo日志表示写入一串数据，但是因为不能确定写入的具体数据占用多少字节，所以需要在日志结构中添加一个len字段: 复杂一些的redo日志类型 有时候执行一条语句会修改非常多的⻚面，包括系统数据⻚面和用户数据⻚面(用户数据指的就是聚簇索引和二级索引对应的B+树)。以一条INSERT语句为例，它除了要向B+树的⻚面中插入数据，也可能更新系统数据Max Row ID的值，不过对于我们用户来说，平时更关心的是语句对B+树所做更新: 表中包含多少个索引，一条INSERT语句就可能更新多少棵B+树。 针对某一棵B+树来说，既可能更新叶子节点⻚面，也可能更新内节点⻚面，也可能创建新的⻚面(在该记录插入的叶子节点的剩余空间比较少，不足以存放该记录时，会进行⻚面的分裂，在内节点⻚面中添加目录项记录)。 在语句执行过程中，INSERT语句对所有⻚面的修改都得保存到 redo日志 中去。这句话说的比较轻巧，做起来可就比较麻烦了，比方说将记录插入到聚簇索引中时，如果定位到的叶子节点的剩余空间足够存储该记录时，那么只更新该叶子节点⻚面就好，那么只记录一条MLOG_WRITE_STRING类型的redo日志，表明在⻚面的某个偏移量处增加了哪些数据就好了么? 那就too young too naive了别忘了一个数据⻚中除了存储实际的记录之后，还有什么 File Header、Page Header、Page Directory 等等部分(在唠叨数据⻚的章节有详细讲解)，所以每往叶子节点代表的数据⻚里插入一条记录时，还有其他很多地方会跟着更新，比如说: 可能更新 Page Directory 中的槽信息 Page Header中的各种⻚面统计信息，比如 PAGE_N_DIR_SLOTS表示的槽数量可能会更改，PAGE_HEAP_TOP代表的还未使用的空间最小地址可能会更改，PAGE_N_HEAP代表的本⻚面中的记录数量可能会更改，吧啦吧啦，各种信息都可能会被修改。 我们知道在数据⻚里的记录是按照索引列从小到大的顺序组成一个单向链表的，每插入一条记录，还需要更新上一条记录的记录头信息中的next_record属性来维护这个单向链表。 还有别的吧啦吧啦的更新的地方，就不一一唠叨了… 画一个简易的示意图就像是这样: 说了这么多，就是想表达: 把一条记录插入到一个⻚面时需要更改的地方非常多。这时我们如果使用上边介绍的简单的物理redo日志来记录这些修改时，可以有两种解决方案: 方案一:在每个修改的地方都记录一条redo日志。 也就是如上图所示，有多少个加粗的块，就写多少条物理redo日志。这样子记录redo日志的缺点是显而易⻅的，因为被修改的地方是在太多了，可能记录的redo日志占用的空间都比整个⻚面占用的空间都多了 😓 方案二:将整个⻚面的第一个被修改的字节到最后一个修改的字节之间所有的数据当成是一条物理redo日志中的具体数据。 从图中也可以看出来，第一个被修改的字节到最后一个修改的字节之间仍然有许多没有修改过的数据，我们把这些没有修改的数据也加入到redo日志中去岂不是太浪费了 😓 正因为上述两种使用物理redo日志的方式来记录某个⻚面中做了哪些修改比较浪费，设计InnoDB的大叔本着勤俭节约的初心，提出了一些新的redo日志类型，比如: MLOG_REC_INSERT(对应的十进制数字为9): 表示插入一条使用非紧凑行格式的记录时的redo日志类型。 MLOG_COMP_REC_INSERT(对应的十进制数字为38): 表示插入一条使用紧凑行格式的记录时的redo日志类型。 Tips:Redundant是一种比较原始的行格式，它就是非紧凑的。而 Compact、Dynamic以及Compressed行格式是较新的行格式，它们是紧凑的(占用更小的存储空间)。 MLOG_COMP_PAGE_CREATE(type字段对应的十进制数字为58): 表示创建一个存储紧凑行格式记录的⻚面的redo日志类型。 MLOG_COMP_REC_DELETE(type字段对应的十进制数字为42): 表示删除一条使用紧凑行格式记录的redo日志类型。 MLOG_COMP_LIST_START_DELETE(type字段对应的十进制数字为44): 表示从某条给定记录开始删除⻚面中的一系列使用紧凑行格式记录的redo日志类型。 MLOG_COMP_LIST_END_DELETE(type字段对应的十进制数字为43): 与MLOG_COMP_LIST_START_DELETE类型的redo日志呼应，表示删除一系列记录直到MLOG_COMP_LIST_END_DELETE类型的redo日志对应的记录为止。 小贴士:我们前边唠叨InnoDB数据⻚格式的时候重点强调过，数据⻚中的记录是按照索引列大小的顺序组成单向链表的。有时候我们会有删除索引列的值在某个区间范围内的所有记录的需求，这时候如果我们每删除一条记录就写一条redo日志的话，效率可能有点低，所以提出 MLOG_COMP_LIST_START_DELETE 和 MLOG_COMP_LIST_END_DELETE 类型的redo日志，可以很大程度上减少redo日志的条数 。 MLOG_ZIP_PAGE_COMPRESS(type字段对应的十进制数字为51): 表示压缩一个数据⻚的redo日志类型。······还有很多很多种类型，这就不列举了，等用到再说哈~ 这些类型的redo日志既包含物理层面的意思，也包含逻辑层面的意思，具体指: 物理层面看，这些日志都指明了对哪个表空间的哪个⻚进行了修改。 逻辑层面看，在系统奔溃重启时，并不能直接根据这些日志里的记载，将⻚面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将⻚面恢复成系统奔溃前的样子。 大家看到这可能有些懵逼，我们还是以类型为 MLOG_COMP_REC_INSERT 这个代表插入一条使用紧凑行格式的记录时的redo日志为例来理解一下我们上边所说的物理层面和逻辑层面到底是个啥意思。废话少说，直接看一下这个类型为 MLOG_COMP_REC_INSERT 的redo日志的结构(由于字段太多了，我们把它们竖着看效果好些):这个类型为MLOG_COMP_REC_INSERT的redo日志结构有几个地方需要大家注意: 我们前边在唠叨索引的时候说过，在一个数据⻚里，不论是叶子节点还是非叶子节点，记录都是按照索引列从小到大的顺序排序的。对于二级索引来说，当索引列的值相同时，记录还需要按照主键值进行排序。图中n_uniques的值的含义是在一条记录中，需要几个字段的值才能确保记录的唯一性，这样当插入一条记录时就可以按照记录的前n_uniques个字段进行排序。对于聚簇索引来说，n_uniques的值为主键的列数，对于其他二级索引来说，该值为索引列数+主键列数。这里需要注意的是，唯一二级索引的值可能为NULL，所以该值仍然为 索引列数+主键列数。 field1_len ~ fieldn_len 代表着该记录若干个字段占用存储空间的大小，需要注意的是，这里不管该字段的类型是固定⻓度大小的(比如INT)，还是可变⻓度大小(比如 VARCHAR(M))的，该字段占用的大小始终要写入redo日志中。 offset 代表的是该记录的前一条记录在⻚面中的地址。为啥要记录前一条记录的地址呢? 这是因为每向数据⻚插入一条记录，都需要修改该⻚面中维护的记录链表，每条记录的记录头信息中都包含一个称为next_record的属性，所以在插入新记录时，需要修改前一条记录的next_record属性。 我们知道一条记录其实由额外信息和真实数据这两部分组成，这两个部分的总大小就是一条记录占用存储空间的总大小。通过end_seg_len的值可以间接的计算出一条记录占用存储空间的总大小，为啥不直接存储一条记录占用存储空间的总大小呢?这是因为写redo日志是一个非常频繁的操作，设计InnoDB的大叔想方设法想减小redo日志本身占用的存储空间大小，所以想了一些弯弯绕的算法来实现这个目标，end_seg_len这个字段就是为了节省redo日志存储空间而提出来的。至于具体设计InnoDB的大叔到底是用了什么神奇魔法减小redo日志大小的，我们这就不多唠叨了，因为的确有那么一丢丢小复杂，说清楚还是有一点点麻烦的，而且说明白了也没啥用。 mismatch_index的值也是为了节省redo日志的大小而设立的，大家可以忽略。 很显然这个类型为MLOG_COMP_REC_INSERT的redo日志并没有记录PAGE_N_DIR_SLOTS的值修改为了啥，PAGE_HEAP_TOP的值修改为了啥，PAGE_N_HEAP的值修改为了啥等等这些信息，而只是把在本⻚面中插入一条记录所有必备的要素记了下来，之后系统奔溃重启时，服务器会调用相关向某个⻚面插入一条记录的那个函数，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数，在调用完该函数后，⻚面中的 PAGE_N_DIR_SLOTS、PAGE_HEAP_TOP、PAGE_N_HEAP等等的值也就都被恢复到系统奔溃前的样子了。这就是所谓的逻辑日志的意思。 redo日志格式小结虽然上边说了一大堆关于redo日志格式的内容，但是如果你不是为了写一个解析redo日志的工具或者自己开发一套redo日志系统的话，那就没必要把InnoDB中的各种类型的redo日志格式都研究的透透的，没那个必要。上边只是象征性的介绍了几种类型的redo日志格式，目的还是想让大家明白: redo日志会把事务在执行过程中对数据库所做的所有修改都记录下来，在之后系统奔溃重启后可以把事务所做的任何修改都恢复出来。 Tips: 为了节省redo日志占用的存储空间大小，设计InnoDB的大叔对redo日志中的某些数据还可能进行压缩处理，比方说spacd ID和 page number一般占用4个字节来存储，但是经过压缩后，可能使用更小的空间来存储。具体压缩算法就不唠叨了。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"20.0 redo日志是个啥","date":"2021-12-11T13:07:32.000Z","path":"2021/12/11/MySQL知识点整理/20.0 redo日志/","text":"前置知识点 : InnoDB记录行格式、⻚面格式、索引原理、表空间的组成等各种基础知识 redo日志是个啥 我们知道 InnoDB存储引擎是以⻚为单位来管理存储空间的 ，我们进行的增删改查操作本质上都是在访问⻚(包括对⻚面的读、写、创建等操作)。 我们前边讲Buffer Pool时说过，在真正访问⻚之前，需要把在磁盘上的⻚缓存到内存中的 Buffer Pool之后才可以访问。 但是在讲事务时又强调过一个称之为持久性的特性，就是说对于一个已经提交的事务，在事务提交后即使系统发生了崩溃，这个事务对数据库中所做的更改也不能丢失。但如果我们只在内存的Buffer Pool中修改了⻚面，假设在事务提交后突然发生了某个故障，导致内存中的数据都失效了，那么这个已经提交了的事务对数据库中所做的更改也就跟着丢失了，这是我们所不能忍受的。 那到底该如何来保证这个持久性呢? 一个很简单的做法就是在事务提交完成之前把该事务所修改的所有⻚面都刷新到磁盘，但是这个做法太简单粗暴了，是有问题的: 刷新一个完整的数据⻚太浪费了有时候我们仅仅修改了某个⻚面中的一个字节，但是InnoDB是以⻚为单位来进行磁盘IO的，也就是说我们在该事务提交时不得不将一个完整的⻚面从内存中刷新到磁盘，只修改一个字节就要刷新16KB的数据到磁盘上显然是太浪费了； 随机IO刷起来比较慢一个事务可能包含很多语句，即使是一条语句也可能修改许多个⻚，这些⻚可能并不相邻，这就意味着在将某个事务修改的Buffer Pool中的⻚刷新到磁盘时，需要进行很多的随机IO，随机IO比顺序IO要慢，尤其对于传统的机械硬盘来说； 咋办呢?其实没有必要在每次事务提交时就把该事务在内存中修改过的全部⻚面刷新到磁盘，只需要把修改了哪些东⻄记录一下就好，比方说某个事务将系统表空间中的第100号⻚面中偏移量为1000处的那个字节的值1改成2我们只需要记录一下:将第0号表空间的100号⻚面的偏移量为1000处的值更新为2。 这样我们在事务提交时，只用把上述内容刷新到磁盘中，即使之后系统崩溃了，重启之后只要按照上述内容所记录的步骤重新更新一下数据⻚，那么该事务对数据库中所做的修改又可以被恢复出来。因为在系统奔溃重启时需要按照上述内容所记录的步骤重新更新数据⻚，所以上述内容也被称之为重做日志，英文名为redo log。 与在事务提交时将所有修改过的内存中的⻚面刷新到磁盘中相比，只将该事务执行过程中产生的redo日志刷新到磁盘的好处如下: redo日志占用的空间非常小存储表空间ID、⻚号、偏移量以及需要更新的值所需的存储空间是很小的，关于redo日志的格式我们稍后会详细唠叨，现在只要知道一条redo日志占用的空间不是很大就好了。 redo日志是顺序写入磁盘的在执行事务的过程中，每执行一条语句，可能会产生若干条redo日志，不过，这些日志是按照产生的顺序写入磁盘的，也就是使用顺序IO，比你每次提交去将不相邻的页(随机IO)落盘强多了。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"19. 事务简介","date":"2021-12-10T13:06:17.000Z","path":"2021/12/10/MySQL知识点整理/19.事务简介/","text":"事务的起源 对于大部分程序员来说，他们的任务就是把现实世界的业务场景映射到数据库世界。 比如银行为了存储人们的账户信息会建立一个account表: 123456CREATE TABLE account ( id INT NOT NULL AUTO_INCREMENT COMMENT &#x27;自增id&#x27;, name VARCHAR(100) COMMENT &#x27;客户名称&#x27;, balance INT COMMENT &#x27;余额&#x27;, PRIMARY KEY (id)) Engine=InnoDB CHARSET=utf8; 狗哥和猫爷是一对好基友，他们都到银行开一个账户，他们在现实世界中拥有的资产就会体现在数据库世界的account表中。比如现在狗哥有11元，猫爷只有2元，那么现实中的这个情况映射到数据库的account表就是这样: 123456+----+------+---------+ | id | name | balance | +----+------+---------+ | 1 | 狗哥 | 11 | | 2 | 猫爷 | 2 | +----+------+---------+ 随着时间的流逝，狗哥和猫爷可能陆续进行向账户中存钱、取钱或者向别人转账，这样他们账户中的余额就可能发生变动。不变不知道，一变吓一跳，现实世界中一些看似很简单的状态转换，映射到数据库世界却不是那么容易的。 比方说有一次猫爷在赌场赌博输了钱，急忙打电话给狗哥要借10块钱，不然那些看场子的就会把自己剁了。现实世界中的狗哥走向了ATM机，输入了猫爷的账号以及10元的转账金额，然后按下确认，狗哥就拔卡走人了。对于数据库世界来说，相当于执行了下边这两条语句: 12UPDATE account SET balance = balance - 10 WHERE id = 1;UPDATE account SET balance = balance + 10 WHERE id = 2; 但是这里头有个问题，上述两条语句如果只执行了一条时，忽然服务器断电了咋办? 把狗哥的钱扣了，但是没给猫爷转过去，那猫爷还是逃脱不了被砍死的噩运。 即使对于单独的一条语句，我们前边唠叨Buffer Pool时也说过，在对某个⻚面进行读写访问时，都会先把这个⻚面加载到Buffer Pool中，之后如果修改了某个⻚面，也不会立即把修改同步到磁盘，而只是把这个修改了的⻚面加到Buffer Pool的flush链表中，在之后的某个时间点才会刷新到磁盘。如果在将修改过的⻚刷新到磁盘之前系统崩溃了那岂不是猫爷还是要被砍死? 或者在刷新磁盘的过程中 只刷新部分数据到磁盘上时，系统奔溃了 猫爷也会被砍死? 怎么才能保证让可怜的猫爷不被砍死呢?其实再仔细想想，我们只是想让某些数据库操作符合现实世界中状态转换的规则而已，设计数据库的大叔们仔细盘算了盘算，现实世界中状态转换的规则有好几条，待我们慢慢道来。 原子性(Atomicity)现实世界中转账操作是一个不可分割的操作，也就是说要么压根儿就没转，要么转账成功，不能存在中间的状态，也就是转了一半的这种情况。设计数据库的大叔们把这种要么全做，要么全不做的规则称之为原子性。 但是在现实世界中的一个不可分割的操作却可能对应着数据库世界若干条不同的操作； 数据库中的一条操作也可能被分解成若干个步骤 (比如先修改缓存⻚，之后再刷新到磁盘等)； 最要命的是在任何一个可能的时间都可能发生意想不到的错误(可能是数据库本身的错误，或者是操作系统错误，甚至是直接断电之类的)而使操作执行不下去； 所以猫爷可能会被砍死。 为了保证在数据库世界中某些操作的原子性，设计数据库的大叔 需要费一些心机来保证如果在执行操作的过程中发生了错误，得把已经做了的操作恢复成没执行之前的样子 ，这也是我们后边章节要仔细唠叨的内容。 隔离性(Isolation) 现实世界中的两次状态转换应该是互不影响的 ，比如说狗哥向猫爷同时进行的两次金额为5元的转账(假设可以在两个ATM机上同时操作)。那么最后狗哥的账户里肯定会少10元，猫爷的账户里肯定多了10元。 但是到对应的数据库世界中，事情又变的复杂了一些。 为了简化问题，我们粗略的假设狗哥向猫爷转账5元的过程是由下边几个步骤组成的: 步骤一: 读取狗哥账户的余额到变量A中，这一步骤简写为read(A)。 步骤二: 将狗哥账户的余额减去转账金额，这一步骤简写为 A = A - 5。 步骤三: 将狗哥账户修改过的余额写到磁盘里，这一步骤简写为 write(A)。 步骤四: 读取猫爷账户的余额到变量B，这一步骤简写为 read(B)。 步骤五: 将猫爷账户的余额加上转账金额，这一步骤简写为 B = B + 5。 步骤六: 将猫爷账户修改过的余额写到磁盘里，这一步骤简写为 write(B)。 我们将狗哥向猫爷同时进行的两次转账操作分别称为T1和T2，在现实世界中T1和T2是应该没有关系的，可以先执行完T1，再执行T2，或者先执行完T2，再执行T1，对应的数据库操作就像这样:但是很不幸，真实的数据库中T1和T2的操作可能交替执行:如果按照上图中的执行顺序来进行两次转账的话，最终狗哥的账户里还剩6元钱，相当于只扣了5元钱，但是猫爷的账户里却成了12元钱，相当于多了10元钱，这银行岂不是要亏死了? 所以对于现实世界中状态转换对应的某些数据库操作来说，不仅要保证这些操作以原子性的方式执行完成，而且要保证其它的状态转换不会影响到本次状态转换，这个规则被称之为隔离性。这时设计数据库的大叔们就需要采取一些措施来让访问相同数据(上例中的A账户和B账户)的不同状态转换(上例中的T1和T2)对应的数据库操作的执行顺序有一定规律，这也是我们后边章节要仔细唠叨的内容。 一致性(Consistency) lant:一致性是指事务执行前后，数据库从一个一致性状态转换到另一个一致性状态。这个一致性包括业务上的一些规则。换句话说，事务应确保数据库的完整性约束得到维护。 例如，如果有一个完整性约束要求一个账户的余额不能为负数，那么在事务执行之后，这个约束仍然应该得到满足。再比如执行转账操作前，我们业务上认为 “A用户100元,B用户0元” 是一个一致性状态，转账成功后，“A用户0元,B用户100元” 是另一个一致性状态。 事务应该保证这样的状态转变。 持久性 lant: 持久性是指事务一旦提交，对数据库所做的修改将会在磁盘上保留下来。即使在系统故障或重启的情况下，已提交的事务对数据库的更改也不会丢失。 MySQL中事务的语法 开启事务(可以使用下边两种语句之一来开启一个事务) BEGIN [WORK] :123456//BEGIN 语句代表开启一个事务，后边的单词`WORK`可有可无。//开启事务后，就可以继续写若干条语句，这些语句都属于刚刚开启的这个事务。mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; 加入事务的语句... START TRANSACTION : 和BEGIN语句有着相同的功效，都标志着开启一个事务1234mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; 加入事务的语句... 提交事务开启事务之后就可以继续写需要放到该事务中的语句了，当最后一条语句写完了之后，我们就可以提交该事务了，提交的语句也很简单：COMMIT [WORK]， 一个简单的事务的完整过程如下： 1234567891011121314mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;Query OK, 1 row affected (0.02 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; UPDATE account SET balance = balance + 10 WHERE id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0// `COMMIT`语句就代表提交一个事务，后边的`WORK`可有可无。mysql&gt; COMMIT;Query OK, 0 rows affected (0.00 sec) 手动中止事务如果我们写了几条语句之后发现上边的某条语句写错了，我们可以手动的使用下边这个语句来将数据库恢复到事务执行之前的样子：ROLLBACK [WORK]， 一个简单的事务回滚案例如下 1234567891011121314mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; UPDATE account SET balance = balance + 1 WHERE id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0// `ROLLBACK`语句就代表中止并回滚一个事务，后边的`WORK`可有可无类似的mysql&gt; ROLLBACK;Query OK, 0 rows affected (0.00 sec) 这里需要强调一下，ROLLBACK语句是我们程序员手动的去回滚事务时才去使用的。 如果事务在执行过程中遇到了某些错误而无法继续执行的话，事务自身会自动的回滚。 事务的 自动提交 MySQL中有一个系统变量autocommit： 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;autocommit&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| autocommit | ON |+---------------+-------+1 row in set (0.01 sec) 可以看到它的默认值为ON。也就是说默认情况下，如果我们不显式的使用START TRANSACTION或者BEGIN语句开启一个事务，那么每一条sql语句都算是一个独立的事务，这种特性称之为事务的自动提交。 当然，如果我们想关闭这种自动提交的功能，可以使用下边两种方法之一： 显式的的使用START TRANSACTION或者BEGIN语句开启一个事务。这样在本次事务提交或者回滚前会暂时关闭掉自动提交的功能。 把系统变量autocommit的值设置为OFF (SET autocommit = OFF;)这样的话，我们写入的多条语句就算是属于同一个事务了，直到我们显式的写出COMMIT语句来把这个事务提交掉，或者显式的写出ROLLBACK语句来把这个事务回滚掉。 事务的 隐式提交当我们使用START TRANSACTION或者BEGIN语句开启了一个事务，或者把系统变量autocommit的值设置为OFF时，事务就不会进行自动提交了。但是如果我们输入了某些语句之后，事务是会悄悄的提交的，就像我们输入了COMMIT语句了一样，这种因为某些特殊的语句而导致事务提交的情况称为隐式提交，这些会导致事务隐式提交的语句包括： 定义或修改数据库对象的数据定义语言(Data definition language，缩写为：DDL)。 所谓的数据库对象，指的就是数据库、表、视图、存储过程等等这些东西。 当我们使用CREATE、ALTER、DROP等语句去修改这些所谓的数据库对象时，就会隐式的提交前边语句所属于的事务，就像这样：1234567BEGIN;SELECT ... # 事务中的一条语句UPDATE ... # 事务中的一条语句... # 事务中的其它语句CREATE TABLE ... # 此语句会隐式的提交前边语句所属于的事务 隐式使用或修改mysql数据库中的表当我们使用ALTER USER、CREATE USER、DROP USER、GRANT、RENAME USER、REVOKE、SET PASSWORD等语句时也会隐式的提交前边语句所属于的事务。 事务控制或关于锁定的语句当我们在一个事务还没提交或者回滚时就又使用START TRANSACTION或者BEGIN语句开启了另一个事务时，会隐式的提交上一个事务，比如这样： 1234567BEGIN;SELECT ... # 事务中的一条语句UPDATE ... # 事务中的一条语句... # 事务中的其它语句BEGIN; # 此语句会隐式的提交前边语句所属于的事务 或者当前的autocommit系统变量的值为OFF，我们手动把它调为ON时，也会隐式的提交前边语句所属的事务。 或者使用LOCK TABLES、UNLOCK TABLES等关于锁定的语句也会隐式的提交前边语句所属的事务。 加载数据的语句比如我们使用LOAD DATA语句来批量往数据库中导入数据时，也会隐式的提交前边语句所属的事务。 关于MySQL复制的一些语句使用START SLAVE、STOP SLAVE、RESET SLAVE、CHANGE MASTER TO等语句时也会隐式的提交前边语句所属的事务。 其它的一些语句使用ANALYZE TABLE、CACHE INDEX、CHECK TABLE、FLUSH、 LOAD INDEX INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE、RESET等语句也会隐式的提交前边语句所属的事务。 Tips: 上边提到的一些语句，如果你都认识并且知道是干嘛用的那再好不过了，不认识也不要气馁，这里写出来只是为了内容的完整性，把可能会导致事务隐式提交的情况都列举一下，具体每个语句都是干嘛用的等我们遇到了再说哈。 事务的 保存点 如果你开启了一个事务，并且已经敲了很多语句，忽然发现上一条语句有点问题，你只好使用ROLLBACK语句来让数据库状态恢复到事务执行之前的样子，然后一切从头再来，总有一种一夜回到解放前的感觉。 所以设计数据库的大叔们提出了一个保存点(savepoint)的概念，就是在事务对应的数据库语句中打几个点，我们在调用ROLLBACK语句时可以指定会滚到哪个点，而不是回到最初的原点 123456789// 定义保存点的语法如下：SAVEPOINT 保存点名称;//当我们想回滚到某个保存点时，可以使用下边这个语句（下边语句中的单词`WORK`和`SAVEPOINT`是可有可无的）：ROLLBACK [WORK] TO [SAVEPOINT] 保存点名称;// 如果`ROLLBACK`语句后边不跟随保存点名称的话，会直接回滚到事务执行之前的状态。//如果我们想删除某个保存点，可以使用这个语句：RELEASE SAVEPOINT 保存点名称; 下面还是以转账的例子展示一下保存点的用法，在执行完扣除狗哥账户的钱10元的语句之后打一个保存点： 12345678mysql&gt; SELECT * FROM account;+----+--------+---------+| id | name | balance |+----+--------+---------+| 1 | 狗哥 | 11 || 2 | 猫爷 | 2 |+----+-------+---------+2 rows in set (0.00 sec) 12345678910111213141516171819202122232425262728293031323334mysql&gt; BEGIN;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; SAVEPOINT s1; # 一个保存点Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM account;+----+--------+---------+| id | name | balance |+----+--------+---------+| 1 | 狗哥 | 1 || 2 | 猫爷 | 2 |+----+--------+---------+2 rows in set (0.00 sec)mysql&gt; UPDATE account SET balance = balance + 1 WHERE id = 2; # 更新错了Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; ROLLBACK TO s1; # 回滚到保存点s1处Query OK, 0 rows affected (0.00 sec)mysql&gt; SELECT * FROM account;+----+--------+---------+| id | name | balance |-----+--------+---------+| 1 | 狗哥 | 1 || 2 | 猫爷 | 2 |+----+--------+---------+2 rows in set (0.00 sec)","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"18. 调节磁盘和CPU的矛盾--InnoDB的Buffer Pool","date":"2021-12-06T14:01:26.000Z","path":"2021/12/06/MySQL-InnoDB-页结构/18.调节磁盘和CPU的矛盾--InnoDB的Buffer Pool/","text":"缓存的重要性通过前边的唠叨我们知道，对于使用InnoDB作为存储引擎的表来说，不管是用于存储用户数据的索引(包括聚簇索引和二级索引)， 还是各种系统数据，都是以⻚的形式存放在表空间中的，而所谓的表空间只不过是InnoDB对文件系统上一个或几个实际文件的抽象 ，也就是说我们的数据说到底还是存储在磁盘上的。但是各位也都知道，磁盘的速度慢的跟乌龟一样，怎么能配得上“快如⻛，疾如电”的CPU呢? 所以InnoDB存储引擎在处理客户端的请求时，当需要访问某个⻚的数据时，就会把完整的⻚的数据全部加载到内存中 ，也就是说即使我们只需要访问一个⻚的一条记录，那也需要先把整个⻚的数据加载到内存中。将整个⻚加载到内存中后就可以进行读写访问了，在进行完读写访问之后并不着急把该⻚对应的内存空间释放掉，而是将其缓存起来，这样将来有请求再次访问该⻚面时，就可以省去磁盘IO的开销了。 啥是个Buffer Pool设计InnoDB的大叔为了缓存磁盘中的⻚，在MySQL服务器启动的时候就向操作系统申请了一片连续的内存，他们给这片内存起了个名，叫做 Buffer Pool(中文名是缓冲池)。 那它有多大呢? 这个其实看我们机器的配置，如果你是土豪，你有512G内存，你分配个几百G作为Buffer Pool也可以啊，当然你要是没那么有钱，设置小点也行呀。默认情况下Buffer Pool只有128M大小。当然如果你嫌这个128M太大或者太小，可以在启动服务器的时候配置 innodb_buffer_pool_size 参数的值，它表示Buffer Pool 的大小，就像这样: 1234[server]innodb_buffer_pool_size = 268435456# 268435456的单位是字节，也就是我指定Buffer Pool的大小为256M。# 需要注意的是，Buffer Pool也不能太小，最小值为5M(当小于该值时会自动设置成5M)。 Buffer Pool内部组成Buffer Pool中默认的缓存⻚大小和在磁盘上默认的⻚大小是一样的，都是16KB。为了更好的管理这些在Buffer Pool中的缓存⻚， 设计InnoDB的大叔为每一个缓存⻚都创建了一些所谓的控制信息， 这些控制信息包括该⻚所属的表空间编号、⻚号、缓存⻚在Buffer Pool中的地址、链表节点信息、一些锁信息以及LSN信息(锁和LSN 我们之后会具体唠叨，现在可以先忽略)，当然还有一些别的控制信息，我们这就不全唠叨一遍了，挑重要的说嘛。 每个缓存⻚对应的控制信息占用的内存大小是相同的，我们就把每个⻚对应的控制信息占用的一块内存称为一个控制块吧，控制块和缓存⻚是一一对应的，它们都被存放到 Buffer Pool 中，其中控制块被存放到 Buffer Pool 的前边，缓存⻚被存放到 Buffer Pool 后边，所以整个Buffer Pool对应的内存空间看起来就是这样的: 咦? 控制块和缓存⻚之间的那个碎片是个什么玩意儿?你想想啊，每一个控制块都对应一个缓存⻚，那在分配足够多的控制块和缓存⻚后，可能剩余的那点儿空间不够一对控制块和缓存⻚的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。当然，如果你把Buffer Pool的大小设置的刚刚好的话，也可能不会产生碎片。 Tips:每个控制块大约占用缓存⻚大小的5%，在MySQL5.7.21这个版本中，每个控制块占用的大小是808字节。而我们设置的innodb_buffer_pool_size 并不包含这部分控制块占用的内存空间大小，也就是说InnoDB在为Buffer Pool向操作系统申请连续的内存空间时，这片连续的内存空间一般会比 innodb_buffer_pool_size的值大5%左右。 free链表的管理当我们最初启动MySQL服务器的时候，需要完成对Buffer Pool的初始化过程，就是先向操作系统申请Buffer Pool的内存空间，然后把它划分成若干对控制块和缓存⻚。 但是此时并没有真实的磁盘⻚被缓存到Buffer Pool中(因为还没有用到)，之后随着程序的运行，会不断的有磁盘上的⻚被缓存到Buffer Pool中。 那么问题来了，从磁盘上读取一个⻚到Buffer Pool中的时候该放到哪个缓存⻚的位置呢? 或者说怎么区分Buffer Pool中哪些缓存⻚是空闲的，哪些已经被使用了呢?我们最好在某个地方记录一下Buffer Pool中哪些缓存⻚是可用的，这个时候缓存⻚对应的控制块就派上大用场了，我们可以把所有空闲的缓存⻚对应的控制块作为一个节点放到一个链表中，这个链表也可以被称作 free链表(或者说空闲链表)。刚刚完成初始化的Buffer Pool中所有的缓存⻚都是空闲的，所以每一个缓存⻚对应的控制块都会被加入到free链表中，假设该Buffer Pool中可容纳的缓存⻚数量为n，那增加了free链表的效果图就是这样的:从图中可以看出，我们为了管理好这个free链表，特意为这个链表定义了一个基节点，里边儿包含着链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。这里需要注意的是，链表的基节点占用的内存空间并不包含在为Buffer Pool申请的一大片连续内存空间之内，而是单独申请的一块内存空间。 Tips:链表基节点占用的内存空间并不大，在MySQL5.7.21这个版本里， 每个基节点只占用40字节大小。后边我们即将介绍许多不同的链表，它们的基节点和free链表的基节点的内存分配方式是一样一样的，都是单独申请的一块40字节大小的内存空间，并不包含在为 Buffer Pool申请的一大片连续内存空间之内。 有了这个free链表之后事儿就好办了，每当需要从磁盘中加载一个⻚到Buffer Pool中时，就从free链表中取一个空闲的缓存⻚，并且把该缓存⻚对应的控制块的信息填上(就是该⻚所在的表空间、⻚ 号之类的信息)，然后把该缓存⻚对应的free链表节点从链表中移除，表示该缓存⻚已经被使用了。 缓存⻚的哈希处理我们前边说过，当我们需要访问某个⻚中的数据时，就会把该⻚从磁盘加载到Buffer Pool中，如果该⻚已经在Buffer Pool中的话直接使用就可以了。 那么问题也就来了，我们怎么知道该⻚在不在Buffer Pool中呢? 难不成需要依次遍历Buffer Pool中各个缓存⻚么? 一个Buffer Pool中的缓存⻚这么多，都遍历完岂不是要累死?再回头想想，我们其实是根据 表空间号 + ⻚号 来定位一个⻚的，也就相当于 表空间号 + ⻚号 是一个key，缓存⻚就是对应的value， 怎么通过一个key来快速找着一个value呢? 哈哈，那肯定是哈希表喽。 所以我们可以用 表空间号 + ⻚号 作为key，缓存⻚作为value创建一个哈希表，在需要访问某个⻚的数据时，先从哈希表中根据 表空间号 + ⻚号 看看有没有对应的缓存⻚，如果有，直接使用该缓存⻚就好，如果没有，那就从free链表中选一个空闲的缓存⻚，然后把磁盘中对应的⻚加载到该缓存⻚的位置。 flush链表的管理如果我们修改了Buffer Pool中某个缓存⻚的数据，那它就和磁盘上的⻚不一致了，这样的缓存⻚也被称为脏⻚(英文名:dirty page)。当然，最简单的做法就是每发生一次修改就立即同步到磁盘上对应的⻚上，但是频繁的往磁盘中写数据会严重的影响程序的性能(毕竟磁盘慢的像乌龟一样)。所以每次修改缓存⻚后，我们并不着急立即把修改同步到磁盘上，而是在未来的某个时间点进行同步， 至于这个同步的时间点我们后边会作说明说明的，现在先不用管哈。但是如果不立即同步到磁盘的话，那之后再同步的时候我们怎么知道Buffer Pool中哪些⻚是脏⻚，哪些⻚从来没被修改过呢? 总不能把所有的缓存⻚都同步到磁盘上吧，假如Buffer Pool被设置的很大，比方说300G，那一次性同步这么多数据岂不是要慢死!所以，我们不得不再创建一个存储脏⻚的链表，凡是修改过的缓存⻚对应的控制块都会作为一个节点加入到一个链表中，因为这个链表节点对应的缓存⻚都是需要被刷新到磁盘上的，所以也叫flush链表。链表的构造和free链表差不多，假设某个时间点Buffer Pool中的脏⻚数量为n，那么对应的flush链表就⻓这样: LRU链表的管理缓存不够的窘境Buffer Pool对应的内存大小毕竟是有限的，如果需要缓存的⻚占用的内存大小超过了Buffer Pool大小，也就是free链表中已经没有多余的空闲缓存⻚的时候岂不是很尴尬，发生了这样的事儿该咋办?当然是把某些旧的缓存⻚从Buffer Pool中移除，然后再把新的⻚放进来喽。 那么问题来了，移除哪些缓存⻚呢? 为了回答这个问题，我们还需要回到我们设立Buffer Pool的初衷，我们就是想减少和磁盘的IO交互，最好每次在访问某个⻚时它都已经被缓存到Buffer Pool中了。假设我们一共访问了n次⻚，那么被访问的⻚已经在缓存中的次数除以n就是所谓的缓存命中率，我们的期望就是让缓存命中率越高越好。从这个⻆度出发，回想一下我们的微信聊天列表，排在前边的都是最近很频繁使用的，排在后边的自然就是最近很少使用的，假如列表能容纳下的联系人有限，你是会把最近很频繁使用的留下还是最近很少使用的留下呢? 当然是留下最近很频繁使用的了。 简单的LRU链表管理Buffer Pool的缓存⻚其实也是这个道理，当Buffer Pool 中不再有空闲的缓存⻚时，就需要淘汰掉部分最近很少使用的缓存⻚。 不过，我们怎么知道哪些缓存⻚最近频繁使用，哪些最近很少使用呢?呵呵，神奇的链表再一次派上了用场，我们可以再创建一个链表，由于这个链表是为了按照最近最少使用的原则去淘汰缓存⻚的， 所以这个链表可以被称为LRU链表(LRU的英文全称:Least Recently Used)。当我们需要访问某个⻚时，可以这样处理LRU链表: 如果该⻚不在Buffer Pool中，在把该⻚从磁盘加载到Buffer Pool中的缓存⻚时，就把该缓存⻚对应的控制块作为节点塞到链表的头部。 如果该⻚已经缓存在Buffer Pool中，则直接把该⻚对应的控制块移动到LRU链表的头部。 也就是说: 只要我们使用到某个缓存⻚，就把该缓存⻚调整到LRU链表的头部，这样LRU链表尾部就是最近最少使用的缓存⻚喽。所以当Buffer Pool中的空闲缓存⻚使用完时，到LRU链表的尾部找些缓存⻚淘汰就OK啦，真简单，啧啧… 划分区域的LRU链表高兴的太早了，上边的这个简单的LRU链表用了没多⻓时间就发现问题了，因为存在这两种比较尴尬的情况: 情况一: InnoDB提供了一个看起来比较贴心的服务–预读 (英文名:read ahead)。 所谓预读，就是InnoDB认为执行当前的请求可能之后会读取某些⻚面，就预先把它们加载到Buffer Pool中。根据触发方式的不同，预读又可以细分为下边两种: 线性预读 设计InnoDB的大叔提供了一个系统变量 innodb_read_ahead_threshold，如果顺序访问了某个区(extent)的⻚面超过这个系统变量的值，就会触发一次异步读取下一个区中全部的⻚面到Buffer Pool的请求，注意异步读取意味着从磁盘中加载这些被预读的⻚面并不会影响到当前工作线程的正常执行。这个 innodb_read_ahead_threshold 系统变量的值默认是56，我们可以在服务器启动时通过启动参数或者服务器运行过程中直接调整该系统变量的值，不过它是一个全局变量，注意使用SET GLOBAL命令来修改哦。Tips:InnoDB是怎么实现异步读取的呢? 在Windows或者 Linux平台上，可能是直接调用操作系统内核提供的AIO接口，在其它类Unix操作系统中，使用了一种模拟AIO接口的方式来实现异步读取，其实就是让别的线程去读取需要预读的⻚面。如果你读不懂上边这段话，那也就没必要懂了，和我们主题其实没太多关系，你只需要知道异步读取并不会影响到当前工作线程的正常执行就好了。其实这个过程涉及到操作系统如何处理IO以及多线程的问题，找本操作系统的书看看吧。 随机预读 如果Buffer Pool中已经缓存了某个区的13个连续的⻚面，不论这些⻚面是不是顺序读取的，都会触发一次异步读取本区中所有其的⻚面到Buffer Pool的请求。设计InnoDB的大叔同时提供了 innodb_random_read_ahead 系统变量，它的默认值为OFF，也就意味着InnoDB并不会默认开启随机预读的功能，如果我们想开启该功能，可以通过修改启动参数或者直接使用SET GLOBAL命令把该变量的值设置为ON。 预读本来是个好事儿，如果预读到Buffer Pool中的⻚成功的被使用到，那就可以极大的提高语句执行的效率。可是如果用不到呢?这些预读的⻚都会放到LRU链表的头部，但是如果此时Buffer Pool的容量不太大而且很多预读的⻚面都没有用到的话，这就会导致处在LRU链表尾部的一些缓存⻚会很快的被淘汰掉，也就是所谓的劣币驱逐良币，会大大降低缓存命中率。 情况二:有的小伙伴可能会写一些需要扫描全表的查询语句(比如没有建立合适的索引或者压根儿没有WHERE子句的查询)。 扫描全表意味着将访问到该表所在的所有⻚! 假设这个表中记录非常多的话，那该表会占用特别多的⻚，当需要访问这些⻚时，会把它们统统都加载到Buffer Pool中， 这也就意味着吧唧一下，Buffer Pool中的所有⻚都被换了一次血，其他查询语句在执行时又得执行一次从磁盘加载到Buffer Pool的操作。而这种全表扫描的语句执行的频率也不高，但每次执行都要把Buffer Pool中的缓存⻚换一次血，这严重的影响到其他查询对 Buffer Pool的使用，从而大大降低了缓存命中率。 总结一下上边说的可能降低Buffer Pool的两种情况: 加载到Buffer Pool中的⻚不一定被用到。 如果非常多的使用频率偏低的⻚被同时加载到Buffer Pool 时，可能会把那些使用频率非常高的⻚从Buffer Pool中淘汰掉。 因为有这两种情况的存在，所以设计InnoDB的大叔把这个LRU链表按照一定比例分成两截，分别是: 一部分存储使用频率非常高的缓存⻚，所以这一部分链表也叫做热数据，或者称young区域。 另一部分存储使用频率不是很高的缓存⻚，所以这一部分链表也叫做冷数据，或者称old区域。 为了方便大家理解，我们把示意图做了简化，各位领会精神就好: 大家要特别注意一个事儿:我们是按照某个比例将LRU链表分成两半的，不是某些节点固定是young区域的，某些节点固定是old区域的，随着程序的运行，某个节点所属的区域也可能发生变化。那这个划分成两截的比例怎么确定呢?对于InnoDB存储引擎来说，我们可以通过查看系统变量innodb_old_blocks_pct的值来确定old区域在LRU链表中所占的比例，比方说这样: 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;innodb_old_blocks_pct&#x27;; +-----------------------+-------+ | Variable_name | Value | +-----------------------+-------+ | innodb_old_blocks_pct | 37 | +-----------------------+-------+ 1 row in set (0.01 sec) 从结果可以看出来，默认情况下，old区域在LRU链表中所占的比例是37%，也就是说old区域大约占LRU链表的3&#x2F;8。这个比例我们是可以设置的，我们可以在启动时修改innodb_old_blocks_pct参数来控制old区域在LRU链表中所占的比例，比方说这样修改配置文件: 12[server] innodb_old_blocks_pct = 40 这样我们在启动服务器后，old区域占LRU链表的比例就是40%。当然，如果在服务器运行期间，我们也可以修改这个系统变量的值，不过需要注意的是，这个系统变量属于全局变量，一经修改，会对所有客户端生效，所以我们只能这样修改: 1SET GLOBAL innodb_old_blocks_pct = 40; 有了这个被划分成young和old区域的LRU链表之后，设计InnoDB的大叔就可以针对我们上边提到的两种可能降低缓存命中率的情况进行优化了: 针对预读的⻚面可能不进行后续访情况的优化设计InnoDB的大叔规定，当磁盘上的某个⻚面在初次加载到Buffer Pool中的某个缓存⻚时，该缓存⻚对应的控制块会被放到old区域的头部。这样针对预读到Buffer Pool却不进行后续访问的⻚面就会被逐渐从old区域逐出，而不会影响young区域中被使用比较频繁的缓存⻚。 针对全表扫描时，短时间内访问大量使用频率非常低的⻚面情况的优化在进行全表扫描时，虽然首次被加载到Buffer Pool的⻚被放到了old区域的头部，但是后续会被⻢上访问到，每次进行访问的时候又会把该⻚放到young区域的头部，这样仍然会把那些使用频率比较高的⻚面给顶下去。有同学会想:可不可以在第一次访问该⻚面时不将其从old区域移动到young区域的头部，后续访问时再将其移动到young区域的头部。回答是: 行不通! 因为设计InnoDB的大叔规定每次去⻚面中读取一条记录时，都算是访问一次⻚面，而一个⻚面中可能会包含很多条记录，也就是说读取完某个⻚面的记录就相当于访问了这个⻚面好多次。咋办? 全表扫描有一个特点，那就是它的执行频率非常低，谁也不会没事儿老在那写全表扫描的语句玩，而且在执行全表扫描的过程中，即使某个⻚面中有很多条记录，也就是去多次访问这个⻚面所花费的时间也是非常少的。所以我们只需要规定，在对某个处在old区域的缓存⻚进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该⻚面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部。上述的这个间隔时间是由系统变量 innodb_old_blocks_time 控制的，你看: 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;innodb_old_blocks_time&#x27;; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | innodb_old_blocks_time | 1000 | +------------------------+-------+ 1 row in set (0.01 sec) 这个innodb_old_blocks_time的默认值是1000，它的单位是毫秒，也就意味着对于从磁盘上被加载到LRU链表的old区域的某个⻚来说，如果第一次和最后一次访问该⻚面的时间间隔小于1s(很明显在一次全表扫描的过程中，多次访问一个⻚面中的时间不会超过 1s)，那么该⻚是不会被加入到young区域的。当然，像 innodb_old_blocks_pct 一样，我们也可以在服务器启动或运行时设置innodb_old_blocks_time的值，这里就不赘述了，你自己试试吧。这里需要注意的是，如果我们把 innodb_old_blocks_time 的值设置为0，那么每次我们访问一个⻚面时就会把该⻚面放到young区域的头部。 综上所述，正是因为将LRU链表划分为young和old区域这两个部分，又添加了innodb_old_blocks_time这个系统变量，才使得预读机制和全表扫描造成的缓存命中率降低的问题得到了遏制，因为用不到的预读⻚面以及全表扫描的⻚面都只会被放到old区域，而不影响young区域中的缓存⻚。 更进一步优化LRU链表LRU链表这就说完了么? 没有，早着呢…对于young区域的缓存⻚来说，我们每次访问一个缓存⻚就要把它移动到LRU链表的头部，这样开销是不是太大啦，毕竟在young区域的缓存⻚都是热点数据，也就是可能被经常访问的，这样频繁的对LRU链表进行节点移动操作是不是不太好啊?是的，为了解决这个问题其实我们还可以提出一些优化策略，比如只有被访问的缓存⻚位于young区域的1&#x2F;4的后边，才会被移动到LRU链表头部，这样就可以降低调整LRU链表的频率，从而提升性能(也就是说如果某个缓存⻚对应的节点在young区域的 1&#x2F;4中，再次访问该缓存⻚时也不会将其移动到LRU链表头部)。 Tips:我们之前介绍随机预读的时候曾说，如果Buffer Pool中有某个区的13个连续⻚面就会触发随机预读，这其实是不严谨的(不幸的是MySQL文档就是这么说的[摊手])，其实还要求这13个⻚面是非常热的⻚面，所谓的非常热，指的是这些⻚面在整个young区域的头1&#x2F;4处。还有没有什么别的针对LRU链表的优化措施呢? 当然有啊，你要是好好学，写篇论文，写本书都不是问题，可是这毕竟是一个介绍MySQL基础知识的文章，再说多了篇幅就受不了了，也影响大家的阅读体验，所以适可而止，想了解更多的优化知识，自己去看源码或者更多关于LRU链表的知识喽。但是不论怎么优化，千万别忘了我们的初心:尽量高效的提高 Buffer Pool 的缓存命中率。 刷新脏⻚到磁盘后台有专⻔的线程每隔一段时间负责把脏⻚刷新到磁盘，这样可以不影响用户线程处理正常的请求。 主要有两种刷新路径: 从LRU链表的冷数据中刷新一部分⻚面到磁盘后台线程会定时从LRU链表尾部开始扫描一些⻚面，扫描的⻚面数量可以通过系统变量innodb_lru_scan_depth来指定，如果从里边儿发现脏⻚，会把它们刷新到磁盘。这种刷新⻚面的方式被称之为BUF_FLUSH_LRU。 从flush链表中刷新一部分⻚面到磁盘后台线程也会定时从flush链表中刷新一部分⻚面到磁盘，刷新的速率取决于当时系统是不是很繁忙。这种刷新⻚面的方式 被称之为BUF_FLUSH_LIST。 有时候后台线程刷新脏⻚的进度比较慢，导致用户线程在准备加载一个磁盘⻚到Buffer Pool时没有可用的缓存⻚，这时就会尝试看看LRU链表尾部有没有可以直接释放掉的未修改⻚面，如果没有的话会不得不将LRU链表尾部的一个脏⻚同步刷新到磁盘(和磁盘交互是很慢的，这会降低处理用户请求的速度)。这种刷新单个⻚面到磁盘中的刷新方式被称之为 BUF_FLUSH_SINGLE_PAGE。当然，有时候系统特别繁忙时，也可能出现用户线程批量的从flush链表中刷新脏⻚的情况，很显然在处理用户请求过程中去刷新脏⻚是一种严重降低处理速度的行为(毕竟磁盘的速度满的要死)，这属于一种迫不得已的情况，不过这得放在后边唠叨redo日志的 checkpoint时说了。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"16. explain详解(下)","date":"2021-11-27T14:11:31.000Z","path":"2021/11/27/MySQL知识点整理/16. explain详解(下)/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"15.0 explain详解(上)","date":"2021-11-24T05:02:16.000Z","path":"2021/11/24/MySQL知识点整理/15.0 explain详解(上)/","text":"尝试用Explain查看执行计划一条查询语句在经过MySQL查询优化器的各种基于成本和规则的优化后，会生成一个所谓的执行计划，这个执行计划展示了接下来具体执行查询的方式，比如多表连接的顺序是什么，对于每个表采用什么访问方法来具体执行查询等等。 设计MySQL的大叔贴心的为我们提供了EXPLAIN语句来帮助我们查看某个查询语句的具体执行计划，本章的内容就是为了帮助大家看懂EXPLAIN语句的各个输出项都是干嘛使的，从而可以有针对性的提升我们查询语句的性能。 如果我们想看看某个查询的执行计划的话，可以在具体的查询语句前边加一个EXPLAIN，就像这样: 1234567mysql&gt; explain select 1;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | No tables used |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+1 row in set, 1 warning (0.00 sec) 上面输出的一大坨东⻄就是所谓的执行计划，我的任务就是带领大家看懂这一大坨东⻄里边的每个列都是干啥用的，以及在这个执行计划的辅助下，我们应该怎样改进自己的查询语句以使查询执行起来更高效。其实除了以SELECT开头的查询语句，其余的 DELETE、INSERT、REPLACE以及UPDATE语句前边都可以加上EXPLAIN这个词儿，用来查看这些语句的执行计划，不过我们这里对SELECT语句更感兴趣，所以后边只会以SELECT语句为例来描述EXPLAIN语句的用法。为了让大家先有一个感性的认识，我们把EXPLAIN语句输出的各个列的作用先大致罗列一下: id : 在一个大的查询语句中每个SELECT关键字都对应一个唯一的id select_type: SELECT关键字对应的那个查询的类型 table: 表名 partitions: 匹配的分区信息 type: 针对单表的访问方法 possible_keys: 可能用到的索引 key: 实际上使用的索引 key_len: 实际使用到的索引⻓度 ref: 当使用索引列等值查询时，与索引列进行等值匹配的对象信息 rows: 预估的需要读取的记录条数 filtered: 某个表经过搜索条件过滤后剩余记录条数的百分比 Extra: 一些额外的信息 需要注意的是，大家如果看不懂上边列的含义，那是正常的，千万不要纠结。这里把它们都列出来只是为了描述一个轮廓，让大家有一个大致的印象，下边会细细道来，等会儿说完了不信你不会~为了故事的顺利发展，我们还是要请出我们前边已经用了n遍的 single_table表: 12345678910111213141516CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 我们仍然假设有两个和single_table表构造一模一样的s1、s2表，而且这两个表里边儿有10000条记录，除id列外其余的列都插入随机值。为了让大家有比较好的阅读体验，我们下边并不准备严格按照EXPLAIN输出列的顺序来介绍这些列分别是干嘛的，大家注意一下就好了。 执行计划输出中的各列详解table不论我们的查询语句有多复杂，里边儿包含了多少个表，到最后也是需要对每个表进行单表访问的。所以设计MySQL的大叔规定 EXPLAIN语句输出的每条记录都对应着某个单表的访问方法，该条记录的table列代表着该表的表名。所以我们看一条比较简单的查询语句: 1234567EXPLAIN SELECT * FROM s1; +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+-------+| 1 | SIMPLE | s1 | NULL | ALL | NULL | NULL| NULL | NULL| 9688 | 100.00 | NULL | +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+-------+1 row in set, 1 warning (0.00 sec) 这个查询语句只涉及对s1表的单表查询，所以EXPLAIN输出中只有一条记录，其中的table列的值是s1，表明这条记录是用来说明对s1表的单表访问方法的。 再看一个连接查询的执行计划: 12345678mysql&gt; EXPLAIN SELECT * FROM s1 INNER JOIN s2; +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+---------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra| +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+---------------------------------------+ | 1 | SIMPLE | s1 | NULL | ALL | NULL | NULL| NULL | NULL| 9688 | 100.00 | NULL | | 1 | SIMPLE | s2 | NULL | ALL | NULL | NULL| NULL | NULL| 9954 | 100.00 | Using join buffer (Block Nested Loop) | +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+---------------------------------------+ 2 rows in set, 1 warning (0.01 sec) 可以看到这个连接查询的执行计划中有两条记录，这两条记录的table列分别是s1和s2，这两条记录用来分别说明对s1表和s2表的访问方法是什么。 id我们写的查询语句一般都以SELECT关键字开头，比较简单的查询语句里只有一个SELECT关键字，比如:SELECT * FROM s1 WHERE key1 = &#39;a&#39;;稍微复杂一点的连接查询中也只有一个SELECT关键字，比如:SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key1 WHERE s1.common_field = &#39;a&#39;; 但是下边两种情况下, 在一条查询语句中会出现多个SELECT关键字: 查询中包含子查询的情况，比如下边这个查询语句中就包含2个SELECT关键字:SELECT * FROM s1 WHERE key1 IN (SELECT * FROM s2); 查询中包含UNION语句的情况 比如下边这个查询语句中也包含2个SELECT关键字:SELECT * FROM s1 UNION SELECT * FROM s2; 查询语句中每出现一个SELECT关键字，设计MySQL的大叔就会为它分配一个唯一的id值。这个id值就是EXPLAIN语句的第一个列，比如下边这个查询中只有一个SELECT关键字，所以EXPLAIN的结果中也就只有一条id列为1的记录: 1234567mysql&gt; EXPLAIN SELECT * FROM s1 WHERE key1 = &#x27;a&#x27;; +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+----------+---------+-------+-----+----------+-------+| 1 | SIMPLE | s1 | NULL | ref | idx_key1 | idx_key1 | 303 | const | 8 | 100.00 | NULL | +----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+1 row in set, 1 warning (0.03 sec) 对于连接查询来说，一个SELECT关键字后边的FROM子句中可以跟随多个表，所以在连接查询的执行计划中，每个表都会对应一条记录，但是这些记录的id值都是相同的，比如: 12345678mysql&gt; EXPLAIN SELECT * FROM s1 INNER JOIN s2; +----+-------------+-------+------------+------+- --------------+------+---------+------+------+----------+------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra+----+-------------+-------+------------+------+---------------+-----+---------+-----+------+----------+---------------------------------------+ | 1 | SIMPLE | s1 | NULL | ALL | NULL | NULL| NULL | NULL| 9688 | 100.00 | NULL| 1 | SIMPLE | s2 | NULL | ALL | NULL | NULL| NULL | NULL| 9954 | 100.00 | Using join buffer (Block Nested Loop) | +----+-------------+-------+------------+------+---------------+-----+---------+------+------+--- -------+-------------------------------------+ 2 rows in set, 1 warning (0.01 sec) 可以看到，上述连接查询中参与连接的s1和s2表分别对应一条记录，但是这两条记录对应的id值都是1。这里需要大家记住的是，在连接查询的执行计划中，每个表都会对应一条记录，这些记录的id列的值是相同的，出现在前边的表表示驱动表，出现在后边的表表示被驱动表。所以从上边的EXPLAIN输出中我们可以看出，查询优化器准备让s1表作为驱动表，让s2表作为被驱动表来执行查询。 对于包含子查询的查询语句来说，就可能涉及多个SELECT关键字， 所以在包含子查询的查询语句的执行计划中，每个SELECT关键字都会对应一个唯一的id值，比如这样: 12345678mysql&gt; EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = &#x27;a&#x27;; +----+-------------+-------+------------+------+---------------+----------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+----------+---------+------+------+----------+-------------+ | 1 | PRIMARY | s1 | NULL | ALL | idx_key3 | NULL | NULL | NULL | 9688 | 100.00 | Using where || 2 | SUBQUERY | s2 | NULL | index| idx_key1 | idx_key1 | 303 | NULL | 9954 | 100.00 | Using index | +----+-------------+-------+------------+-------+---------------+----------+---------+------+---- --+----------+-------------+2 rows in set, 1 warning (0.02 sec) 从输出结果中我们可以看到，s1表在外层查询中，外层查询有一个独立的SELECT关键字，所以第一条记录的id值就是1，s2表在子查询中，子查询有一个独立的SELECT关键字，所以第二条记录的id值就是2。但是这里大家需要特别注意，查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询。 所以如果我们想知道查询优化器对某个包含子查询的语句是否进行了重写，直接查看执行计划就好了，比如说: 12345678mysql&gt; EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2 WHERE common_field = &#x27;a&#x27;); +----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra+----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+------------------------------+| 1 | SIMPLE | s2 | NULL | ALL | idx_key3 | NULL | NULL | NULL | 9954 | 10.00 | Using where; Start temporary || 1 | SIMPLE | s1 | NULL | ref | idx_key1 | idx_key1 | 303 | xiaohaizi.s2.key3 | 1 | 100.00 | End temporary | +----+-------------+-------+------------+------+- --------------+----------+---------+------------- ------+------+----------+----------------------------+2 rows in set, 1 warning (0.00 sec) 可以看到，虽然我们的查询语句是一个子查询，但是执行计划中s1和s2表对应的记录的id值全部是1，这就表明了查询优化器将子查询转换为了连接查询 。 对于包含UNION子句的查询语句来说，每个SELECT关键字对应一个id值也是没错的，不过还是有点儿特别的东⻄，比方说下边这个查询: 123456789mysql&gt; EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2; +----+-------------+------------+------------+-- ----+---------------+------+---------+------+------+----------+-----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+------------+------------+------+---------------+-----+---------+-----+------+----------+-----------------+| 1 | PRIMARY | s1 | NULL | ALL | NULL |NULL | NULL | NULL| 9688 | 100.00 | NULL || 2 | UNION | s2 | NULL | ALL | NULL |NULL | NULL | NULL| 9954 | 100.00 | NULL ||NULL| UNION RESULT| &lt;union1,2&gt; | NULL | ALL | NULL |NULL | NULL | NULL| NULL | NULL | Using temporary | +----+-------------+------------+------------+------+---------------+-----+---------+------+-----+----------+-----------------+3 rows in set, 1 warning (0.00 sec) 这个语句的执行计划的第三条记录是个什么⻤? 为毛id值是NULL， 而且table列⻓的也怪怪的?大家别忘了UNION子句是干嘛用的，它会把多个查询的结果集合并起来并对结果集中的记录进行去重，怎么去重呢? MySQL使用的是内部的临时表。正如上边的查询计划中所示，UNION子句是为了把id为1的查询和id为2的查询的结果集合并起来并去重，所以在内部创建了一个名为&lt;union1, 2&gt;的临时表 (就是执行计划第三条记录的table列的名称)，id为NULL表明这个临时表是为了合并两个查询的结果集而创建的。 跟UNION对比起来，UNION ALL就不需要为最终的结果集进行去重，它只是单纯的把多个查询的结果集中的记录合并成一个并返回给用户，所以也就不需要使用临时表。所以在包含UNION ALL子句的查询的执行计划中，就没有那个id为NULL的记录，如下所示: 12345678mysql&gt; EXPLAIN SELECT * FROM s1 UNION ALL SELECT * FROM s2; +----+-------------+-------+------------+------+---------------+-----+---------+-----+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+-----+---------+------+------+---------+-------+| 1 | PRIMARY | s1 | NULL | ALL | NULL | NULL| NULL | NULL| 9688| 100.00 | NULL || 2 | UNION | s2 | NULL | ALL | NULL | NULL| NULL | NULL| 9954| 100.00 | NULL | +----+-------------+-------+------------+------+---------------+-----+---------+------+------+---------+-------+2 rows in set, 1 warning (0.01 sec) select_type通过上边的内容我们知道，一条大的查询语句里边可以包含若干个SELECT关键字，每个SELECT关键字代表着一个小的查询语句， 而每个SELECT关键字的FROM子句中都可以包含若干张表(这些表用来做连接查询)，每一张表都对应着执行计划输出中的一条记录，对于在同一个SELECT关键字中的表来说，它们的id值是相同的。设计MySQL的大叔为每一个SELECT关键字代表的小查询都定义了一个称之为select_type的属性，意思是我们只要知道了某个小查询的select_type属性，就知道了这个小查询在整个大查询中扮演了一个什么⻆色，口说无凭，我们还是先来⻅识⻅识这个select_type都能取哪些值:","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"14. 基于规则的优化","date":"2021-11-21T12:31:27.000Z","path":"2021/11/21/MySQL知识点整理/14. 基于规则的优化/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"12. 基于成本的优化","date":"2021-11-13T05:27:25.000Z","path":"2021/11/13/MySQL知识点整理/12. TODO 基于成本的优化/","text":"什么是成本我们之前老说MySQL执行一个查询可以有不同的执行方案，它会选择其中成本最低，或者说代价最低的那种方案去真正的执行查询。 不过我们之前对成本的描述是非常模糊的，其实在MySQL中一条查询语句的执行成本是由下边这两个方面组成的: I/O成本我们的表经常使用的MyISAM、InnoDB存储引擎都是将数据和索引存储到磁盘上的，当我们想查询表中的记录时，需要先把数据或者索引加载到内存中然后再操作。这个从磁盘到内存这个加载的过程损耗的时间称之为I/O成本。 CPU成本读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称之为CPU成本。 对于InnoDB存储引擎来说，**⻚是磁盘和内存之间交互的基本单位** ，设计MySQL的大叔规定读取一个⻚面花费的成本默认是1.0，读取以及检测一条记录是否符合搜索条件的成本默认是0.2。1.0、0.2这些数字称之为成本常数，这两个成本常数我们最常用到，其余的成本常数我们后边再说哈。(需要注意的是，不管读取记录时需不需要检测是否满足搜索条件， 其成本都算是0.2) 单表查询的成本准备工作为了故事的顺利发展，我们还得把之前用到的single_table表搬来: 12345678910111213141516CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 还是假设这个表里有10000条记录，除id列外其余的列都插入随机值。下边正式开始我们的表演。 基于成本的优化步骤在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案 ，对比之后找出成本最低的方案，这个成本最低的方案就是所谓的执行计划 ，之后才会调用存储引擎提供的接口真正的执行查询，这个过程总结一下就是这样: 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 下边我们就以一个实例来分析一下这些步骤，单表查询语句如下: 1234567SELECT * FROM single_table WHERE key1 IN (&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;) AND key2 &gt; 10 AND key2 &lt; 1000 AND key3 &gt; key2 AND key_part1 LIKE &#x27;%hello%&#x27; AND common_field = &#x27;123&#x27;; 根据搜索条件，找出所有可能使用的索引我们前边说过，对于B+树索引来说，只要索引列和常数使用 &#x3D;、&lt;&#x3D;&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;&#x3D;、&lt;&#x3D;、BETWEEN、!&#x3D;(不等于也可以写成&lt;&gt;)或者LIKE操作符连接起来，就可以产生一个所谓的范围区间(LIKE匹配字符串前缀也行)，也就是说这些搜索条件都可能使用到索引，设计MySQL的大叔把一个查询中可能使用到的索引称之为 possible keys。 我们分析一下上边查询中涉及到的几个搜索条件: key1 IN (‘a’, ‘b’, ‘c’)，这个搜索条件可以使用二级索引idx_key1。 key2 &gt; 10 AND key2 &lt; 1000，这个搜索条件可以使用二级索引idx_key2。 key3 &gt; key2，这个搜索条件的索引列由于没有和常数比较，所以并不能使用到索引。 key_part1 LIKE ‘%hello%’，key_part1通过LIKE操作符和以通配符开头的字符串做比较，不可以使用索引。 common_field &#x3D; ‘123’，由于该列上压根儿没有索引，所以不会用到索引。 综上所述，上边的查询语句可能用到的索引，也就是possible keys只有idx_key1和idx_key2。 计算全表扫描的代价 对于InnoDB存储引擎来说，全表扫描的意思就是把聚簇索引中的记录都依次和给定的搜索条件做一下比较，把符合搜索条件的记录加入到结果集，所以需要将聚簇索引对应的⻚面加载到内存中，然后再检测记录是否符合搜索条件。由于 查询成本=I/O成本+CPU成本，所以计算全表扫描的代价需要两个信息: 聚簇索引占用的⻚面数 该表中的记录数 这两个信息从哪来呢?设计MySQL的大叔为每个表维护了一系列的统计信息，关于这些统计信息是如何收集起来的我们放在本章后边详细唠叨，现在看看怎么查看这些统计信息。设计MySQL的大叔给我们提供了 SHOW TABLE STATUS 语句来查看表的统计信息，如果要看指定的某个表的统计信息，在该语句后加对应的LIKE语句就好了，比方说我们要查看order_by_demo这个表的统计信息可以这么写:虽然出现了很多统计选项，但我们目前只关心两个: Rows本选项表示表中的记录条数。对于使用MyISAM存储引擎的表来说，该值是准确的，对于使用InnoDB存储引擎的表来说，该值是一个估计值。从查询结果我们也可以看出来，由于我们的 single_table表 是使用InnoDB存储引擎的，所以虽然实际上表中有10000条记录，但是SHOW TABLE STATUS显示的Rows值只有9693条记录。 Data_length本选项表示表占用的存储空间字节数。使用MyISAM存储引擎的表来说，该值就是数据文件的大小，对于使用InnoDB存储引擎的表来说，该值就相当于聚簇索引占用的存储空间大小，也就是说可以这样计算该值的大小:Data_length = 聚簇索引的⻚面数量 x 每个⻚面的大小我们的single_table使用默认16KB的⻚面大小，而上边查询结果显示Data_length的值是1589248，所以我们可以反向来推导出聚簇索引的⻚面数量:聚簇索引的⻚面数量 = 1589248 ÷ 16 ÷ 1024 = 97我们现在已经得到了聚簇索引占用的⻚面数量以及该表记录数的估计值，所以就可以计算全表扫描成本了，但是设计MySQL的大叔在真实计算成本时会进行一些微调，这些微调的值是直接硬编码到代码里的，由于没有注释，我也不知道这些微调值是个啥子意思，但是由于这些微调的值十分的小，并不影响我们分析，所以我们也没有必要在这些微调值上纠结了。 现在可以看一下全表扫描成本的计算过程: I&#x2F;O成本: 97 x 1.0 + 1.1 = 98.197指的是聚簇索引占用的⻚面数，1.0指的是加载一个⻚面的成本常数，后边的1.1是一个微调值，我们不用在意。 CPU成本: 9639 x 0.2 + 1.0 = 1939.69639指的是统计数据中表的记录数，对于InnoDB存储引擎来说是一个估计值，0.2指的是访问一条记录所需的成本常数，后边的1.0是一个微调值，我们不用在意。 总成本: 98.1 + 1939.6 = 2037.7综上所述，对于single_table的全表扫描所需的总成本就是2037.7。 Tips:我们前边说过表中的记录其实都存储在聚簇索引对应B+树的叶子节点中，所以只要我们通过根节点获得了最左边的叶子节点，就可以沿着叶子节点组成的双向链表把所有记录都查看一遍。也就是说全表扫描这个过程其实有的B+树内节点是不需要访问的，但是设计MySQL的大叔们在计算全表扫描成本时直接使用聚簇索引占用的⻚面数作为计算I&#x2F;O成本的依据，是不区分内节点和叶子节点的，有点儿简单暴力，大家注意一下就好了。 计算使用不同索引执行查询的代价 从第1步分析我们得到，上述查询可能使用到 idx_key1和 idx_key2这两个索引，我们需要分别分析单独使用这些索引执行查询的成本，最后还要分析是否可能使用到索引合并。这里需要提一点的是，MySQL查询优化器先分析使用唯一二级索引的成本，再分析使用普通索引的成本，所以我们也先分析idx_key2的成本，然后再看使用idx_key1的成本。 使用idx_key2执行查询的成本分析idx_key2对应的搜索条件是: key2 &gt; 10 AND key2 &lt; 1000， 即对应的范围区间就是:(10, 1000)，使用idx_key2搜索的示意图就是这样子: 对于使用 `二级索引 + 回表` 方式的查询，设计MySQL的大叔计算这种查询的成本依赖两个方面的数据: 范围区间数量不论某个范围区间的二级索引到底占用了多少⻚面，查询优化器 粗暴 的认为读取索引的一个范围区间的I/O成本和读取一个⻚面是相同的。本例中使用idx_key2的范围区间只有一 个:(10, 1000)，所以相当于访问这个范围区间的二级索引付出的I&#x2F;O成本就是: 1 x 1.0 = 1.0 需要回表的记录数优化器需要计算二级索引的某个范围区间到底包含多少条记录，对于本例来说就是要计算idx_key2在(10, 1000)这个范围区间中包含多少二级索引记录，计算过程是这样的:步骤1:先 根据key2 &gt; 10这个条件访问一下idx_key2对应的B+树索引，找到满足key2 &gt; 10这个条件的第一条记录，我们把这条记录称之为区间最左记录。我们前头说过在B+数树中定位一条记录的过程是贼快的，是常数级别的，所以这个过程的性能消耗是可以忽略不计的。步骤2:然后再根据key2 &lt; 1000这个条件继续从idx_key2对应的B+树索引中找出第一条满足这个条件的记录，我们把这条记录称之为区间最右记录，这个过程的性能消耗也可以忽略不计的。步骤3:如果区间最左记录和区间最右记录相隔不太远 (在MySQL 5.7.21这个版本里，只要相隔不大于10个⻚面即可)，那就可以精确统计出满足key2 &gt; 10 AND key2 &lt; 1000条件的二级索引记录条数。否则只沿着区间最左记录向右读10个⻚面，计算平均每个⻚面中包含多少记录，然后用这个平均值乘以区间最左记录和区间最右记录之间的⻚面数量就可以了。 那么问题又来了，怎么 估计区间最左记录和区间最右记录之间有多少个⻚面呢? 解决这个问题还得回到B+树索引的结构中来:如图，我们假设区间最左记录在⻚b中，区间最右记录在⻚c中，那么我们想计算区间最左记录和区间最右记录之间的⻚面数量就相当于计算⻚b和⻚c之间有多少⻚面，而每一条目录项记录都对应一个数据⻚，所以计算⻚b和⻚c之间有多少⻚面就相当于计算它们父节点(也就是⻚ a)中对应的目录项记录之间隔着几条记录。 在一个⻚面中统计两条记录之间有几条记录的成本就贼小了。不过还有问题，如果⻚b和⻚c之间的⻚面实在太多，以至于⻚b和⻚c对应的目录项记录都不在一个⻚面中该咋办? 继续递归啊，也就是再统计⻚b和⻚c对应的目录项记录所在⻚之间有多少个⻚面。之前我们说过一个B+树有4层高已经很了不得了，所以这个统计过程也不是很耗费性能。 知道了如何统计二级索引某个范围区间的记录数之后，就需要回到现实问题中来，根据上述算法测得idx_key2在区间(10, 1000)之间大约有95条记录。读取这95条二级索引记录需要付出的CPU成本就是:95 x 0.2 + 0.01 = 19.01其中95是需要读取的二级索引记录条数，0.2是读取一条记录成本常数，0.01是微调。 在通过二级索引获取到记录之后，还需要干两件事儿: 根据这些记录里的主键值到聚簇索引中做回表操作这里需要大家使劲儿睁大自己滴溜溜的大眼睛仔细瞧，设计MySQL的大叔评估回表操作的I&#x2F;O成本依旧很豪放，他们认为每次回表操作都相当于访问一个⻚面，也就是说二级索引范围区间有多少记录，就需要进行多少次回表操作，也就是需要进行多少次⻚面I&#x2F;O。我们上边统计了使用idx_key2二级索引执行查询时，预计有95条二级索引记录需要进行回表操作，所以回表操作带来的I&#x2F;O成本就是: 95 x 1.0 = 95.0其中95是预计的二级索引记录数，1.0是一个⻚面的I&#x2F;O成本常数。 回表操作后得到的完整用户记录，然后再检测其他搜索条件是否成立回表操作的本质就是通过二级索引记录的主键值到聚簇索引中找到完整的用户记录，然后再检测除 key2 &gt; 10 AND key2 &lt; 1000 这个搜索条件以外的搜索条件是否成立。因为我们通过范围区间获取到二级索引记录共95条，也就对应着聚簇索引中95条完整的用户记录，读取并检测这些完整的用户记录是否符合其余的搜索条件的 CPU成本如下: 设计MySQL的大叔只计算这个查找过程所需的I/O成本， 也就是我们上一步骤中得到的95.0，在内存中的定位完整用户记录的过程的成本是忽略不计的。在定位到这些完整的用户记录后， 需要检测除 key2 &gt; 10 AND key2 &lt; 1000这个搜索条件以外的搜索条件是否成立，这个比较过程花费的CPU成本就是:95 x 0.2 = 19.0，其中95是待检测记录的条数，0.2是检测一条记录是否符合给定的搜索条件的成本常数。 所以本例中使用idx_key2执行查询的成本就如下所示: I&#x2F;O成本: 1.0 + 95 x 1.0 &#x3D; 96.0 (范围区间的数量 + 预估的二级索引记录条数) CPU成本: 95x0.2+0.01+95x0.2&#x3D;38.01 (读取二级索 引记录的成本 + 读取并检测回表后聚簇索引记录的成本) 综上所述，使用idx_key2执行查询的总成本就是: 96.0 + 38.01 &#x3D; 134.01 使用idx_key1执行查询的成本分析idx_key1对应的搜索条件是: key1 IN (‘a’, ‘b’, ‘c’)，也就是说相当于3个单点区间，使用idx_key1搜索的示意图就是这样子: 与使用idx_key2的情况类似，我们也需要计算使用idx_key1时需要访问的范围区间数量以及需要回表的记录数: 范围区间数量使用idx_key1执行查询时很显然有3个单点区间，所以访问这3个范围区间的二级索引付出的I&#x2F;O成本就是: 3 x 1.0 &#x3D; 3.0 需要回表的记录数由于使用idx_key1时有3个单点区间，所以每个单点区间都需要查找一遍对应的二级索引记录数:查找单点区间[‘a’, ‘a’]对应的二级索引记录数 计算单点区间对应的二级索引记录数和计算连续范围区间对应的二级索引记录数是一样的，都是先计算区间最左记录和区间最右记录，然后再计算它们之间的记录数，具体算法上边都唠叨过了，就不赘述了。最后计算得到单点区 间[‘a’, ‘a’]对应的二级索引记录数是:35。查找单点区间[‘b’, ‘b’]对应的二级索引记录数与上同理，计算得到本单点区间对应的记录数是:44。查找单点区间[‘c’, ‘c’]对应的二级索引记录数与上同理，计算得到本单点区间对应的记录数是:39。 所以，这三个单点区间总共需要回表的记录数就是: 35 + 44 + 39 = 118读取这些二级索引记录的CPU成本就是: 118 x 0.2 + 0.01 = 23.61 得到总共需要回表的记录数之后，就要考虑:根据这些记录里的主键值到聚簇索引中做回表操作所需的I&#x2F;O成本就是:118 x 1.0 = 118.0回表操作后得到的完整用户记录，然后再比较其他搜索条件是否成立。 此步骤对应的CPU成本就是:118 x 0.2 = 23.6所以本例中使用idx_key1执行查询的成本就如下所示:I&#x2F;O成本: 3.0 + 118 x 1.0 &#x3D; 121.0 (范围区间的数量 + 预估的二级索引记录条数)CPU成本: 118x0.2+0.01+118x0.2&#x3D;47.21 (读取二级 索引记录的成本 + 读取并检测回表后聚簇索引记录的成本)综上所述，使用idx_key1执行查询的总成本就是: 121.0 + 47.21 &#x3D; 168.21 是否有可能使用索引合并(Index Merge)本例中有关key1和key2的搜索条件是使用AND连接起来的，而对于 idx_key1和idx_key2都是范围查询，也就是说查找到的二级索引记录并不是按照主键值进行排序的，并不满足使用Intersection索引合并的条件，所以并不会使用索引合并。Tips: MySQL查询优化器计算索引合并成本的算法也比较麻烦，所以我们 这也就不展开唠叨了。 对比各种执行方案的代价，找出成本最低的那一个下边把执行本例中的查询的各种可执行方案以及它们对应的成本列出来:全表扫描的成本:2037.7使用idx_key2的成本:134.01使用idx_key1的成本:168.21很显然，使用idx_key2的成本最低，所以当然选择idx_key2来执行查询喽。 Tips:小贴士:考虑到大家的阅读体验，为了最大限度的减少大家在理解优化器工作原理的过程中遇到的懵逼情况，这里对优化器在单表查询中对比各种执行方案的代价的方式稍稍的做了简化，不过毕竟大部分同学不需要去看MySQL的源码，把大致的精神传递正确就好了哈。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"11. 连接的原理","date":"2021-11-09T14:10:12.000Z","path":"2021/11/09/MySQL知识点整理/11. 连接的原理/","text":"搞数据库一个避不开的概念就是Join 连接。很多小伙伴在初学连接时可能会有些懵，理解了连接的语义可能又不明白各个表中的记录到底是怎么连起来的，以至于在使用的时候常常陷入下边两种误区: 误区一: 业务至上，管他三七二十一，再复杂的查询也用在一个连接语句中搞定。 误区二: 敬而远之，上次 DBA 那给报过来的慢查询就是因为使用了连接导致的，以后再也不敢用了。 所以本章就来扒一扒连接的原理。 连接简介为了故事的顺利发展，我们先建立 t1、t2 两个简单的表并给它们填充一点数据，这两个表都有两个列，一个是INT类型的，一个是CHAR(1)类型的。 其实连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。所以我们把t1和t2两个表连接起来的过程如下图所示:这个过程看起来就是把t1表的记录和t2的记录连起来组成新的更大的记录，所以这个查询过程称之为 连接查询。连接查询的结果集中包含一个表中的每一条记录与另一个表中的每一条记录相互匹配的组合，像这样的结果集就可以称之为笛卡尔积。因为表t1中有3条记录，表t2中也有3条记录，所以这两个表连接之后的笛卡尔积就有3×3&#x3D;9行记录。 在MySQL中，连接查询的语法也很随意，只要在FROM语句后边跟多个表名就可以，比如我们把t1表和t2表连接起来的查询语句可以写成这样: 123456789101112131415mysql&gt; SELECT * FROM t1, t2; +------+------+------+------+ |m1 |n1 |m2 |n2 | +------+------+------+------+ |1|a|2|b| |2|b|2|b| |3|c|2|b| |1|a|3|c| |2|b|3|c| |3|c|3|c| |1|a|4|d| |2|b|4|d| |3|c|4|d| +------+------+------+------+ 9 rows in set (0.00 sec) 连接过程简介如果我们乐意，我们可以连接任意数量张表，但是如果没有任何限制条件的话，这些表连接起来产生的笛卡尔积可能是非常巨大的。比方说3个100行记录的表连接起来产生的笛卡尔积就有 100×100×100&#x3D;1000000行数据!所以在连接的时候过滤掉特定记录组合是有必要的，在连接查询中的过滤条件可以分成两种: 涉及单表的条件这种只涉及单表的过滤条件我们之前都提到过一万遍了，我们之前也一直称为搜索条件，比如t1.m1 &gt; 1是只针对t1表的过滤条件，t2.n2 &lt; ‘d’是只针对t2表的过滤条件。 涉及两表的条件这种过滤条件我们之前没⻅过，比如 t1.m1 = t2.m2、t1.n1 &gt; t2.n2 等，这些条件中涉及到了两个表，我们稍后会仔细分析这种过滤条件是如何使用的哈。 下边我们就要看一下携带过滤条件的连接查询的大致执行过程了，比方说查询语句:SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &#39;d&#39;;在这个查询中我们指明了这三个过滤条件:t1.m1 &gt; 1t1.m1 = t2.m2t2.n2 &lt; &#39;d&#39; 那么这个连接查询的大致执行过程如下: 首先确定第一个需要查询的表，这个表称之为驱动表。怎样在单表中执行查询语句我们在前一章都唠叨过了，只需要选取代价最小的那种访问方法去执行单表查询语句就好了(就是说从 const、ref、ref_or_null、range、index、all这些执行方法中选取代价最小的去执行查询)。此处假设使用t1作为驱动表，那么就需要到t1表中找满足 t1.m1 &gt; 1 的记录，因为表中的数据太少，我们也没在表上建立二级索引，所以此处查询t1表的访问方法就设定为all吧，也就是采用全表扫描的方式执行单表查询。关于如何提升连接查询的性能我们之后再说，现在先把基本概念捋清楚哈。所以查询过程就如下图所示: 我们可以看到，t1表中符合 `t1.m1 > 1` 的记录有两条。 针对上一步骤中从驱动表产生的结果集中的每一条记录，分别需要到t2表中查找匹配的记录，所谓匹配的记录，指的是符合过滤条件的记录。因为是根据t1表中的记录去找t2表中的记录，所以t2表也可以被称之为被驱动表。 上一步骤从驱动表中得到了2条记录，所以需要查询2次t2表。此时涉及两个表的列的过滤条件 t1.m1 = t2.m2 就派上用场了: 当t1.m1 &#x3D; 2时，过滤条件t1.m1 &#x3D; t2.m2就相当于t2.m2 &#x3D; 2，所以此时t2表相当于有了t2.m2 &#x3D; 2、t2.n2 &lt; ‘d’这两个过滤条件，然后到t2表中执行单表查询。 当t1.m1 &#x3D; 3时，过滤条件t1.m1 &#x3D; t2.m2就相当于t2.m2 &#x3D; 3，所以此时t2表相当于有了t2.m2 &#x3D; 3、t2.n2 &lt; ‘d’这两个过滤条件，然后到t2表中执行单表查询。 所以整个连接查询的执行过程就如下图所示:也就是说整个连接查询最后的结果只有两条符合过滤条件的记录。 从上边两个步骤可以看出来，我们上边唠叨的这个两表连接查询共需要查询1次t1表，2次t2表。 当然这是在特定的过滤条件下的结果，如果我们把t1.m1 &gt; 1这个条件去掉，那么从t1表中查出的记录就有3条，就需要查询3次t3表了。 也就是说在两表连接查询中，驱动表只需要访问一次，被驱动表可能被访问多次。 内连接和外连接示例表： 12345678910111213CREATE TABLE student (number INT NOT NULL AUTO_INCREMENT COMMENT &#x27;学号&#x27;,name VARCHAR(5) COMMENT &#x27;姓名&#x27;, major VARCHAR(30) COMMENT &#x27;专业&#x27;, PRIMARY KEY (number)) Engine=InnoDB CHARSET=utf8 COMMENT &#x27;学生信息表&#x27;;CREATE TABLE score (number INT COMMENT &#x27;学号&#x27;,subject VARCHAR(30) COMMENT &#x27;科目&#x27;, score TINYINT COMMENT &#x27;成绩&#x27;, PRIMARY KEY (number, score)) Engine=InnoDB CHARSET=utf8 COMMENT &#x27;学生成绩表&#x27;; 我们新建了一个学生信息表，一个学生成绩表，然后向上述两个表中插入一些数据，插入后两表中的数据如下: 现在我们想把每个学生的考试成绩都查询出来就需要进行两表连接了(因为score中没有姓名信息，所以不能单纯只查询score表)。连接过程就是从student表中取出记录，在score表中查找number相同的成绩记录，所以过滤条件就是 student.number = socre.number，整个查询语句就是:SELECT s1.number, s1.name, s2.subject, s2.score FROM student AS s1, score AS s2 WHERE s1.number = s2.number; 从上述查询结果中我们可以看到，各个同学对应的各科成绩就都被查出来了，可是有个问题，史珍香同学，也就是学号为20180103的同学因为某些原因没有参加考试，所以在score表中没有对应的成绩记录。那如果老师想查看所有同学的考试成绩，即使是缺考的同学也应该展示出来，但是到目前为止我们介绍的连接查询是无法完成这样的需求的。 我们稍微思考一下这个需求，其本质是想: 驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。 为了解决这个问题，就有了内连接和外连接的概念: 对于内连接的两个表，驱动表中的记录在被驱动表中找不到匹配的记录，该记录不会加入到最后的结果集，我们上边提到的连接都是所谓的内连接; 对于外连接的两个表，驱动表中的记录即使在被驱动表中没有匹配的记录，也仍然需要加入到结果集。 在MySQL中，根据选取驱动表的不同，外连接仍然可以细分为2种: 左外连接: 选取左侧的表为驱动表。 右外连接: 选取右侧的表为驱动表。 可是这样仍然存在问题，即使对于外连接来说，有时候我们也并不想把驱动表的全部记录都加入到最后的结果集。 这就犯难了，有时候匹配失败要加入结果集，有时候又不要加入结果集，这咋办? 把过滤条件分为两种不就解决了这个问题了么，所以放在不同地方的过滤条件是有不同语义的: WHERE子句中的过滤条件WHERE子句中的过滤条件就是我们平时⻅的那种，不论是内连接还是外连接，凡是不符合WHERE子句中的过滤条件的记录都不会被加入最后的结果集。 ON子句中的过滤条件对于外连接的驱动表的记录来说，如果无法在被驱动表中找到匹配ON子句中的过滤条件的记录，那么该记录仍然会被加入到结果集中，对应的被驱动表记录的各个字段使用NULL值填充。需要注意的是，这个ON子句是专⻔为外连接驱动表中的记录在被驱动表找不到匹配记录时应不应该把该记录加入结果集这个场景下提出的 ，所以如果把ON子句放到内连接中，MySQL会把它和WHERE子句一样对待，也就是说: 内连接中的WHERE子句和ON子句是等价的。 一般情况下，我们都把只涉及单表的过滤条件放到WHERE子句中，把涉及两表的过滤条件都放到ON子句中，我们也一般把放到ON子句中的过滤条件也称之为连接条件。 Tips: 左外连接和右外连接简称左连接和右连接，所以下边提到的左外连接和右外连接中的外字都用括号扩起来，以表示这个字儿可有可无。 左(外)连接语法左(外)连接的语法还是挺简单的，比如我们要把t1表和t2表进行左外连接查询可以这么写:SELECT * FROM t1 LEFT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];其中中括号里的OUTER单词是可以省略的。对于LEFT JOIN类型的连接来说，我们把放在左边的表称之为外表或者驱动表，右边的表称之为内表或者被驱动表。所以上述例子中t1就是外表或者驱动表，t2就是内表或者被驱动表。需要注意的是，对于左(外)连接和右(外)连接来说，必须使用ON子句来指出连接条件。 了解了左 (外)连接的基本语法之后，再次回到我们上边那个现实问题中来，看看怎样写查询语句才能把所有的学生的成绩信息都查询出来，即使是缺考的考生也应该被放到结果集中:从结果集中可以看出来，虽然史珍香并没有对应的成绩记录，但是由于采用的是连接类型为左(外)连接，所以仍然把她放到了结果集中，只不过在对应的成绩记录的各列使用NULL值填充而已。 右(外)连接语法右(外)连接和左(外)连接的原理是一样一样的，语法也只是把LEFT换成RIGHT而已:SELECT * FROM t1 RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];只不过驱动表是右边的表，被驱动表是左边的表，具体就不唠叨了。 内连接的语法内连接和外连接的根本区别就是在驱动表中的记录不符合ON子句中的连接条件时不会把该记录加入到最后的结果集，我们最开始唠叨的那些连接查询的类型都是内连接。不过之前仅仅提到了一种最简单的内连接语法，就是直接把需要连接的多个表都放到FROM子句后边。其实针对内连接，MySQL提供了好多不同的语法，我们以t1和t2表为例瞅瞅:SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接 条件] [WHERE 普通过滤条件];也就是说在MySQL中，下边这几种内连接的写法都是等价的: SELECT * FROM t1 JOIN t2; SELECT * FROM t1 INNER JOIN t2; SELECT * FROM t1 CROSS JOIN t2; 上边的这些写法和直接把需要连接的表名放到FROM语句之后，用逗号,分隔开的写法是等价的: SELECT * FROM t1, t2; 现在我们虽然介绍了很多种内连接的书写方式，不过熟悉一种就好了，这里我们推荐INNER JOIN的形式书写内连接(因为INNER JOIN语义很明确嘛，可以和LEFT JOIN和RIGHT JOIN很轻松的区分开)。这里需要注意的是，由于在内连接中ON子句和WHERE子句是等价的，所以内连接中不要求强制写明ON子句。 我们前边说过，连接的本质就是把各个连接表中的记录都取出来依次匹配的组合加入结果集并返回给用户。不论哪个表作为驱动表，两表连接产生的笛卡尔积肯定是一样的。而对于内连接来说，由于凡是不符合ON子句或WHERE子句中的条件的记录都会被过滤掉，其实也就相当于从两表连接的笛卡尔积中把不符合过滤条件的记录给踢出去，所以对于内连接来说，驱动表和被驱动表是可以互换的，并不会影响最后的查询结果。但是对于外连接来说，由于驱动表中的记录即使在被驱动表中找不到符合ON子句连接条件的记录，所以此时驱动表和被驱动表的关系就很重要了，也就是说左外连接和右外连接的驱动表和被驱动表不能轻易互换。 连接的原理上边贼啰嗦的介绍都只是为了唤醒大家对连接、内连接、外连接这些概念的记忆，这些基本概念是为了真正进入本章主题做的铺垫。真正的重点是MySQL采用了什么样的算法来进行表与表之间的连接，了解了这个之后，大家才能明白为啥有的连接查询运行的快如闪电，有的却慢如蜗牛。 嵌套循环连接(Nested-Loop Join)我们前边说过，对于两表连接来说，驱动表只会被访问一遍，但被驱动表却要被访问到好多遍，具体访问几遍取决于对驱动表执行单表查询后的结果集中的记录条数。对于内连接来说，选取哪个表为驱动表都没关系，而外连接的驱动表是固定的，也就是说左(外)连接的驱动表就是左边的那个表，右(外)连接的驱动表就是右边的那个表。 我们上边已经大致介绍过t1表和t2表执行内连接查询的大致过程，我们温习一下: 步骤1:选取驱动表，使用与驱动表相关的过滤条件，选取代价最低的单表访问方法来执行对驱动表的单表查询。 步骤2:对上一步骤中查询驱动表得到的结果集中每一条记录，都分别到被驱动表中查找匹配的记录。 通用的两表连接过程如下图所示:如果有3个表进行连接的话，那么步骤2中得到的结果集就像是新的驱动表，然后第三个表就成为了被驱动表，重复上边过程，也就是步骤2中得到的结果集中的每一条记录都需要到t3表中找一找有没有匹配的记录。 这个过程就像是一个嵌套的循环，所以这种驱动表只访问一次，但被驱动表却可能被多次访问，访问次数取决于对驱动表执行单表查询后的结果集中的记录条数的连接执行方式称之为嵌套循环连接 (Nested-Loop Join)，这是最简单，也是最笨拙的一种连接查询算法。 使用索引加快连接速度我们知道在嵌套循环连接的步骤2中可能需要访问多次被驱动表。如果访问被驱动表的方式都是全表扫描的话，那得要扫描好多次！但是别忘了，查询t2表其实就相当于一次单表查询，我们可以利用索引来加快查询速度。回顾一下最开始介绍的t1表和t2表进行内连接的例子: SELECT * FROM t1, t2 WHERE t1.m1 &gt; 1 AND t1.m1 = t2.m2 AND t2.n2 &lt; &#39;d&#39;; 我们使用的其实是嵌套循环连接算法执行的连接查询，再把上边那个查询执行过程表拉下来给大家看一下:查询驱动表t1后的结果集中有两条记录，嵌套循环连接算法需要对被驱动表查询2次: 当t1.m1 &#x3D; 2时，去查询一遍t2表，对t2表的查询语句相当于:SELECT * FROM t2 WHERE t2.m2 = 2 AND t2.n2 &lt; &#39;d&#39;; 当t1.m1 &#x3D; 3时，再去查询一遍t2表，此时对t2表的查询语句相当于:SELECT * FROM t2 WHERE t2.m2 = 3 AND t2.n2 &lt; &#39;d&#39;; 可以看到，原来的t1.m1 = t2.m2这个涉及两个表的过滤条件在针对t2表做查询时，关于t1表的条件就已经确定了，所以我们只需要单单优化对t2表的查询即可。上述两个对t2表的查询语句中利用到的是m2和n2列，我们可以进行如下尝试: 在m2列上建立索引，因为对m2列的条件是等值查找，比如 t2.m2 = 2、t2.m2 = 3 等，所以可能使用到ref的访问方法。假设使用ref访问方法来执行对t2表的查询，需要在回表之后再判断 t2.n2 &lt; d 这个条件是否成立。 这里有一个比较特殊的情况，即假设m2列是t2表的主键或者唯一二级索引列，那么使用 `t2.m2 = 常数值` 这样的条件从t2表中查找记录的过程的代价就是`常数级别`的。 我们知道在`单表`中使用`主键值`或者`唯一二级索引列的值`进行`等值`查找的方式称之为`const`，而设计MySQL的大叔把在`连接查询`中对`被驱动表`使用`主键值`或者`唯一二级索引列的值`进行`等值`查找的查询执行方式称之为: `eq_ref`。 在n2列上建立索引，涉及到的条件是t2.n2 &lt; ‘d’，可能用到range访问方法，假设使用range的访问方法对t2表的查询的话，需要回表之后再判断在m2列上的条件是否成立。假设m2和n2列上都存在索引的话，那么就需要从这两个里边儿挑一个代价更低的去执行对t2表的查询。当然，建立了索引不一定使用索引，只有 在二级索引 + 回表 的代价比 全表扫描 的代价更低时才会使用索引。另外，有时候连接查询的查询列表和过滤条件中可能只涉及被驱动表的部分列，而这些列都是某个索引的一部分，这种情况下即使不能使用eq_ref、ref、ref_or_null或者range这些访问方法执行对被驱动表的查询的话，也可以使用索引扫描，也就是index的访问方法来查询被驱动表。所以我们建议在真实工作中最好不要使用*作为查询列表，最好把真实用到的列作为查询列表。 基于块的嵌套循环连接(Block Nested-Loop Join)扫描一个表的过程其实是先把这个表从磁盘上加载到内存中，然后从内存中比较匹配条件是否满足。 现实生活中的表可不像t1、t2这种只有3条记录，成千上万条记录都是少的，几百万、几千万甚至几亿条记录的表到处都是。内存里可能并不能完全存放的下表中所有的记录，所以在扫描表前边记录的时候后边的记录可能还在磁盘上，等扫描到后边记录时, 可能内存已经不足了，所以需要把前边的记录从内存中释放掉。我们前边又说过，采用嵌套循环连接算法的两表连接过程中，被驱动表可是要被访问好多次的，如果这个被驱动表中的数据特别多而且不能使用索引进行访问，那就相当于要从磁盘上读好几次这个表，这个I&#x2F;O代价就非常大了，所以我们得想办法: 尽量减少访问被驱动表的次数。 当被驱动表中的数据非常多时，每次访问被驱动表，被驱动表的记录会被加载到内存中，在内存中的每一条记录只会和驱动表结果集的一条记录做匹配，之后就会被从内存中清除掉。然后再从驱动表结果集中拿出另一条记录，再一次把被驱动表的记录加载到内存中一遍，周而复始，驱动表结果集中有多少条记录，就得把被驱动表从磁盘上加载到内存中多少次。所以我们可不可以在把被驱动表的记录加载到内存的时候，一次性和多条驱动表中的记录做匹配，这样就可以大大减少重复从磁盘上加载被驱动表的代价了。所以设计MySQL的大叔提出了一个join buffer的概念，join buffer就是执行连接查询前申请的一块固定大小的内存，先把若干条驱动表结果集中的记录装在这个join buffer中，然后开始扫描被驱动表，每一条被驱动表的记录一次性和join buffer中的多条驱动表记录做匹配，因为匹配的过程都是在内存中完成的，所以这样可以显著减少被驱动表的I&#x2F;O 代价。 使用join buffer的过程如下图所示:最好的情况是join buffer足够大，能容纳驱动表结果集中的所有记录，这样只需要访问一次被驱动表就可以完成连接操作了。设计 MySQL的大叔把这种加入了join buffer的嵌套循环连接算法称之为基于块的嵌套连接(Block Nested-Loop Join)算法。 这个join buffer的大小是可以通过启动参数或者系统变量 join_buffer_size 进行配置，默认大小为262144字节(也就是256KB)，最小可以设置为128字节。当然，对于优化被驱动表的查询来说，最好是为被驱动表加上效率高的索引 ，如果实在不能使用索引，并且自己的机器的内存也比较大可以尝试调大join_buffer_size的值来对连接查询进行优化。 另外需要注意的是，驱动表的记录并不是所有列都会被放到join buffer中，只有查询列表中的列和过滤条件中的列才会被放到join buffer中，所以再次提醒我们，最好不要把*作为查询列表 ，只需要把我们关心的列放到查询列表就好了，这样还可以在join buffer中放置更多的记录呢哈。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"},{"name":"不要 select*","slug":"不要-select","permalink":"http://rymuscle.github.io/tags/%E4%B8%8D%E8%A6%81-select/"}]},{"title":"10.1 单表访问方法 -- 注意事项","date":"2021-11-06T14:41:21.000Z","path":"2021/11/06/MySQL知识点整理/10.1 TODO 单表访问方法 注意事项/","text":"重温二级索引 + 回表一般情况下只能利用单个二级索引执行查询，比方说这个查询:SELECT * FROM single_table WHERE key1 = &#39;abc&#39; AND key2 &gt; 1000;查询优化器会识别到这个查询中的两个搜索条件:key1 = &#39;abc&#39;、key2 &gt; 1000 优化器一般会根据single_table表的统计数据来判断到底使用哪个条件到对应的二级索引中查询扫描的行数会更少，然后选择那个扫描行数较少的条件到对应的二级索引中查询(关于如何比较的细节我们后边的章节中会唠叨)。然后将从该二级索引中查询到的结果经过回表得到完整的用户记录后， 再根据其余的WHERE条件过滤记录 。 一般来说，等值查找比范围查找需要扫描的行数更少(也就是ref的访问方法一般比range好，但这也不总是一定的，也可能采用ref访问方法的那个索引列的值为特定值的行数特别多)所以这里假设优化器决定使用idx_key1索引进行查询，那么整个查询过程可以分为两个步骤: 步骤1:使用二级索引定位记录的阶段，也就是根据条件key1 &#x3D; ‘abc’从idx_key1索引代表的B+树中找到对应的二级索引记录。 步骤2:回表阶段，也就是根据上一步骤中找到的记录的主键值进行回表操作，也就是到聚簇索引中找到对应的完整的用户记录，再根据条件key2 &gt; 1000到完整的用户记录继续过滤。将最终符合过滤条件的记录返回给用户。 这里需要特别提醒大家的一点是，因为二级索引的节点中的记录只包含索引列和主键，所以在步骤1中使用idx_key1索引进行查询时只会用到与key1列有关的搜索条件，其余条件，比如key2 &gt; 1000这个条件在步骤1中是用不到的 ，只有在步骤2完成回表操作后才能继续针对完整的用户记录中继续过滤。 明确range访问方法使用的范围区间其实对于B+树索引来说，只要索引列和常数使用&#x3D;、&lt;&#x3D;&gt;、IN、NOT IN、IS NULL、IS NOT NULL、&gt;、&lt;、&gt;&#x3D;、&lt;&#x3D;、BETWEEN、!&#x3D;(不等于也可以写成&lt;&gt;)或 者LIKE操作符连接起来，就可以产生一个所谓的区间。 小贴士:LIKE操作符比较特殊，只有在匹配完整字符串或者匹配字符串前缀时才可以利用索引，这里就不赘述了。IN操作符的效果和若干个等值匹配操作符=之间用OR连接起来是一样的，也就是说会产生多个单点区间，比如下边这两个语句的效果是一样的: 12SELECT * FROM single_table WHERE key2 IN (1438, 6328);SELECT * FROM single_table WHERE key2 = 1438 OR key2 = 6328; 不过在日常的工作中，一个查询的WHERE子句可能有很多个小的搜索条件，这些搜索条件需要使用AND或者OR操作符连接起来。当我们想使用range访问方法来执行一个查询语句时，重点就是找出该查询可用的索引以及这些索引对应的范围区间。下边分两种情况看一下怎么从由AND或OR组成的复杂搜索条件中提取出正确的范围区间。 所有搜索条件都可以使用某个索引的情况有时候每个搜索条件都可以使用到某个索引，比如这个查询语句:SELECT * FROM single_table WHERE key2 &gt; 100 AND key2 &gt; 200;这个查询中的搜索条件都可以使用到key2，也就是说每个搜索条件都对应着一个idx_key2的范围区间。这两个小的搜索条件使用AND 连接起来，也就是要取两个范围区间的交集。也就是说，在我们使用range访问方法执行查询时，上边这个查询使用idx_key2的范围区间就是(200, +∞)。 我们再看一下使用OR将多个搜索条件连接在一起的情况: SELECT * FROM single_table WHERE key2 &gt; 100 OR key2 &gt; 200;OR意味着需要取各个范围区间的并集，所以上边这个查询在我们使用range访问方法执行查询时，使用的idx_key2索引的范围区间就是(100， +∞)。 📌有的搜索条件无法使用索引的情况比如这个查询:SELECT * FROM single_table WHERE key2 &gt; 100 AND common_field = &#39;abc&#39;;请注意，这个查询语句中能利用的索引只有idx_key2一个， 而idx_key2这个二级索引的记录中又不包含common_field这个字段，所以在使用二级索引idx_key2定位定位记录的阶段用不到common_field &#x3D; ‘abc’这个条件，这个条件是在回表获取了完整的用户记录后才使用的。 📌而 范围区间是为了 到索引中取记录 中提出的概念 ，所以在确定范围区间的时候不需要考虑common_field &#x3D; ‘abc’这个条件，我们在为某个索引确定范围区间时，只需要把用不到相关索引的搜索条件替换为TRUE就好了。 也就是说最上边那个查询使用idx_key2的范围区间就是:(100, +∞)。 再来看一下使用OR的情况: SELECT * FROM single_table WHERE key2 &gt; 100 OR common_field = &#39;abc&#39;;同理，我们把使用不到idx_key2索引的搜索条件替换为TRUE: SELECT * FROM single_table WHERE key2 &gt; 100 OR TRUE;接着化简为:SELECT * FROM single_table WHERE TRUE; 额，这也就说明如果我们强制使用idx_key2执行查询的话，对应的范围区间就是(-∞, +∞)，也就是 需要将全部二级索引的记录进行回表 ，这个代价肯定比直接全表扫描都大了 。📌也就是说 一个使用到索引的搜索条件 和 没有使用该索引的搜索条件 使用 OR 连接起来后是无法使用该索引的 。 复杂搜索条件下找出范围匹配的区间有的查询的搜索条件可能特别复杂，光是找出范围匹配的各个区间就挺烦的，比方说下边这个: 1234567SELECT * FROM single_table WHERE(key1 &gt; &#x27;xyz&#x27; AND key2 = 748 ) OR (key1 &lt; &#x27;abc&#x27; AND key1 &gt; &#x27;lmn&#x27;) OR ( key1 LIKE &#x27;%suf&#x27; AND key1 &gt; &#x27;zzz&#x27; AND (key2 &lt; 8000 OR common_field = &#x27;abc&#x27;)) ; 这个搜索条件也真是绝了，不过大家不要被复杂的表象迷住了双眼，按着下边这个套路分析一下: 首先查看WHERE子句中的搜索条件都涉及到了哪些列，哪些列可能使用到索引。这个查询的搜索条件涉及到了key1、key2、common_field 这3个列，然后key1列有普通的二级索引idx_key1，key2列有唯一二级索引idx_key2。 对于那些可能用到的索引，分析它们的范围区间 假设我们使用idx_key1执行查询 我们需要把那些用不到该索引的搜索条件暂时移除掉，移除方法也简单，直接把它们替换为TRUE就好了。上边的查询中除了有关key2和 common_field列不能使用到idx_key1索引外，key1 LIKE ‘%suf’也使用不到索引，所以把这些搜索条件替换为TRUE之后的样子就是这样:(key1 &gt; &#39;xyz&#39; AND TRUE ) OR (key1 &lt; &#39;abc&#39; AND key1 &gt; &#39;lmn&#39;) OR (TRUE AND key1 &gt; &#39;zzz&#39; AND (TRUE OR TRUE))化简一下上边的搜索条件就是:(key1 &gt; &#39;xyz&#39;) OR (key1 &lt; &#39;abc&#39; AND key1 &gt; &#39;lmn&#39;) OR (key1 &gt; &#39;zzz&#39;) 替换掉永远为TRUE或FALSE的条件因为符合key1 &lt; ‘abc’ AND key1 &gt; ‘lmn’永远为FALSE，所以上边的搜索条件可以被写成: (key1 &gt; &#39;xyz&#39;) OR (key1 &gt; &#39;zzz&#39;)继续化简区间key1 &gt; ‘xyz’和key1 &gt; ‘zzz’之间使用OR操作符连接起来的，意味着要取并集，所以最终的结果化简的到的区间就是: key1 &gt; xyz。 也就是说:上边那个有一坨搜索条件的查询语句如果使用 idx_key1 索引执行查询的话，需要把满足key1 &gt; xyz的二级索引记录都取出来，然后拿着这些记录的id再进行回表，得到完整的用户记录之后再使用其他的搜索条件进行过滤。 假设我们使用idx_key2执行查询 我们需要把那些用不到该索引的搜索条件暂时使用TRUE条件替换掉，其中有关key1和 common_field的搜索条件都需要被替换掉，替换结果就是:(TRUE AND key2 = 748 ) OR (TRUE AND TRUE) OR (TRUE AND TRUE AND (key2 &lt; 8000 OR TRUE))key2 &lt; 8000 OR TRUE的结果肯定是TRUE呀，也就是说化简之后的搜索条件成了:key2 = 748 OR TRUE这个化简之后的结果就更简单了: TRUE 这个结果也就意味着如果我们要使用idx_key2索引执行查询语句的话，需要扫描idx_key2二级索引的所有记录，然后再回表，这不是得不偿失么，所以这种情况下不会使用idx_key2索引的。 TODO 为啥没有用 联合索引的情况，毕竟 idx_key_part 索引 中包含了 key1 和 key2 ， 应该都能用到二级索引吧？ 索引合并 index merge我们前边说过MySQL在一般情况下只会为单个索引生成扫描区间，但还是有特殊情况。在这些特殊情况下也可能在一个查询中使用到多个二级索引，设计MySQL的大叔把这种使用到多个索引来完成一次查询的执行方法称之为:index merge，具体的索引合并算法有下边三种。 Intersection 合并Intersection翻译过来的意思是交集。这里是说某个查询可以使用多个二级索引，将从多个二级索引中查询到的结果取交集，比方说下边这个查询: 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;; 假设这个查询使用Intersection合并的方式执行的话，那这个过程就是这样的: 从idx_key1二级索引对应的B+树中取出key1 &#x3D; ‘a’的相关记录。 从idx_key3二级索引对应的B+树中取出key3 &#x3D; ‘b’的相关记录。二级索引的记录都是由 索引列 + 主键 构成的，所以我们可以计算出这两个结果集中id值的交集。按照上一步生成的id值列表进行回表操作，也就是从聚簇索引中把指定id值的完整用户记录取出来，返回给用户。 MySQL在某些特定的情况下才可能会使用到 Intersection索引合并: 情况一: 二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配 且 不能出现只出现匹配部分列的情况。 情况二: 主键列可以是范围匹配 比方说下边这个查询可能用到主键和idx_key_part进行Intersection索引合并的操作: 1SELECT * FROM single_table WHERE id &gt; 100 AND key1 = &#x27;a&#x27;; 为啥呢?凭啥呀?突然冒出这么两个规定让大家一脸懵逼，下边我们慢慢品一品这里头的玄机。这话还得从InnoDB的索引结构说起，你要是记不清麻烦再回头看看。对于InnoDB的二级索引来说，记录先是按照索引列进行排序，如果该二级索引是一个联合索引，那么会按照联合索引中的各个列依次排序。而二级索引的用户记录是由 索引列 + 主键构成的，二级索引列的值相同的记录可能会有好多条，这些索引列的值相同的记录又是按照主键的值进行排序的。所以重点来了，之所以在二级索引列都是等值匹配的情况下才可能使用Intersection索引合并 ，是因为只有在这种情况下根据二级索引查询出的结果集是按照主键值排序的。 so?还是没看懂根据二级索引查询出的结果集是按照主键值排序的对使用Intersection索引合并有啥好处?小伙子，别忘了 Intersection索引合并会把从多个二级索引中查询出的主键值求交集，如果从各个二级索引中查询的到的结果集本身就是已经按照主键排好序的，那么求交集的过程就很easy啦。假设某个查询使用Intersection索引合并的方式从idx_key1和idx_key2这两个二级索引中获取到的主键值分别是:从idx_key1中获取到已经排好序的主键值:1、3、5从idx_key2中获取到已经排好序的主键值:2、3、4那么求交集的过程就是这样:逐个取出这两个结果集中最小的主键值，如果两个值相等，则加入最后的交集结果中，否则丢弃当前较小的主键值，再取该丢弃的主键值所在结果集的后一个主键值来比较，直到某个结果集中的主键值用完了，如果还是觉得不太明白那继续往下看:先取出这两个结果集中较小的主键值做比较，因为1 &lt; 2，所以把idx_key1的结果集的主键值1丢弃，取出后边的3来比较。因为3 &gt; 2，所以把idx_key2的结果集的主键值2丢弃，取出 后边的3来比较。因为3 &#x3D; 3，所以把3加入到最后的交集结果中，继续两个结 果集后边的主键值来比较。后边的主键值也不相等，所以最后的交集结果中只包含主键 值3。 别看我们写的啰嗦，这个过程其实可快了，时间复杂度是O(n)，但是如果从各个二级索引中查询出的结果集并不是按照主键排序的话， 那就要先把结果集中的主键值排序完再来做上边的那个过程，就比较耗时了。 小贴士:按照有序的主键值去回表取记录有个专有名词儿，叫:Rowid Ordered Retrieval，简称ROR，以后大家在某些地方⻅到这个名词儿就眼熟了。 另外，不仅是多个二级索引之间可以采用Intersection索引合并，索引合并也可以有聚簇索引参加，也就是我们上边写的情况二: 在搜索条件中有主键的范围匹配的情况下也可以使用Intersection索引合并索引合并。为啥主键这就可以范围匹配 了?还是得回到应用场景里，比如看下边这个查询: 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND id &gt; 100; 假设这个查询可以采用Intersection索引合并，我们理所当然的以为这个查询会分别按照id &gt; 100这个条件从聚簇索引中获取一些记录，在通过key1 &#x3D; ‘a’这个条件从idx_key1二级索引中获取一些记录，然后再求交集，其实这样就把问题复杂化了，没必要从聚簇索引中获取一次记录。别忘了二级索引的记录中都带有主键值的，所以可以在从idx_key1中获取到的主键值上直接运用条件id &gt; 100 过滤就行了，这样多简单。所以涉及主键的搜索条件只不过是为了从别的二级索引得到的结果集中过滤记录罢了，是不是等值匹配不重要。 当然，上边说的情况一和情况二只是发生Intersection索引合并的必要条件，不是充分条件。也就是说即使情况一、情况二成立，也不一定发生Intersection索引合并，这得看优化器的心情。优化器在下边两个条件满足的情况下才趋向于使用Intersection索引合并: 单独根据搜索条件从某个二级索引中获取的记录数太多，导致回表开销太大 通过Intersection索引合并后需要回表的记录数大大减少 Union合并我们在写查询语句时经常想把既符合某个搜索条件的记录取出来，也把符合另外的某个搜索条件的记录取出来，我们说这些不同的搜索条件之间是OR关系。有时候OR关系的不同搜索条件会使用到同一个索引，比方说这样: 1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR key3 = &#x27;b&#x27; Intersection是交集的意思，这适用于使用不同索引的搜索条件之间使用AND连接起来的情况;Union是并集的意思，适用于使用不同索引的搜索条件之间使用OR连接起来的情况。与Intersection索引合并类似，MySQL在某些特定的情况下才可能会使用到Union索引合并: 情况一:二级索引列是等值匹配的情况，对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只出现匹配部分列的情况。比方说下边这个查询可能用到idx_key1和idx_key_part这两个二级索引进行Union索引合并的操作:1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR ( key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;); 而下边这两个查询就不能进行Union索引合并:12SELECT * FROM single_table WHERE key1 &gt; &#x27;a&#x27; OR (key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27;);SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; OR key_part1 = &#x27;a&#x27;; 第一个查询是因为对key1进行了范围匹配，第二个查询是因为联合索引idx_key_part中的key_part2列并没有出现在搜索条件中，所以这两个查询不能进行Union索引合并。 情况二:主键列可以是范围匹配 情况三:使用Intersection索引合并的搜索条件这种情况其实也挺好理解，就是搜索条件的某些部分使用Intersection索引合并的方式得到的主键集合和其他方式得到的主键集合取交集，比方说这个查询:1SELECT * FROM single_table WHERE key_part1 = &#x27;a&#x27; AND key_part2 = &#x27;b&#x27; AND key_part3 = &#x27;c&#x27; OR (key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;); 优化器可能采用这样的方式来执行这个查询: 先按照搜索条件key1 &#x3D; ‘a’ AND key3 &#x3D; ‘b’从索 引idx_key1和idx_key3中使用Intersection索引合 并的方式得到一个主键集合。 再按照搜索条件key_part1 &#x3D; ‘a’ AND key_part2 &#x3D; ‘b’ AND key_part3 &#x3D; ‘c’从联合索 引idx_key_part中得到另一个主键集合。 采用Union索引合并的方式把上述两个主键集合取并集， 然后进行回表操作，将结果返回给用户。 当然，查询条件符合了这些情况也不一定就会采用Union索引合并， 也得看优化器的心情。优化器在下边两个条件满足的情况下才趋向于 使用Union索引合并: 单独根据搜索条件从某个二级索引中获取的记录数比较少 通过Intersection索引合并后需要回表的记录数大大减少 Sort-Union合并Union索引合并的使用条件太苛刻，必须保证各个二级索引列在进行等值匹配的条件下才可能被用到，比方说下边这个查询就无法使用到Union索引合并: 1SELECT * FROM single_table WHERE key1 &lt; &#x27;a&#x27; OR key3 &gt; &#x27;z&#x27; 这是因为根据key1 &lt; ‘a’从idx_key1索引中获取的二级索引记录的主键值不是排好序的，根据key3 &gt; ‘z’从idx_key3索引中获取的二级索引记录的主键值也不是排好序的，但是key1 &lt; ‘a’和 key3 &gt; ‘z’这两个条件又特别让我们动心，所以我们可以这样: 先根据key1 &lt; ‘a’条件从idx_key1二级索引总获取记录， 并按照记录的主键值进行排序 再根据key3 &gt; ‘z’条件从idx_key3二级索引总获取记录， 并按照记录的主键值进行排序 因为上述的两个二级索引主键值都是排好序的，剩下的操作和 Union索引合并方式就一样了。 我们把上述这种先按照二级索引记录的主键值进行排序，之后按 照Union索引合并方式执行的方式称之为Sort-Union索引合并，很 显然，这种Sort-Union索引合并比单纯的Union索引合并多了一步 对二级索引记录的主键值排序的过程。 小贴士:为啥有Sort-Union索引合并，就没有Sort-Intersection索引 合并么?是的，的确没有Sort-Intersection索引合并这么一 说，Sort-Union的适用场景是单独根据搜索条件从某个二级索引中获 取的记录数比较少，这样即使对这些二级索引记录按照主键值进行 排序的成本也不会太高而Intersection索引合并的适用场景是单独根据搜索条件从某个 二级索引中获取的记录数太多，导致回表开销太大，合并后可以明 显降低回表开销，但是如果加入Sort-Intersection后，就需要 为大量的二级索引记录按照主键值进行排序，这个成本可能比回表 查询都高了，所以也就没有引入Sort-Intersection这个玩意 儿。 索引合并注意事项联合索引替代Intersection索引合并1SELECT * FROM single_table WHERE key1 = &#x27;a&#x27; AND key3 = &#x27;b&#x27;; 这个查询之所以可能使用Intersection索引合并的方式执行，还 不是因为idx_key1和idx_key2是两个单独的B+树索引，你要是把 这两个列搞一个联合索引，那直接使用这个联合索引就把事情搞定 了，何必用啥索引合并呢，就像这样: 1ALTER TABLE single_table drop index idx_key1, idx_key3, add index idx_key1_key3(key1, key3); 这样我们把没用的idx_key1、idx_key3都干掉，再添加一个联合 索引idx_key1_key3，使用这个联合索引进行查询简直是又快又 好，既不用多读一棵B+树，也不用合并结果，何乐而不为? 小贴士:不过小心有单独对key3列进行查询的业务场景，这样子不得不再把 key3列的单独索引给加上。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"10.0 单表访问方法","date":"2021-11-06T12:21:43.000Z","path":"2021/11/06/MySQL知识点整理/10.0 单表访问方法/","text":"前言 对于我们这些MySQL的使用者来说，MySQL其实就是一个软件，平时用的最多的就是查询功能。DBA时不时丢过来一些慢查询语句让优化，我们如果连查询是怎么执行的都不清楚还优化个毛线，所以是时候掌握真正的技术了。 我们在第一章的时候就曾说过，MySQL Server有一个称为查询优化器的模块，一条查询语句进行语法解析之后就会被交给查询优化器来进行优化，优化的结果就是生成一个所谓的执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的，等等。最后会按照执行计划中的步骤调用存储引擎提供的接口来真正地执行查询，并将查询结果返回给客户端。 不过查询优化这个主题有点儿大，在学会跑之前还得先学会走，所以本章先来瞅瞅MySQL怎么执行单表查询(就是FROM子句后边只有一个表，最简单的那种查询~)。 Demo准备123456789101112131415CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3)) Engine=InnoDB CHARSET=utf8; 我们为这个single_table表建立了1个聚簇索引和4个二级索引，分别是: 为id列建立的聚簇索引； 为key1列建立的idx_key1二级索引； 为key2列建立的idx_key2二级索引，而且该索引是唯一二级索引； 为key3列建立的idx_key3二级索引； 为key_part1、key_part2、key_part3列建立的idx_key_part二级索引，这也是一个联合索引。 访问方法(access method)的概念我们平时写的查询语句本质上只是告诉MySQL我们要获取的数据符合哪些规则，至于MySQL背地里是怎么把查询结果搞出来的那是MySQL自己的事儿。设计MLySQL的大叔把MySQL执行查询语句的方式称为访问方法(access method)或者访问类型。同一个查询语句可以使用多种不同的访问方法来执行，虽然最后的查询结果都是一样的，但是不同的执行方式花费的时间成本可能差距甚大。 const 访问方法主键 与 常数 等值匹配 有的时候我们可以通过主键列来定位一条记录，比方说这个查询:SELECT * FROM single_table WHERE id = 1438;MySQL会直接利用主键值在聚簇索引中定位对应的用户记录。 唯一二级索引列 与 常数 等值匹配 与之类似，根据唯一二级索引列来定位一条记录的速度也是贼快的，比如下面这个查询：SELECT * FROM single_table WHERE key2 = 3841;不过这个查询的执行会分两步 第一步先从idx_key2对应的B+树索引中根据key2列与常数的等值比较条件定位到一条二级索引记录; 然后再根据该记录的id值到聚簇索引中获取到完整的用户记录; 设计MySQL的大叔认为 通过主键或者唯一二级索引列与常数的等值比较 来定位一条记录是像坐火箭一样快的，所以他们把这种通过主键或者唯一二级索引列来定位一条记录的访问方法定义为:const，意思是 常数级别 的，代价是可以忽略不计的。不过这种const访问方法 只能在主键列或者唯一二级索引列和一个常数进行等值比较时才有效 ， 如果主键或者唯一二级索引是由多个列构成的话，索引中的每一个列都需要与常数进行等值比较，这个const访问方法才有效(这是因为只有该索引中全部列都采用等值比较才可以定位唯一的一条记录)。 ❌唯一二级索引 IS NULL问题 对于唯一二级索引来说，查询该列为NULL值的情况比较特殊，比如这样:SELECT * FROM single_table WHERE key2 IS NULL;因为 唯一二级索引列并不限制NULL值的数量 ，所以上述语句可能访问到多条记录，也就是说上边这个语句不可以使用 const访问方法 来执行。 ref 访问方法普通二级索引列 与 常数 等值匹配有时候我们对某个普通的二级索引列与常数进行等值比较，比如: SELECT * FROM single_table WHERE key1 = &#39;abc&#39;; 对于这个查询，我们当然可以选择全表扫描来逐一对比搜索条件是否满足要求，我们也可以先使用二级索引找到对应记录的id值，然后再回表到聚簇索引中查找完整的用户记录。 由于普通二级索引并不限制索引列值的唯一性，所以可能找到多条对应的记录，也就是说 使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数。 如果匹配的记录较少，则回表的代价还是比较低的(如果匹配到的记录太多...啧啧...MySQL可能会认为还不如走全表扫描)，所以MySQL可能会选择 `使用索引` 或者 `全表扫描` 来执行查询。 如果MySQL使用了索引，设计MySQL的大叔把这种 `搜索条件为二级索引列与常数等值比较`，`采用二级索引`来执行查询的访问方法称为:`ref`。 采用ref访问方法执行查询的图示: 从图示中可以看出，对于普通的二级索引来说，通过索引列进行等值比较后可能匹配到多条连续的记录，而不是像主键或者唯一二级索引那样最多只能匹配1条记录，所以这种ref访问方法比const差了那么一丢丢，但是在二级索引等值比较时匹配的记录数较少时的效率还是很高的(如果匹配的二级索引记录太多那么回表的成本就太大了)。 普通二级索引列 IS NULL 问题不过需要注意下边两种情况: 二级索引列值为NULL的情况不论是普通的二级索引，还是唯一二级索引，它们的索引列对包含NULL值的数量并不限制 ， 所以我们采用key IS NULL这种形式的搜索条件最多只能使用ref的访问方法，而不是const的访问方法 。 对于某个包含多个索引列的二级索引来说，只要是最左边的连续索引列是与常数的等值比较就可能采用ref的访问方法;但是如果最左边的连续索引列并不全部是等值比较的话，它的访问方法就不能称为ref了;比如：SELECT * FROM single_table WHERE key_part1 = &#39;god like&#39; AND key_part2 &gt; &#39;legendary&#39;; ref_or_null 访问方法(二级索引 ref or NULL)有时候我们不仅想找出某个二级索引列的值等于某个常数的记录，还想把该列的值为NULL的记录也找出来，就像这个查询:SELECT * FROM single_demo WHERE key1 = &#39;abc&#39; OR key1 IS NULL; 我们前面提到过 使用二级索引来执行查询的代价取决于等值匹配到的二级索引记录条数，如果匹配的记录较少，则回表的代价还是比较低的，如果匹配到的记录太多...啧啧...MySQL可能会认为还不如走全表扫描 如果这里的查询是使用二级索引而不是全表扫描的方式执行该查询时，这种类型的查询使用的访问方法就称为 ref_or_null，这个ref_or_null访问方法的执行过程如下:可以看到，上边的查询相当于先分别从idx_key1索引对应的B+树中找出 key1 IS NULL和key1 = &#39;abc&#39;的两个连续的记录范围，然后根据这些二级索引记录中的id值再回表查找完整的用户记录。 range 访问方法(二级&#x2F;聚簇索引 范围匹配)我们之前介绍的几种访问方法都是在对索引列与某一个常数进行等值比较的时候才可能使用到(ref_or_null比较奇特，还计算了值为NULL的情况)，但是有时候我们面对的搜索条件更复杂，比如这个查询:SELECT * FROM single_table WHERE key2 IN (1438, 6328) OR (key2 &gt;= 38 AND key2 &lt;= 79); 我们当然还可以使用全表扫描的方式来执行这个查询，不过也可以使用 二级索引 + 回表 的方式执行。 如果采用 二级索引 + 回表 的方式来执行的话，那么此时的搜索条件就不只是要求索引列与常数的等值匹配了，而是索引列需要匹配某个或某些范围的值，在本查询中key2列的值只要匹配下列3个范围中的任何一个就算是匹配成功了: key2的值是1438； key2的值是6328 ； key2的值在38和79之间；设计MySQL的大叔把这种利用索引进行范围匹配的访问方法称之为: range。我们可以把那种索引列等值匹配的情况称之为单点区间，上边所说的范围1和范围2都可以被称为单点区间；而像范围3这种的我们可以称为连续范围区间。 小贴士:此处所说的使用索引进行范围匹配中的 索引 可以是聚簇索引， 也可以是二级索引。 index 访问方法(直接遍历二级索引获取结果集,不用回表)看这个查询: SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = &#39;abc&#39;;由于key_part2并不是联合索引idx_key_part最左索引列，所以我们无法使用ref或者range访问方法来执行这个语句。 但是这个查询符合下边这两个条件: 它的查询列表只有3个列: key_part1, key_part2, key_part3，而索引idx_key_part又包含这三个列； 搜索条件中只有key_part2列。这个列也包含在索引idx_key_part中； 也就是说我们可以直接通过遍历idx_key_part索引的叶子节点的记录来比较key_part2 &#x3D; ‘abc’这个条件是否成立，把匹配成功的二级索引记录的key_part1, key_part2, key_part3列的值直接加到结果集中就行了。由于二级索引记录比聚簇索记录小的多(聚簇索引记录要存储所有用户定义的列以及所谓的隐藏列，而二级索引记录只需要存放索引列和主键)，而且这个过程也不用进行回表操作 ，所以直接遍历二级索引比直接遍历聚簇索引的成本要小很多 。设计MySQL的大叔就把这种采用 遍历二级索引记录 的执行方式称之为: index。 all 访问方法 (全表扫描, InnoDB为直接扫描聚簇索引)最直接的查询执行方式就是我们已经提了无数遍的全表扫描，对于 InnoDB表来说也就是直接扫描聚簇索引(lant:的叶子节点)。设计MySQL的大叔把这种使用全表扫描执行查询的方式称之为: all。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.6 InnoDB 系统表空间的结构","date":"2021-11-04T14:15:17.000Z","path":"2021/11/04/MySQL知识点整理/9.6 InnoDB 系统表空间的结构/","text":"了解完了独立表空间的基本结构，系统表空间的结构也就好理解多了，系统表空间的结构和独立表空间基本类似，只不过由于整个MySQL进程只有一个系统表空间，在系统表空间中会额外记录一些有关整个系统信息的⻚面，所以会比独立表空间多出一些记录这些信息的⻚面。因为这个系统表空间最牛逼，相当于是表空间之首，所以它的表空间ID(Space ID)是0。 系统表空间的整体结构系统表空间与独立表空间的一个非常明显的不同之处就是在表空间开头有许多记录整个系统属性的⻚面，如图:可以看到，系统表空间和独立表空间的前三个⻚面(⻚号分别为0、1、2，类型分别是FSP_HDR、IBUF_BITMAP、INODE)的类型是一致的，只是⻚号为3到7的⻚面是系统表空间特有的:除了这几个记录系统属性的⻚面之外，系统表空间的extent 1和 extent 2这两个区，也就是⻚号从64~127这128个⻚面被称为Doublewrite buffer，也就是双写缓冲区。 不过上述的大部分知识都涉及到了事务和多版本控制的问题，这些问题我们会放在后边的章节集中唠叨，现在讲述太影响用户体验，所以现在我们只唠叨一下有关InnoDB数据字典的知识，其余的概念在后边再看。 InnoDB数据字典我们平时使用INSERT语句向表中插入的那些记录称之为用户数据， MySQL只是作为一个软件来为我们来保管这些数据，提供方便的增删改查接口而已。但是每当我们向一个表中插入一条记录的时候， MySQL先要校验一下插入语句对应的表存不存在，插入的列和表中的列是否符合，如果语法没有问题的话，还需要知道该表的聚簇索引和所有二级索引对应的根⻚面是哪个表空间的哪个⻚面，然后把记录插入对应索引的B+树中。所以说，MySQL除了保存着我们插入的用户数据之外，还需要保存许多额外的信息，比方说: 某个表属于哪个表空间，表里边有多少列 表对应的每一个列的类型是什么 该表有多少索引，每个索引对应哪几个字段，该索引对应的根⻚面在哪个表空间的哪个⻚面 该表有哪些外键，外键对应哪个表的哪些列 某个表空间对应文件系统上文件路径是什么 balabala … 还有好多，不一一列举了 上述这些数据并不是我们使用INSERT语句插入的用户数据，实际上是为了更好的管理我们这些用户数据而不得已引入的一些额外数据， 这些数据也称为元数据。InnoDB存储引擎特意定义了一系列的内部系统表(internal system table)来记录这些这些元数据:这些系统表也被称为数据字典，它们都是以B+树的形式保存在系统表空间的某些⻚面中，其中 SYS_TABLES、SYS_COLUMNS、SYS_INDEXES、SYS_FIELDS这四个表尤其重要，称之为基本系统表(basic system tables)，我们先看看这4个表的结构: 这个SYS_TABLES表有两个索引: - 以NAME列为主键的聚簇索引 - 以ID列建立的二级索引 只要有了上述4个基本系统表，也就意味着可以获取其他系统表以及用户定义的表的所有元数据。比方说我们想看看 SYS_TABLESPACES 这个系统表里存储了哪些表空间以及表空间对应的属性，那就可以: 到SYS_TABLES表中根据表名定位到具体的记录，就可以获取到SYS_TABLESPACES表的TABLE_ID 使用这个TABLE_ID到SYS_COLUMNS表中就可以获取到属于该表的所有列的信息。 使用这个TABLE_ID还可以到SYS_INDEXES表中获取所有的索引的信息，索引的信息中包括对应的INDEX_ID，还记录着该索引对应的B+数根⻚面是哪个表空间的哪个⻚面。 使用INDEX_ID就可以到SYS_FIELDS表中获取所有索引列的信息。 也就是说这4个表是表中之表，那这4个表的元数据去哪里获取呢? 没法搞了，只能把这4个表的元数据，就是它们有哪些列、哪些索引等信息硬编码到代码中，然后设计InnoDB的大叔又拿出一个固定的⻚面来记录这4个表的聚簇索引和二级索引对应的B+树位置，这个⻚面就是⻚号为7的⻚面，类型为SYS，记录了Data Dictionary Header，也就是数据字典的头部信息。除了这4个表的5个索引的根⻚面信息外，这个⻚号为7的⻚面还记录了整个InnoDB存储引擎的一些全局属性，说话太啰嗦，直接看这个⻚面的示意图:可以看到这个⻚面里竟然有Segment Header部分，意味着设计InnoDB的大叔把这些有关数据字典的信息当成一个段来分配存储空间，我们就姑且称之为数据字典段吧。由于目前我们需要记录的数据字典信息非常少(可以看到Data Dictionary Header部分仅占用了56字节)，所以该段只有一个碎片⻚，也就是⻚号为7的这个⻚。 接下来我们需要细细唠叨一下Data Dictionary Header部分的各个字段: Max Row ID: 我们说过如果我们不显式的为表定义主键，而且表中也没有UNIQUE索引，那么InnoDB存储引擎会默认为我们生成一个名为row_id的列作为主键。因为它是主键，所以每条记录的row_id列的值不能重复。原则上只要一个表中的row_id列不重复就可以了，也就是说表a和表b拥有一样的row_id列也没啥关系，不过设计InnoDB的大叔只提供了这个Max Row ID字段，不论哪个拥有row_id列的表插入一条记录时，该记录的row_id列的值就是Max Row ID对应的值，然后再把Max Row ID对应的值加1，也就是说 这个Max Row ID是全局共享的 。 Max Table ID: InnoDB存储引擎中的所有的表都对应一个唯一的ID，每次新建一个表时，就会把本字段的值作为该表的ID，然后自增本字段的值。 Max Index ID: InnoDB存储引擎中的所有的索引都对应一个唯一的ID，每次新建一个索引时，就会把本字段的值作为该索引的ID，然后自增本字段的值。 Max Space ID: InnoDB存储引擎中的所有的表空间都对应一个唯一的ID，每次新建一个表空间时，就会把本字段的值作为该表空间的ID，然后自增本字段的值。 ~~ Mix ID Low(Unused): 这个字段没啥用，跳过。 ~~ Root of SYS_TABLES clust index: 本字段代表SYS_TABLES表聚簇索引的根⻚面的⻚号。 Root of SYS_TABLE_IDS sec index: 本字段代表SYS_TABLES表为ID列建立的二级索引的根⻚面的⻚号。 Root of SYS_COLUMNS clust index: 本字段代表SYS_COLUMNS表聚簇索引的根⻚面的⻚号。 Root of SYS_INDEXES clust index: 本字段代表SYS_INDEXES表聚簇索引的根⻚面的⻚号。 Root of SYS_FIELDS clust index: 本字段代表SYS_FIELDS表聚簇索引的根⻚面的⻚号。 ~~&#96;Unused&#96;: 这4个字节没用，跳过。 ~~ 以上就是⻚号为7的⻚面的全部内容，初次看可能会懵逼(因为有点儿绕)，大家多瞅几次。 information_schema系统数据库需要注意一点的是，用户是不能直接访问InnoDB的这些内部系统表的，除非你直接去解析系统表空间对应文件系统上的文件。不过设计 InnoDB的大叔考虑到查看这些表的内容可能有助于大家分析问题， 所以在系统数据库information_schema中提供了一些以innodb_sys开头的表: 1234567891011121314151617mysql&gt; USE information_schema; Database changedmysql&gt; SHOW TABLES LIKE &#x27;innodb_sys%&#x27;; +--------------------------------------------+ | Tables_in_information_schema (innodb_sys%) | +--------------------------------------------+ | INNODB_SYS_DATAFILES | | INNODB_SYS_VIRTUAL | | INNODB_SYS_INDEXES | | INNODB_SYS_TABLES | | INNODB_SYS_FIELDS | | INNODB_SYS_TABLESPACES | | INNODB_SYS_FOREIGN_COLS | | INNODB_SYS_COLUMNS | | INNODB_SYS_FOREIGN | | INNODB_SYS_TABLESTATS | +--------------------------------------------+ 10 rows in set (0.00 sec) 在information_schema数据库中的这些以INNODB_SYS开头的表并不是真正的内部系统表(内部系统表就是我们上边唠叨的以SYS开头的那些表)，而是在存储引擎启动时读取这些以SYS开头的系统表，然后填充到这些以INNODB_SYS开头的表中。以INNODB_SYS开头的表和以SYS开头的表中的字段并不完全一样，但供大家参考已经足矣 。这些表太多了，我就不唠叨了，大家自个儿动手试着查一查这些表中的数据吧哈~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.5 InnoDB独立表空间结构 之 各类型⻚面详细情况","date":"2021-10-29T14:11:32.000Z","path":"2021/10/29/MySQL-InnoDB-页结构/9.5 InnoDB的表空间 之 独立表空间结构(5)/","text":"到现在为止我们已经大概清楚了表空间、段、区、XDES Entry、 各种以XDES Enty为节点的链表、List Base Node、INODE Entry 等概念了。可是总有一种不踏实的感觉： 每个区对应的 XDES Entry结构 到底存储在表空间的什么地方? 直属于 表空间的 FREE、FREE_FRAG、FULL_FRAG 链表的基节点到底存储在表空间的什么地方? (其实上一篇我们已经知道 段的3种链表的基节点都在INODE Entry结构中，只不过不知道 INODE Entry到底在表空间哪个位置罢了) 每个段对应的INODE Entry结构到底存在表空间的什么地方? 我们前边介绍了每256个连续的区算是一个组，想解决刚才提出来的这些个疑问还得从每个组开头的一些类型相同的⻚面说起，接下来我们一个⻚面一个⻚面的分析，真相⻢上就要浮出水面了。 FSP_HDR类型的页首先看表空间-&gt;第一个组-&gt;第一个区-&gt;第一个⻚面(⻚号为0)，这个⻚面的类型是FSP_HDR，它存储了表空间的一些整体属性以及第一个组内256个区的对应的XDES Entry结构，直接看这个类型的⻚面的示意图:从图中可以看出，一个完整的FSP_HDR类型的⻚面大致由5个部分组成，各个部分的具体释义如下表:File Header ： 文件头部； 38字节； ⻚的一些通用信息；File Space Header： 表空间头部；112字节； 表空间的一些整体属性信息；XDES Entry：区描述信息；10240字节；存储本组256个区对应的属性信息；Empty Space：尚未使用空间；5986字节；用于⻚结构的填充，没啥实际意义；File Trailer：文件尾部；8字节； 校验⻚是否完整； File Header和File Trailer就不再强调了，另外的几个部分中，Empty Space是尚未使用的空间，我们不用管它，重点来看看File Space Header和XDES Entry这两个部分。 File Space Header部分从名字就可以看出来，这个部分是用来存储表空间的一些整体属性的: Space ID : 4字节；表空间ID；Not Used : 4字节；这四个字节未被使用，可以忽略；Size : 4字节；当前表空间占有的页面数；FREE Limit : 4字节；尚未被初始化的最小页号，大于或等于这个页号的区对应的XDES Entry结构都没有被加入FREE链表；Space Flags : 4字节；表空间的一些占用存储空间比较小的属性；FRAG_N_USED : 4字节；FREE_FRAG链表中已使用的⻚面数量；List Base Node for Free List: 16字节；FREE链表的基节点；List Base Node for FREE_FRAG List : 16字节；FREE_FRAG链表的基节点；List Base Node for FULL_FRAG List : 415字节；FULL_FRAG链表的基节点；Next Unused Segment ID: 8字节； 当前表空间中下一个未使用的 Segment ID;List Base Node for SEG_INNODES_FULL List：16字节；SEG_INODES_FULL链表的基节点；List Base Node for SEG_INNODES_FREE List：16字节；SEG_INODES_FREE链表的基节点； 这里头的Space ID、Not Used、Size 这三个字段大家肯定一看就懂，其他的字段我们再详细瞅瞅。 📌 List Base Node for FREE List、List Base Node for FREE_FRAG List、List Base Node for FULL_FRAG List这三个大家看着太亲切了，分别是直属于表空间的FREE链表的基节点、FREE_FRAG链表的基节点、FULL_FRAG链表的基节点， 这三个链表的基节点在表空间的位置是固定的，就在表空间的第一个⻚面 (也就是FSP_HDR类型的⻚面)的File Space Header部分。所以之后定位这几个链表就so easy 啦。 📌 FRAG_N_USED这个字段表明在 FREE_FRAG链表 中已经使用的⻚面数量，方便之后在链表中查找空闲的⻚面。 FREE Limit 我们知道表空间都对应着具体的磁盘文件，一开始我们创建表空间的时候对应的磁盘文件中都没有数据，所以我们需要对表空间完成一个初始化操作，包括为表空间中的区建立XDES Entry结构，为各个段建立INODE Entry结构，建立各种链表&#96;吧啦吧啦的各种操作。我们可以一开始就为表空间申请一个特别大的空间，但是实际上有绝大部分的区是空闲的，我们可以选择把所有的这些空闲区对应的XDES Entry结构加入FREE链表，也可以选择只把一部分的空闲区加入FREE链表，等啥时候空闲链表中的XDES Entry结构对应的区不够使了，再把之前没有加入FREE链表的空闲区对应的XDES Entry结构加入FREE链表，中心思想就是啥时候用到啥时候初始化，设计InnoDB的大叔采用的就是后者，他们为表空间定义了FREE Limit这个字段，在该字段表示的⻚号之前的区都被初始化了，之后的区尚未被初始化。 Next Unused Segment ID表中每个索引都对应2个段，每个段都有一个唯一的ID，那当我们为某个表新创建一个索引的时候，就意味着要创建两个新的段。那怎么为这个新创建的段找一个唯一的ID呢?去遍历现在表空间中所有的段么?我们说过，遍历是不可能遍历的，这辈子都不可能遍历，所以设计InnoDB的大叔们提出了这个名叫Next Unused Segment ID的字段，该字段表明当前表空间中最大的段ID的下一个ID，这样在创建新段的时候赋予新段一个唯一的ID值就so easy啦，直接使用这个字段的值就好了。 Space Flags表空间对于一些布尔类型的属性，或者只需要寥寥几个比特位搞定的属性都放在了这个Space Flags中存储，虽然它只有4个字节，32个比特位大小，却存储了好多表空间的属性，详细情况如下表: Tips: 不同MySQL版本里 SPACE_FLAGS 代表的属性可能有些差异，这里列举的是5.7.21版本。不过大家现在不必深究它们的意思，因为我们一旦把这些概念展开，就需要非常大的篇幅，主要怕大家受不了。我们还是先挑重要的看，把主要的表空间结构了解完，这些 SPACE_FLAGS 里的属性的细节就暂时不深究了。 List Base Node for SEG_INODES_FULL List 和 List Base Node for SEG_INODES_FREE List每个段对应的INODE Entry结构会集中存放到一个类型为INODE的⻚中，如果表空间中的段特别多，则会有多个INODE Entry结构，可能一个⻚放不下，这些INODE类型的⻚会组成两种列表:SEG_INODES_FULL链表，该链表中的INODE类型的⻚面都已经被INODE Entry结构填充满了，没空闲空间存放额外的INODE Entry了。SEG_INODES_FREE链表，该链表中的INODE类型的⻚面都已经仍有空闲空间来存放INODE Entry结构。由于我们现在还没有详细唠叨INODE类型⻚，所以等会说过INODE类型的⻚之后再回过头来看这两个链表。 XDES Entry部分紧接着 File Space Header部分 的就是 XDES Entry部分。我们唠叨过无数次但却一直未见真身的XDES Entry就存储在表空间的第一个页面中。一个XDES Entry结构的大小是 40字节，由于一个⻚面的大小有限，只能存放有限个XDES Entry 结构，所以我们才把256个区划分成一组，在每组的第一个⻚面中存放256个XDES Entry结构。大家回看那个FSP_HDR类型⻚面的示意图，XDES Entry 0就对应着extent 0，XDES Entry 1就对 应着extent 1… 依此类推，XDES Entry255就对应着extent 255。 因为每个区对应的XDES Entry结构的地址是固定的，所以我们可以很轻松地访问它们。 XDES类型的页面我们说过，每一个XDES Entry结构对应表空间的一个区，虽然一个XDES Entry结构只占用40字节，但抵不住表空间区的数量也多啊。 在区的数量非常多时，一个单独的⻚可能就不够存放足够多的XDES Entry结构，所以我们把表空间的区分为了若干个组，每组开头的一个⻚面记录着本组内所有的区对应的XDES Entry结构。 由于第一个组的第一个⻚面有些特殊，因为它也是整个表空间的第一个⻚面，所以除了记录本组中的所有区对应的XDES Entry结构以外， 还记录着表空间的一些整体属性，这个⻚面的类型就是我们刚刚说完的FSP_HDR类型，整个表空间里只有一个这个类型的⻚面。 除去第一个分组以外，之后的每个分组的第一个⻚面只需要记录本组内所有的区对应的XDES Entry结构即可，不需要再记录表空间的属性了， 为了和FSP_HDR类型做区别，我们把之后每个分组的第一个⻚面的类型定义为XDES，它的结构和FSP_HDR类型是非常相似的:与FSP_HDR类型的⻚面对比，除了少了File Space Header部分之外(少了记录表空间整体属性的部分)，其余的部分是一样一样的。由于上边唠叨FSP_HDR类型的页面时已经够仔细了，对于XDES类型的⻚面也就不重复唠叨了。 IBUF_BITMAP类型的页面对比前边介绍表空间的图，每个分组的第二个⻚面的类型都是IBUF_BITMAP，这种类型的⻚里边记录了一些有关Change Buffer的东东。 INODE类型的页面再次对比前边介绍表空间的图，第一个分组的第三个⻚面的类型是INODE。我们前边说过设计InnoDB的大叔为每个索引定义了两个段，而且为某些特殊功能定义了些特殊的段。为了方便管理，他们又为每个段设计了一个INODE Entry结构，这个结构中记录了关于这个段的相关属性。我们将要介绍的这个INODE类型的⻚就是为了存储INODE Entry结构而存在的。 直接看图:从图中可以看出，一个INODE类型的⻚面是由这几部分构成的: 除了File Header、Empty Space、File Trailer这几个老朋友外，我们重点关注 List Node for INODE Page List 和 INODE Entry 这两个部分。 INODE Entry部分我们前边已经详细介绍过这个结构的组成了，主要包括对应的段内零散⻚面的地址以及附属于该段的FREE、NOT_FULL和FULL链表的基节点。每个INODE Entry结构占用192字节，一个⻚面里可以存储84个这样的结构。 List Node for INODE Page List结构重点看一下这个，因为一个表空间中可能存在超过84个段，所以可能一个INODE类型的⻚面不足以存储所有的段对应的INODE Entry结构，所以就需要额外的INODE类型的⻚面来存储这些结构。还是为了方便管理这些INODE类型的⻚面，设计InnoDB的大叔们将这些INODE类型的⻚面串联成两个不同的链表: SEG_INODES_FULL链表: 该链表中的INODE类型的⻚面中已经没有空闲空间来存储额外的INODE Entry结构了。 SEG_INODES_FREE链表: 该链表中的INODE类型的⻚面中还有空闲空间来存储额外的INODE Entry结构了。 想必大家已经认出这两个链表了，我们前边提到过这两个链表的基节点就存储在File Space Header里边，也就是说这两个链表的基节点的位置是固定的，所以我们可以很轻松的访问到这两个链表。 以后每当我们新创建一个段(创建索引时就会创建段)时，都会创建一个INODE Entry结构与之对应，存储INODE Entry的大致过程就是这样的: 先看看SEG_INODES_FREE链表是否为空，如果不为空，直接从该链表中获取一个节点，也就相当于获取到一个仍有空闲空间的INODE类型的⻚面，然后把该INODE Entry结构放到该⻚面中。当该⻚面中无剩余空间时，就把该⻚放到SEG_INODES_FULL链表中。 如果SEG_INODES_FREE链表为空，则需要从表空间的FREE_FRAG链表中申请一个⻚面，修改该⻚面的类型为INODE，把该⻚面放到SEG_INODES_FREE链表中，与此同时把该INODE Entry结构放入该⻚面。 Segment Header 结构我们知道一个索引会产生两个段，分别是叶子节点段和非叶子节点段，而每个段都会对应一个INODE Entry结构，那我们怎么知道某个段对应哪个INODE Entry结构呢? 所以得找个地方记下来这个对应关系。希望你还记得我们在唠叨数据⻚，也就是INDEX类型的⻚时有一个Page Header部分，当然我不能指望你记住，所以把Page Header部分再抄一遍给你看:其中的PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP都占用10个字 节，它们其实对应一个叫Segment Header的结构，该结构图示如 下:各个部分的具体释义如下:这样子就很清晰了，PAGE_BTR_SEG_LEAF记录着叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个⻚面的哪个偏移量；PAGE_BTR_SEG_TOP记录着非叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个⻚面的哪个偏移量。这样子索引和其对应的段的关系就建立起来了。不过需要注意的一点是，因为一个索引只对应两个段，所以只需要在索引的根⻚面中记录这两个结构即可。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.4 InnoDB的表空间 之 独立表空间结构(4)","date":"2021-10-28T12:57:09.000Z","path":"2021/10/28/MySQL-InnoDB-页结构/9.4 InnoDB的表空间 之 独立表空间结构(4)/","text":"段的结构(INODE Entry结构)我们前边说过，段其实不对应表空间中某一个连续的物理区域，而是一个 逻辑上的概念 ，由若干个零散的⻚面以及一些完整的区组成。 像每个区都有对应的 XDES Entry结构 来记录这个区中的属性一样，设计 InnoDB的大叔也为每个段都定义了一个INODE Entry结构来记录段中的属性。示意图如下: Segment ID : 就是指这个 INODE Entry结构 对应的段的编号(ID)。 NOT_FULL_N_USED这个字段指在 NOT_FULL链表中已经使用了多少⻚面。有了这个字段之后就可以快速定位空闲⻚面。 List Base Node ：段的3个链表对应的基节点分别为段的FREE链表、NOT_FULL链表、FULL链表 定义了 List Base Node。这样我们想查找某个段的某个链表的头节点和尾节点的时候，就可以直接到这个部分找到对应链表的 List Base Node。so easy! Magic Number这个值是用来标记这个 INODE Entry 是否已经被初始化了(初始化的意思就是把各个字段的值都填进去了)。如果这个数字是值的97937874，表明该INODE Entry已经初始化，否则没有被初始化。(不用纠结这个值有啥特殊含义，人家规定的)。 Fragment Array Entry我们前边强调过无数次段是一些零散⻚面和一些完整的区的集合，每个Fragment Array Entry结构都对应着一个零散的⻚面，这个结构一共4个字节，表示一个零散⻚面的⻚号。 结合着这个INODE Entry结构，大家可能对段是一些零散⻚面和一些完整的区的集合的理解再次深刻一些。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"📌 9.3 InnoDB的表空间 之 独立表空间结构(3)","date":"2021-10-27T14:19:17.000Z","path":"2021/10/27/MySQL-InnoDB-页结构/9.3 InnoDB的表空间 之 独立表空间结构(3)/","text":"到现在为止，我们已经提出的概念五花八⻔(像 区、碎片区、段、附属于段的区、区对应的XDES Entry结构)。我们把事情搞这么麻烦，初心仅仅是 想减少随机IO，而又不至于数据量少的表浪费空间 。 现在我们知道向表中插入数据本质上就是向表中各个索引的 叶子节点段、非叶子节点段 插入数据，也知道了不同的区有不同的状态。再回到最初的起点，捋一捋向某个段中插入数据时，申请新页面的过程; 先从直接隶属于表空间的碎片区中申请页一开始，当段中数据较少时，首先会查看表空间中是否有状态为FREE_FRAG的区，也就是找还空闲页的碎片区 如果找到了，则从该区中取一些零碎的⻚把数据插进去; 如果没找到，则到表空间下申请一个状态为FREE的区(也就是空闲的区)，把该区的状态变为FREE_FRAG，(lant:相当于从表空间中新拿了个FREE空闲区作为 新的FREE_FRAG空闲碎片区)，然后从 新的FREE_FRAG空闲碎片区 中取一些零碎的⻚把数据插进去。之后不同的段使用零碎⻚的时候都从该区中取，直到该区中没有空闲页面，然后该区的状态就变成了FULL_FRAG 。 引出 XDES Entry 链表：(lant: 3种区状态链表)现在的问题是你怎么知道表空间里的哪些区是FREE的，哪些区的状态是FREE_FRAG的，哪些区是FULL_FRAG的?要知道表空间的大小是可以不断增大的，当增⻓到GB级别的时候，区的数量也就上千了，我们总不能每次都遍历这些区对应的 XDES Entry结构(查看其 state状态) 吧? 这时候就是 XDES Entry结构 中的List Node部分发挥奇效的时候了，我们可以通过List Node中的指针做下面三件事: 把 状态为FREE的区 对应的 XDES Entry结构 通过 List Node 连接成一个链表，称之为 FREE链表； 把 状态为FREE_FRAG的区 对应的 XDES Entry结构 通过 List Node 连接成一个链表，称之为 FREE_FRAG链表； 把 状态为FULL_FRAG的区 对应的 XDES Entry结构 通过 List Node 连接成一个链表，称之为 FULL_FRAG链表； 这样每当我们想找一个FREE_FRAG状态的区时，就直接把 FREE_FRAG链表 的头节点拿出来，从这个节点对应的区中取一些零碎的⻚来插入数据，当这个节点对应的区用完时，就修改一下这个节点的State字段的值，然后从FREE_FRAG链表中移到FULL_FRAG链表中。同理，如果 FREE_FRAG链表 中一个节点都没有，那么就直接从 FREE链表 中取一个节点移动到 FREE_FRAG链表 的状态，并修改该节点的STATE字段值为FREE_FRAG，然后从这个节点对应的区中获取零碎的⻚就好了。当段中数据已经占满了32个零散的⻚后，就直接申请完整的区来插入数据了。 lant小结:我这里给 XDES Entry 链表 叫 XDES Entry 状态链表其实 3种XDES Entry 链表 就是根据区的状态，将 相同状态的区 对应的 XDES Entry 结构 连起来组成的三种状态链表。这样，无论我们需要哪种状态的区，直接找到对应的状态链表，就能快速地拿到处于该状态的区，而不用遍历表空间的所有区才能拿到你想要的那个装态的区。 申请完整的区在段中数据已经占满32个零碎的页后，我们就可以申请完整的区来插入数据了。 引出 段状态链表：(每个段下都有3类状态链表)还是那个问题，那么多区，我们怎么知道哪些区已经是属于哪个段的了呢?lant: 毕竟你不能随便拿个有空闲页的区就去用了，因为该区可能已经被别的段使用了(属于别的段了)，你肯定要保证每个段使用的区都是属于自己的段(这样段中的数据才会尽可能在物理上连续，减少随机IO)；其次，即便你取到的区属于当前段，但也可能已经没有空闲页了。那咋办？再遍历各个XDES Entry结构，查看区状态和区所属的段ID1? 遍历是不可能的，这辈子都不可能遍历的，有链表还遍历个毛线啊。 所以我们这里可以根据段号(也就 是Segment ID)来建立链表，有多少个段就建多少个链表?因为一个段中可以有好多个区，有的区是完全空闲的，有的区还有一些⻚面可以用，有的区已经没有空闲⻚面可以用了，所以设计InnoDB的大叔们为每个段中的区对应的XDES Entry结构建立了三个链表: FREE (段)链表: 同一个段中，所有⻚面都是空闲的区 对应的 XDES Entry结构 会被加入到这个链表。注意和直属于表空间的FREE链表区别开了，此处的FREE链表是附属于某个段的。 NOT_FULL (段)链表: 同一个段中，仍有空闲空间的区 对应的 XDES Entry结构 会被加入到这个链表。 FULL (段)链表: 同一个段中，已经没有空闲空间的区 对应的 XDES Entry结构 会被加入到这个链表。 再次强调一遍，每一个索引都对应两个段，每个段都会维护上述的3个链表。 假设表t共有两个索引，一个聚簇索引，一个二级索引idx_c2，每个索引都有 叶子节点段 和 非叶子节点段 2个段，所以这个表共有4个段，每个段都会维护上述3个链表，所以这个表共需要维护12个链表。 所以段在数据量比较大时插入数据的话，会先获取NOT_FULL链表的头节点，直接把数据插入这个头节点对应的区中即可，如果该区的空间已经被用完，就把该节点移到FULL链表中。 Tiplant: 当然，无论是直属于 表空间 的链表 还是 属于 段 的链表, 我估计一开始都是从 Free状态链表那里取直属于表空间的Free状态的区 新的空闲区的。 链表基节点 List Base Node上边介绍了一堆链表，可我们怎么在表空间中找到这些链表呢，或者说怎么找到某个链表的头节点或者尾节点在表空间中的位置呢?设计 InnoDB的大叔当然考虑了这个问题，他们设计了一个叫List Base Node的结构，翻译成中文就是链表的基节点。这个结构中包含了链表的头节点和尾节点的指针以及这个链表中包含了多少节点的信息，示意图如下: 我们上边介绍的 每个链表都对应这么一个 List Base Node结构 ， 其中: List Length表明该链表一共有多少节点； First Node Page Number 和 First Node Offset 表明该链表的头节点在表空间中的位置； Last Node Page Number 和 Last Node Offset 表明该链表的尾节点在表空间中的位置。 一般我们把某个链表对应的 List Base Node结构 放置在表空间中固定的位置(后面会介绍)，这样想找定位某个链表就变得so easy啦。 链表小结 📌 综上所述，表空间 是由若干个区 组成的，每个区都对应一个XDES Entry的结构； 直属于表空间的区对应的XDES Entry结构可以分成FREE、FREE_FRAG和FULL_FRAG这3个链表； 每个段可以拥有若干个区，每个段中的区对应的XDES Entry结构可以分成 FREE、NOT_FULL 和 FULL 这3个链表； 上面每个链表都对应一个List Base Node的结构，这个结构里记录了链表的头、尾节点的位置以及该链表中包含的节点数； 正是因为这些链表的存在，管理这些区才变成了一件so easy的事情。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.2 InnoDB的表空间 之 独立表空间结构(2)","date":"2021-10-26T10:42:11.000Z","path":"2021/10/26/MySQL-InnoDB-页结构/9.2 InnoDB的表空间 之 独立表空间结构(2)/","text":"区的分类通过上边一通唠叨，大家知道了表空间的是由若干个区组成的，这些区大体上可以分为4种类型: 有剩余空间的碎片区: 表示碎片区中还有可用的⻚面; 没有剩余空间的碎片区: 表示碎片区中的所有⻚面都被使用，没有空闲⻚面; 空闲的区: 区中⻚面还没有被使用过; 附属于某个段的区: 每一个索引都可以分为叶子节点段和非叶子节点段，在这些段中的数据量很大时 就会使用区来作为基本的分配单位。这些区中的页面完全用来存储该段中的数据。 这4种类型的区也可以被称为区的4种状态(State)，设计InnoDB 的大叔们为这4种状态的区定义了特定的名词儿: FREE_FRAG 有剩余空间的碎片区 FULL_FRAG 没有剩余空间的碎片区 FREE 空闲的区 现在还没有用到这个区中的任何页面 FSEG 附属于某个段的区 需要再次强调一遍的是，处于FREE、FREE_FRAG以及FULL_FRAG 这三种状态的区都是独立直属于表空间的; 而处于FSEG状态的区是附属于某个段的。 Tips:如果把表空间比作是一个集团军，段就相当于师，区就相当于团。一般的团都是隶属于某个师的，就像是处于FSEG的区全都隶属于某个段，而处于FREE、FREE_FRAG以及FULL_FRAG这三种状态的区却直接隶属于表空间，就像独立团直接听命于军部一样。 区对应的 XDES Entry 结构为了方便管理这些区，设计InnoDB的大叔设计了一个称为 XDES Entry的结构(全称是Extent Descriptor Entry)。每一个区都对应着一个XDES Entry结构 ，这个结构记录了对应的区的一些属性。 先通过下图对这个结构有个大致的了解: Segment ID(8字节): 表示该区所在的段(每一个段都有一个唯一ID)。当然前提是该区已经被分配给某个段了，不然的话该字段的值没啥意义。 List Node(12字节):这个部分可以将若干个 XDES Entry结构 串联成一个链表，大家看一下这个List Node的结构: 把一些XDES Entry结构连成一个链表有啥用?稍安勿躁，我们稍后唠叨XDES Entry结构组成的链表问题。 State(4字节):这个字段表明区的状态。可选的值就是我们前边说过的那4个，分别是:FREE、FREE_FRAG、FULL_FRAG和FSEG。 Page State Bitmap(16字节):这个部分共占用16个字节(128个比特位)。我们说一个区默认有64个⻚，这128个比特位被划分为64个部分，每个部分2个比特位，对应区中的一个⻚。 比如Page State Bitmap部分的第1和第2个比特位对应着区中的第1个⻚面，第3和第4个比特位对应着区中的第2个⻚面，依此类推，这两个比特位的第一个位表示对应的⻚是否是空闲的，第二个比特位还没有用。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.1 InnoDB的表空间 之 独立表空间结构(1)","date":"2021-10-26T05:19:37.000Z","path":"2021/10/26/MySQL-InnoDB-页结构/9.1 InnoDB的表空间 之 独立表空间结构(1)/","text":"我们知道InnoDB支持许多种类型的表空间，本章重点关注 独立表空间 和 系统表空间 的结构。它们的结构比较相似，但是由于 系统表空间 中额外包含了一些关于整个系统的信息，所以我们先挑简单一点的 独立表空间 来聊，稍后再说系统表空间的结构。 区(extent)的概念：为了顺序IO 表空间 中的 ⻚ 实在是太多了，为了更好的管理这些⻚，设计InnoDB的大叔们提出了区(extent)的概念。对于16KB的⻚来说，连续的64个⻚ 就是一个区，也就是说一个区默认占用1MB空间大小。 为啥好端端地提出一个区的概念呢？ 我们以前学到的InnoDB存储结构的相关知识大致是:表中的记录存储到⻚里，然后⻚作为节点组成B+树，这个B+树就是索引，然后吧啦吧啦一堆聚簇索引和二级索引的区别。这套路也没啥不妥的呀~ 是的，如果我们表中数据量很少的话，比如说你的表中只有几十条、几百条数据的话，的确用不到区的概念，因为简单的几个⻚就能把对应的数据存储起来。但是你架不住表里的记录越来越多呀。 我们每向表中插入一条记录，本质上就是向该表的聚簇索引以及所有二级索引代表的B+树的节点中插入数据。而 B+树的每一层中的⻚都会形成一个双向链表 ， 如果是以⻚为单位来分配存储空间的话， 双向链表相邻的两个⻚之间的物理位置可能离得非常远 。 我们介绍B+树索引的适用场景的时候特别提到 范围查询只需要定位到最左边的记录和最右边的记录，然后沿着双向链表一直扫描就可以了 。 而如果双向链表中相邻的两个⻚的物理位置不连续，对于传统机械硬盘来说，需要重新定位磁头的位置，就是所谓的随机I&#x2F;O，这样会影响磁盘的性能。随机I/O是非常慢的。 所以 我们应该尽量让链表中相邻的⻚的物理位置也相邻 ，这样进行范围查询时，扫描叶子节点中大量记录时才可以使用顺序I/O。 所以才引入了区(extent)的概念，一个区就是在物理位置上连续的64个⻚。在表中数据量大的时候，为某个索引分配空间的时候就 不再按照⻚为单位分配了 ，而是 按照区为单位分配，甚至在表中的数据十分非常特别多的时候，可以 一次性分配多个连续的区。虽然可能造成一点点空间的浪费(数据不足填充满整个区)，但是从性能⻆度看，可以消除很多的随机I/O，功大于过嘛! 独立表空间的结构不论是系统表空间还是独立表空间，都可以看成是由若干个区组成的，每256个区被划分成一组 , 示意图如下： 每个组里的头几个⻚面(lant:自然也是位于该组的第一个区里)的类型都是类似的: 第一个组中的最开始的3个⻚面(也就是说extent 0这个区最开始的3个⻚面)的类型是固定的，分别是: FSP_HDR类型的页: 这个类型的⻚面是用来登记 整个表空间的一些整体属性 以及 本组256个区的属性，稍后详细唠叨。 需要注意的一点是，整个表空间只有一个FSP_HDR类型的⻚面。 IBUF_BITMAP类型的页: 这个类型的⻚面是存储本组所有区的所有⻚面关于 INSERT BUFFER 的信息。当然，你现在不用知道啥是个INSERT BUFFER。 INODE类型的页: 这个类型的⻚面存储了许多称为INODE的数据结构，还是那句话，现在你不需要知道啥是个INODE， 后边儿会说到你吐。 其余各组最开始的2个⻚面的类型是固定的，分别是: XDES类型:全称是extent descriptor，用来登记本组256个区的属性;上边介绍的FSP_HDR类型的⻚面其实和XDES类型的⻚面的作用类似，只不过FSP_HDR类型的⻚面还会额外存储一些表空间的属性。 ❓IBUF_BITMAP类型:上边介绍过了。 好了，宏观的结构介绍完了，里边儿的名词大家也不用记清楚，只要大致记得: 表空间被划分为许多连续的区，每个区默认由64个⻚组成 每256个区又被划分为一组，每个组的最开始的几个⻚面类型是固定的就好了。 段(segment) 的概念：还是为了顺序IO 😁然而事情到这里并没有结束，因为我们之前提到的范围查询是对B+树叶子节点中的记录进行顺序扫描 。而如果你在以页为单位存储记录时，如果不区分普通记录页和目录页(也就是不区分叶子节点和非叶子节点) ，无论什么类型的节点都统统放到申请到的区中的话，那范围扫描的效果就大打折扣了。 (lant: 提出区的概念本来就是为了让存放叶子节点的页在物理上尽量连续，减少随机IO，结果现在存放叶子节点的页和存放非叶子节点的页是混在一起在存到申请的区中的，这样存放叶子节点的页在物理上又不是顺序了)。 所以设计InnoDB的大叔们对B+树的叶子节点和非叶子节点进行了区别对待，也就是说 叶子节点有自己独有的区 ， 非叶子节点也有自己独有的区 。(lant: 这样，存放叶子节点的页在物理上就会尽量被连续存放起来，毕竟申请的区里的页都会用来存储叶子节点)。存放叶子节点的区的集合 和 存放非叶子节点的区的集合 都被称为 段。 也就是说一个索引会生成2个段，一个叶子节点段，一个非叶子节点段 。 碎片区 的概念默认情况下，InnoDB引擎的表只有一个聚簇索引，会生成2个段。而段是以区为单位申请存储空间的，一个区默认占用1M存储空间，所以默认情况下一个只存了几条记录的小表也需要2M的存储空间么? 以后每次添加一个索引都要申请2M的存储空间么? 这对于存储记录比较少的表简直是天大的浪费。 设计InnoDB 的大叔们都挺节俭的，当然也考虑到了这种情况。这个问题的症结在于 到现在为止我们都是认为 区是被整个分配给某一个段 的(即使段的数据填不满区中所有的⻚面)。 但是为了考虑 以完整的区为单位分配给某个段 对于数据量较小的表太浪费存储空间的这种情况，设计InnoDB的大叔们提出了一个碎片(fragment)区的概念。在一个碎片区中的⻚，不一定会全部分配给某个段；碎片区中的⻚可以用于不同的目的，比如有些⻚用于段A，有些⻚用于段B，有些⻚甚至哪个段都不属于 。 碎片区` 直属于 `表空间`，并不属于任何一个`段`。所以此后为某个`段`分配存储空间的策略是这样的: 在刚开始向表中插入数据的时候，`段`是从某个`碎片区`以`单个⻚面为单位`来分配存储空间的； 当某个段已经占用了32个碎片区⻚面之后，就会以完整的区为单位来分配存储空间； 所以现在 段 不能仅定义为是 某些区的集合，更精确的应该是 某些零散的⻚面以及 一些完整的区 的集合。 另外，除了索引的叶子节点段和非叶子节点段之外，InnoDB中还有为存储一些特殊的数据而定义的段，比如 回滚段，当然我们现在并不关心别的类型的段，现在只需要知道段是一些零散的⻚面以及一些完整的区的集合就好了。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"9.0 InnoDB的表空间 之 页相关知识回顾","date":"2021-10-23T13:16:21.000Z","path":"2021/10/23/MySQL-InnoDB-页结构/9.0 InnoDB的表空间 之 页相关知识回顾/","text":"表空间 回顾通过前边的学习，大家知道， 表空间是一个抽象的概念 ，对于 系统表空间 来说，对应着文件系统中一个或多个实际文件;对于 每个独立表空间 来说，对应着文件系统中一个名为 表名.ibd 的实际文件(InnoDB)。 (lant: 其实可以认为 表空间就是个抽象出来的概念，它代表的其实就是 数据目录(真实存在)下与数据库名同名的子目录(真实存在)下的 表名.ibd文件 / 表名.MYD+表名.MYI文件(真实存在)) 大家可以把表空间想象成被切分为许许多多个⻚的池子，当我们想为某个表插入一条记录的时候，就从池子中捞出一个对应的⻚来把数据写进去。 ⻚面类型 回顾可参考 5.5 通用页 结构 之 File Header(文件头)部分再一次强调，InnoDB 是以⻚为单位管理存储空间的，我们的聚簇索引(也就是完整的表数据)和其他的二级索引都是以B+树的形式保存到表空间的，而B+树的节点就是数据⻚。我们前边说过，这个数据⻚的类型名其实是:FIL_PAGE_INDEX，除了这种存放索引数据的⻚面类型之外，InnoDB 也为了不同的目的设计了若干种不同类型的⻚面，为了唤醒大家的记忆，我们再一次把各种常用的⻚面类型(FIL_PAGE_TYPE)提出来: 因为⻚面类型前边都有个FIL_PAGE或者FIL_PAGE_TYPE的前缀， 为简便起⻅我们后边唠叨⻚面类型的时候就把这些前缀省略掉了，比方说FIL_PAGE_TYPE_ALLOCATED类型称为ALLOCATED类型，FIL_PAGE_INDEX类型称为INDEX类型。 ⻚面通用部分 回顾我们前边说过数据⻚，也就是INDEX类型的⻚由7个部分组成，其中的两个部分是所有类型的⻚面都通用的。在这里重新强调一遍，任何类型的⻚面都有下边这种通用的结构:从上图中可以看出，任何类型的⻚都会包含这两个部分: File Header: 记录⻚面的一些通用信息 File Trailer: 校验⻚是否完整，保证从内存到磁盘刷新时内容的一致性。 对于File Trailer我们不再做过多强调，全部忘记了的话可以到数据⻚的那一章回顾一下。我们这里再强调一遍File Header的各个组成部分:现在除了名称里边儿带有LSN的两个字段大家可能看不懂以外，其他的字段肯定都是倍儿熟了，不过我们仍要强调这么几点: 表空间中的每一个⻚都对应着一个⻚号，也就是FIL_PAGE_OFFSET，这个⻚号由4个字节组成，也就是32个比特位，所以页号最大也就到 2^32，所以一个表空间最多可以拥有2^32个⻚。如果按照⻚的默认大小16KB来算，一个表空间最多支持64TB的数据。(表空间的第一个⻚的⻚号为0，之后的⻚号分别是1，2，3…依此类推) 某些类型的⻚可以组成链表，链表中的⻚可以不按照物理顺序存储，而是根据FIL_PAGE_PREV和FIL_PAGE_NEXT来存储上一个⻚和下一个⻚的⻚号。需要注意的是，这两个字段主要是为了INDEX类型的⻚，也就是我们之前一直说的数据⻚建立B+树后，为每层节点建立双向链表用的，一般类型的⻚是不使用这两个字段的。 每个⻚的类型由FIL_PAGE_TYPE表示，比如像数据⻚的该字段的值就是0x45BF，我们后边会介绍各种不同类型的⻚，不同类型的⻚在该字段上的值是不同的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"8.0 数据的家--MySQL的数据目录","date":"2021-10-22T11:11:32.000Z","path":"2021/10/22/MySQL-InnoDB-页结构/8.0 数据的家--MySQL的数据目录/","text":"数据库和文件系统的关系 我们知道像 InnoDB、MyISAM 这样的存储引擎都是把表数据存储在磁盘上的，而操作系统用来管理磁盘的那个东东又被称为文件系统，所以直接点来说就是: 像 InnoDB 、 MyISAM 这样的存储引擎都是把表存储在文件系统上的。当我们想读取数据时，这些存储引擎会从文件系统中把数据读出来返回给我们，当我们想写入数据时，这些存储引擎会把这些数据又写回文件系统。 所以，接下来就是要聊一下InnoDB和MyISAM这两个存储引擎的数据是如何在文件系统中存储的。 MySQL数据目录 MySQL服务器程序在启动时会到文件系统的某个目录下加载一些文件，之后在运行过程中产生的数据也都会存储到这个目录下的某些文件中，这个目录就称为数据目录，我们下边就要详细唠唠这个目录下具体都有哪些重要的东⻄。 数据目录和安装目录的区别 我们之前只接触过 MySQL的安装目录，而且重点强调过这个安装目录下非常重要的bin目录，它里边存储了许多关于控制客户端程序和服务器程序的命令(许多可执行文件，比如mysql，mysqld，mysqld_safe等等好几十个)。 而数据目录是用来存储MySQL在运行过程中产生的数据，一定要和安装目录区别开! MySQL中的数据目录在哪儿？ 那说了半天，MySQL中的数据目录到底在哪儿(数据到底被它存储到哪个目录了)？其实数据目录对应着一个系统变量 datadir，我们在使用客户端与服务器建立连接之后查看这个系统变量的值就可以了: 1234567mysql&gt; SHOW VARIABLES LIKE &#x27;datadir&#x27;; +---------------+-----------------------+ | Variable_name | Value | +---------------+-----------------------+ | datadir | /usr/local/mysql/var | +---------------+-----------------------+ 1 row in set (0.00 sec) 从结果中可以看出，在我的计算机上MySQL的数据目录就是 /usr/local/mysql/var，你用你的计算机试试呗~ MySQL运行过程中会产生哪些数据? 首先，它当然会包含我们创建的 数据库、表、视图、 触发器、用户数据 … 除了这些用户数据， 为了程序更好的运行，MySQL也会创建一些其他的额外数据，我们接下来细细的品味一下这个数据目录下的内容。 数据库在文件系统中的表示每当我们使用 CREATE DATABASE 数据库名 创建一个数据库时，在文件系统上实际发生了什么呢?其实很简单， 每个数据库都对应数据目录下的一个子目录 。 每当我们新建一个数据库时，MySQL会帮我们做这两件事儿: 在数据目录下创建一个和数据库名同名的子目录(或者说是文件夹); 在与该数据库名同名的子目录下创建一个名为 db.opt的文件，这个文件中包含了该数据库的各种属性，比方说该数据库的字符集和比较规则是个啥。 比方说我们查看一下在我的计算机上当前有哪些数据库: 123456789101112mysql&gt; SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || jm_taxi || mysql || performance_schema || sys |+--------------------+5 rows in set (0.00 sec)mysql&gt; 可以看到在我的计算机上当前有5个数据库，其中 jm_taxi 数据库是我们自定义的，其余4个数据库是属于MySQL自带的系统数据库。我们再看一下我的计算机上的数据目录下的内容:当前MySQL服务器上的数据目录下的文件和子目录比较多哈，不过仍然能看到我们创建的数据库 jm_taxi 在数据目录下是有对应的子目录的。数据目录下的其他的文件和子目录，我们暂时先忽略它们的存在就好了。 表在文件系统中的表示每个表的信息其实可以分为两种: 表结构信息 表结构 就是该表的名称是啥，表里边有多少列，每个列的数据类型是啥，有啥约束条件和索引，用的是啥字符集和比较规则吧啦吧啦的各种信息，这些信息都体现在了我们的建表语句中了。为了保存这些信息，InnoDB和MyISAM这两种存储引擎都在数据目录下对应的数据库子目录下创建了一个专⻔用于描述表结构的文件，文件名是 表名.frm (这个后缀名为.frm是以二进制格式存储的，直接打开会是乱码的~);(值得注意的是：MySQL8版本中的innodb存储引擎的表没有.frm文件。MySQL8开始删除了原来的frm文件，并采用 Serialized Dictionary Information (SDI),SDI信息源记录保存在ibd文件中。) 表中的数据 描述表结构的文件我们知道了，那表中的数据被存到什么文件中了呢?在这个问题上，不同的存储引擎就产生了分歧了，下边我们分别看一下InnoDB和MyISAM是用什么文件来保存表中数据的。 InnoDB是如何存储表数据的 我们前边重点唠叨过InnoDB的一些实现原理，到现在为止我们应该熟悉下边这些东东: InnoDB 是使用⻚为基本单位来管理存储空间的，默认的⻚大小为16KB。 对于InnoDB存储引擎来说，每个索引都对应着一棵B+树，该B+树的每个节点都是一个数据⻚，数据⻚之间不必要是物理连续的 ，因为数据⻚之间有双向链表来维护着这些⻚的顺序。 InnoDB的聚簇索引的叶子节点存储了完整的用户记录，也就是所谓的 索引即数据，数据即索引 。 表空间 的概念 不过，为了更好的管理这些⻚，设计InnoDB的大叔们又提出了一个表空间或者文件空间(英文名:table space或者file space)的概念。其实 表空间 是一个抽象的概念，它可以对应文件系统上一个或多个真实文件(不同表空间对应的文件数量可能不同);每一个表空间可以被划分为很多很多很多个⻚，我们的表数据就存放在某个表空间下的某些⻚里 ; 设计InnoDB的大叔还将表空间划分为几种不同的类型，我们一个一个看一下。 系统表空间(system tablespace)这个所谓的系统表空间可以对应文件系统上一个或多个实际的文件。默认情况下，InnoDB会在 数据目录 下创建一个名为 ibdata1、大小为12M的文件，这个文件就是对应的系统表空间在文件系统上的表示。之所以只有12M，那是因为这个文件是所谓的自扩展文件，也就是当不够用的时候它会自己增加文件大小~ 当然，如果你想让系统表空间对应文件系统上多个实际文件，或者仅仅觉得原来的ibdata1这个文件名难听，那可以在MySQL启动时配置对应的文件路径以及它们的大小，比如我们这样修改一下配置文件: 12[server] innodb_data_file_path=data1:512M;data2:512M:autoextend 这样在MySQL启动之后就会创建这两个512M大小的文件作为系统表空间，其中的autoextend表明这两个文件如果不够用会自动扩展data2文件的大小。 我们也可以把系统表空间对应的文件路径不配置到数据目录下，甚至可以配置到单独的磁盘分区上，涉及到的启动参数就是innodb_data_file_path和innodb_data_home_dir，具体的配置逻辑挺绕的，就不多唠叨了，知道改哪个参数可以修改系统表空间对应的文件，有需要的时候到官方文档里一查就好了。 需要注意的一点是，在一个MySQL服务器中，系统表空间只有一份 (可以配置 系统表空间 对应多个实际文件) 。从MySQL5.5.7到MySQL5.6.6之间的各个版本中，我们表中的数据都会被默认存储到这个系统表空间。 独立表空间(file-per-table tablespace)在MySQL5.6.6以及之后的版本中，InnoDB并不会默认的把各个表的数据存储到系统表空间中，而是为每一个表建立一个独立表空间，也就是说我们 创建了多少个表，就有多少个独立表空间 。 使用独立表空间 来存储表数据的话，会在该表所属数据库对应的子目录下创建一个表示该独立表空间的文件，文件名和表名相同，只不过添加了一个.ibd的扩展名而已，所以完整的文件名称就是: 表名.ibd 比方说假如我们使用了独立表空间去存储 jm_taxi数据库下的 jm_member 表的话，那么在该表所在数据库对应的jm_taxi目录下会为jm_member表创建这两个文件: jm_member.frm、 jm_member.ibd其中 jm_member.ibd文件 就用来存储jm_member表中的数据和索引 (索引和数据在一起的哦，正所谓 索引即数据，数据即索引)。 当然我们也可以自己指定使用系统表空间还是独立表空间来存储数据，这个功能由启动参数innodb_file_per_table控制。 比如说我们想刻意将表数据都存储到系统表空间时，可以在启动MySQL服务器的时候这样配置: 12[server] innodb_file_per_table=0 // 0:代表使用系统表空间;1:代表使用独立表空间。 不过innodb_file_per_table参数只对新建的表起作用，对于已经分配了表空间的表并不起作用。 如果我们想把已经存在系统表空间中的表转移到独立表空间，可以使用下边的语法: 1ALTER TABLE 表名 TABLESPACE [=] innodb_file_per_table; //其中中括号扩起来的=可有可无 或者把已经存在独立表空间的表转移到系统表空间，可以使用下边的语法: 1ALTER TABLE 表名 TABLESPACE [=] innodb_system; // 其中中括号扩起来的=可有可无 其他类型的表空间 随着MySQL的发展，除了上述两种老牌表空间之外，现在还新提出了一些不同类型的表空间比如 通用表空间(general tablespace)、undo表空间(undo tablespace)、临时表空间 (temporary tablespace) …… 等等具体情况我们等用到的时候再提 MyISAM是如何存储表数据的好了，唠叨完了InnoDB的系统表空间和独立表空间，现在轮到MyISAM了。 我们知道，和InnoDB的索引和数据是一个东东不同。MyISAM中的索引全部都是二级索引，该存储引擎的数据和索引是分开存放的。所以MyISAM在文件系统中也是使用不同的文件来存储数据和索引的。而且和InnoDB不同的是，MyISAM并没有什么所谓的表空间一说，表数据都存放到对应的数据库子目录下。 假如 jm_member表 使用MyISAM存储引擎的话，那么在它所在数据库对应的 jm_taxi目录下会为 jm_member表 创建这三个文件: jm_member.frm、jm_member.MYD、jm_member.MYI 其中 jm_member.MYD 代表表的数据文件，也就是我们插入的用户记录; jm_member.MYI 代表表的索引文件，我们为该表创建的索引都会放到这个文件中。 视图在文件系统中的表示 我们知道MySQL中的视图其实是虚拟的表，也就是某个查询语句的一个别名而已，所以在存储视图的时候是不需要存储真实的数据的，只需要把它的结构存储起来就行了。和表一样，描述视图结构的文件也会被存储到所属数据库对应的子目录下边，只会存储一个 视图名.frm 的文件。 其他的文件除了我们上边说的这些用户自己存储的数据以外，数据目录 下还包括为了更好运行程序的一些额外文件，主要包括这几种类型的文件: 服务器进程文件 我们知道每运行一个MySQL服务器程序，都意味着启动一个进程。MySQL服务器会把自己的进程ID写入到一个文件中。 服务器日志文件 在服务器运行过程中，会产生各种各样的日志, 比如常规的 查询日志、错误日志、二进制日志、redo日志… 等 各种日志，这些日志各有各的用途，现在暂时先了解一下就可以了。 默认&#x2F;自动生成的SSL和RSA证书和密钥文件 主要是为了客户端和服务器安全通信而创建的一些文件， 大家看不懂可以忽略~ 文件系统对数据库的影响因为MySQL的数据都是存在文件系统中的，就不得不受到文件系统的一些制约，这在数据库和表的命名、表的大小和性能方面体现的比较明显，比如下边这些方面: 数据库名称和表名称不得超过文件系统所允许的最大⻓度。 每个数据库都对应数据目录的一个子目录;每个表都会在数据库子目录下产生一个和表名同名的.frm文件(如果是InnoDB的独立表空间或者使用MyISAM引擎还会有别的文件名称与表名一致)。 特殊字符的问题 为了避免因为数据库名和表名出现某些特殊字符而造成文件系统不支持的情况，MySQL会把数据库名和表名中所有除数字和拉丁字母以外的所有字符在文件名里都映射成 @+编码值的形式 作为文件名。 文件⻓度受文件系统最大⻓度限制 对于InnoDB的独立表空间来说，每个表的数据都会被存储到一个与表名同名的.ibd文件中;对于MyISAM存储引擎来说，数据和索引会分别存放到与表同名的.MYD和.MYI文件中。这些文件会随着表中记录的增加而增大，它们的大小受限于文件系统支持的最大文件大小。 MySQL系统数据库简介我们前边提到了MySQL的几个系统数据库，这几个数据库包含了 MySQL服务器运行过程中所需的一些信息以及一些运行状态信息， 我们现在稍微了解一下。 mysql 这个数据库贼核心，它存储了MySQL的用户账户和权限信息， 一些存储过程、事件的定义信息，一些运行过程中产生的日志信息，一些帮助信息以及时区信息等。 information_schema 这个数据库保存着MySQL服务器维护的所有其他数据库的信息，比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦。这些信息并不是真实的用户数据，而是一些描述性信息，有时候也称之为元数据。 performance_schema 这个数据库里主要保存MySQL服务器运行过程中的一些状态信息，算是对MySQL服务器的一个性能监控。包括统计最近执行了哪些语句，在执行过程的每个阶段都花费了多⻓时间，内存的使用情况等等信息。 sys 这个数据库主要是通过视图的形式把information_schema 和performance_schema结合起来，让程序员可以更方便的了解MySQL服务器的一些性能信息。啥?这四个系统数据库这就介绍完了? 是的，这里只是因为介绍数据目录里遇到了，为了内容的完整性跟大家提一下，具体如何使用还是要参照文档~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.4 主键自增","date":"2021-10-20T09:03:19.000Z","path":"2021/10/20/MySQL-InnoDB-页结构/7.4 主键自增/","text":"我们知道，对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据⻚中的，数据⻚和记录又是按照记录主键值从小到大的顺序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满一个数据⻚就换到下一个数据⻚继续插。 而如果我们插入的主键值忽大忽小的话，这就比较麻烦了，假设某个数据⻚存储的记录已经满了，它存储的主键值在1~100之间, 如果此时再插入一条主键值为9的记录，那它插入的位置就如下图::可这个数据⻚已经满了啊，再插进来咋办呢?我们需要把当前⻚面分裂成两个⻚面，把本⻚中的一些记录移动到新创建的这个⻚中。⻚面分裂和记录移位意味着什么?意味着: 性能损耗! 所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会发生这样的性能损耗了。所以我们建议:让主键具有AUTO_INCREMENT，让存储引擎自己为表生成主键，而不是我们手动插入。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.3 如何选择索引","date":"2021-10-20T07:21:31.000Z","path":"2021/10/20/MySQL知识点整理/7.3 如何选择索引/","text":"上边我们以 idx_name_birthday_phone_number索引 为例对索引的适用条件进行了详细的唠叨，下边看一下我们在建立索引时或者编写查询语句时就应该注意的一些事项。 考虑列的基数 列的基数指的是某一列中不重复数据的个数，比方说某个列包含值2, 5, 8, 2, 5, 8, 2, 5, 8，虽然有9条记录，但该列的基数却是3。也就是说，在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。这个列的基数指标非常重要，直接影响我们是否能有效的利用索引。 假设某个列的基数为1，也就是所有记录在该列中的值都一样，那为该列建立索引是没有用的，因为所有值都一样就无法排序，无法进行快速查找了~而且如果某个建立了二级索引的列的重复值特别多，那么使用这个二级索引查出的记录还可能要做回表操作，这样性能损耗就更大了。所以结论就是:最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好。 索引列的类型尽量小 我们在定义表结构的时候要显式的指定列的类型，以整数类型为例，有TINYINT、MEDIUMINT、INT、BIGINT这么几种，它们占用的存储空间依次递增，我们这里所说的类型大小指的就是该类型表示的数据范围的大小。如果我们想要对某个整数列建立索引的话，在表示的整数范围允许的情况下，尽量让索引列使用较小的类型，比如我们能使用INT就不要使用BIGINT，能使用MEDIUMINT就不要使用INT~这是因为: 数据类型越小，在查询时进行的比较操作越快(这是CPU层次 的东东) 数据类型越小，索引占用的存储空间就越少，在一个数据⻚内就可以放下更多的记录，从而减少磁盘I&#x2F;O带来的性能损耗， 也就意味着可以把更多的数据⻚缓存在内存中，从而加快读写效率。 这个建议对于表的主键来说更加适用，因为不仅是聚簇索引中会存储主键值，其他所有的二级索引的节点处都会存储一份记录的主键值， 如果主键适用更小的数据类型，也就意味着节省更多的存储空间和更高效的I&#x2F;O。 索引字符串值的前缀 当我们的字符串很⻓时，存储一个字符串就需要占用很大的存储空间。在我们需要为这个字符串列建立索引时，那就意味着在对应的B+树中有这么两个问题: B+树索引中的记录需要把该列的完整字符串存储起来，而且字符串越⻓，在索引中占用的存储空间越大。 如果B+树索引中索引列存储的字符串很⻓，那在做字符串比较时会占用更多的时间。 我们前边儿说过索引列的字符串前缀其实也是排好序的，所以索引的设计者提出了个方案 – 只对字符串的前几个字符进行索引，也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时, 虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。这样只在B+树中存储字符串的前几个字符的编码，既节约空间，又减少了字符串的比较时间，还大概能解决排序的问题，何乐而不为，比方说我们在建表语句中只对name列的前10个字符进行索引可以这么写: 1234567CREATE TABLE person_info(name VARCHAR(100) NOT NULL,birthday DATE NOT NULL,phone_number CHAR(11) NOT NULL,country varchar(100) NOT NULL,KEY idx_name_birthday_phone_number (name(10),birthday, phone_number) ); name(10)就表示在建立的B+树索引中只保留记录的前10个字符的编码，这种只索引字符串值的前缀的策略是我们非常鼓励的，尤其是在字符串类型能存储的字符比较多的时候。 索引列前缀对排序的影响 如果使用了 索引列前缀，比方说前边只把name列的前10个字符放到了二级索引中, 下边这个查询可能就有点儿尴尬了:SELECT * FROM person_info ORDER BY name LIMIT 10;因为二级索引中不包含完整的name列信息，所以无法对前十个字符相同，后边的字符不同的记录进行排序，也就是使用索引列前缀的方式无法支持使用索引排序，只好乖乖的用文件排序喽 。 让索引列在比较表达式中单独出现 假设表中有一个整数列my_col，我们为这个列建立了索引。下边的两个WHERE子句虽然语义是一致的，但是在效率上却有差别:WHERE my_col * 2 &lt; 4WHERE my_col &lt; 4/2第1个WHERE子句中my_col列并不是以单独列的形式出现的，而是以my_col * 2这样的表达式的形式出现的，存储引擎会依次遍历所有的记录，计算这个表达式的值是不是小于4，所以这种情况下是使用不到为my_col列建立的B+树索引的。而第2个WHERE子句中my_col列是以单独列的形式出现的，这样的情况可以直接使用B+树索引。 所以结论就是:如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.2 回表的代价与覆盖索引","date":"2021-10-16T15:01:19.000Z","path":"2021/10/16/MySQL-InnoDB-页结构/7.2 回表的代价与覆盖索引/","text":"之前我们在谈到回表这个词时，多是一带而过，可能大家没啥深刻的体会，下边我们详细唠叨下。还是用idx_name_birthday_phone_number索引为例，看下边这个查询: 1SELECT * FROM person_info WHERE name &gt; &#x27;Asa&#x27; AND name &lt; &#x27;Barlow&#x27;; 在使用idx_name_birthday_phone_number索引进行查询时大致可以分为这两个步骤: 从索引idx_name_birthday_phone_number对应的B+树中取出name值在Asa~Barlow之间的用户记录。 由于索引idx_name_birthday_phone_number对应的B+树用户记录中只包含name、age、birthday、id这4个字段， 而查询列表是*，意味着要查询表中所有字段，也就是还要包括country字段。这时需要把从上一步中获取到的每一条记录的id字段都到聚簇索引对应的B+树中找到完整的用户记录，也就是我们通常所说的回表，然后把完整的用户记录返回给查询用户。 由于索引idx_name_birthday_phone_number对应的B+树中的记录首先会按照name列的值进行排序，所以值在Asa~Barlow之间的记录在磁盘中的存储是相连的，集中分布在一个或几个数据⻚中， 我们可以很快的把这些连着的记录从磁盘中读出来，这种读取方式我们也可以称为顺序I&#x2F;O。根据第1步中获取到的记录的id字段的值可能并不相连，而在聚簇索引中记录是根据id(也就是主键)的顺序排列的，所以根据这些并不连续的id值到聚簇索引中访问完整的用户记录可能分布在不同的数据⻚中，这样读取完整的用户记录可能要访问更多的数据⻚，这种读取方式我们也可以称为随机I&#x2F;O。一般情 况下，顺序I&#x2F;O比随机I&#x2F;O的性能高很多，所以步骤1的执行可能很快，而步骤2就慢一些。所以这个使用索 引idx_name_birthday_phone_number的查询有这么两个特点: 会使用到两个B+树索引，一个二级索引，一个聚簇索引。 访问二级索引使用顺序I&#x2F;O，访问聚簇索引使用随机I&#x2F;O。 需要回表的记录越多，使用二级索引的性能就越低，甚至让某些查询宁愿使用全表扫描也不使用二级索引。比方说name值在Asa ~Barlow之间的用户记录数量占全部记录数量90%以上，那么如果使用idx_name_birthday_phone_number索引的话，有90%多的id值需要回表，这不是吃力不讨好么，还不如直接去扫描聚簇索引 (也就是全表扫描)。 那什么时候采用全表扫描的方式，什么使用采用 二级索引 + 回表 的方式去执行查询呢?这个就是传说中的查询优化器做的工作，查询优化器会事先对表中的记录计算一些统计数据，然后再利用这些统计数据根据查询的条件来计算一下需要回表的记录数，需要回表的记录数越多，就越倾向于使用全表扫描，反之倾向于使用二级索引 + 回表 的方式。当然优化器做的分析工作不仅仅是这么简单，但是大致上是个这个过程。一般情况下，限制查询获取较少的记录数会让优化器更倾向于选择使用 二级索引 + 回表 的方式进行查询，因为回表的记录越少，性能提升就越高，比方说上边的查询可以改写成这样:SELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39; LIMIT 10;添加了LIMIT 10的查询更容易让优化器采用二级索引 + 回表的方 式进行查询。 对于有排序需求的查询，上边讨论的采用 全表扫描 还是 二级索引 + 回表 的方式进行查询的条件也是成立的，比方说下边这个查询:SELECT * FROM person_info ORDER BY name, birthday, phone_number;由于查询列表是*，所以如果使用二级索引进行排序的话，需要把排序完的二级索引记录全部进行回表操作，这样操作的成本还不如直接遍历聚簇索引然后再进行文件排序(filesort)低，所以优化器会倾向于使用全表扫描的方式执行查询。如果我们加了LIMIT子句，比如这样:SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;这样需要回表的记录特别少，优化器就会倾向于使用 二级索引 + 回表 的方式执行查询。 覆盖索引 为了彻底告别回表操作带来的性能损耗，我们建议: 最好在查询列表里只包含索引列，比如这样:SELECT name, birthday, phone_number FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;因为我们只查询name, birthday, phone_number这三个索引列的值，所以在通过idx_name_birthday_phone_number索引得到结果后就不必到聚簇索引中再查找记录的剩余列，也就是country列的值了，这样就省去了回表操作带来的性能损耗。我们把这种只需要用到索引的查询方式称为索引覆盖。 排序操作也优先使用覆盖索引的 方式进行查询，比方说这个查询:SELECT name, birthday, phone_number FROM person_info ORDER BY name, birthday, phone_number;虽然这个查询中没有LIMIT子句，但是采用了覆盖索引，所以查询优化器就会直接使用idx_name_birthday_phone_number索引进行排序而不需要回表操作了。 当然，如果业务需要查询出索引以外的列，那还是以保证业务需求为重。但是我们很不鼓励用*号作为查询列表，最好把我们需要查询的列依次标明。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.1 索引的使用及注意事项","date":"2021-10-16T13:05:37.000Z","path":"2021/10/16/MySQL知识点整理/7.1 索引的使用及注意事项/","text":"测试数据表准备B+树索引并不是万能的，并不是所有的查询语句都能用到我们建立的索引。 为了故事的顺利发展，我们需要先创建一个 用户基本信息 表: 123456789CREATE TABLE person_info(id INT NOT NULL auto_increment,name VARCHAR(100) NOT NULL,birthday DATE NOT NULL,phone_number CHAR(11) NOT NULL,country varchar(100) NOT NULL,PRIMARY KEY (id),KEY idx_name_birthday_phone_number (name,birthday, phone_number) ); 对于这个person_info表我们需要注意两点: 表中的主键是id列，它存储一个自动递增的整数。所以InnoDB存储引擎会自动为id列建立聚簇索引。 我们额外定义了一个二级索引 idx_name_birthday_phone_number，它是由3个列组成的联合索引。 所以在这个索引对应的B+树的叶子节点处存储的用户记录只保留name、birthday、phone_number这三个列的值以及主键id的值，并不会保存country列的值。 person_info表会为 聚簇索引 和 idx_name_birthday_phone_number索引 建立2棵B+树下边我们画一下索引idx_name_birthday_phone_number的示意图，不过既然我们已经掌握了InnoDB的B+树索引原理，那我们在画图的时候为了让图更加清晰，所以在省略一些不必要的部分，比如记录的额外信息，各⻚面的⻚号等等，其中内节点中目录项记录的⻚号信息我们用箭头来代替，在记录结构中只保 留name、birthday、phone_number、id这四个列的真实数据值，所以示意图就⻓这样:为了方便大家理解，我们特意标明了哪些是内节点，哪些是叶子节点。再次强调一下，内节点中存储的是目录项记录，叶子节点中存储的是用户记录(由于不是聚簇索引，所以用户记录是不完整的，缺少country列的值)。 从图中可以看出，这个 idx_name_birthday_phone_number 索引对应的B+树中⻚面和记录的排序方式就是这样的: 先按照name列的值进行排序。 如果name列的值相同，则按照birthday列的值进行排序。 如果birthday列的值也相同，则按照phone_number的值进行排序。这个排序方式十分、特别、非常、巨、very very very重要，因为只要⻚面和记录是排好序的，我们就可以通过二分法来快速定位查找。 下边的内容都仰仗这个图了，大家对照着图理解。 全值匹配当我们的 where搜索条件 中的列和 索引列 一致的话，这种情况就称为全值匹配，比方说下边这个查找语句: 1SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27; AND birthday = &#x27;1990-09-27&#x27; AND phone_number = &#x27;15123983239&#x27;; 我们建立的 idx_name_birthday_phone_number索引 包含的3个列在这个查询语句中都展现出来了。 大家可以想象一下这个查询过程: 因为B+树的数据⻚和记录先是按照name列的值进行排序的， 所以先可以很快定位name列的值是Ashburn的记录位置。 在name列相同的记录里又是按照birthday列的值进行排序的，所以在name列的值是Ashburn的记录里又可以快速定位birthday列的值是’1990-09-27’的记录。 如果很不幸，name和birthday列的值都是相同的，那记录是按照phone_number列的值排序的，所以联合索引中的三个列都可能被用到。 有的同学也许有个疑问，如果调换WHERE子句中的几个搜索条件的顺序对查询结果有啥影响么? 比方说写成下边这样: 1SELECT * FROM person_info WHERE birthday = &#x27;1990- 09-27&#x27; AND phone_number = &#x27;15123983239&#x27; AND name = &#x27;Ashburn&#x27;; 答案是: 没影响哈。MySQL有一个叫查询优化器的东东，会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件。我们后边儿会有专⻔的章节来介绍查询 优化器，敬请期待。 匹配左边的列 其实在我们的搜索语句中也可以不用包含全部联合索引中的列，只包含左边 的就行，比方说下边的查询语句: 1234SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27;;或者SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27; AND birthday = &#x27;1990-09-27&#x27;; 那为什么搜索条件中必须出现左边的列才可以使用到这个B+树索引呢? 比如下边的语句就用不到这个B+树索引么? 1SELECT * FROM person_info WHERE birthday = &#x27;1990-09-27&#x27;; 是的，的确用不到，因为B+树的数据⻚和记录先是按照name列的值排序的，在name列的值相同的情况下才使用birthday列进行排序，也就是说name列的值不同的记录中birthday的值可能是无序的。而现在你跳过name列直接根据birthday的值去查找，臣妾做 不到呀~ 那如果我就想在只使用birthday的值去通过B+树索引进行查找咋办呢?这好办，你再对birthday列建一个B+树索引就行了。 但是需要特别注意的一点是，如果我们想使用联合索引中尽可能多的列，搜索条件中的各个列必须是联合索引中从最左边连续的列。比方说联合索引idx_name_birthday_phone_number中列的定义顺序是name、birthday、phone_number，如果我们的搜索条件中只有name和phone_number，而没有中间的birthday，比方说这样: 1SELECT * FROM person_info WHERE name = &#x27;Ashburn&#x27; AND phone_number = &#x27;15123983239&#x27;; 这样只能用到name列的索引，birthday和phone_number的索引就用不上了，因为name值相同的记录先按照birthday的值进行排序，birthday值相同的记录才按照phone_number值进行排序。 匹配列前缀 我们前边说过为某个列建立索引的意思其实就是 在对应的B+树的记录中使用该列的值进行排序比方说person_info表上建立的联合索引idx_name_birthday_phone_number会先用name列的值进行排序，所以这个联合索引对应的B+树中的记录的name列的排列就是这样的: 123456789101112AaronAaron...AaronAsaAshburn...AshburnBairdBarlow...Barlow 字符串排序的本质就是比较哪个字符串大一点儿，一般的比较规则都是逐个比较字符的大小，也就是说我们比较两个字符串的大小的过程其实是这样的: 先比较字符串的第一个字符，第一个字符小的那个字符串就比较小。 如果两个字符串的第一个字符相同，那就再比较第二个字符， 第二个字符比较小的那个字符串就比较小。 如果两个字符串的第二个字符也相同，那就接着比较第三个字符，依此类推。 也就是说这些字符串的前n个字符，也就是前缀都是排好序的， 所以对于字符串类型的索引列来说，我们只匹配它的前缀也是可以快速定位记录的 。 比方说我们想查询名字以’As’开头的记录，那就可以这么写查询语句:SELECT * FROM person_info WHERE name LIKE ‘As%’;但是需要注意的是，如果只给出后缀或者中间的某个字符串，比如这样:SELECT * FROM person_info WHERE name LIKE ‘%As%’;MySQL就无法快速定位记录位置了，因为字符串中间有’As’的字符串并没有排好序， 所以只能全表扫描了 。 匹配范围值 回头看我们idx_name_birthday_phone_number索引的B+树示意图，所有记录都是按照索引列的值从小到大的顺序排好序的，所以这极大的方便我们查找索引列的值在某个范围内的记录。 比方说查询语句: SELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39;;由于B+树中的数据⻚和记录是先按name列排序的，所以我们上边的查询过程其实是这样的:找到name值为Asa的记录。找到name值为Barlow的记录。哦啦，由于所有记录都是由链表连起来的(记录之间用单链表，数据⻚之间用双链表)，所以他们之间的记录都可以很容易的取出来喽~找到这些记录的主键值，再到聚簇索引中回表查找完整的记录。 不过在使用联合索引进行范围查找的时候需要注意，如果对多个列同时进行范围查找的话，只有对索引最左边的那个列进行范围查找的时候才能用到B+树索引，比方说这样:SELECT * FROM person_info WHERE name &gt; &#39;Asa&#39; AND name &lt; &#39;Barlow&#39; AND birthday &gt; &#39;1980-01-01&#39;;上边这个查询可以分成两个部分: 通过条件name &gt; ‘Asa’ AND name &lt; ‘Barlow’来对name进行范围，查找的结果可能有多条name值不同的记录 对这些name值不同的记录继续通过 birthday &gt; ‘1980-01-01’条件继续过滤 这样子对于联合索引idx_name_birthday_phone_number来说，只能用到name列的部分，而用不到birthday列的部分，因为只有name值相同的情况下才能用birthday列的值进行排序，而这个查询中通过name进行范围查找的记录中可能并不是按照birthday列进行排序的，所以在搜索条件中继续以birthday列进行查找时是用不到这个B+树索引的。 精确匹配某一列并范围匹配另外一列 对于同一个联合索引来说，虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找，比方说这样:SELECT * FROM person_info WHERE name = &#39;Ashburn&#39; AND birthday &gt; &#39;1980-01-01&#39; AND birthday &lt; &#39;2000- 12-31&#39; AND phone_number &gt; &#39;15100000000&#39;;name &#x3D; ‘Ashburn’，对name列进行精确查找，当然可以使用B+树索引了。birthday &gt; ‘1980-01-01’ AND birthday &lt; ‘2000- 12-31’，由于name列是精确查找，所以通过name &#x3D; ‘Ashburn’条件查找后得到的结果的name值都是相同的，它们会再按照birthday的值进行排序。所以此时对birthday 列进行范围查找是可以用到B+树索引的。phone_number &gt; ‘15100000000’，通过birthday的范围查找的记录的birthday的值可能不同，所以这个条件无法再利用B+树索引了，只能遍历上一步查询得到的记录。 用于排序 （注意 文件排序(英文名:filesort)） 我们在写查询语句的时候经常需要对查询出来的记录通过 ORDER BY 子句按照某种规则进行排序。 一般情况下，我们只能把记录都加载到内存中，再用一些排序算法，比如快速排序、归并排序、吧啦吧啦排序…… 在内存中对这些记录进行排序，有的时候可能查询的结果集太大以至于不能在内存中进行排序的话，还可能暂时借助磁盘的空间来存放中间结果，排序操作完成后再把排好序的结果集返回到客户端。 在MySQL中，把这种在内存中或者磁盘上进行排序的方式统称为 文件排序(英文名:filesort)，跟文件这个词儿一沾边儿，就显得这些排序操作非常慢了。但是如果ORDER BY子句里使用到了我们的索引列，就有可能省去在内存或文件中排序的步骤，比如下边这个简单的查询语句:SELECT * FROM person_info ORDER BY name, birthday, phone_number LIMIT 10;这个查询的结果集需要先按照name值排序，如果记录的name值相同，则需要按照birthday来排序，如果birthday的值相同，则需要按照phone_number排序。大家可以回过头去看我们建立的 idx_name_birthday_phone_number 索引的示意图，因为这个B+树索引本身就是按照上述规则排好序的，所以直接从索引中提取数据，然后进行回表操作取出该索引中不包含的列就好了。简单吧? 是的，索引就是这么牛逼。 （lant:如果用到索引，你就不用再次排序了。） Tips:请注意，本例的查询语句中加了limit子句，这是因为如果不限制需要获取的记录数量，会导致为大量二级索引记录执行回表操作，这样会影响整体的查询性能。关于回表操作造成的影响，我们后续再聊。 使用联合索引进行排序注意事项 对于联合索引有个问题需要注意，ORDER BY的子句后边的列的顺序也必须按照索引列的顺序给出，如果给出ORDER BY phone_number, birthday, name的顺序，那也是用不了B+树索引，这种颠倒顺序就不能使用索引的原因我们上边详细说过了，这就不赘述了。 当联合索引左边列的值为常量，也可以使用后边的列进行排序，比如这样:SELECT * FROM person_info WHERE name = &#39;A&#39; ORDER BY birthday, phone_number LIMIT 10;这个查询能使用联合索引进行排序是因为name列的值相同的记录是按照birthday, phone_number排序的，说了好多遍了都。 不可以使用索引进行排序的几种情况ASC、DESC混用 对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC规则排序，要么都是DESC规则排序。为啥会有这种奇葩规定呢? 这个还得回头想想这个idx_name_birthday_phone_number联合索引中记录的结构: 先按照记录的name列的值进行升序排列。 如果记录的name列的值相同，再按照birthday列的值进行升序排列。 如果记录的birthday列的值相同，再按照phone_number列的值进行升序排列。 如果查询中的各个排序列的排序顺序是一致的，比方说下边这两种情况:ORDER BY name, birthday LIMIT 10 : 这种情况直接从索引的最左边开始往右读10行记录就可以了。ORDER BY name DESC, birthday DESC LIMIT 10: 这种情况直接从索引的最右边开始往左读10行记录就可以了。 但是如果我们查询的需求是先按照name列进行升序排列，再按照birthday列进行降序排列的话，比如说这样的查询语句:SELECT * FROM person_info ORDER BY name ASC, birthday DESC LIMIT 10;这样就不能高效使用索引，而要采取更复杂的算法去从索引中取数据，设计MySQL的大叔觉得这样还不如直接文件排序来的快，所以就规定使用联合索引的各个排序列的排序顺序必须是一致的。 WHERE子句中出现非排序使用到的索引列 如果WHERE子句中出现了非排序使用到的索引列，那么排序依然是使用不到索引的，比方说这样:SELECT * FROM person_info WHERE country = &#39;China&#39; ORDER BY name LIMIT 10;这个查询只能先把符合搜索条件country &#x3D; ‘China’的记录提取出来(这个筛选本身就用不到索引)后再进行排序。注意和下边这个查询作区别:SELECT * FROM person_info WHERE name = &#39;A&#39; ORDER BY birthday, phone_number LIMIT 10;虽然这个查询也有搜索条件，但是name &#x3D; ‘A’可以使用到索引 idx_name_birthday_phone_number，而且过滤剩下的记录还是按照birthday、phone_number列排序的，所以还是可以使用索引进行排序的。 排序列包含非同一个索引的列 有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序，比方说:SELECT * FROM person_info ORDER BY name, country LIMIT 10;name和country并不属于一个联合索引中的列，所以无法使用索引进行排序，至于为啥我就不想再唠叨了，自己用前边的理论自己捋一捋把~ &#x2F;&#x2F; TODO: 为什么不能先用 order by name 索引先拿出10条记录，然后用这10条记录的主键id再去回表取到country列，然后再在内存中做 order by country 呢？&#x2F;&#x2F; 哦： 这样在内存中进行排序，其实就是 文件排序了，也就是说还要你重新再排序，并没有使用到现成排好序的索引。 排序列使用了复杂的表达式 要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式，比方说这样:SELECT * FROM person_info ORDER BY UPPER(name) LIMIT 10;使用了UPPER函数修饰过的列就不是单独的列啦，这样就无法使用索引进行排序啦。 用于分组 有时候我们为了方便统计表中的一些信息，会把表中的记录按照某些列进行分组。比如下边这个分组查询:SELECT name, birthday, phone_number, COUNT(*) FROM person_info GROUP BY name, birthday, phone_number 这个查询语句相当于做了3次分组操作: 先把记录按照name值进行分组，所有name值相同的记录划分为一组。 将每个name值相同的分组里的记录再按照birthday的值进行分组，将birthday值相同的记录放到一个小分组里，所以看起来就像在一个大分组里又化分了好多小分组。 再将上一步中产生的小分组按照phone_number的值分成更小的分组，所以整体上看起来就像是先把记录分成一个大分组，然后把大分组分成若干个小分组，然后把若干个小分组再细分成更多的小小分组。 然后针对那些小小分组进行统计，比如在我们这个查询语句中就是统计每个小小分组包含的记录条数。 如果没有索引的话，这个分组过程全部需要在内存里实现，而如果有了索引的话，恰巧这个分组顺序又和我们的B+树中的索引列的顺序是一致的，而我们的B+树索引又是按照索引列排好序的，这不正好么，所以可以直接使用B+树索引进行分组。 和使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"7.0 回顾B+树索引的本质","date":"2021-10-16T11:15:21.000Z","path":"2021/10/16/MySQL-InnoDB-页结构/7.0 回顾B+树索引的本质/","text":"回顾 B+树的索引本质我们前边非常详细地唠叨了InnoDB存储引擎的B+树索引， 我们必须熟悉下边这些结论: 每个索引都对应一棵B+树，B+树分为好多层，最下边一层是叶子节点，其余的是内节点。 所有用户记录都存储在B+树的叶子节点，所有目录项记录都存储在内节点。 InnoDB存储引擎会自动为主键(如果没有它会自动帮我们添加)建立聚簇索引，聚簇索引的叶子节点包含完整的用户记录。 我们可以为自己感兴趣的列建立二级索引，二级索引的叶子节点包含的用户记录由 索引列+主键 组成，所以如果想通过二级索引来查找完整的用户记录的话，需要通过回表操作，也就是在通过二级索引找到主键值之后再到聚簇索引中查找完整的用户记录。 B+树中每层节点(页)都是按照索引列值从小到大的顺序排序而组成了双向链表；而且每个⻚内的记录(不论是用户记录还是目录项记录)都是按照索引列的值从小到大的顺序而形成了一个单链表。 如果是联合索引的话，则⻚面和记录先按照联合索引前边的列排序，如果该列值相同，再按照联合索引后边的列排序。 通过索引查找记录是从B+树的根节点开始，一层一层向下搜索。由于每个⻚面都按照索引列的值建立了 Page Directory(⻚目录)，所以在这些⻚面内的查找非常快。 如果你读上边的几点结论有些任何一点点疑惑的话，那下边的内容不适合你，回过头先去看前边的内容去。 索引的代价在熟悉了B+树索引原理之后，本篇文章的主题是唠叨如何更好的使用索引，虽然索引是个好东⻄，可不能乱建，在介绍如何更好的使用索引之前先要了解一下使用这玩意儿的代价，它在空间和时间上都会拖后腿: 空间上的代价 这个是显而易⻅的，每建立一个索引都要为它建立一棵B+树， 每一棵B+树的每一个节点都是一个数据⻚，一个⻚默认会占用16KB的存储空间，一棵很大的B+树由许多数据⻚组成，那可是很大的一片存储空间呢。 时间上的代价 每次对表中的数据进行增、删、改操作时，都需要去修改各个B+树索引。因为B+树每层节点都是按照索引列的值从小到大的顺序排序而组成了双向链表。不论是叶子节点中的记录，还是内节点中的记录(也就是不论是用户记录还是目录项记录)都是按照索引列的值从小到大的顺序而形成了一个单向链表。 而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，⻚面分裂、⻚面回收啥的操作来维护好节点和记录的排序。 如果我们建了许多索引，每个索引对应的B+树都要进行相关的维护操作，这还能不给性能拖后腿么? 所以说，一个表上索引建的越多，就会占用越多的存储空间，在增删改记录的时候性能就越差。为了能建立又好又少的索引，我们先得学学这些索引在哪些条件下起作用的。 B+树索引适用的条件接下来将唠叨许多种让B+树索引发挥最大效能的技巧和注意事项。不过大家要清楚，所有的技巧都是源自你对B+树索引本质的理解，所以如果你还不能保证对B+树索引充分的理解，那么再次建议回过头把前边的内容看完了再来，要不然读文章对你来说是一种折磨。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.8 索引基本操作","date":"2021-10-14T12:29:53.000Z","path":"2021/10/14/MySQL-InnoDB-页结构/6.8 索引基本操作/","text":"小结: InnoDB和MyISAM会自动为主键或者声明为UNIQUE的列去自动建立B+树索引。 但是如果我们想为其他的列建立索引就需要我们显式的去指明。 为啥不自动为每个列都建立个索引呢?别忘了，每建立一个索引都会建立一棵B+树，每插入一条记录都要维护各个记录、数据⻚的排序关系，这是很费性能和存储空间的。 创建、修改、删除 索引: 我们可以在创建表的时候指定需要建立索引的单个列或者建立联合索引的多个列: 12CREATE TALBE 表名 ( 各种列的信息 ··· ,[KEY|INDEX] 索引名 (需要被索引的单个列或多个列) ) 其中的KEY和INDEX是同义词，任意选用一个就可以。 我们也可以在 修改表结构的时候添加索引 1ALTER TABLE 表名 ADD [INDEX|KEY] 索引名 (需要被索引的 单个列或多个列); 也可以在修改表结构的时候删除索引: 1ALTER TABLE 表名 DROP [INDEX|KEY] 索引名; 我们创建的索引名名称可以随便起，不过我们还是建议以idx_为前缀，后边跟着需要建立索引的列名，多个列名之间用下划线_分隔开。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.7 MyISAM中的索引方案简单介绍","date":"2021-10-14T12:19:26.000Z","path":"2021/10/14/MySQL-InnoDB-页结构/6.7 MyISAM中的索引方案简单介绍/","text":"前面我们介绍的都是InnoDB存储引擎中的索引方案，为了内容的完整性以及各位可能在面试时遇到这类的问题，我们有必要再简单介绍一下MyISAM存储引擎中的索引方案。 我们知道InnoDB中 索引即数据 ，也就是聚簇索引的那棵B+树的叶子节点中已经把所有完整的用户记录都包含了。而MyISAM的索引方案虽然也使用树形结构，但是却将索引和数据分开存储: MyISAM的数据文件： 它将表中的记录按照记录的插入顺序单独存储在一个文件中，称之为数据文件。这个文件并不划分为若干个数据⻚，有多少记录就往这个文件中塞多少记录就成了。我们可以通过行号而快速访问到一条记录。 MyISAM的索引文件： 使用MyISAM存储引擎的表, 会把索引信息另外存储到一个称为 索引文件 的另一个文件中MyISAM会单独为表的主键创建一个索引，只不过在索引的叶子节点中存储的不是完整的用户记录，而是 主键值+行号 的组合。也就是先通过索引找到对应的行号，再通过行号去找对应的记录!这一点和InnoDB是完全不相同的，在InnoDB存储引擎中，如果是根据主键查找数据，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录；而在MyISAM中却需要进行一次回表操作，意味着MyISAM中建立的索引相当于全部都是二级索引! 如果有需要的话，我们也可以对其它的列分别建立索引或者建立联合索引，原理和InnoDB中的索引差不多，不过在叶子节点处存储的是 相应的列+行号。这些索引也全部都是二级索引。 Tips:小贴士:MyISAM的行格式有定长记录格式(Static)、变长记录格式 (Dynamic)、压缩记录格式(Compressed)。如果数据表采用的市定长记录格式，也就是一条记录占用存储空间的大小是固定的，这样就可以轻松算出某条记录在数据文件中的 地址偏移量。但是变长记录格式就不行了，MyISAM会直接在索引叶子节点处存储该条记录在数据文件中的地址偏移量。通过这个可以看出， MyISAM的回表操作是十分快速的 ，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里边儿找记录，虽然说也不慢，但还是比不上直接用地址去访问。 此处我们只是非常简要的介绍了一下MyISAM的索引，具体细节全拿出来又可以写一篇文章了。这里只是希望大家理解InnoDB中的索引即数据，数据即索引，而MyISAM中却是索引是索引、数据是数据。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.6 InnoDB B+树索引 注意事项","date":"2021-10-13T14:21:36.000Z","path":"2021/10/13/MySQL-InnoDB-页结构/6.6 InnoDB B+树索引 注意事项/","text":"根⻚面万年不动窝我们前边介绍B+树索引时，为了大家理解上的方便，先把 存储用户记录的叶子节点都画出来，然后接着画 存储目录项记录 的内节点，实际上B+树的形成过程是这样的: 每当为某个表创建一个B+树索引(聚簇索引不是人为创建的， 默认就有)时，都会为这个索引创建一个根节点⻚面。 最开始表中没有数据时，每个B+树索引对应的根节点中既没有用户记录，也没有目录项记录。 随后向表中插入用户记录时，先把用户记录存储到这个 根节点 中。 当 根节点 中的可用空间用完时继续插入记录，此时会将根节点中的所有记录复制到一个新分配的⻚，比如⻚a中，然后对这个新⻚进行⻚分裂(lant:这个算是正常的页分裂)的操作，得到另一个新⻚，比如⻚b。这时新插入的记录根据键值(也就是聚簇索引中的主键值，二级索引中对应的索引列的值)的大小就会被分配到⻚a或者⻚b中，**而根节点便升级为存储目录项记录的⻚**。 这个过程需要大家特别注意的是: 一个B+树索引的根节点自诞生之日起，便不会再移动 。 这样只要我们对某个表建立一个索引，那么 它的根节点的⻚号便会被记录到某个地方，然后凡是InnoDB存储引擎需要用到这个索引的时候，都会从那个固定的地方取出根节点的⻚号，从而来访问这个索引 。 内节点中目录项记录的唯一性我们知道B+树索引的 内节点 中 目录项记录的内容是 索引列+⻚号 的搭配，但是这个搭配对于二级索引来说有点儿不严谨。 还拿index_demo表为例，假设这个表中的数据是这样的:c1 c2 c31 1 ‘u’3 1 ‘d’5 1 ‘y’7 1 ‘a’如果二级索引中目录项记录的内容只是 索引列 + ⻚号 的搭配的话， 那么为c2列建立索引后的B+树应该⻓这样: 如果我们想新插入一行记录(其中c1、c2、c3的值分别是:9、1、’c’)，那么在修改这个为c2列建立的二级索引对应的B+树时便碰到了个大问题: 由于⻚3中存储的目录项记录是由 c2列+⻚号的值 构成的，⻚3中的两条目录项记录对应的c2列的值都是1，而我们新插入的这条记录的c2列的值也是1，那我们这条新插入的记录到底应该放到⻚4中，还是⻚5中啊? 答案是: 对不起，懵逼了。 为了让新插入记录能找到自己在哪个⻚里，我们需要保证 在B+树的同一层 内节点 的 目录项记录 除⻚号这个字段外，其他字段(作为一个整体)应该是唯一的 。所以其实二级索引的内节点(目录项记录页)中的目录项记录的内容实际上是由三个部分构成的: 索引列的值 主键值 ⻚号 也就是我们把主键值也添加到二级索引的内节点中的目录项记录了，这样就能保证 **在B+树的同一层 内节点 的 目录项记录 除⻚号这个字段外，其他字段(作为一个整体)应该是唯一的**，所以我们为c2列建立二级索引后的示意图实际上应该是:这样我们再插入记录(9, 1, ‘c’)时，由于⻚3中存储的目录项记录是由 c2列 + 主键 + ⻚号 的值构成的，可以先把新记录的c2列的值和⻚3中各目录项记录的c2列的值作比较，如果c2列的值相同的话，可以接着比较主键值，因为B+树同一层中不同目录项记录的 c2 列 + 主键 的值肯定是不一样的，所以最后肯定能定位唯一的一条目录项记录，在本例中最后确定新记录应该被插入到⻚5中。 一个⻚面最少存储2条记录","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.5 InnoDB 的联合索引","date":"2021-10-13T13:19:37.000Z","path":"2021/10/13/MySQL-InnoDB-页结构/6.5 InnoDB 的联合索引/","text":"我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引。比方说我们想让B+树按照c2和c3列的大小进行排序,这个包含两层含义: 先把各个记录和⻚按照c2列进行排序； 在记录的c2列相同的情况下，采用c3列进行排序； 为c2和c3列建立的联合索引的示意图如下： 如图所示，我们需要注意以下几点: 每条目录项记录都由 c2、c3、⻚号 这三个部分组成，各条记录先按照c2列的值进行排序，如果记录的c2列相同，则按照c3列的值进行排序。 B+树叶子节点处的用户记录由 c2、c3、主键c1列组成。 千万要注意一点，以c2和c3列的大小为排序规则建立的B+树称为联合索引，本质上也是一个二级索引。它的意思与分别为c2和c3列分别建立索引的表述是不同的，建立联合索引只会建立如上图一样的1棵B+树。而为c2和c3列分别建立索引会分别以c2和c3列的大小为排序规则建立2棵B+树","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.4 InnoDB 的 二级索引及其回表操作","date":"2021-10-06T14:04:19.000Z","path":"2021/10/06/MySQL-InnoDB-页结构/6.4 InnoDB 的 二级索引及其回表操作/","text":"之前介绍的 聚簇索引 只能在搜索条件是主键值时才能发挥作用 😓，因为B+树中的记录都是按照主键进行排序的。 二级索引 如果我们想以别的列作为搜索条件该咋办呢? 难道只能从头到尾沿着链表依次遍历记录么? 🤔 不，我们可以多建几棵B+树，不同的B+树中的数据采用不同的排序规则 ✅。 比方说我们用c2列的大小作为数据⻚、⻚中记录的排序规则，再建一棵B+树，效果如下图所示:这个B+树与上边介绍的聚簇索引有几处不同: 使用记录c2列的大小进行 记录 和 ⻚ 的排序，这包括三个方面的含义: ⻚内的记录是按照c2列的大小顺序排成一个单向链表； 存放用户记录的⻚之间也是根据⻚中记录的c2列大小顺序排成一个双向链表； 存放目录项记录的⻚分为不同的层次，在同一层次中的⻚也是根据⻚中目录项记录的c2列大小顺序排成一个双向链表。 B+树的叶子节点存储的并不是完整的用户记录，而只是 c2列 +主键 这两个列的值； 目录项记录中不再是主键+⻚号的搭配，而变成了 c2列+⻚号的 搭配； 所以如果我们现在想通过c2列的值查找某些记录的话就可以使用我们刚刚建好的这个B+树了。 以查找c2列的值为4的记录为例，查找过程如下: 确定目录项记录⻚根据根⻚面，也就是⻚44，可以快速定位到目录项记录所在的⻚为⻚42(因为2 &lt; 4 &lt; 9)。 通过目录项记录⻚确定用户记录真实所在的⻚。在⻚42中可以快速定位到实际存储用户记录的⻚，但是由于c2列并没有唯一性约束，所以c2列值为4的记录可能分布在多个数据⻚中，又因为2 &lt; 4 ≤ 4，所以确定实际存储用户记录的⻚在⻚34和⻚35中。在真实存储用户记录的⻚中定位到具体的记录。 到⻚34和⻚35中定位到具体的记录。 但是这个B+树的叶子节点中的记录只存储了c2和c1(也就是主键)两个列，所以我们必须再根据主键值去聚簇索引中再查找一遍完整的用户记录。 二级索引需要回表哦 各位看到上面步骤4的操作了么?我们根据这个以c2列大小排序的B+树只能确定我们要查找记录的主键值，所以如果我们想根据c2列的值查找到完整的用户记录的话，仍然需要到聚簇索引中再查一遍， 这个过程也被称为回表。 也就是根据c2列的值查询一条完整的用户记录需要使用到2棵B+树!!! 为什么我们还需要一次回表操作呢?直接把完整的用户记录放到叶子节点不就好了么? 你说的对，如果把完整的用户记录放到叶子节点是可以不用回表，但是太占地方了呀~相当于每建立一棵B+树都需要把所有的用户记录再都拷⻉一遍，这就有点太浪费存储空间了。 因为 这种按照非主键列建立的B+树需要一次回表操作才可以定位到完整的用户记录，所以这种B+树也被称为二级索引(英文名secondary index)，或者辅助索引。由于我们使用的是c2列的大小作为B+树 的排序规则，所以我们也称这个B+树为为c2列建立的索引。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.3 InnoDB 的 聚簇索引 - 索引即数据","date":"2021-10-06T10:21:31.000Z","path":"2021/10/06/MySQL-InnoDB-页结构/6.3 InnoDB 的 聚簇索引 - 索引即数据/","text":"我们上边介绍的B+树索有两个特点: 使用记录主键值的大小进行记录和⻚的排序，这包括三个方面 的含义: ⻚内的记录是按照主键的大小顺序排成一个单向链表； 存放用户记录的⻚之间也是根据⻚中用户记录的主键大小顺序排成一个双向链表； 存放目录项记录的⻚分为不同的层次，在同一层次中的⻚也是根据⻚中目录项记录的主键大小顺序排成一个双向链表。 B+树的叶子节点存储的是完整的用户记录，所谓完整的用户记录，就是指这个记录中存储了所有列的值 (包括隐藏列)。 我们把具有这两种特性的B+树称为聚簇索引， 所有完整的用户记录都存放在这个聚簇索引的叶子节点处 。这种聚簇索引并不需要我们在MySQL语句中显式的使用INDEX语句去创建(后边会介绍索引相关的语句)，InnoDB存储引擎会自动的为我们创建聚簇索引。 另外有趣的一点是，在InnoDB存储引擎中， 聚簇索引就是数据的存储方式 (所有的用户记录都存储在了叶子节点)，也就是所谓的 索引即数据，数据即索引。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.2 快速查询的秘籍 - B+树索引 之 `InnoDB中的索引方案 B+树`","date":"2021-10-04T14:09:13.000Z","path":"2021/10/04/MySQL-InnoDB-页结构/6.2 快速查询的秘籍 - B+树索引 之 `InnoDB中的索引方: B+树`/","text":"普通用户记录 vs 目录项记录 设计InnoDB的大叔们为了灵活管理所有目录项。他们发现这些目录项其实跟我们的用户记录也差不多，只不过目录项中的两个列是主键和⻚号而已。所以大叔们复用了之前存储用户记录的数据⻚来存储目录项，为了和用户记录做一下区分，我们把这些用来表示目录项的记录称为目录项记录。 为了区分一条记录是普通用户记录还是目录项记录呢，InnoDB 就用到了记录头信息里的record_type属性(0:普通的用户记录、1:目录项记录、2:最小记录、3:最大记录) 所以我们把前面使用到的目录项放到数据⻚中的样子就是这样: 从图中可以看出来，我们新分配了一个编号为30的⻚来专⻔存储 目录项记录。 Tips:目录项记录和普通的用户记录 除了 内容不同、记录头信息 里的 record_type 不同，还有个不同点(可参考 5.2 回顾: 行格式 之 记录头信息 的秘密) :我们之前在唠叨记录头信息时提到过一个叫 min_rec_mask的，只有在存储目录项记录的⻚中的主键值最小的目录项记录的min_rec_mask值为1，其他别的记录的min_rec_mask值都是0。 除了上述几点外，这两者就没啥差别了，它们用的是一样的数据⻚。⻚的组成结构也是一样一样的。 只有单个存储目录项记录的数据⻚时的查找 现在以查找主键为20的记录为例，查找记录的步骤就可以大致拆分成下边两步: 先到存储目录项记录的数据⻚(也就是⻚30)中，通过二分法快速定位到对应目录项 (因为12 &lt; 20 &lt; 209，所以定位到对应的记录所在的⻚就是⻚9)； 再到存储用户记录的⻚9中定位到主键值为20的用户记录。(之前多次提到的页内查找方法：O(log n) + O(1)) 大量存储目录项记录的数据⻚时的查找 虽然说目录项记录中只存储主键值和对应的⻚号，比用户记录需要的存储空间小多了，但是不论怎么说一个⻚只有16KB大小，能存放的目录项记录也是有限的，如果表中的数据太多，以至于一个数据⻚不足以存放所有的目录项记录，该咋办呢?当然是再多整一个存储目录项记录的⻚喽~ 为了大家更好的理解新分配一个目录项记录⻚的过程，我们假设一个存储目录项记录的⻚最多只能存放4条目录项记录，所以如果此时我们再向上图中插入一条主键值为320的用户记录的话，那就需要分配一个新的存储目录项记录的⻚喽:从图中可以看出，我们插入了一条主键值为320的用户记录之后需要两个新的数据⻚: 为存储该用户记录而新生成了⻚31。 因为原先存储目录项记录的⻚30的容量已满(我们前边假设只能存储4条目录项记录)，所以不得不需要一个新的⻚32来存放⻚31对应的目录项。 现在因为存储目录项记录的⻚不止一个，所以如果我们想根据主键值查找一条用户记录大致需要3个步骤，以查找主键值为20的记录为例: 确定目录项记录⻚ 我们现在的存储目录项记录的⻚有两个，即⻚30和⻚32，又因为⻚30表示的目录项的主键值的范围是[1, 320)，⻚32表示的目录项的主键值不小于320，所以主键值为20的记录对应的目录项记录在⻚30中。 在一个存储目录项记录的⻚中通过主键值定位一条目录项记录的方式说过了，不赘述了~ 在真实存储用户记录的⻚中定位到具体的记录。 也多次提过了，不赘述了~ B+树 那么问题又来了:在这个查询步骤的第1步中我们需要定位 存储目录项记录的⻚，但是这些⻚在存储空间中也可能不挨着，如果我们表中的数据非常多则会产生很多存储目录项记录的⻚，那我们怎么根据主键值快速定位一个存储目录项记录的⻚呢?其实也简单， 为这些存储目录项记录的⻚再生成一个更高级的目录 ，所以现在各个⻚的 示意图就是这样子:如图，我们生成了一个存储更高级目录项的⻚33，这个⻚中的两条记录分别代表⻚30和⻚32，如果用户记录的主键值在[1, 320)之间，则到⻚30中查找更详细的目录项记录，如果主键值不小于320的话，就到⻚32中查找更详细的目录项记录。 不过，随着表中记录的增加，这个目录的层级会继续增加，如果简化一下，这玩意儿就像一个倒过来的树，上头是树根，下头是树叶! 这种组织数据的形式，或者说是一种数据结构，它的名称是B+树。 不论是存放用户记录的数据⻚，还是存放目录项记录的数据⻚，我们都把它们存放到B+树这个数据结构中了，所以我们也称这些数据⻚为节点。从图中可以看出来，我们的实际用户记录其实都存放在B+树的最底层的节点上，这些节点也被称为叶子节点或叶节点，其余用来存放目录项记录的节点称为非叶子节点或者内节点，其中B+树最上边的那个节点也称为根节点。 从图中可以看出来，一个B+树的节点其实可以分成好多层，设计InnoDB的大叔们为了讨论方便，规定最下边的那层，也就是存放我们用户记录的那层为第0层，之后依次往上加。 之前的讨论我们做了一个非常极端的假设:存放用户记录的⻚最多存放3条记录，存放目录项记录的⻚最多存放4条记录。其实真实环境中一个⻚存放的记录数量是非常大的 假设，假设，假设所有存放用户记录的叶子节点代表的数据⻚可以存放100条用户记录，所有存放目录项记录的内节点代表的数据⻚可以存放1000条目录项记录，那么: 如果B+树只有1层，也就是只有1个用于存放用户记录的节点，最多能存放100条记录。 如果B+树有2层，最多能存放1000×100&#x3D;100000条记录。 如果B+树有3层，最多能存放1000×1000×100&#x3D;100000000 条记录。 如果B+树有4层，最多能存放1000×1000×1000×100&#x3D;100000000000条记录。 你的表里能存放100000000000条记录么?所以一般情况下，我们用到的B+树都不会超过4层，那我们通过主键值去查找某条记录最多只需要做4个⻚面内的查找(查找3个目录项⻚和1个用户记录⻚)，又因为在每个⻚面内有所谓的Page Directory(⻚目录)，所以在⻚面内也可以通过二分法实现快速定位记录，这不是很牛么，哈哈!","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.1 快速查询的秘籍 - B+树索引 之 简易目录(索引的雏形)","date":"2021-10-04T12:17:57.000Z","path":"2021/10/04/MySQL-InnoDB-页结构/6.1 快速查询的秘籍 - B+树索引 之 简易目录(索引的雏形)/","text":"Demo表 为了故事的顺利发展，我们先建一个表:mysql&gt; CREATE TABLE index_demo( c1 INT,-&gt; c2 INT,-&gt; c3 CHAR(1),-&gt; PRIMARY KEY(c1)-&gt; ) ROW_FORMAT = Compact;-&gt; Query OK, 0 rows affected (0.03 sec) 这个新建的index_demo表中有2个INT类型的列，1个CHAR(1)类型的列，而且我们规定了c1列为主键。 这个表是使用Compact行格式来实际存储记录的。为了我们理解上的方便，我们简化了一下 index_demo表 的行格式示意图: record_type: 记录头信息的一个属性，表示记录的类型：0 表示普通记录、2表示最小记录、3表示最大记录、1我们还没用过，等会再说~ next_record: 记录头信息的一个属性，表示下一条地址相对于本条记录的地址偏移量，为了方便大家理解，我们都会用箭头来表明下一条记录是谁。 各个列的值: 这里只记录在index_demo表中的三个列，分别是c1、c2和c3。 其他信息:除了上述3种信息以外的所有信息，包括其他隐藏列的值以及记录的额外信息。 我们之后的示意图中会把 记录的其他信息 这个部分省略掉，因为它占地方并且不会有什么观赏效果: 把一些记录放到⻚里边的示意图就是: 一个简单的索引方案 现在我们已经知道，当我们根据某个搜索条件查找一些记录时，首先需要遍历所有的数据⻚ O(n)，然后再在每个数据页内利用 pagedirectory二分法定位槽 O(logn) + 组内遍历单链表 O(1) 进行记录的匹配。 所以… 效率问题目前是出在第一步，也就是在所有数据页中快速定位我们需要的页。还记得我们 通过主键 在 页内查找 时为了快速定位一条记录在⻚中的位置而设立的 ⻚目录 么?我们也可以想办法为快速定位记录所在的 数据⻚ 而建立一个别的目录，不过，要建这个目录必须完成下边的事儿； 数据页可以像页内记录那样也按主键顺序排列下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值。 页分裂问题： 😱 为了故事的顺利发展，我们这里需要做一个假设: 假设我们的每个数据⻚最多能存放3条记录(实际上一个数据⻚非常大，可以存放下好多记录)。 有了这个假设之后，如果我们向index_demo表插入4条记录，因为⻚10最多只能放3条记录，所以我们不得不再分配一个新⻚:你可以看到，新分配的数据页的页号并不是11，而是28这是因为我们使用的这些⻚在存储空间里可能并不挨着。它们只是通过维护着上一个⻚和下一个⻚的编号而建立了链表关系。另外，⻚10中用户记录最大的主键值是5，而⻚28中有一条记录的主键值是4，因为5 &gt; 4，所以不符合下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值的要求，**所以在插入主键值为4的记录时需要伴随着一次记录移动**，也就是把主键值为5的记录移动到⻚28中，然后再把主键值为4的记录插入到⻚10中，这个过程的示意图如下: 这个过程表明了在对⻚中的记录进行增删改操作的过程中， 我们必须通过一些诸如 记录移动的操作 来始终保证这个状态一直成立 : 下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值。这个过程我们也可以称为 **⻚分裂**。(lant:所以，所以这也说明了，主键为什么我们一般设置自增的，最好不要乱动主键，因为如果要保证“下一个数据⻚中用户记录的主键值必须大于上一个⻚中用户记录的主键值”的要求，逐渐最好自增，不然就会经常出现页分裂，这显然是个低效的动作。即便要删除记录，我们最好也是给记录标记一个删除状态即可。) 数据页也可以像页内记录那样也有一个 Page Directory 页目录 由于数据⻚的编号可能并不是连续的，所以在向index_demo 表中插入许多条记录后，可能是这样的效果: 如果想从更大量的⻚中根据主键值快速定位某些记录所在的⻚，我们也可以给这些页做个目录，每个⻚对应一个目录项，每个目录项包括下边两个部分: ⻚的用户记录中最小的主键值，我们用key来表示。 ⻚号，我们用page_no表示。所以我们为上边几个⻚做好的目录就像这样子: 以⻚28为例，它对应目录项2，这个目录项中包含着该⻚的⻚号28以及该⻚中用户记录的最小主键值5。比方说我们想找主键值为20的记录，具体查找过程分两步: 先从目录项中根据二分法快速确定出主键值为20的记录在目录项3中，它对应的⻚是 ⻚9。 再根据前边说的在⻚中查找记录的方式去⻚9中定位具体的记录。 由一个个的目录项组成的类似书籍中的简易目录，其实就是索引的雏形 至此，针对数据⻚做的简易目录就搞定了。不过忘了说了，这个目录有一个别名，称为索引。 所以：上一篇讲的，数据页内，为许多记录设计的目录，叫 页目录；本篇讲的，为许多数据页设计的目录，叫 索引；","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"6.0 没有索引时，如何查找数据？","date":"2021-10-04T11:53:21.000Z","path":"2021/10/04/MySQL-InnoDB-页结构/6.0 没有索引时，如何查找数据？/","text":"没有索引的查找本集的主题是索引，在正式介绍索引之前，我们需要了解一下没有索引时是怎么查找记录的。为了方便理解，下边先只唠叨搜索条件为对某个列精确匹配的情况，如：SELECT [列名列表] FROM 表名 WHERE 列名 = xxx; 在单个数据页中的查找 假设目前表中的记录比较少，所有的记录都可以被存放到一个⻚中。在查找记录的时候可以根据搜索条件的不同分为两种情况: 以主键为搜索条件 (😄 O(log n) + O(1) &#x3D; O(log n))可参考 5. 7 前情回顾: 数据页、目录页、槽、(页内)分组、记录 以其他列作为搜索条件 (😭 O(n))对非主键列的查找的过程可就不这么幸运了，因为在数据⻚中并没有对非主键列建立所谓的⻚目录，所以我们无法通过二分法快速定位相应的槽。这种情况下只能从最小记录开始依次遍历单链表中的每条记录，然后对比每条记录是不是符合搜索条件。很显然，这种查找的效率是非常低的。 所以结论就是：在单个数据页内 主键查找可以使用 “二分找槽 + 页内遍历”；(😄 O(log n) + O(1) &#x3D; O(log n)) 非主键查找还无法做到快速查找；(😭 O(n)) 在很多⻚中查找 大部分情况下我们表中存放的记录都是非常多的，需要好多的 数据⻚ 来存储这些记录。在很多⻚中查找记录的话可以分为两个步骤: 定位到记录所在的⻚； ⻚内查找； (这个前面已经多次提过了) 现在问题就是第1步了，如何定位记录所在的页?由于目前我们还没有讲什么方法去快速的定位到记录所在的⻚，所以只能从第一个⻚沿着双向链表一直往下找; 这种遍历所有数据⻚的方式显然是超级耗时的，如果一个表有一亿条记录，使用这种方式去查找记录那要等到猴年⻢月才能等到查找结果。（定位页的操作，时间复杂度此时成了 O(n)，显然很低效 ）所以祖国和人⺠都在期盼一种能高效完成搜索的方法，索引同志就要亮相登台了。 小结lant: 所以…… 到了这里，我们应该清楚： 索引 这个方案 是为了：当数据量很大时(InnoDB会用到大量的数据页)，在 大量的 数据页 中高效定位到 某个数据页； Page Directory、槽(对应分组) 是为了：在页内高效定位到某行记录（在页的目录页中通过二分法定位槽(页内分组) + 分组内遍历）。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.7 前情回顾 数据页、目录页、槽、(页内)分组、记录","date":"2021-10-02T02:21:43.000Z","path":"2021/10/02/MySQL-InnoDB-页结构/5.7 前情回顾 数据页、目录页、槽、(页内)分组、记录/","text":"前情回顾: 数据页、目录页、槽、(页内)分组、记录 之间的关系 前边我们详细唠叨了InnoDB数据⻚的7个组成部分，知道了: 各个数据⻚ 可能在物理结构上并不相连，而是通过双向链表相关联； 而每个数据⻚中的记录会按照主键值从小到大的顺序组成一个单向链表； 数据页、目录页、槽、(页内)分组、记录 之间的关系 回顾: 每个数据页内的记录，会被分成一个个的(页内)分组； 每个分组中的记录也都是按照主键值从小到大由单链表串联起来的(页内记录本来就是这样串联的)； 每个分组中的最大记录的地址偏移量被叫做槽 （由于槽就是分组中最大那条记录的地址偏移量，所以槽其实也就指向(代表)了对应分组中的最大那条记录的主键值）； 每个分组对应的槽都被放到了页内一个叫页目录的地方； 在某个页中 通过主键查找某条记录的时候: 可以先在⻚目录中使用二分法快速定位到对应的槽 (O(log n)) 然后再遍历该槽对应分组中的记录，即可快速找到指定的记录(O(1))。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.6 `通用页`结构 之 File Trailer(文件尾)部分","date":"2021-09-29T13:37:31.000Z","path":"2021/09/29/MySQL-InnoDB-页结构/5.6 通用页结构 之 File Trailer(文件尾)部分/","text":"通用页结构 之 File Trailer(文件尾)部分 File Trailer(文件尾) 部分和 File Header 部分 一样，都是所有类型的⻚通用的。 我们知道InnoDB存储引擎会把数据存储到磁盘上，但是磁盘速度太慢，需要以⻚为单位把数据加载到内存中处理，如果该⻚中的数据在内存中被修改了，那么在修改后的某个时间还需要把数据刷新到磁盘中。但是， 如果在刷新还没有结束时断电了咋办，这不是相当尴尬么? 为了检测一个⻚是否完整(也就是在刷新时有没有发生只刷新了一部分的尴尬情况)，设计InnoDB的大叔们在每个⻚的尾部都加了一个File Trailer部分，这个部分由8个字节组成，可以分成2个小部分: 前4个字节代表⻚的校验和：这个部分是和 File Header 中的校验和相对应的。每当一个⻚面在内存中发生修改时，在刷新之前就要把页面的校验和算出来。因为File Header在⻚面的前边，所以File Header中的校验和会被首先刷新到磁盘，当完全写完时，校验和也会被写到⻚的尾部。如果页面刷新完全成功，则⻚的首部和尾部的校验和应该是一致的。如果是刷新一部分后断电了，那么在File Header中的校验和就代表着已经修改过的⻚，而在File Trialer中的校验和则代表着原先的⻚，二者不同则意味着同步中间出了错。 后4个字节代表⻚面被最后修改时对应的日志序列位置(LSN)的后4个字节，正常情况下应该与File Header部分的FIL_PAGE_LSN的后4字节相同。这个部分也是为了校验⻚的完整性的，只不过我们目前还没说LSN是个什么意思，所以大家可以先不用管这个属性。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.5 `通用页`结构 之 File Header(文件头)部分","date":"2021-09-28T14:07:14.000Z","path":"2021/09/28/MySQL-InnoDB-页结构/5.5 通用页结构 之 File Header(文件头)部分/","text":"通用页结构 之 File Header(文件头)部分 上一篇讲的 数据页结构的Page Header部分 是 专⻔针对 页类型为 数据⻚ 的这种页。它的各个属性描述了 数据页 中的记录的各种状态信息，比方说⻚里头有多少个记录了呀，有多少个槽了呀。 而我们现在讲到的 页结构的File Header部分 是属于各种类型的⻚都通用的部分，它描述了一些针对各种⻚都通用的一些信息，比方说 这个⻚的编号是多少，它的上一个⻚、下一个⻚是谁 ……这个部分占用固定的38个字节，是由下边这些内容组成的: 名称 占用空间 描述 📌 FIL_PAGE_SPACE_OR_CHKSUM 4字节 页的校验和(checksum值) ✅ FIL_PAGE_OFFSET 4字节 页号 ✅ FIL_PAGE_PREV 4字节 上一个页的页号 ✅ FIL_PAGE_NEXT 4字节 下一个页的页号 FIL_PAGE_LSN 8字节 页面被最后修改时对应的日志序列(LSN)位置(log sequence number) ✅ FIL_PAGE_TYPE 2字节 该⻚的类型 FIL_PAGE_FILE_FLUSH_LSN 8字节 仅在系统表空间的第一个⻚中定义，代表文件至少被刷新到了对应的LSN值 FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID 4字 ⻚属于哪个表空间 对照着这个表格，我们看几个目前比较重要的部分:FIL_PAGE_SPACE_OR_CHKSUM:这个属性代表当前⻚面的校验和(checksum)。啥是校验和?就是对于一个很⻓很⻓的字节串来说，我们会通过某种算法计算出一个比较短的值来代表这个很⻓的字节串，这个比较短的值就称为校验和。**这样在比较两个很⻓的字节串之前先比较这两个⻓字节串的校验和，如果校验和都不一样两个⻓字节串肯定是不同的，所以省去了直接比较两个比较⻓的字节串的时间损耗**。 FIL_PAGE_OFFSET:每一个⻚都有一个单独的⻚号，InnoDB通过⻚号来可以唯一定位一个⻚。 FIL_PAGE_TYPE:这个代表当前⻚的类型，我们前边说过，InnoDB为了不同的目的而把⻚分为不同的类型，我们上边介绍的其实都是存储记录的数据⻚，其实还有很多别的类型的⻚。(我们存放记录的数据⻚的类型其实是FIL_PAGE_INDEX，也就是所谓的索引⻚。至于啥是个索引，且听下回分解~) FIL_PAGE_PREV 和 FIL_PAGE_NEXT:我们前边强调过，InnoDB是以⻚为单位存放数据的，有时候我们存放的数据占用的空间非常大(比如一张表中可以有成千上万条记录)，InnoDB可能不可以一次性为这么多数据分配一个非常大的存储空间，如果分散到多个不连续的⻚中存储的话需要把这些⻚关联起来，FIL_PAGE_PREV和 FIL_PAGE_NEXT就分别代表本⻚的上一个和下一个⻚的⻚号。这样**通过建立一个双向链表把许许多多的⻚就都串联起来 了**，而无需这些⻚在物理上真正连着。(Tips: 也不是所有类型的⻚都有上一个和下一个⻚的属性，不过我们本集中唠叨的数据⻚(也就是类型为FIL_PAGE_INDEX的⻚)是有这两个属性的）。所以所有的数据⻚其实是一个双链表，就像这样: 关于File Header的其他属性我们暂时用不到，等用到的时候再提~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.4 `数据页`结构 之 Page Header(页面头部)部分","date":"2021-09-26T13:46:53.000Z","path":"2021/09/26/MySQL-InnoDB-页结构/5.4 数据页结构 之 Page Header(页面头部)部分/","text":"数据页结构 之 Page Header(页面头部)部分 设计InnoDB的大叔们为了能得到某个数据⻚中存储的记录的状态信息，比如 本⻚中已经存储了多少条记录、第一条记录的地址是什么、⻚目录中存储了多少个槽(通过页目录中的槽的数量，其实也就能知道本页面被分出了多少个分组) 等信息……。大叔们特意在⻚中定义了一个叫 Page Header的部分，页结构的这个部分占用固定的56个字节，通过多个属性专⻔来存储各种状态信息: 名称 占用空间 描述 ✅ PAGE_N_DIR_SLOTS 2字节 页目录中槽的数量 ✅ PAGE_HEAP_TOP 2字节 还未使用空间的起始地址，你自然能明白，该地址之后就是 页结构的 Free Space 部分了 ✅ PAGE_N_HEAP 2字节 本⻚中的记录数量(包括最小和最大记录以及标记为删除的记录) ✅ PAGE_FREE 2字节 第一个已经标记为删除的记录地址(各个已删除的记录通过next_record也会组成一个单链表) ✅ PAGE_GARBAGE 2字节 已删除记录占用的字节数 ✅ PAGE_LAST_INSERT 2字节 最后插入记录的位置 PAGE_DIRECTION 2字节 记录插入的方向 PAGE_N_DIRECTION 2字节 一个方向连续插入的记录数量 ✅ PAGE_N_RECS 2字节 本⻚中的记录数量(不包括最小和最大记录以及被标记为删除的记录) PAGE_MAX_TRX_ID 8字节 修改当前⻚的最大事务ID，该值仅在二级索引中定义 📌 PAGE_LEVEL 2字节 当前⻚在B+树中所处的层级 PAGE_INDEX_ID 8字节 索引ID，表示当前页属于哪个索引 PAGE_BTR_SEG_LEAF 10字节 B+树叶子节点段的头部信息，尽在B+树的Root页定义 PAGE_BTR_SEG_TOP 10字节 B+树非叶子节点段的头部信息，尽在B+树的Root页定义 如果大家认真看过前边的文章，从 PAGE_N_DIR_SLOTS 到 PAGE_LAST_INSERT 以及 PAGE_N_RECS 的意思大家一定是清楚的。⚠️ 如果不清楚，对不起，你应该回头再看一遍前边的文章。⚠️ 剩下的状态信息看不明白不要着急，饭要一口一口吃，东⻄要一点一点学 (一定要稍安勿躁哦，不要被这些名词吓到)。 接下来我们先唠叨一下 PAGE_DIRECTION 和 PAGE_N_DIRECTION 的意思: PAGE_DIRECTION:假如新插入的一条记录的主键值比上一条记录的主键值大，我们说这条记录的插入方向是右边，反之则是左边。用来表示最后一条记录插入方向的状态就PAGE_DIRECTION。 PAGE_N_DIRECTION:假设连续几次插入新记录的方向都是一致的，InnoDB会把沿着同一个方向插入记录的条数记下来，这个条数就用 PAGE_N_DIRECTION 这个状态表示。当然，如果最后一条记录的插入方向改变了的话，这个状态的值会被清零重新统计。(🤔TODO :目前是能读懂意思，至于用途嘛…暂时还不明白) 至于上面还没提到的那些状态属性，现在大家还不需要知道。不要着急，当我们学完了后边的内容，你再回头看，一切都是那么清晰。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.3 `数据页`结构 之 Page Directory(⻚目录) 部分","date":"2021-09-25T06:36:09.000Z","path":"2021/09/25/MySQL-InnoDB-页结构/5.3 数据页结构 之 Page Directory(⻚目录) 部分/","text":"数据页结构 之 Page Directory&#96;(⻚目录) 部分单链表存储数据记录的低效问题现在我们已经知道， 记录在⻚中是按照主键值由小到大顺序串联成一个单链表放在 UserRecords 部分的 。 那如果我们想根据主键值查找⻚中的某条记录该咋办? 最笨的办法: 从 Infimum记录(最小记录)开始，沿着链表一直往后找，总有一天会找到(或者找不到)，在找的时候还能投机取巧，因为链表中各个记录的值是按照从小到大顺序排列的，所以当链表的某个节点代表的记录的主键值大于你想要查找的主键值时，你就可以停止查找了。 这个方法在⻚中存储的记录数量比较少的情况用起来也没啥问题，但是如果一个⻚中存储了非常多的记录，这么查找对性能来说还是有损耗的，所以我们说这种遍历查找这是一个笨办法。（ 时间复杂度很显然是 O(n) ） 索引页结构 之 Page Directory 设计InnoDB的大叔们自然不会用上面那种笨办法，他们从现实中的书籍目录中找到了灵感。他们为我们的记录也制作了一个类似的目录，他们的制作过程是这样的: 将所有正常的记录(包括页内的最大和最小记录，不包括标记为已删除的记录) 划分为几个组 ； 每个组的最后一条记录(也就是组内最大的那条记录)的头信息中的n_owned属性表示该组内共有几条记录； 将每个组内最后一条记录的地址偏移量单独提取出来并且还按主键顺序存储到靠近⻚的尾部的地方，这个地方就是所谓的 Page Directory，也就是⻚目录。⻚目录中的这些地址偏移量被称为槽(英文 名:Slot)，所以这个⻚目录就是由槽组成的。 比方说现在的page_demo表中正常的记录共有6条，InnoDB会把它们分成两组，第一组中只有一个最小记录，第二组中是剩余的5条记录，看下边的示意图:现在⻚目录部分中有两个槽，也就意味着我们的记录被分成了两个组:槽1中的值是112，代表最大记录(组内最后一条记录)的地址偏移量(就是从⻚面的0字节开始数，数112个字节);槽0中的值是99，代表最小记录(组内最后一条记录)的地址偏移量。 注意上面两个分组中最后一条记录的头信息中的 n_owned 属性：在第一个分组中，只有最小记录这一条记录，它的记录头信息的n_owned属性值为1，这就代表着以最小记录结尾的这个分组中只有1条记录；在第二个分组中，最后一条记录(此处是最大记录)的n_owned值为5，这就代表着以最大记录结尾的这个分组中有5条记录。 99和112这样的地址偏移量很不直观，我们用箭头指向的方式替代数字，这样更易于我们理解，所以修改后的示意图就是这样:不过上面的图看上去还是怪不好看的，我们就单纯从逻辑上对图做点改动:这样看就顺眼多了。 还有个问题，那就是为什么最小记录的n_owned值为1，而最大记录的n_owned值为5呢，这里头有什么猫腻么?这是因为，设计InnoDB的大叔们对每个分组中的记录条数是有规定的: 对于最小记录所在的分组只能有 1 条记录； 最大记录所在的分组拥有的记录条数只能在 1~8 条之间； 其他的分组中记录的条数范围只能在是 4~8 条之间。 所以分组是按照下边的步骤进行的: 初始情况下一个数据⻚里只有最小记录和最大记录两条记录，它们分属于两个分组。 之后每插入一条记录，都会从⻚目录中找到主键值比本记录的主键值大并且差值最小的槽（页目录中哪儿有主键值？页目录中不是 每个分组的最后一条记录的偏移量 即 槽 么？ 这是因为从本质上来说，通过槽就可以直接找到某个组内最后一条记录的主键 ），然后把该槽对应的记录的n_owned值加1，表示本组内又添加了一条记录，直到该组中的记录数等于8个。 在一个组中的记录数等于8个后再插入一条记录时，会将组中的记录拆分成两个组，一个组中4条记录，另一个5条记录。这个过程会在⻚目录中新增一个槽来记录这个新增分组中最大的那条记录的偏移量。 由于现在page_demo表中的记录太少，无法演示添加了⻚目录之后加快查找速度的过程，所以我们一口气又往表中添加了12条记录，现在⻚里边就一共有18 条记录了(包括最小和最大记录)，这些记录被分成了5个组，如图 所示:因为把16条记录的全部信息都画在一张图里太占地方，图中只保留了用户记录头信息中的n_owned和next_record属性，也省略了各个记录之间的箭头! 现在看怎么使用⻚目录来查找记录因为各个槽代表的是每个分组中最后一条记录的主键值，也就是说 槽 代表的主键当然也是从小到大排序的(分组内的记录不必多说，肯定是按照主键从小到大排序的)，所以我们可以在页目录中使用二分法快速定位我们要查找的记录的主键在哪个分组中。 4个槽的编号分别是:0、1、2、3、4，所以初始情况下最低的槽就是low&#x3D;0，最高的槽就是high&#x3D;4。比方说我们想找主键值为6的记录，过程是这样的: 计算中间槽的位置:(0+4)&#x2F;2&#x3D;2，所以查看槽2对应记录的主键值为8，又因为8 &gt; 6，所以设置high&#x3D;2，low保持不变。 重新计算中间槽的位置:(0+2)&#x2F;2&#x3D;1，所以查看槽1对应的主键值为4，又因为4 &lt; 6，所以设置low&#x3D;1，high保持不变。 因为high - low的值为1，所以确定主键值为5的记录在槽2对应的组中。 此刻我们需要找到槽2中主键值最小的那条记录，然后沿着单向链表遍历槽2中的记录。但是我们前边又说过，每个槽对应的记录都是该组中主键值最大的记录，这里槽2对应的记录是主键值为8的记录，怎么定位一个组中最小的记录呢?别忘了各个槽都是挨着的，我们可以很轻易的拿到槽1对应的记录(主键值为4)，该条记录的下一条记录就是槽2中主键值最小的记录，该记录的主键值为5。所以我们可以从这条主键值为5的记录出发，遍历槽2中的各条记录，直到找到主键值为6的那条记录即可。由于一个组中包含的记录条数只能是1~8条，所以遍历一个组中的记录的代价是很小的。 所以在一个数据⻚中查找指定主键值的记录的过程分为两步:**通过二分法确定该记录所在的槽，并找到该槽中主键值最小的那条记录**。(时间复杂度是 O(log n))通过记录的 记录头信息中的next_record属性遍历该槽所在的组中的各个记录 （每个分组中的记录数比较少，属于常量级别，所以时间复杂度是 O(1) ）。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.2 回顾 行格式 之 记录头信息 的秘密","date":"2021-09-24T05:31:16.000Z","path":"2021/09/24/MySQL知识点整理/5.2 回顾: 行格式 之 记录头信息 的秘密/","text":"为了故事的顺利发展，我们先创建一个表:mysql&gt; CREATE TABLE page_demo( -&gt; c1 INT, -&gt; c2 INT, -&gt; c3 VARCHAR(10000), -&gt; PRIMARY KEY (c1) -&gt; ) CHARSET=ascii ROW_FORMAT=Compact; Query OK, 0 rows affected (0.03 sec) 这个新创建的page_demo表有3个列，其中c1和c2列是用来存储整数的，c3列是用来存储字符串的。需要注意的是，我们把 c1 列指定为主键，所以在具体的行格式中InnoDB就没必要为我们去创建那个所谓的 row_id 隐藏列了。而且我们为这个表指定了ascii字符集以及Compact的行格式。所以这个表中记录的行格式示意图就是这样的: 我们再次先把这些记录头信息中各个属性的大体意思浏览一下(这里仍然使用Compact行格式进行演示): 为了进一步方便大家分析这些记录在⻚的User Records部分中是怎么表示的，我把记录中头信息和实际的列数据都用十进制表示出来了(其实是一堆二进制位)，这些记录的示意图如下:我们对照着这个图来看看记录头信息中的各个属性是啥意思。 delete_mask 这个属性标记着当前记录是否被删除，占用1个二进制位，值为0的时候代表记录并没有被删除，为1的时候代表记录被删除掉了。 这些被删除的记录之所以不立即从磁盘上移除，是因为移除它们之后把其他的记录在磁盘上重新排列需要性能消耗，所以只是打一个删除标记，所有被删除的记录会组成一个所谓的垃圾链表，在这个链表中的记录占用的空间称之为可重用空间，之后如果有新记录插入到表中的话，可能把这些被删除的记录占用的存储空间覆盖掉。 Tips：将这个delete_mask位设置为1 和 将被删除的记录加入到垃圾 链表中 其实是两个阶段，我们后边在介绍事务的时候会详细唠叨删除操作的详细过程，稍安勿躁。 min_rec_mask B+树的每层非叶子节点中的最小记录都会添加该标记。 什么是个B+树? 什么是个非叶子节点?好吧，别着急，等会儿再聊这个问题。 反正我们自己插入的四条记录的min_rec_mask值都是0，意味着它们都不是B+树的非叶子节点中的最小记录。 n_owned这个暂时保密，稍后它是主⻆~ heap_no 这个属性表示当前记录在本⻚中的位置。 从图中可以看出来， 我们插入的4条记录在本⻚中的位置分别是: 2、3、4、5。可怎么不⻅heap_no值为0和1的记录呢?这其实是设计InnoDB的大叔们玩的一个小把戏，他们自动给每个⻚里加了两个记录，由于这两个记录并不是我们自己插入的，所以有时候也称为伪记录或者虚拟记录。这两个伪记录一个代表最小记录，一个代表最大记录。 等一下哈~，记录可以比大小么?是的，记录也可以比大小，对于一条完整的记录来说，比较记录的大小就是比较主键的大小。比方说我们插入的4行记录的主键值分别是:1、2、3、4，这也就意味着这4条记录是从小到大依次递增。 但是不管我们向⻚中插入了多少自己的记录，设计InnoDB的大叔们都规定他们定义的两条伪记录分别为最小记录与最大记录。这两条记录的构造十分简单，都是由5字节大小的记录头信息和8字节大小的一个固定的部分组成的，如图所示： 由于这两条记录不是我们自己定义的记录，所以它们并不存放在⻚的User Records部分，他们被单独放在一个称为 Infimum + Supremum的部分，如下图所示: record_type 这个属性表示当前记录的类型，一共有4种类型的记录：0表示：普通记录1表示：B+树非叶节点记录2表示：最小记录3表示：最大记录 从图中我们也可以看出来，我们自己插入的记录就是普通记录，它们的record_type值都是0，而最小记录和最大记录的record_type值分别为2和3。至于record_type为1的情况，我们之后在说索引的时候会重点强调的。 next_record 这玩意儿非常重要，它表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。比方说第一条记录的 next_record 值为32，意味着从第一条记录的真实数据的地址处向后找32个字节便是下一条记录的真实数据。如果你熟悉数据结构的话，就立即明白了，这其实是个链表，可以通过一条记录找到它的下一条记录。 但是需要注意注意再注意的一点是，下一条记录指得并不是按照我们插入顺序的下一条记录，而是按照主键值由小到大的顺序的下一条记录。而且规定Infimum记录(也就是最小记录) 的下一条记录就是本⻚中主键值最小的用户记录，而本⻚中主键值最大的用户记录的下一条记录就是 Supremum记录(也就是最大记录) 。为了更形象的表示一下这个next_record起到的作用，我们用箭头来替代一下next_record中的地址偏移量: 从图中可以看出来，我们的记录按照主键从小到大的顺序形成了一个单链表。最大记录的next_record的值为0，这也就是说最大记录是没有下一条记录了，它是这个单链表中的最后一个节点。 如果从中删除掉一条记录，这个链表也是会跟着变化的，比如我们把第2条记录删掉后的示意图就是:从图中可以看出来，删除第2条记录前后主要发生了这些变化: 第2条记录并没有从存储空间中移除，而是把该条记录的delete_mask值设置为1。 第2条记录的next_record值变为了0，意味着该记录没有下一条记录了。 第1条记录的next_record指向了第3条记录。 还有一点你可能忽略了，就是最大记录的n_owned值从5变成了4，关于这一点的变化我们稍后会详细说明的。 再来看一个有意思的事儿，因为主键值为2的记录被我们删掉了，但是存储空间却没有回收，如果我们再次把这条记录插入到表中，会发生什么事呢? InnoDB并没有因为新记录的插入而为它申请新的存储空间，而是直接复用了原来被删除记录的存储空间。 所以，不论我们怎么对⻚中的记录做增删改操作，InnoDB始终会维护一条 由记录组成的单链表，链表中的各个节点是按照主键值由小到大的顺序连接起来的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.1 `数据页` 结构 之 User Records、Free Space 部分","date":"2021-09-23T15:12:10.000Z","path":"2021/09/23/MySQL-InnoDB-页结构/5.1 数据页结构 之 User Records、Free Space 部分/","text":"数据页 结构 之 User Records、Free Space 部分 在索引⻚的7个组成部分中，我们自己存储的记录会按照我们指定的行格式存储到 User Records 部分。 但是在一开始生成⻚的时候，其实并没有 User Records 这个部分，每当我们插入一条记录，都会从 Free Space 部分(也就是尚未使用的存储空间中)申请一个记录大小的空间划分到 User Records 部分，当 Free Space 部分的空间全部被 User Records 部分替代掉之后，也就意味着这个⻚使用完了，如果还有新的记录插入的话，就需要去申请新的⻚了，这个过程的图示如下: 为了更好的管理 User Records中的这些记录，InnoDB可费了一番力气呢，在哪费力气了呢? 不就是把记录按照指定的行格式一条一条摆在User Records部分么? 其实这话还得从记录行格式的记录头信息中说起。(回顾：4.1 compact 行格式，当时在提到 记录头信息 时，只是简单地了解了 记录头信息 的基本构成)，下面就着重看下之前学的行格式的知识中的记录头信息部分的秘密吧。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"5.0 盛放记录的大盒子 - InnoDB的数据页结构","date":"2021-09-23T13:25:09.000Z","path":"2021/09/23/MySQL-InnoDB-页结构/5.0 盛放记录的大盒子 - InnoDB的数据页结构/","text":"不同类型的页简介 前边已经简单提到过 ⻚ 的概念了， 它是InnoDB管理存储空间的基本单位 ，一个⻚的大小一般是16KB。 InnoDB为了不同的目的而设计了许多种不同类型的⻚，比如 存放 表空间头部信息 的⻚、存放 Insert Buffer信息 的⻚、存放 INODE信息 的⻚、存放 undo日志信息 的⻚ 等等…… 当然，如果这些名词你一个都没有听过也无所谓~~~目前暂时还不准备说这些类型的⻚。我们聚焦的是那些存放我们表中记录的那种类型的⻚，官方称这种存放记录的⻚为索引(INDEX)⻚，鉴于我们还没有了解过索引是个什么东⻄，而这些表中的记录就是我们日常口中所称的数据，所以目前还是叫这种存放记录的⻚为数据⻚吧。 索引(INDEX)⻚的结构概括 数据⻚的16KB存储空间可以被划分为多个部分，不同部分有不同的功能: 可以看出，一个InnoDB数据⻚的存储空间大致被划分成了7个部分，有的部分占用的字节数是确定的，有的部分占用的字节数是不确定的。 下边我们用表格的方式来大致描述一下这7个部分都存储一些啥内容(快速的瞅一眼就行了，后边会详细唠叨的): 名称 中文名 占用空间大小 简单描述 👌 File Header 文件头部 38字节 ⻚的一些通用信息(所有类型的页都有这个部分) ✅ Page Header ⻚面头部 56字节 数据⻚这种页类型专有的一些信息 ✅ Infimum + Supremum 最小记录和最大记录 26字节 两个虚拟的行记录 ✅ *User Records 用户记录 不确定 实际存储的行记录内容 ✅ Free Space 空闲空间 不确定 ⻚中尚未使用的空间 ✅ Page Directory ⻚面目录 不确定 ⻚中的某些记录的相对位置 👌 File Trailer 文件尾部 8字节 校验⻚是否完整 不过，我们接下来并不打算按照⻚中各个部分的出现顺序来依次介绍它们，因为各个部分中会出现很多大家目前不理解的概念，这会打击 各位读文章的信心与兴趣，希望各位能接受这种拍摄手法~","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.4 CHAR(M)中的M值过大的情况","date":"2021-09-21T11:51:16.000Z","path":"2021/09/21/MySQL知识点整理/4.4 CHAR(M)中的M值过大的情况/","text":"CHAR(M)中的M值过大的情况 CHAR(M)类型的列所占用的最大字节⻓度等于 该列使用的字符集表示一个字符需要的最大字节数和M的乘积。 如果某个列使用的是CHAR(M)类型，并且它存储的最大字节⻓度超过768字节，那么不论我们使用的是之前讲过的4种行格式中的哪种，InnoDB都会把该列当成变⻓字段看待。比方说采用utf8mb4的CHAR(255)类型的列将会被当作变⻓字段看待，因为 4×255 &gt; 768。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.3 Dynamic 和 Compressed 行格式","date":"2021-09-21T11:11:27.000Z","path":"2021/09/21/MySQL知识点整理/4.3 Dynamic 和 Compressed 行格式/","text":"Dynamic 和 Compressed 行格式 我现在使用的MySQL版本是5.7，它的默认行格式就是Dynamic，这俩行格式和Compact行格式挺像，只不过在处理行溢出数据时有点儿分歧，它们不会在记录的真实数据处存储字段真实数据的前768个字节，而是把所有的字节都存储到其他⻚面中，只在记录的真实数据处存储其他⻚面的地址，就像这样: Compressed行格式和Dynamic不同的一点是，Compressed行格式会采用压缩算法对⻚面进行压缩，以节省空间。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.2 行溢出数据 与 溢出页","date":"2021-09-19T14:01:52.000Z","path":"2021/09/19/MySQL知识点整理/4.2 行溢出数据 与 溢出页/","text":"VARCHAR(M)最多能存储的数据 我们知道，对于VARCHAR(M)类型的列最多可以占用65535个字节。(lant: 因为在变长字段长度列表中，每个变长字段实际存储的数据的长度值最多占2个字节，而2个字节最大能表示的数就是65535了)。而之前我们也说过，VARCHAR(M)的M代表该类型最多存储的字符数量 使用ascii定长字符集 如果我们使用ascii字符集的话，一个字符就代表一个字节，我们看看VARCHAR(65535)是否可用: mysql&gt; CREATE TABLE varchar_size_demo(-&gt; c VARCHAR(65535)-&gt; ) CHARSET=ascii ROW_FORMAT=Compact; ERROR 1118 (42000): Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to change some columns to TEXT or BLOBs mysql&gt; 从报错信息里可以看出，MySQL对一条记录占用的最大存储空间是有限制的，除了BLOB或者TEXT类型的列之外， 其他所有的列(不包括隐藏列和记录头信息)占用的字节⻓度加起来不能超过65535个字节 。所以上面可以看到MySQL服务器建议我们把存储类型改为TEXT或者BLOB的类型。 这65535个字节除了列本身的数据外，还包括一些其他数据，比如说为了存储一个VARCHAR(M)类型的列，其实需要占用3部分存储空间: 真实数据、真实数据的⻓度占用的字节、NULL值标识(如果该列有NOT NULL属性则可以没有这部分存 储空间)…如果该VARCHAR类型的列没有NOT NULL属性，那最多只能存储65532个字节的数据，因为真实数据的⻓度在变长字段列表中会占2个字节，NULL 值标识需要占用1个字节，再次尝试，果然成功了mysql&gt; CREATE TABLE varchar_size_demo(-&gt; c VARCHAR(65532)-&gt; ) CHARSET=ascii ROW_FORMAT=Compact;Query OK, 0 rows affected (0.02 sec) 使用变长字符集如果VARCHAR(M)类型的列使用的不是ascii字符集，那会怎么样呢? mysql&gt; CREATE TABLE varchar_size_demo( -&gt; c VARCHAR(65532)-&gt; ) CHARSET=gbk ROW_FORMAT=Compact;ERROR 1074 (42000): Column length too big for column &#39;c&#39; (max = 32767); use BLOB or TEXT instead mysql&gt; CREATE TABLE varchar_size_demo(-&gt; c VARCHAR(65532)-&gt; ) CHARSET=utf8 ROW_FORMAT=Compact;ERROR 1074 (42000): Column length too big for column &#39;c&#39; (max = 21845); use BLOB or TEXT instead 从执行结果中可以看出，如果VARCHAR(M)类型的列使用的不是ascii字符集，那M的最大取值取决于该字符集表示一个字符最多需要的字节数。gbk字符集表示一个字符最多需要2个字符，在列的值允许为NULL的情况下，M的最大取值就是32766(也就是: 65535-2(变长字段列表占2字节)-1(null列表占1字节) &#x3D; 65532)，也就是说最多能存储32766(65532&#x2F;2)个字符;utf8字符集表示一个字符最多需要3个字符，那在该字符集下，M的最大取值就是21844，就是说最多能存储21844(也就是: (65535-2-1)&#x2F;3)个字符。 Tips:上述所言在列的值允许为NULL的情况下，gbk字符集下M的最大取值就是32766，utf8字符集下M的最大取值就是21844， 这都是在表中只有一个字段的情况下说的 ， 一定要记住一个行中的所有列(不包括隐藏列和记录头信息)占用的字节⻓度加起来不能超过65535个字节 ! 记录中的数据太多产生的溢出 前边说过， MySQL中磁盘和内存交互的基本单位是⻚，也就是说MySQL是以⻚为基本单位来管理存储空间的，我们的记录都会被分配到某个⻚中存储 。 而一个⻚的大小一般是16KB，也就是16384字节，而一个VARCHAR(M)类型的列就最多可以存储65532个字节，这样就可能造成一个⻚存放不了一条记录的尴尬情况。 在Compact和Reduntant行格式中，对于占用存储空间非常大的列，在记录的真实数据处只会存储该列的一部分数据，而剩余的数据则会被分散存储在几个其他的⻚中，然后记录的真实数据处用20个字节存储指向这些⻚的地址(当然这20个字节中还包括这些分散在其他⻚面中的数据的占用的字节数)，从而可以找到剩余数据所在的⻚。 从图中可以看出来，对于Compact和Reduntant行格式来说，如果 某一列中的数据非常多的话，在本记录的真实数据处只会存储该列的 前768个字节的数据和一个指向其他⻚的地址，然后把剩下的数据存 放到其他⻚中，这个过程也叫做行溢出，存储超出768字节的那些⻚面也被称为溢出⻚。简图如下：最后需要注意的是，不只是 VARCHAR(M) 类型的列，其他的 TEXT、BLOB 类型的列在存储数据非常多的时候也会发生行溢出。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.1 compact 行格式","date":"2021-09-18T12:41:09.000Z","path":"2021/09/18/MySQL-InnoDB-页结构/4.1 compact 行格式/","text":"COMPACT行格式 直接看图:从图中可以看出来，一条完整的记录其实可以被分为 记录的额外信息 和 记录的真实数据 两大部分，下边我们详细看一下这两部分的组成。 记录的额外信息这部分信息是 服务器为了描述这条记录而不得不额外添加的一些信息 。这些额外信息分为3部分，分别是 变⻓字段⻓度列表、NULL值列表 和 记录头信息，我们分别看一下 记录的额外信息 之 变⻓字段⻓度列表 我们知道MySQL支持一些变⻓的数据类型，比如 VARCHAR(M)、VARBINARY(M)、各种TEXT类型，各种BLOB类型，我们可以把被设置为这些数据类型的列称为变⻓字段；变⻓字段中存储多少字节的数据是不固定的，所以我们在存储真实数据时，InnoDB引擎会顺便把这些数据实际占用的字节数也存起来，这样才不至于把MySQL服务器搞懵，所以这些变⻓字段占用的存储空间分为两部分: 真正的数据内容、数据内容占用的字节数。 在Compact行格式中，把所有变⻓字段的真实数据所占用的字节数都存放在记录的开头部位，从而形成一个变⻓字段⻓度列表。各变⻓字段的真实数据所占用的字节数，按照列的顺序逆序存放。 示例:拿 record_format_demo 示例表中的 第一条记录 来举例: 因为record_format_demo表的c1、c2、c4字段都是 VARCHAR(10)类型(变⻓数据类型)， 所以这三个列的所存储的真实数据的⻓度值都需要保存在当前记录的 变⻓字段⻓度列表中 ； 又因为record_format_demo表中的各个列都使用的是ascii字符集(每个字符只需要1个字节来进行编码);来看一下第一条记录各变⻓字段的 实际内容 的⻓度: 又因为这些⻓度值需要按照列的逆序存放，所以最后这条记录的变⻓字段⻓度列表 的字节串用十六进制表示的效果就是： 第一行记录中，c1、c2、c4 每列中的真实数据所占的字节长度的数值比较小(4，3，1这些小数字)，用1个字节就可以表示；但是如果变⻓列的数据占用的字节数比较多，可能就需要用2个字节来表示 。(如果某行记录的c1变长字段的真实数据长度是300字节，300这个数值用一个字节就无法表示了，因为一个字节是8位，最大只能表示的数字是255)每个变长字段在 变长字段列表中 具体用1个还是2个字节来表示真实数据所占用的字节数，InnoDB有它的一套规则，我们首先声明一下W、M和L的意思。 W:假设一个字符集中表示一个字符最多需要使用的字节数为W，也就是使用 SHOW CHARSET 语句的结果中的Maxlen列。(比方说utf8字符集中的W就是3，utf8mb4字符集中的W就是4)。 M:对于变⻓类型VARCHAR(M)来说， 这种类型表示能存储最多M个字符 (注意是字符不是字节)，所以这个类型能表示的字符串最多占用的字节数就是 M×W。 L:假设该变长实际存储的字符串占用的字节数是 L; 所以确定使用1个字节还是2个字节表示真正字符串占用的字节数的规则就是: 如果 M×W &lt;= 255，那么使用1个字节来表示真正字符串占用的字节数； (一个字节能表示的最大数值就是255) 如果M×W &gt; 255，则分为两种情况: 如果 L &lt;= 127，则用1个字节来表示真正字符串占用的字节数。 如果 L &gt; 127，则用2个字节来表示真正字符串占用的字节数。 对于一些占用字节数非常多的字段，比方说某个字段⻓度大于了16KB，即 该记录在单个⻚面中都存储不下时，InnoDB 会把一部分数据存放到所谓的溢出⻚中(我们后边会唠叨)，在变⻓字段⻓度列表处只存储留在本⻚面中的⻓度，所以使用两个字节也可以存放下来。 总结一下就是说: 如果该变长字段允许存储的最大字节数(M×W)超过255字节并且真实存储的字节数(L)超过127字节，则使用2个字节，否则使用1个字节。 另外需要注意的一点是，变⻓字段⻓度列表中只存储实际内容为非NULL的列数据占用的字节数，值为NULL的列的⻓度是不储存的也就是 说对于第二条记录来说，因为c4列的值为NULL，所以第二条记录的变⻓字段⻓度列表只需要存储c1和c2列的⻓度即可（其中c1列存储的值为’eeee’，占用的实际字节数为4，c2列存储的值为’fff’，占用的实际字节数为3。数字4可以用1个字节表示，3也可以用1个字节表示， 所以整个变⻓字段⻓度列表共需2个字节）。填充完变⻓字段⻓度列表 的两条记录的对比图如下: Tips:并不是所有记录都有这个 变⻓字段⻓度列表 部分，比方说表中所有的列都不是变⻓的数据类型的话，这一部分就不需要有。 记录的额外信息 之 NULL值列表我们知道表中的某些列可能存储NULL值，如果把这些NULL值都放到记录的真实数据中存储，那就会很占地方，所以Compact行格式把这些值为NULL的列统一管理起来，存储到了 记录的额外信息 中的 NULL值列表 中，它的处理过程是这样的: 首先统计表中允许存储NULL的列有哪些像 主键列、被NOT NULL修饰的列 都是不可以存储NULL值的，所以在统计时不会把这些列算进去。 如果表中没有允许存储 NULL 的列，则NULL值列表也不存在。否则 将每个允许存储NULL的列对应一个二进制位 ，二进制位按照列的顺序逆序排列，二进制位的值为1时，代表该列的值为NULL。二进制位的值为0时，代表该列的值不为NULL。 MySQL规定NULL值列表必须用整数个字节的位表示，如果可以为NULL的字段数 达不到整数个字节，则在字节的高位补0。表record_format_demo只有3个值允许为NULL的列，对应3个二进制位，不足一个字节，所以在字节的高位补0，效果就是这样: 对于第一条记录来说，c1、c3、c4 这3个列的值都不为NULL，所以它们对应的二进制位都是0: 对于第二条记录来说，c1、c3、c4 这3个列中c3和c4的值都为NULL，所以这3个列对应的二进制位的情况就是: 所以这两条记录在填充了NULL值列表后的示意图就是这样: 记录的额外信息 之 记录头信息 除了 变⻓字段⻓度列表、NULL值列表 之外，还有一个 用于描述记录的 记录头信息。 记录头信息 由固定的5个字节组成(也就是40个二进制位，不同的位代表不同的意思)，如图: 这些二进制位代表的详细信息如下表:现在暂时也没必要把它们的意思都记住，只需要看一遍混个脸熟，等之后用到这些属性的时候我们再回过头来看 现在我们并不清楚这些属性详细的用法，所以这里就不分析各个属性值是怎么产生的了，之后我们遇到会详细看的。 所以我们现在直接看一下record_format_demo 表中的两条记录的头信息分别是什么:目前，你只需要对这两条记录的 记录头信息部分 有个印象就行。 记录的真实数据 对于record_format_demo表来说，记录的真实数据除了 c1、c2、c3、c4 这几个我们自己定义的列的数据以外， MySQL会为每个记录默认的添加一些列(也称为隐藏列) ，具体的列如下: 列名 是否必须 占用空间 描述 row_id 否 6字节 行ID，唯一标识一条记录 transaction_id 是 6字节 事务ID roll_pointer 是 7字节 回滚指针 Tips: 实际上这几个列的真正名称其实是: DB_ROW_ID、DB_TRX_ID、 DB_ROLL_PTR，我们为了美观才写成了row_id、 transaction_id和roll_pointer。 这里需要提一下 InnoDB表对主键的生成策略: 优先使用用户自定义的主键作为主键; 如果用户没有定义主键，则选取一个Unique键作为主键; 如果表中连Unique键都没有定义的话，则InnoDB会为表默认添加一个名为row_id 的隐藏列作为主键。 所以我们可以看出: InnoDB存储引擎会为每条记录都添加 transaction_id 和 roll_pointer 这两个列，但是 row_id 是可选的(在没有自定义主键及Unique键的情况下才会添加该列)。这些隐藏列的值不用我们操心，InnoDB存储引擎会自己帮我们生成的。 因为表record_format_demo示例表并没有定义主键，所以MySQL服务器会为每条记录增加上述的3个列。现在看一下加上记录的真实数据的、两个记录⻓什么样吧:看这个图的时候我们需要注意几点:表record_format_demo使用的是ascii字符集，所以0x61616161就表示字符串’aaaa’，0x626262就表示字符 串’bbb’，以此类推; 注意第1条记录中c3列的值，它是CHAR(10)类型的，虽然它实际存储的字符串是:’cc’(ascii字符集的字节表示是’0x6363’)，虽然表示这个字符串只需要用2个字节，但整个c3列仍然占用了10个字节的空间，除真实数据以外的8个字节的统统都用空格字符填充，空格字符在ascii字符集的表示就是0x20。 注意第2条记录中c3和c4列的值都为NULL，它们被存储在了前边的NULL值列表处，在记录的真实数据处就不再冗余存储，从而节省存储空间 。 字符集对 COMPACT 行格式的影响COMPACT行格式会受字符集的影响。 以 CHAR(M)列的存储格式 为例尽管我们说在 Compact行格式 下只会把变⻓字段存储的实际数据的⻓度逆序存到 变⻓字段⻓度列表中。 但其实除了考虑字段本身的类型是否是变长字段，还需要考虑字符集的影响 。 对于record_format_demo示例表的c1,c2,c4列来说，它们是变长字段，这个没毛病，但此时我们的表采用的是ascii字符集(这个字符集是一个定⻓字符集，一个字符采用固定的一个字节)。如果采用变⻓的字符集(也就是表示一个字符需要的字节数不确定，比如gbk表示一个字符要12个字节、utf8表示一个字符要13个字节等)的话， 此时c3列虽然是char(10)这种定长字段，但它的数据⻓度也会被存储到变⻓字段⻓度列表中 。 假如我们将record_format_demo表的字符集修改为utf8,修改该列字符集后记录的变⻓字段⻓度列表也发生了变化: 这就意味着: 对于 CHAR(M) 类型的列来说，当采用的是定⻓字符集时，该列实际数据占用的字节数不会被加到变⻓字段⻓度列表中; 而如果采用的是变⻓字符集时，该列实际数据占用的字节数也会被加到变⻓字段⻓度列表 。 Tips:另外有一点还需要注意， 变⻓字符集的CHAR(M)类型的列要求至少占用M个字节 （utf8表示一个字符要1~3个字节），而VARCHAR(M)却没有这个要求。 比方说对于使用utf8字符集的CHAR(10)的列来说，该列存储的数据字节⻓度的范围是10~30个字节。即使我们向该列中存储一个空字符串也会占用10个字节。这样的话，将来更新该列的值时，如果字节⻓度小于10个字节时，可以在该记录处直接更新，而不是在存储空间中重新分配一个新的记录空间，导致原有的记录空间成为所谓的碎片。(这里你感受到设计Compact行格式的大叔既想节省存储空间，又不想更新CHAR(M)类型的列产生碎片时的纠结心情了吧。) Redundant行格式 其实知道了Compact行格式之后，其他的行格式就是依葫芦画瓢了。我们现在要介绍的Redundant行格式是MySQL5.0之前用的一种行格式，也就是说它已经非常老了，大家乐呵乐呵的看就好。 …… Redundant行格式: CHAR(M) 不会产生碎片我们知道Compact行格式在CHAR(M)类型的列中存储数据的时候还挺麻烦，分 变⻓字符集 和 定⻓字符集 的情况，而在Redundant行格式中十分干脆，不管该列使用的字符集是啥，只要是使用CHAR(M)类型，占用的真实数据空间就是该字符集表示一个字符最多需要的字节数和M的乘积。比方说使用utf8字符集的CHAR(10)类型的列占用的真实数据空间始终为30个字节，使用gbk字符集的CHAR(10)类型的列占用的真实数据空间始终为20个字节。由此可以看出来，使用Redundant行格式的CHAR(M)类型的列是不会产生碎片的。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"4.0 InnoDB记录存储结构 之 页的概念、行格式的概念","date":"2021-09-18T12:01:19.000Z","path":"2021/09/18/MySQL-InnoDB-页结构/4.0 InnoDB记录存储结构 之 页的概念、行格式的概念/","text":"前言 到现在为止，MySQL对于我们来说还是一个黑盒。我们只是简单使用客户端发送请求并等待服务器返回结果。至于 表中的数据到底存到了哪里? 以什么格式存放的? MySQL是以什么方式来访问的这些数据? 这些问题我们统统不知道。 不过前面已经多次提到， MySQL服务器上负责对表中数据的读取和写入工作的部分是存储引擎 。MySQL服务器支持多种不同类型的存储引擎(如InnoDB、MyISAM、Memory……)，不同的存储引擎一般是由不同的人为实现不同的特性而开发的，真实数据在不同存储引擎中存放的方式一般是不同的，甚至有的存储引擎比如Memory都不用磁盘来存储数据。 由于InnoDB是MySQL默认的存储引擎，也是我们最常用到的存储引擎，我们也没有那么多时间去把各个存储引擎的内部实现都看一遍，所以本集要唠叨的是使用InnoDB作为存储引擎时的数据存储结构，了解了一个存储引擎的数据存储结构之后，其他的存储引擎都是依葫芦画瓢，等以后用到了再说~ InnoDB存储引擎中⻚的概念 InnoDB是一个将表中的数据存储到磁盘上的存储引擎，所以即使关机后重启我们的数据还是存在的。 不过，尽管InnoDB是将数据存储到磁盘上的存储引擎，但真正处理数据的过程却是发生在内存中的，所以需要把磁盘中的数据加载到内存中，如果是处理写入或修改请求的话，还需要把内存中的内容刷新到磁盘上。 而我们知道读写磁盘的速度非常慢，和内存读写差了几个数量级，所以当我们想从表中获取某些记录时，InnoDB存储引擎需要一条一条的把记录从磁盘上读出来么?不，那样会慢死，InnoDB采取的方式是: 将数据划分为若干个⻚，以⻚作为磁盘和内存之间交互的基本单位，InnoDB 中⻚的大小一般为16KB。也就是在一般情况下，一次最少从磁盘中读取16KB的内容到内存中，一次最少把内存中的16KB内容刷新到磁盘中。 InnoDB引擎的行格式(记录格式) 我们平时是以行(也叫记录)为单位来向表中插入数据的，这些记录在磁盘上的存放方式也被称为行格式或者记录格式。 设计InnoDB存储引擎的大叔们到现在为止设计了4种不同类型的行格式，分别是 Compact、Redundant、Dynamic 和 Compressed 行格式，随着时间的推移，他们可能会设计出更多的行格式，但是不管怎么变，在原理上大体都是相同的。 如何指定表的行格式？我们可以在创建或修改表的语句中指定行格式:&#x2F;&#x2F; 语法如下CREATE TABLE 表名 ( 列的信息) ROW_FORMAT=行格式名称 ALTER TABLE 表名 ROW_FORMAT=行格式名称","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"3. 字符集和比较规则","date":"2021-09-14T14:53:41.000Z","path":"2021/09/14/MySQL知识点整理/3. 字符集和比较规则/","text":"字符集的概念 我们知道在计算机中只能存储二进制数据，那该怎么存储字符串呢? 当然是建立字符与二进制数据的映射关系了 ，建立这个关系最起码要搞清楚两件事儿: 你要把哪些字符映射成二进制数据? (其实就是字符集要包含的 字符范围) 怎么映射? (其实就是 编码规则)将一个字符映射成一个二进制数据的过程也叫做编码，将一个二进制数据映射到一个字符的过程叫做解码。 为此，人们抽象出了一个叫 字符集 的概念来描述某个字符范围的编码规则。 比方说，我们现在可以自定义一个名称为 xiaohaizi 的字符集，它包含的 字符范围 和 编码规则 如下: 字符范围: 包含字符：’a’、’b’、’A’、’B’ ； 编码规则是：采用1个字节编码一个字符，字符和字节的映射关系如下:‘a’ -&gt; 00000001 (十六进制:0x01)‘b’ -&gt; 00000010 (十六进制:0x02)‘A’ -&gt; 00000011 (十六进制:0x03)‘B’ -&gt; 00000100 (十六进制:0x04) 有了 xiaohaizi 这个字符集后，我们就可以用二进制形式表示一些字符串了，下边是一些字符串用 xiaohaizi 这个字符集编码后的二进制表示:bA’ -&gt; 00000010 00000011 (十六进制:0x0203)‘baB’ -&gt; 00000010 00000001 00000100 (十六进 制:0x020104)‘cd’ -&gt; 无法表示，因为字符集xiaohaizi不包含字符’c’和’d’ 所以，字符集 其实就是通过制定 字符范围 和 编码规则 来将日常字符数据映射到计算机能存储的二进制数据的一套规则。 比较规则的概念 在我们确定了xiaohaizi字符集表示字符的范围以及编码规则后，怎么比较两个字符的大小呢? 最容易想到的就是直接比较这两个字符对应的二进制编码的大小，比方说字符’a’的编码为0x01，字符’b’的编码为0x02，所以’a’小于’b’，这种简单的比较规则也可以被称为二进制比较规则，英文名为binary collation。 二进制比较规则 非常简单，但有时候并不符合现实需求，比如在很多场合对于英文字符我们都是不区分大小写的，也就是说’a’和’A’是相等的，在这种场合下就不能简单粗暴的使用二进制比较规则了，这时候我们可以这样指定比较规则: 将两个大小写不同的字符全都转为大写或者小写。 然后再比较这两个字符对应的二进制数据。 这是一种稍微复杂一点点的比较规则，但是实际生活中的字符不止英文字符一种，比如我们的汉字有几万几十万之多，即便对于某一种字符集来说，比较两个字符大小的规则也可以制定出很多种。后面会介绍各种现实生活中用的字符集以及它们的一些比较规则。 一些重要的字符集不幸的是，这个世界太大了，不同的人制定出了好多种字符集，每个字符集表示的字符范围和用到的编码规则可能都不一样。我们看一下一些常用字符集的情况: ASCII字符集 字符范围：共收录128个字符包括空格、标点符号、数字、大小写字母 和一些不可⻅字符。 编码规则：由于总共才128个字符，所以可以使用1个字节来进行编码，我们简单看一下该字符集的编码方式:‘L’ -&gt; 01001100(十六进制:0x4C，十进制:76)‘M’ -&gt; 01001101(十六进制:0x4D，十进制:77) ISO 8859-1字符集这个字符集有一个别名 latin1 字符范围：共收录256个字符，是在ASCII字符集的基础上又扩充了128个⻄欧常用字符(包括德法两国的字母); 编码 方式/规则/方案：它也是使用1个字节来进行编码。 GB2312字符集 字符范围：收录了汉字以及拉丁字母、希腊字母、日文平假名及片假名字母、俄语⻄里尔字母。其中收录汉字6763个，其他文字符号682个。 编码规则：同时这种字符集又兼容ASCII字符集，所以在编码方式上显得有些奇怪: 如果该字符在ASCII字符集中，则采用1字节编码。 否则采用2字节编码。 这种表示一个字符需要的字节数可能不同的编码方式称为变⻓编码方式。比方说字符串’爱u’，其中’爱’需要用2个字节进行编码，编码后的十六进制表示为0xCED2;而’u’只需要用1个字节进行编码，编码后的十六进制表示为0x75;所以拼合起来就是0xCED275。 ⚠️ Tips:我们怎么区分某个字节代表一个单独的字符还是代表某个字符的一部分呢?别忘了ASCII字符集只收录128个字符，使用0127就可以表示全部字符(只用到了01111111 一个字节的前7位)，所以如果某个字节是在0127之内的(如果第8个字节是0)，就意味着一个字节代表一个单独的字符，否则就是两个字节代表一个单独的字符。 GBK字符集 字符范围： GBK字符集只是在收录字符范围上对GB2312字符集作了扩充； 编码方式: 兼容GB2312； utf8字符集 字符范围: 收录地球上能想到的所有字符，而且还在不断扩充。 编码方式: 这种字符集兼容ASCII字符集，采用变⻓编码方式，编码一个字符需要使用1~4个字节，比方说这样:‘L’ -&gt; 01001100(十六进制:0x4C)‘啊’ -&gt; 111001011001010110001010(十六进 制:0xE5958A) ⚠️ Tips:其实准确的说，utf8并不是一个字符集，它只是Unicode字符集的一种编码方案。Unicode字符集可以采用utf8、utf16、utf32这几种编码方案： utf8使用1~4个字节编码一个字符； utf16使用2个或4个字节编码一个字符； utf32使用4个字节编码一个字符。 更详细的Unicode和其编码方案的知识不是本书的重点，大家上网查查哈~ 虽然 编码方案 只是 字符集 内包含的一部分功能，但 MySQL中并不区分字符集和编码方案的概念，所以后边唠叨的时候把utf8、utf16、utf32都当作一种字符集对待。 小结字符集的概念包括字符范围和编码规则两部分功能；可以对字符集制定多种不同的比较规则； utf8并不是一个字符集，它只是Unicode字符集的一种编码方案； MySQL中并不区分字符集和编码方案的概念，所以后边唠叨的时候把 utf8、utf16、utf32都当作一种字符集&#96;对待。 MySQL中支持的字符集和排序规则MySQL中的 utf8 和 utf8mb4 我们上边说utf8字符集表示一个字符需要使用1~4个字节，但是我们常用的一些字符使用1~3个字节就可以表示了。而在MySQL中字符集表示一个字符所用最大字节⻓度在某些方面会影响系统的存储和性能，所以设计MySQL的大叔偷偷的定义了两个概念: utf8mb3: 阉割过的utf8字符集，只使用1~3个字节表示字符。 utf8mb4: 正宗的utf8字符集，使用1~4个字节表示字符。 有一点需要大家十分的注意，在MySQL中utf8是utf8mb3的别名，所以之后在MySQL中提到utf8就意味着使用1~3个字节来表示一个字符， 如果大家有使用4字节编码一个字符的情况，比如存储一些emoji表情啥的，那请使用utf8mb4 。 字符集的查看 MySQL支持好多好多种字符集，查看当前MySQL中支持的字符集可以用 SHOW (CHARSET) [LIKE 匹配的模式]; 这个语句:我们查询一下(支持的字符集太多了，我们省略了一些)，为了让大家的印象更深刻，下面把几个常用到的字符集的Maxlen列摘抄下来，大家务必记住: 字符集名称 Maxlen ascii 1 latin1 1 gb2312 2 gbk 2 utf8 3 utf8mb4 4 比较规则的查看 查看MySQL中支持的比较规则的命令为: SHOW COLLATION [LIKE 匹配的模式]; 我们前边说过一种字符集可能对应着若干种比较规则，MySQL支持的字符集就已经非常多了，所以支持的比较规则更多，我们先只查看一下utf8字符集下的比较规则:SHOW COLLATION LIKE &#39;utf8%&#39;; 每种字符集对应若干种比较规则，每种字符集都有一种默认的比较规则，SHOW COLLATION的返回结果中的Default列的值为YES的就是该字符集的默认比较规则，比方说utf8字符集默认的比较规则就是utf8_general_ci。 各级别的字符集和比较规则MySQL有4个级别的字符集和比较规则，分别是: 服务器级别 MySQL提供了两个系统变量来表示服务器级别的字符集和比较规则character_set_server 服务器级别的字符集 collation_server 服务器级别的比较规则 我们可以在启动服务器程序时通过启动选项或者在服务器程序运行过程中使用SET语句修改这两个变量的值。比如我们可以在配置文件中这样写:[server]character_set_server=gbkcollation_server=gbk_chinese_ci 数据库级别 我们在创建和修改数据库时可以指定该数据库的字符集和比较规则；如果想查看当前数据库使用的字符集和比较规则，可以查看下面两个系统变量的值；character_set_database 和 collation_database 这两个系统变量是只读的，我们不能通过修改这两个变量的值而改变当前数据库的 字符集和比较规则数据库的创建语句中也可以不指定字符集和比较规则，这样的话将使用服务器级别的字符集和比较规则作为数据库的字符集和比较规则； 表级别 我们也可以在创建和修改表的时候指定表的字符集和比较规则如果创建和修改表的语句中没有指明字符集和比较规则，将使用该表所在数据库的字符集和比较规则作为该表的字符集和比较规则 列级别 需要注意的是，对于存储字符串的列，同一个表中的不同的列也可以 有不同的字符集和比较规则。对于某个列来说，如果在创建和修改的语句中没有指明字符集和比较 规则，将使用该列所在表的字符集和比较规则作为该列的字符集和比 较规则。 客户端和服务器通信中的字符集 如果对于同一个字符串编码和解码使用的字符集不一样，会产生意想不到的结果，作为人类的我们看上去就像是产生了乱码一样。 我们知道从客户端发往服务器的请求本质上就是一个字符串，服务器向客户端返回的结果本质上也是一个字符串，而字符串其实是使用某种字符集编码的二进制数据。这个字符串可不是使用一种字符集的编码方式一条道走到黑的，从发送请求到返回结果这个过程中伴随着多次字符集的转换，在这个过程中会用到3个系统变量，我们先把它们写出来看一下: 系统变量 描述 character_set_client 服务器解码请求时使用的字符集 character_set_connection 服务器运行过程中使用的字符集 character_set_results 服务器向客户端返回数据时使用的字符集 我们通常都把 character_set_client 、character_set_connection、character_set_results 这三个 系统变量设置成和客户端使用的字符集一致的情况，这样减少了很多无谓的字符集转换。 为了方便我们设置，MySQL提供了一条非常简便的语句: SET NAMES 字符集名; 这一条语句产生的效果和下面这3条的效果是一样的:SET character_set_client = 字符集名;SET character_set_connection = 字符集名;SET character_set_results = 字符集名; 另外，如果你想在启动客户端的时候就把这三个系统变量的值设置成一样的，那我们可以在启动客户端的时候指定一个叫default-character-set的启动选项，比如在配置文件里可以这么写:[client]default-character-set=utf8它起到的效果和执行一遍 SET NAMES utf8 是一样一样的，都会将那三个系统变量的值设置成utf8。lant: 这怪方便，只用设置这个，mysql启动后，所有的客户端都连接上来都会先设置这三个系统变量…. 妥妥的无乱码喽","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"2. MySQL的启动选项和配置文件、系统变量、状态变量","date":"2021-09-14T13:17:21.000Z","path":"2021/09/14/MySQL知识点整理/2. MySQL的启动选项和配置文件、系统变量、状态变量/","text":"MySQL的启动选项 MySQL的 服务器程序 和 客户端程序 都有很多的设置项: 比如 MySQL服务器程序 可以指定像 允许同时连入的客户端数量、客户端和服务器通信方式、表的默认存储引擎、查询缓存的大小…等 设置项。 对于MySQL客户端程序，则可以指定像 需要连接的服务器程序所在主机的主机名或IP地址、用户名及密码等信息。 这些设置项一般都有各自的默认值，比方说服务器允许同时连入的客户端的默认数量是151，表的默认存储引擎是InnoDB。 我们可以在程序启动的时候去修改这些默认值，对于这种在程序启动时指定的设置项也称之为启动选项(startup options)，这些选项控制着程序启动后的行为。 在MySQL安装目录下的bin目录中的各种可执行文件，不论是服务器相关的程序(比如mysqld、mysqld_safe)还是客户端相关的程序(比如mysql、mysqladmin)， 在启动时基本都可以指定启动参数 。 这些启动参数可以放在命令行中指定，也可以把它们放在配置文件中指定。 下面会以`mysqld`为例，来详细唠叨如何指定`启动选项`。下边出现的`启动选项不`论大家认不认识，先不用去纠结每个选项具体的作用是啥，之后我们会对一些重要的启动选项详细唠叨。 在命令行上设置启动选项 通过上一篇的学习，我们已经知道，如果我们在启动客户端程序时在-h参数后边紧跟服务器的IP地址，这就意味着客户端和服务器之间需要通过TCP/IP网络进行通信（当然，如果ip指定的是 127.0.0.1，那也可能是通过 unix套接字进行通信）。 如果我们在启动服务器程序时，想禁止各客户端使用TCP&#x2F;IP网络与服务器程序进行通信，则可以在启动服务器程序的命令行里添加 skip-networking 启动选项，如: mysqld --skip-networking Tips：在命令行中指定启动选项时需要在选项名前加上 --前缀。如果选项名是由多个单词构成的，它们之间可以由短划线-连接起来，也可以使用下划线_连接起来，也就是说 skip-networking 和 skip_networking 表示的含义是相同的。 在按照上述命令启动服务器程序后，如果我们再使用mysql来启动客户端程序时，仍把服务器主机名指定为127.0.0.1(IP地址的形式)的话，就会显示连接失败。这就意味着我们指定的启动选项 skip-networking 生效了! 再举一个例子，我们前边说过如果在创建表的语句中没有显式指定表的存储引擎的话，则会默认使用InnoDB作为表的存储引擎。如果我们想改变表的默认存储引擎的话，可以这样写启动服务器的命令行: mysqld --default-storage-engine=MyISAM。这下，你再次建表时即便没有明确指定表的存储引擎，建表成功后通过 SHOW CREATE TABLE 表名\\G 会发现表已经是 MyISAM 引擎了。 小结：在启动服务器程序的命令行后边指定启动选项的通用格式是 --启动选项1[=值1] --启动选项2[=值2] ... --启动选项n[= 值n] 即，我们可以将多个启动选项写到一行，各个启动选项间用空白字符隔开，在每个启动选项名称前边添加--。对于不需要值的启动选项，比方说 skip-networking，它们就不需要指定对应的值。对于需要指定值的启动选项，比如default-storage-engine,我们在指定这个设置项的时候需要显式的指定它的值。 在命令行上指定有值的启动选项时，需要注意，选项名、=、选项值之间不可以有空白字符。 每个MySQL程序都有许多不同的启动选项。大多数程序提供了一个 --help 选项来查看该程序支持的全部启动选项以及它们的默认值。例如，使用 mysql --help 可以看到mysql程序支持的启动选项，mysqld_safe --help 可以看mysqld_safe程序支持的启动选项。查看mysqld支持的启动选项有些特别，需要使用 mysqld --verbose --help。 启动选项的⻓形式和短形式 我们前边提到的 skip-networking、default-storage-engine称之为⻓形式的选项，设计MySQL的大叔为了我们使用的方便，对于一些常用的选项提供了短形式，我们列举一些具有短形式的启动选项来瞅瞅(MySQL支持的短形式选项太多了，全列出来会刷屏的) ⻓形式 短形式 含义 host -h 主机名 –user -u 用户名 –password -p 密码 –port -P 端口 –version -V 版本信息 …… …… …… 短形式的选项名只有一个字母，与使用⻓形式选项时需要在选项名前加--前缀不同的是，使用短形式选项时在选项名前只加一个短划线-前缀。 使用短形式指定启动选项时，选项名和选项值之间可以无间隙，也可以用空白字符隔开(-p选项有些特殊，-p和密码值之间不能有空白字符)。(得了，无论 短形式 还是 长形式，选项名和选项值之间都别有空格就行了) 在配置文件中设置启动选项 在命令行中设置启动选项只对当次启动生效，下次重启程序时还得在启动命令行中加这些启动选项! 于是设计MySQL的大叔们提出 配置文件(也称为选项文件)的概念，我们把需要设置的启动选项都写在这个配置文件中，每次启动服务器时都从这个文件里加载相应的启动选项。由于这个配置文件可以⻓久的保存在计算机的硬盘里，所以只需我们配置一次，以后就都不用显式的把启动选项都写在启动命令行中了， 所以我们推荐使用配置文件的方式来设置启动选项 。 配置文件的路径: MySQL程序在启动时会寻找多个路径下的配置文件，这些路径有的是固定的，有的是可以在命令行指定的。根据操作系统的不同，配置文件的路径也有所不同，这里重点看下类unix系统。 在类UNIX操作系统中，MySQL会按照下列路径来寻找配置文件: 路径名 备注 说明 &#x2F;etc&#x2F;my.cnf &#x2F;etc&#x2F;mysql&#x2F;my.cnf SYSCONFDIR&#x2F;my.cnf SYSCONFDIR 表示在使用CMake构建MySQL时使用SYSCONFDIR选项指定的目录。默认情况下，这是位于编译安装目录下的etc目录。 $MYSQL_HOME&#x2F;my.cnf 特定于服务器的选项(仅限服务器) MYSQL_HOME是一个环境变量，该变量的值是我们自己设置的，我们想设置就设置，不想设置就不设置。该变量的值代表一个路径，我们可以在该路径下创建一个my.cnf配置文件。这个配置文件中只能放置关于启动服务器程序相关的选项(言外之意就是其他的配置文件既能存放服务器相关的选项也 能存放客户端相关的选项，.mylogin.cnf除外，它只能存放客户端相关的一些选项)。 defaults-extra-file 命令行指定的额外配置文件路径 ~&#x2F;.my.cnf 用户特定选项 ~&#x2F;.mylogin.cnf 用户特定的登录路径选项(仅限客户端) .mylogin.cnf 不是纯文本文件，只能使用mysql_config_editor实用程序去创建或修改，用于存放客户端登陆服务器时的相关选 项。 这也就是说，在我的计算机中这几个路径中的任意一个都可以当作配置文件来使用，如果它们不存在，你可以手动创建一个。 另外，我们在唠叨如何启动MySQL服务器程序的时候说过，使用mysqld_safe程序启动服务器时，会间接调用mysqld，所以对于传递给mysqld_safe的启动选项来说，如果mysqld_safe程序不处理，会接着传递给mysqld程序处理。比方说skip-networking选项是由mysqld处理的，mysqld_safe并不处理。 配置文件的内容:与在命令行中指定启动选项不同的是，配置文件中的启动选项被划分为若干个组，每个组有一个组名，用中括号[]扩起来，像这样: [server] (具体的启动选项...)[mysqld] (具体的启动选项...)[mysqld_safe] (具体的启动选项...)[client] (具体的启动选项...)[mysql] (具体的启动选项...)[mysqladmin] (具体的启动选项...) 每个组下边可以定义若干个启动选项，我们以[server]组为例来看一下填写启动选项的形式[server]option1 #这是option1，该选项不需要选项值option2 = value2 #这是option2，该选项需要选项值 ... 在配置文件中指定启动选项的语法类似于命令行语法，但是配置文件中只能使用⻓形式的选项。在配置文件中指定的启动选项不允许加--前缀，并且每行只指定一个选项，而且&#x3D;周围可以有空白字符。另外，在配置文件中，我们可以使用#来添加注释，从#出现直到行尾的内容都属于注释内容，读取配置文件时会忽略这些注释内容。 配置文件中不同的选项组是给不同的启动命令使用的，如果选项组名称与程序名称相同，则组中的选项将专⻔应用于该程序。例如，[mysqld] 和 [mysql] 组分别应用于mysqld服务器程序 和 mysql客户端程序。不过有两个选项组比较特别: [server]组下边的启动选项将作用于所有的服务器程序。 [client]组下边的启动选项将作用于所有的客户端程序。 不过， 需要注意的一点是，mysqld_safe和mysql.server这两个程序在启动时都会读取[mysqld]选项组中的内容。 为了直观感受一下，我们挑一些启动命令来看一下它们能读取的选项组都有哪些: 启动命令 类别 能读取的组 mysqld 启动服务器 [mysqld]、[server] mysqld_safe 启动服务 [mysqld]、[server]、[mysqld_safe] mysql.server 启动服务 [mysqld]、[server]、[mysql.server] mysql 启动客户端 [mysql]、[client] mysqladmin 启动客户端 [mysqladmin]、[client] mysqldump 启动客户端 [mysqldump]、[client] 特定MySQL版本的专用选项组我们可以在选项组的名称后加上特定的MySQL版本号，比如对于 [mysqld]选项组 来说，我们可以定义一个 [mysqld-5.7] 的选项组，它的含义和 [mysqld] 一样，只不过只有版本号为5.7的 mysqld程序才能使用这个选项组中的选项。 配置文件的优先级我们前边唠叨过MySQL将在某些固定的路径下搜索配置文件，我们也可以通过在命令行上指定defaults-extra-file启动选项 来指定额外的配置文件路径。MySQL将按照我们在上表中给定的顺序依次读取各个配置文件，如果该文件不存在则忽略。值得注意的是，如果我们在多个配置文件中设置了相同的启动选项，那以最后一个配置文件中的为准。 同一个配置文件中多个组的优先级我们说同一个命令可以访问配置文件中的多个组，比如mysqld可以访问[mysqld]、[server]组，如果在同一个配置文件中的这些组里出现了同样的配置项，比如:[server]default-storage-engine=InnoDB[mysqld]default-storage-engine=MyISAM那么，将以最后一个出现的组中的启动选项为准，因为[mysqld]组在[server]组后边，就以 [mysqld]组中的配置项为准。 defaults-file的使用如果我们不想让MySQL到默认的路径下搜索配置文件(就是上表中列出的那些)，则可以在命令行指定defaults-file选项比如：mysqld --defaults-file=/tmp/myconfig.txt，在程序启动的时候将只在&#x2F;tmp&#x2F;myconfig.txt路径下搜索配置文件。如果文件不存在或无法访问，则会发生错误。 Tips: 注意defaults-extra-file和defaults-file的区别使用defaults-extra-file可以指定额外的配置文件搜索路径 (也就是说那些固定的配置文件路径也会被搜索)。 命令行和配置文件中启动选项的区别在命令行上指定的绝大部分启动选项都可以放到配置文件中，但是有一些选项是专⻔为命令行设计的，比方说defaults-extra-file、defaults-file这样的选项本身就是为了指定配置文件路径的，再放在配置文件中使用就没啥意义了。剩下的一些只能用在命令行上而不能用到配置文件中的启动选项就不一一列举了，用到的时候再提。 另外有一点需要特别注意，如果同一个启动选项既出现在命令行中，又出现在配置文件中，那么以命令行中的启动选项为准! 系统变量简介 MySQL服务器程序运行过程中会用到许多影响程序行为的变量，它们被称为MySQL系统变量。 比如允许同时连入的客户端数量用系统变量 max_connections 表示 表的默认存储引擎用系统变量 default_storage_engine 表示 查询缓存的大小用系统变量 query_cache_size 表示 MySQL服务器程序的系统变量有好几百条，我们就不一一列举了。每个系统变量都有一个默认值，我们可以使用命令行或者配置文件中的选项在启动服务器时改变它们。 不过，大多数的系统变量的值也可以在程序运行过程中修改，而无需停止并重新启动它。 查看系统变量 可以使用 SHOW VARIABLES [LIKE 匹配的模式]; 命令查看MySQL服务器程序支持的系统变量以及它们的当前值:不过，由于系统变量实在太多了，如果我们直接使用 SHOW VARIABLES 查看的话就直接刷屏了，所以通常都会带一个LIKE过滤条件来查看我们需要的系统变量的值，比如:mysql&gt; SHOW VARIABLES LIKE ‘default_storage_engine’;+————————+——–+| Variable_name | Value |+————————+——–+| default_storage_engine | InnoDB |+————————+——–+1 row in set (0.01 sec) mysql&gt; SHOW VARIABLES like ‘max_connections’;+—————–+——-+| Variable_name | Value |+—————–+——-+| max_connections | 151 |+—————–+——-+1 row in set (0.00 sec) mysql&gt; 设置系统变量通过启动选项设置系统变量 大部分的系统变量都可以通过启动服务器时传送启动选项的方式来进行设置。如何填写启动选项我们上边已经花了大篇幅来唠叨了，就是下边两种方式: 通过命令行添加启动选项:比方说我们在启动服务器程序时用命令: mysqld --default-storage-engine=MyISAM --max-connections=10 通过配置文件添加启动选项:[server] default-storage-engine=MyISAM max-connections=10 有一点需要注意的是，对于启动选项来说，如果启动选项名由多个单词组成，各个单词之间用短划线-或者下划线_连接起来都可以，但是对应的 系统变量 之间必须使用下划线_连接起来。 服务器程序运行过程中设置系统变量 系统变量比较牛逼的一点就是，对于大部分系统变量来说，它们的值可以在服务器程序运行过程中进行动态修改而无需停止并重启服务器。不过系统变量有作用范围之分，下边详细唠叨下。 系统变量的不同作用范围我们前边说过，多个客户端程序可以同时连接到一个服务器程序。对于同一个系统变量，我们有时想让不同的客户端有不同的值。 比方说狗哥使用客户端A，他想让当前客户端对应的默认存储引擎为InnoDB，所以他可以把系统变量default_storage_engine的值设置为InnoDB; 猫爷使用客户端B，他想让当前客户端对应的默认存储引擎为MyISAM，所以他可以把系统变量default_storage_engine的值设置为MyISAM。这样可以使狗哥和猫爷的的客户端拥有不同的默认存储引擎，使用时互不影响，十分方便。但是这样各个客户端都私有一份系统变量会产生这么两个问题: 有一些系统变量并不是针对单个客户端的，比如允许同时连接到服务器的客户端数量max_connections，查询缓存的大小query_cache_size，这些公有的系统变量让某个客户端私有显然不合适。 一个新连接到服务器的客户端对应的系统变量的值该怎么设置? 为了解决这两个问题，设计MySQL的大叔提出了系统变量的作用范围的概念，具体来说作用范围分为这两种: GLOBAL:全局变量，影响服务器的整体操作。 SESSION:会话变量，影响某个客户端连接的操作。(注:SESSION有个别名叫LOCAL) 在服务器启动时，会将每个全局变量初始化为其默认值(可以通过命令行或配置文件中指定的选项更改这些默认值)。然后服务器还为每个连接的客户端维护一组会话变量，客户端的会话变量在连接时使用相应全局变量的当前值初始化。以default_storage_engine举例，在服务器启动时会初始化一个名为default_storage_engine，作用范围为GLOBAL的系统变量。之后每当有一个客户端连接到该服务器时，服务器都会单独为该客户端分配一个名为default_storage_engine，作用范围为SESSION的系统变量，该作用范围为SESSION的系统变量值按照当前作用范围为GLOBAL的同名系统变量值进行初始化。 服务器程序运行过程中设置系统变量了解了系统变量的GLOBAL和SESSION作用范围之后，我们再看一下在服务器程序运行期间通过客户端程序设置系统变量的语法:SET [GLOBAL|SESSION] 系统变量名 = 值;或者SET [@@(GLOBAL|SESSION).]var_name = XXX; 如果在设置系统变量的语句中省略了作用范围，默认的作用范围就是SESSION 查看不同作用范围的系统变量 既然系统变量有作用范围之分，那我们的SHOW VARIABLES语句查看的是什么作用范围的系统变量呢?答:默认查看的是SESSION作用范围的系统变量。 当然我们也可以在查看系统变量的语句上加上要查看哪个作用范围的系统变量，就像这样:SHOW [GLOBAL|SESSION] VARIABLES [LIKE 匹配的模式]; 如果某个客户端改变了某个系统变量在GLOBAL作用范围的值，并不会影响该系统变量在当前已经连接的客户端作用范围为 SESSION的值，只会影响后续连入的客户端在作用范围为 SESSION的值。 注意事项 并不是所有系统变量都具有GLOBAL和SESSION的作用范围 有一些系统变量只具有GLOBAL作用范围，比方说 max_connections，表示服务器程序支持同时最多有多少个客户端程序进行连接。 有一些系统变量只具有SESSION作用范围，比如 insert_id，表示插入值时使用的AUTO_INCREMENT修饰的列的值。 有一些系统变量的值既具有GLOBAL作用范围，也具有SESSION作用范围，比如我们前边用到的 default_storage_engine，而且其实大部分的系统变量都是这样的。 有些系统变量是只读的，并不能设置值。 比方说version，表示当前MySQL的版本，我们客户端是不能设置它的值的，只能在SHOW VARIABLES语句里查看。 启动选项和系统变量的区别启动选项是在程序启动时我们程序员传递的一些参数，而系统变量是影响服务器程序运行行为的变量，它们之间的关系如下: 大部分的系统变量都可以被当作启动选项传入; 有些系统变量是在程序运行过程中自动生成的，是不可以当作启动选项来设置，比如 auto_increment_offset、character_set_client啥的。 有些启动选项也不是系统变量，比如defaults-file。 状态变量为了让我们更好的了解服务器程序的运行情况，MySQL服务器程序中维护了好多关于程序运行状态的变量，它们被称为状态变量。比方说 Threads_connected 表示当前有多少客户端与服务器建立了连接，Handler_update表示已经更新了多少行记录吧啦吧啦，像这样显示服务器程序状态信息的状态变量还有好几百个，我们就不一一唠叨了，等遇到了会详细说它们的作用的。 由于状态变量是用来显示服务器程序运行状况的，所以它们的值只能由服务器程序自己来设置，我们程序员是不能设置的。与系统变量类似，状态变量也有GLOBAL和SESSION两个作用范围的，所以查看状态变量的语句可以这么写: 123456789101112131415SHOW [GLOBAL|SESSION] STATUS [LIKE 匹配的模式];// 类似的，如果我们不写明作用范围，默认的作用范围是SESSION// 如下， 所有以Thread开头的SESSION作用范围的状态变量就都被展示出来 了。mysql&gt; SHOW STATUS LIKE &#x27;thread%&#x27;;+-------------------+-------+| Variable_name | Value |+-------------------+-------+| Threads_cached | 1 || Threads_connected | 1 || Threads_created | 2 || Threads_running | 2 |+-------------------+-------+4 rows in set (0.00 sec)mysql&gt;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"1. 重新认识MySQL","date":"2021-09-12T05:01:09.000Z","path":"2021/09/12/MySQL知识点整理/1. 重新认识MySQL/","text":"MySQL的 客户端&#x2F;服务器架构我们日常使用MySQL的情景一般是: 启动 MySQL服务器程序； 启动 MySQL客户端程序 并连接到 MySQL服务器程序； 在 MySQL客户端程序 中输入一些 命令语句 作为请求发送到 MySQL服务器程序； MySQL服务器程序 收到这些请求后，会根据请求的内容来操作具体的数据并向 MySQL客户端程序 返回操作结果。 MySQL服务器程序 和 MySQL客户端程序 本质上都算是计算机上的一个进程，代表 MySQL服务器程序 的进程也被称为 MySQL数据库实例(简称数据库实例)； 每个进程都有一个唯一的编号，称为 进程ID，英文名叫PID， 这个编号是在我们启动程序的时候由操作系统 随机分配的，操作系统会保证在某一时刻同一台机器上的进程号不重复。 比如你打开了计算机中的QQ程序，那么操作系统会为它分配一个唯一的进程号；如果你把这个程序关掉了，那操作系统就会把这个进程号回收，之后可能会重新分配给别的进程。当我们下一次再启动QQ程序的时候分配的就可能是另一个编号。 每个进程都有一个名称，这个名称是编写程序的人自己定义的，比如我们启动的 MySQL服务器进程 的默认名称是 mysqld，而我们常用的MySQL客户端进程的默认名称为 mysql。 MySQL安装 小须知首先你要知道：无论我们通过 下载源代码自行编译安装的方式 还是 直接使用官方提供的安装包进行安装的方式。之后，MySQL的服务器程序和MySQL的客户端程序 都会被安装到我们的机器上。 Tips:MySQL的大部分安装包都包含了服务器程序和客户端程序，不过在Linux下使用 RPM包 安装时会有单独的 服务器RPM包 和 客户端RPM包，需要分别安装。 不论使用上述两者的哪种安装方式，一定要记住你的 MySQL的安装目录 。 在 MySQL的安装目录 下有一个特别特别重要的目录 bin目录 ，这个目录下存放着许多可执行文件。 启动MySQL服务器程序在 类UNIX系统 中，用来 启动MySQL服务器程序 的可执行文件有很多，大多都在 MySQL安装目录 的 bin目录 下。 mysqldmysqld 这个可执行文件就代表着 MySQL服务器程序，运行这个可执行文件就可以直接启动一个服务器进程。 但这个命令不常用，我们继续往下看更牛逼的启动命令。 mysqld_safemysqld_safe 是一个启动脚本: 它会间接的调用 mysqld ; 而且还顺便启动了另外一个 监控进程；这个 监控进程 在服务器进程挂了的时候，可以帮助重启它; 另外，它会将服务器程序的出错信息和其他诊断信息重定向到某个文件中，产生错误日志，方便我们找出发生错误的原因。 mysql.servermysql.server 也是一个启动脚本，它会间接的调用 mysqld_safe； 命令用法如下： 启动服务器程序 ：mysq.server start 停止服务器程序：mysq.server stop 需要注意的是，这个 mysql.server 文件其实是一个链接文件，它的实际文件是 ../support-files/mysql.server 。 我使用的macOS操作系统会帮我在bin目录下自动创建一个指向实际文件的链接文件，如果你的操作系统没有帮你自动创建这个链接文件，那就自己创建一个呗~ mysqld_multi 其实我们一台计算机上也可以运行多个MYSQL数据库实例。mysql_multi可执行文件 可以对每一个服务器进程的启动或停止进行监控。这个命令的使用比较复杂，本书主要是为了讲清楚MySQL服务器和客户端运行的过程，不会对启动多个服务器程序进行过多唠叨。 启动MySQL客户端程序 在成功启动MySQL服务器程序后，就可以接着启动MySQL客户端程序来连接到这个服务器。 bin目录下有许多客户端程序，比方说 mysqladmin、mysqldump、mysqlcheck 等等 (好多呢，就不一一列举了)。 这里我们重点要关注的是 可执行文件 mysql： 通过这个可执行文件可以让我们和服务器程序进程交互(也就是发送请求，接受服务器的处理结果)。 命令用法：&#x2F;&#x2F; 启动这个可执行文件时一般需要一些参数，格式如下:mysql -h主机名 -u用户名 -p密码 &#x2F;&#x2F; 如果我们想断开客户端与服务器的连接并且关闭客户端的话，&gt; 可以在 mysql&gt; 提示符后输入下边任意一个命令: quit exit \\q Tips:像 h、u、p 这样只有一个英文字母的参数称为 短形式的参数，使用时前边需要加单短划线;而像 host、user、password 这样大于一个英文字母的参数称为⻓形式的参数，使用时前边需要加 双短划线。 如果你愿意，你可以多打开几个终端窗口(每个黑框框都使用 mysql -hlocalhost -uroot -p123456)来运行多个 客户端程序，每个客户端程序 其实都是互不影响的。如果你有多个电脑，也可以试试把它们用局域网连起来，在一个电脑上启动 MySQL服务器程序，在另一个电脑上执行 mysql命令 使用IP地址作为主机名来连接到服务器。 客户端与服务器连接的过程我们现在已经知道如何启动 MySQL的服务器程序，以及如何启动 MySQL的客户端程序来连接到这个服务器程序。 运行着的服务器程序和客户端程序本质上都是计算机上的一个进程，所以客户端进程向服务器进程发送请求并得到回复的过程本质上是一个进程间通信的过程! MySQL支持下边三种客户端进程和服务器进程的通信方式: TCP&#x2F;IP真实环境中，数据库服务器进程 和 客户端进程 可能运行在不同的主机中，它们之间必须通过网络来进行通讯。 MySQL采用 TCP 作为服务器和客户端 之间的网络通信协议: 在网络环境下，每台计算机都有一个唯一的IP地址，如果某个进程有需要采用TCP协议进行网络通信方面的需求，可以向操作系统申请一个端口号，这是一个整数值，它的取值范围是0~65535。这样在网络中的其他进程就可以通过 IP地址 + 端口号的方式来与这个进程连接，这样进程之间就可以通过网络进行通信了。 MySQL服务器启动时会默认申请3306端口号(即，MySQL服务器会默认监听3306端口)，之后就在这个端口号上等待客户端进程进行连接。 Tips:&#x2F;&#x2F; 如果3306端口号已经被别的进程占用了或者我们单纯的想自定义该 数据库实例监听的端口号，那我们可以在启动服务器程序的命令行里添加 -P参数 来明确指定一下端口号，比如这样: mysqld -P3307&#x2F;&#x2F; 这样MySQL服务器在启动时就会去监听我们指定的端口号3307。 命名管道和共享内存如果你是一个Windows用户，那么客户端进程和服务器进程之间可以考虑使用命名管道或共享内存进行通信。 Unix域套接字文件如果我们的服务器进程和客户端进程都运行在 同一台 操作系统为 类Unix的机器上的话，我们可以使用Unix域套接字文件来进行进程间通信。 如果我们在启动客户端程序时指定的主机名为localhost，或者指定了--protocal=socket的启动参数，那服务器程序和客户端程序之间就可以通过Unix域套接字文件来进行通信了。 MySQL服务器程序默认监听的Unix域套接字文件路径为/tmp/mysql.sock，客户端程序也默认连接到这个Unix域套接字文件。 如果我们想改变这个默认路径，可以在启动服务器程序时指定socket参数，就像这样: mysqld --socket=/tmp/a.txt，这样服务器启动后便会监听/tmp/a.txt。 在服务器改变了默认的UNIX域套接字文件后，如果客户端程序想通过UNIX域套接字文件进行通信的话，也需要显式的指定连接到的UNIX域套接字文件路径，就像这样:mysql -hlocalhost -uroot --socket=/tmp/a.txt -p 这样该客户端进程和服务器进程就可以通过路径为/tmp/a.txt的Unix域套接字文件进行通信了。 服务器处理客户端请求 其实不论客户端进程和服务器进程是采用哪种方式进行通信，最后实现的效果都是:客户端进程向服务器进程发送一段文本(MySQL语句)，服务器进程处理后再向客户端进程返回一段文本(处理结果)。 那服务器进程对客户端进程发送的请求做了什么处理，才能产生最后的处理结果呢? 客户端可以向服务器发送增删改查各类请求，我们这里以比较复杂的查询请求为例来画个图展示一下大致的过程: 从图中可以看出，服务器程序处理来自客户端的查询请求大致需要经过三个部分，分别是 连接管理、解析与优化、 存储引擎 。下边我们来详细看一下这三个部分都干了什么。 📌连接管理 客户端进程 可以采用我们上边介绍的 TCP/IP、命名管道或共享内存、Unix域套接字 这几种方式之一来与 服务器进 程建立连接。 每当有一个客户端进程连接到服务器进程时，服务器进程都会创建一个线程来专⻔处理与这个客户端的交互； 当该客户端退出时会与服务器断开连接，服务器并不会立即把与该客户端交互的线程销毁掉，而是把它缓存起来； 在另一个新的客户端再进行连接时，服务器会把这个缓存的线程重新分配给该新客户端。 这样就起到了不频繁创建和销毁线程的效果，从而节省开销 。 从这一点大家也能看出， MySQL服务器会为每一个连接进来的客户端分配一个线程，但是线程分配的太多了会严重影响系统性能，所以我们也需要限制一下可以同时连接到服务器的客户端数量 ，至于怎么限制我们后边再说哈~ 在客户端程序发起连接的时候，需要携带 主机信息、用户名、密码，服务器程序会对客户端程序提供的这些信息进行认证，如果认证失败，服务器程序会拒绝连接。另外，如果客户端程序和服务器程序不运行在一台计算机上，我们还可以采用使用了SSL(安全套接字)的网络连接进行通信，来保证数据传输的安全性。 当连接建立后，与该客户端关联的服务器线程会一直等待客户端发送过来的请求，MySQL服务器接收到的请求只是一个文本消息，该文本消息还要经过各种处理，预知后事如何，继续往下看哈~ 解析与优化到现在为止，MySQL服务器已经获得了文本形式的请求，接着还要经过九九八十一难的处理，其中的几个比较重要的部分分别是 查询缓存、语法解析 和 查询优化，下边我们详细来看。 查询缓存 如果我问你 9+8×16-3×2×17 的值是多少，你可能会用计算器去算一下，或者牛逼一点用心算，最终得到了结果35，如果我再问你一遍 9+8×16-3×2×17 的值是多少，你还用再傻呵呵的算一遍么?我们 刚刚已经算过了，直接说答案就好了。 MySQL服务器程序处理查询请求的过程也是这样，会把刚刚处理过的查询请求和结果缓存起来，如果下一次有一模一样的请求过来，直接从缓存中查找结果就好了，就 不用再傻呵呵的去底层的表中查找了。 并且 这个查询缓存可以在不同客户端之间共享 ，也就是说如果客户端A刚刚查询了一个语句，而客户端B之后发送了同样的查询请求，那么客户端B的这次查询就可以直接使用查询缓存中的数据。 当然，MySQL服务器并没有人聪明: 如果两个查询请求在任何字符上的不同(例如:空格、注释、大小写)，都会导致缓存不会命中。 另外，如果查询请求中包含某些系统函数、用户自定义变量和函数、一些系统表，如 mysql 、information_schema、 performance_schema 数据库中的表，那这个请求就不会被缓存。 以某些系统函数举例，可能同样的函数的两次调用会产生不一样的结果，比如 函数NOW，每次调用都会产生最新的当前时间，如果在一个查询请求中调用了这个函数，那即使查询请求的文本信息都一样，那不同时间的两次查询也应该得到不同的结果，如果在第一次查询时就缓存了，那第二次查询的时候直接使用第一次查询的结果就是错误的! 而且，既然是缓存，那就有它缓存失效的时候。MySQL的缓存系统会监测涉及到的每张表，只要该表的结构或者数据被修改，如对该表使用了INSERT、 UPDATE、DELETE、TRUNCATE TABLE、ALTER TABLE、DROP TABLE或 DROP DATABASE 语句，那使用该表的所有高速缓存查询都将变为无效并从高速缓存中删除! 所以，虽然查询缓存有时可以提升系统性能，但也不得不因维护这块缓存而造成一些开销，比如每次都要去查询缓存中检索，查询请求处理完需要更新查询缓存，维护该查询缓存对应的内存区域。从MySQL 5.7.20开始，不推荐使用查询缓存，并在MySQL 8.0中删除。 语法解析 如果 查询缓存 没有命中，接下来就需要进入正式的 查询阶段 了。 但由于客户端程序 发送过来的请求只是一段文本而已，所以MySQL服务器程序首先要对这段文本做分析，判断请求的语法是否正确，然后从文本中将 要查询的表、各种查询条件 … 等信息都提取出来放到MySQL服务器内部使用的一些数据结构上来。⚠️ Tips:这个从指定的文本中提取出我们需要的信息本质上算是一个编译过程，涉及 词法解析、语法分析、语义分析 等阶段，这些问题不属于我们讨论的范畴，大家只要了解在处理请求的过程中需要这个步骤就好了。 📌 查询优化 语法解析之后，服务器程序获得到了需要的信息，比如 要查询的列是哪些，表是哪个，搜索条件是什么 等等…，但光有这些是不够的，因为我们写的MySQL语句执行起来效率可能并不是很高，MySQL的优化程序会对我们的语句做一些优化，如外连接转换为内连接、表达式简化、子查询转为连接吧啦吧啦的一堆东⻄。 优化的结果会 生成一个执行计划 ，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的。我们可以使用EXPLAIN语句来查看某个语句的执行计划，关于查询优化这部分的详细内容我们后边会仔细唠叨，现在你只需要知道在MySQL服务器程序处理请求的过程中有这么一个步骤就好了。 📌 存储引擎截止到服务器程序完成了查询优化为止，还没有真正的去访问真实的数据表。 MySQL服务器把数据的存储和提取操作都封装到了一个叫 存储引擎 的模块里 。 我们知道表是由一行一行的记录组成的， 但这只是一个逻辑上的概念，物理上如何表示 记录，怎么从表中读取数据，怎么把数据写入具体的物理存储器上? 这都是 存储引擎 负责的事情。 为了实现不同的功能，MySQL提供了各式各样的存储引擎，不同存储引擎管理的表具体的存储结构可能不同，采用的存取算法也可能不同 。 为了管理方便，人们把 连接管理、查询缓存、语法解析、查询优化 这些并不涉及真实数据存储的功能划分为MySQL server的功能。 而把真实存取数据的功能划分为存储引擎的功能。（各种不同的 存储引擎 向上边的 MySQL server层 提供统一的调用接口(也就是存储引擎 API)，包含了几十个底层函数，像”读取索引第一条内容”、”读取索引下一条内容”、”插入记录”等等。所以在MySQL server完成了查询优化后，只需按照生成的执行计划 调用 底层存储引擎 提供的API，获取到数据后返回给客户端就好了。 常用存储引擎MySQL支持非常多种存储引擎，我这先列举一些: 存储引擎 描述 ARCHIVE 用于数据存档(行被插入后不能再修改) BLACKHOLE 丢弃写操作，读操作会返回空内容 CSV 在存储数据时，以逗号分隔各个数据项 FEDERATED 用来访问远程表 InnoDB 具备外键支持功能的事务存储引擎 MEMORY 置于内存的表 MERGE 用来管理多个MyISAM表构成的表集合 MyISAM 主要的非事务处理存储引擎 NDB MySQL集群专用存储引 这么多我们怎么挑啊，哈哈，你多虑了，其实我们最常用的就是InnoDB 和 MyISAM，有时会提一下 Memory。其中InnoDB是MySQL默认的存储引擎，我们之后会详细唠叨这个存储引擎的各种功能。现在先看一下一些存储引擎对于某些功能的支持情况: Feature MyISAM Memory InnoDB Archive NDB B-tree indexes yes yes yes no no Clustered indexes no no yes no no Full-text search indexes yes no yes no no MVCC no no yes no no …… …… …… …… …… …… Hash indexes no yes no no yes 密密麻麻列了这么多，看的头皮都发麻了，达到的效果就是告诉你: 这玩意儿很复杂。其实这些东⻄大家没必要立即就给记住，列出来的目的就是想让大家明白不同的存储引擎支持不同的功能，有些重要的功能我们会在后边的唠叨中慢慢让大家理解的~ 查看、设置 存储引擎 我们可以用SHOW ENGINES;命令来查看当前服务器程序支持的存储引擎: Support列 表示该存储引擎是否可用; DEFAULT值 代表是当前服务器程序的默认存储引擎; Comment列 是对存储引擎的一个描述; Transactions列 代表该存储引擎是否支持事务处理; XA列 代表着该存储引擎是否支持分布式事务; (也许你并不知道什么是个事务、更别提分布式事务了，这些内容在后边的章节会详细唠叨，现在看个新鲜就得了) Savepoints列 代表着该列是否支持部分事务回滚。 设置表的存储引擎前边说过， 存储引擎是负责对表中的数据进行提取和写入工作的 ，我们可以为不同的表设置不同的存储引擎，也就是说 不同的表可以有不同的物理存储结构，不同的提取和写入方式 。 创建表时指定存储引擎 我们之前创建表的语句都没有指定表的存储引擎，那就会使用默认的存储引擎InnoDB。(查看表结构可以使用:show create tables 表名\\G)如果我们想显式的指定一下表的存储引擎，那可以这么写:CREATE TABLE 表名( 建表语句;) ENGINE = 存储引擎名称; 如果表已经建好了，我们也可以使用 ALTER TABLE 表名 ENGINE = 存储引擎名称; 这个语句来修改表的存储引擎。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"0. 重要知识点梳理","date":"2021-09-11T11:43:20.000Z","path":"2021/09/11/MySQL知识点整理/0. 初阶需要重点关注 InnoDB存储引擎 存储结构 的相关知识/","text":"InnoDB存储引擎 存储结构的相关知识 记录结构 ⻚结构 索引结构 表空间结构 索引优化(基于对索引结构的了解)查询优化Explain 执行计划分析redologundologMVCC锁","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://rymuscle.github.io/tags/MySQL/"}]},{"title":"HTTP 之 method","date":"2017-11-27T11:43:20.000Z","path":"2017/11/27/HTTP/4. method/","text":"PUT vs POST PUT: 替换资源; PUT 和 POST的区别: 在HTTP中, PUT被定义为 idempotent(幂等性) 的方法, POST则不是, 这是一个很重要的区别 应该用 PUT 还是 POST? 取决于这个REST服务的行为是否是idempotent(幂等)的 假如发送两个请求, 希望服务器端是产生两个新数据，那就说明这个服务不是idempotent的, 因为多次使用产生了副作用了, 那就应该使用 POST 方法; 但如果是希望后一个请求把第一个请求覆盖掉(这不正是修改么), 那这个服务就是idempotent的, 那就应该使用 PUT 方法; 虽然 POST 和 PUT 差别不大, 用错了也没关系, 但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦; POST POST: 上面已经提过了, POST是非幂等的; POST 和 PUT 都可以上传文件或者创建新信息, 但主要看你的REST服务行为是否是幂等的; PATCHPATCH不是HTTP标准方法的，服务端需要考虑客户端是否能够支持的问题; 对已有资源的操作: 用于对资源的 部分内容 进行更新 (例如更新某一个字段, 具体比如说只更新用户信息的电话号码字段); 而 PUT 则用于更新某个资源较完整的内容, 比如说用户要重填完整表单更新所有信息, 后台处理更新时可能只是保留内部记录ID不变; HEAD HEAD和 GET 本质是一样的, 区别在于如果使用HEAD, 响应体将不会被返回, 而仅仅返回HTTP头信息;比如: 欲判断某个资源是否存在, 我们通常使用GET, 但这里用HEAD则意义更加明确; GET比较简单, 直接获取资源; OPTIONS这个方法使用比较少, 它用于获取当前URL所支持的方法;若请求成功, 则它会在HTTP头中包含一个名为 Allow 的头, 值是服务器所支持的方法, 如 GET, POST;之前跨域相关博文 CORS方案 not-so-simple request 中的”预检”请求用的请求方法就是 OPTIONS; CONNECT要求用隧道协议连接代理, 如使用SSL TRACE~~未完待续 DELETE参考 PURGE非规范中定义的方法","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]},{"title":"认证与授权","date":"2017-11-25T13:12:54.000Z","path":"2017/11/25/HTTP/3. 认证与授权/","text":"认证 (Authentication) 和 授权 (Authorization) 的区别？这是一个绝大多数人都会混淆的问题。简单点说： 认证 (Authentication)： 你是谁 是验证您的身份的凭据（例如用户名&#x2F;用户ID和密码），通过这个凭据，系统得以知道你就是你，也就是说系统是否存在你这个用户。所以，Authentication 被称为身份&#x2F;用户验证。 401 Unauthorized : 表示 认证(Authentication) 类型的错误比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 授权 (Authorization)： 你有权限干什么 Authorization（授权） 发生在 Authentication（认证） 之后。它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。 403 Forbidden : 经常和401状态码混淆; 其实403表示的是 授权(Authotization) 类型的错误, 授权和认证的不同之处是: 小结通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限”这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。 Cookie Session 身份验证 Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 用户成功登陆系统，然后返回给客户端具有 SessionID 的 Cookie，只有用户向再后端发起请求的时候会把 SessionID 带上，这样后端就知道你的身份状态了。 使用 Session 的时候需要注意下面几个点： 依赖Session的关键业务一定要确保客户端开启了Cookie 注意Session的过期时间 如果没有Cookie的话Session还能用吗？一般是通过 Cookie 来保存 SessionID，假如你使用了 Cookie 保存 SessionID的方案的话，如果客户端禁用了Cookie，那么 Session就无法正常工作。但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将SessionID放在请求的 url 里面 https://javaguide.cn/?session_id=xxx 。这种方案可行，但是安全性和用户体验感降低。当然，你也可以对 SessionID 进行一次加密之后再传入后端。 Cookie 无法防止CSRF攻击，而token可以CSRF（Cross Site Request Forgery）一般被翻译为 跨站请求伪造 。简单来说就是用你的身份去发送一些对你不友好的请求。举个简单的例子： 小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了10000元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。&lt;a src&#x3D;http://www.mybank.com/Transfer?bankId=11&amp;money=10000&gt;科学理财，年盈利率过万&lt;&#x2F;&gt;上面也提到过，进行Session 认证的时候，我们一般使用 Cookie 来存储 SessionId, 当我们登陆后，后端生成一个SessionId放在Cookie中返回给客户端，服务端通过Redis或者其他存储工具记录保存着这个Sessionid，客户端登录以后每次请求都会带上这个SessionId，服务端通过这个SessionId来标识你这个人。如果别人通过 cookie拿到了 SessionId ，那他就可以代替你的身份访问系统了。而 Session 认证中，Cookie 中的 SessionId是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。 但是，我们使用 token 的话就不会存在这个问题，在我们登录成功获得 token 后，然后我们在前端通过某些方式会给每个发到后端的请求加上这个 token,这样就不会出现 CSRF 漏洞的问题。因为，即使你点击了某个非法链接发送请求到服务端，这个非法请求是无法自动携带 token 的，所以这个请求将是非法的。 ** 其实CSRF主要是利用浏览器会携带已登录的用户标识，来达到冒充用户的目的，从而对被攻击的网站执行某项操作。** 无论 Cookie 还是 token 都无法避免 跨站脚本攻击（Cross Site Scripting）XSS跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为XSS。XSS中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如cookie。 推荐阅读：如何防止CSRF攻击？—美团技术团队CSRF的特点： 攻击一般发起在第三方网站，而不是被攻击的网站。 攻击利用受害者在被攻击网站的登录凭证，冒充受害者提交操作；而不是直接窃取数据。 整个过程攻击者并不能获取到受害者的登录凭证，仅仅是“冒用”。 跨站请求可以用各种方式：图片URL、超链接、CORS、Form提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪。CSRF通常是跨域的，因为外域通常更容易被攻击者掌控(lant:也就是说，如果你的站点是跨域的，这个域最好有个一级域名的限制，否则其他网站都能钓鱼了)。但是如果本域下有容易被利用的功能，比如可以发图和链接的论坛和评论区，攻击可以直接在本域下进行，而且这种攻击更加危险。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]},{"title":"03. HTTP状态码详解","date":"2017-11-25T05:30:12.000Z","path":"2017/11/25/HTTP/2. status_code/","text":"1xx 101: 参考博文WebSocket简单示例分析 (做协议升级, 还会响应: Connection: Upgrade) 2xx Web API的设计与开发 P109 200 OK : 200码非常出名, 似乎没有对它进一步说明的必要; 201 Created : 当在服务器端创建数据成功时, 会返回201状态码; 也就是使用 POST 请求方法的场景 (如:用户登录后添加了新用户, 上传了图片等新创建数据的场景) 202 Accepted : 在异步处理客户端请求时, 它用来表示服务器端已经接受了来自客户端的请求, 但处理尚未结束; 在文件格式转换, 处理远程通知(Apple Push Notification等)这类很耗时的场景中, 如果等到所有处理都结束后才向客户端返回响应消息, 就会花费相当长的时间, 造成应用可用性不高; 这时采用的方法是服务器向客户端返回一次响应消息, 然后立刻开始异步处理。 202状态码就被用于告知客户端服务器端已经开始处理请求, 但整个处理过程尚未结束; 比如: 以LinkedIn的参与讨论的API为例如果成功参与讨论并发表意见, 服务器端通常会返回201状态码;但如果需要得到群主的确认, 那么所发表的意见就无法立即在页面显示出来, 这时服务器端就需要返回202状态码; 从广义上来看, 该场景也属于异步处理, 但和程序设计里的异步执行当然不同; 204 No Content : 正如其字面意思, 当响应消息为空时会返回该状态码。 其实就是告诉浏览器, 服务端执行成功了, 但是没什么数据返回给你, 所以你不用刷新页面, 也不用导向新的页面; 在用 DELETE 方法删除数据时, 服务器端通常会返回204状态码(阮一峰博文也提到过, 对DELETE适用); 除此之外, 也有人认为在使用 PUT或PATCH 方法更新数据时, 因为只是更新已有数据, 所以返回204状态码更加自然;书中建议 DELETE 返回204; PUT或PATCH返回200并返回该方法所操作的数据; 关于204状态码的讨论可以参考 p111; 205 Reset Content : 告诉浏览器, 页面表单需要被重置; 205的意思是服务端在接收了浏览器POST请求以后, 处理成功以后, 告诉浏览器, 执行成功了, 请清空用户填写的Form表单, 方便用户再次填写; 206 Partial Content : 成功执行了一个部分或Range(范围)的请求; 206响应中, 必须包含 Content-Range, Date 以及 ETag或Content-Location首部; 3xx300 Multiple Choices : 客户端驱动方式进行内容协商时, 服务器可能返回多个连接供客户端进行选择 (比如多语言网站可能会出现); 301 Moved Permanently : 在请求的URL已经被移除时使用, 响应的Location首部中应该包含资源现在所处的URL; (比较适合永久重定向) 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是301; 则即便稍后取消了location.php中的跳转(或者修改了跳转地址), 由于浏览器还是会认为你之前的跳转是永久性的, 再次访问www.test.com/location.php仍然会跳转到之前的跳转链接(除非清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 302 Found: 与301类似, 但是客户端应该使用Location首部给出的URL来进行临时定位资源, 将来的请求仍应该使用老的URL; 比如你从 www.test.com/location.php 中location跳转到 www.test.com/index.html 时, 如果响应的是302; 如果稍后取消了location.php中的跳转, 再次访问www.test.com/location.php, 会发现不会进行跳转, 而是访问到 location.php 修改后的代码 (不用清浏览器缓存); 另外, 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 会转成GET; 303 See Other : HTTP&#x2F;1.1使用303来实现和302一样的临时重定向; 307 Temporary Redirect HTTP&#x2F;1.1规范要求用307来取代302进行临时重定向; (302临时重定向留给HTTP&#x2F;1.0) 所以他也具备302临时重定向的特点; 但是, 与 302, 303 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 308 Permanent Redirect 貌似不是rfc2616的标准 具备和301永久重定向的特点, 需要清除浏览器缓存才行; 但是, 与 301 不同, 它会将客户端的POST请求, 发送给location的目标页; 假设你之前是先访问www.test.com/test.html, 然后通过post提交到www.test.com/location.php, 最后由location.php再进行跳转的话, 仍然是POST; 304 Not Modified : 参考博文缓存相关 4xx Web API的设计与开发 P1134字头状态码主要用于描述因客户端请求的问题而引发的错误。也就是说, 服务器端不存在问题, 但服务器端无法理解客户端发送的请求, 或虽然服务器端能够理解但请求却没有被执行, 当遇到这些情况引发的错误时, 服务器端便会向客户端返回这一类别的状态码。因此, 当服务器端返回4字头的状态码时, 就表示客户端的访问方式发生了问题, 用户需要检查一下客户端的访问方式或访问的目标资源等。 400 Bad Request : 表示其他错误的意思, 即其他4字头状态码都无法描述的错误类型; 401 Unauthorized : 表示认证(Authentication)类型的错误 比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 403 Forbidden : 和401状态码比较相似, 所以也经常被混淆; 其实403表示的是授权(Authotization)类型的错误, 授权和认证的不同之处是: 认证表示”识别前来访问的是谁”, 而授权则表示”赋予特定用户执行特定操作的权限” 通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限” 404 Not Found : 表示访问的数据不存在, 但是 例如当客户端湿度获取不存在的用户信息时, 或者试图访问原本就不存在的端点时, 服务器就会返回404状态码; 所以, 如果客户端想要获取用户信息, 却得到服务器端返回的404状态码, 客户端仅凭”404 Not Found”将难以区分究竟是用户不存在, 还是端点URI错误导致访问了原本不存在的URI; 405 Method Not Allowed : 表示虽然访问的端点存在, 但客户端使用的HTTP方法不被服务器端允许; 比如客户端使用了POST方法来访问只支持GET方法的信息检索专用的API; 又比如客户端用了GET方法来访问更新数据专用的API等; 406 Not Acceptable : 服务器端API不支持客户端指定的数据格式时, 服务器端所返回的状态码; 比如, 服务器端只支持JSON和XML输出的API被客户端指定返回YAML的数据格式时, 服务器端就会返回406状态码; 408 Request Timeout : 当客户端发送请求至服务器端所需的时间过长时, 就会触发服务器端的超时处理, 从而使服务器端返回该状态码; 409 Conflict: 用于表示资源发生冲突时的错误 (es中就会有该错误码) 比如通过指定ID等唯一键值信息来调用注册功能的API时, 倘若已有相同ID的数据存在, 就会导致服务器端返回409状态码; 在使用邮箱地址及Facebook ID等信息进行新用户注册时, 如果该邮箱地址或者ID已经被其他用户注册, 就会引起冲突, 这时服务器端就会返回409状态码告知客户端该邮箱地址或ID已被使用; 410 Gone : 和 404状态码 相同, 都表示访问资源不存在, 只是410状态码不单表示资源不存在, 还进一步告知资源曾经存在, 只是目前已经消失了; 因此服务器端常在访问被删除的数据时返回该状态码, 但是为了返回该状态码, 服务器必须保存该数据已被删除的信息, 而且客户端也应该知晓服务器端保存了这样的信息; 但是在通过邮箱地址搜索用户信息的API中, 从保护个人信息的角度来说, 返回410状态码的做法也会受到质疑; (所以在此种资源不存在的情况下, 为了稍微安全一些, 返回410状态码需要慎重) 413 Request Entity Too Large : 413也是比较容易出现的一种状态码, 表示请求实体过大而引发的错误 请求消息体过长是指, 比如在上传文件这样的API中, 如果发送的数据超过了所允许的最大值, 就会引发这样的错误; 414 Request-URI Too Large : 414是表示请求首部过长而引发的错误 如果在进行GET请求时, 查询参数被指定了过长的数据, 就会导致服务器端返回414状态码 415 Unsupported Media Type : 和406比较相似 406我们知道是表示服务器端不支持客户端想要接收的数据格式 而415表示的是服务器端不支持客户端请求首部 Content-Type 里指定的数据格式, 也就是说, 当客户端通过POST,PUT,PATCH等方法发送的请求消息体的数据格式不被服务器支持时, 服务器端就会返回415状态码; 例如在只接收JSON格式的API里, 如果客户端请求时发送的是XML格式的数据去请求服务器端, 或者在 Content-Type 首部指定 application/xml, 都会导致该类型错误; 429 Too Many Requests : 是2012年RFC6585文档中新定义的状态码, 表示访问次数超过了所允许的范围; 例如某API存在一小时内只允许访问100次的访问限制, 这种情况下入股哦客户端视图进行第101次访问, 服务器便会返回该状态码; 表示在一定的时间内用户发送了太多的请求, 即超出了”频次限制”, 在响应中，可以提供一个 Retry-After 首部来提示用户需要等待多长时间之后再发送新的请求; 5xx 5字头状态码表示错误不发生在客户端, 而是由服务器自身问题引发的。 500 Internal Server Error : 是web应用程序开发里非常常见的错误, 当服务器代码里存在bug, 输出错误信息并停止运行等情况下, 就会返回该类型的错误; 因此, 不仅限于API, 对于5字头状态码的错误, 都要认真监视错误日志, 使系统在出错时及时告知管理员, 以便在错误发生时做好应对措施, 防止再次发生。 501 Not Implemented : ??? 502 Bad GateWay : ??? 503 Service Unavaliable : 用来表示服务器当前处于暂不可用状态 可以回送:响应首部 Retry-After 表示多久恢复; 不同的客户端与服务器端应用对于 Retry-After 首部的支持依然不太一致; 不过，一些爬虫程序，比如谷歌的爬虫程序Googlebot, 会遵循Retry-After响应首部的规则, 将其与503(Service Unavailable,当前服务不存在)响应一起发送有助于互联网引擎做出判断,在宕机结束之后继续对网站构建索引。 参考:https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Retry-After 504 Gateway Time-out: 复现这个错误码比较简单, 让你的php程序模拟耗时请求, 如下代码 123&lt;?phpsleep(70);//模拟耗时，睡70秒echo &quot;睡醒了&quot;; 就会返回 12504 Gateway Time-outnginx/1.11.4505 HTTP Version Not Supported: 服务器收到的请求, 使用的是它无法支持的HTTP协议版本; 参考:《HTTP权威指南》、《Web API的设计与开发》","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]},{"title":"HTTP 之 同源策略SOP","date":"2017-11-24T15:01:19.000Z","path":"2017/11/24/HTTP/1. 同源策略/","text":"同源策略SOP浏览器安全的基石是”同源政策”（same-origin policy） 1995年，同源政策由 Netscape 公司引入浏览器。目前所有浏览器都实行这个政策; 简单来说，A站点设置的Cookie，B站点不能打开，除非这两个站点属同源，所谓同源指的是 “三个相同”: 协议相同http://blog.renyimin.com 和 https://blog.renyimin.com 就不是同一个源 ； 域名完全相同http://blog.renyimin.com/test/index.php 和 http://blog.renyimin.com/welcome/index.html 就是同一个源;但是 http://www.renyimin.com/test/index.php 和 http://blog.renyimin.com/test/index.php 就不是同一个源 ；localhost 和 127.0.0.1 也不是同一个源 ; 端口相同http://www.renyimin.com:8080/test/index.php 和 http://www.renyimin.com:80/test/index.php 就不是同一个源 ; 同源策略的限制随着互联网的发展, “同源政策”越来越严格, 目前, 如果非同源, 共有三种行为受到限制: Cookie、LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求不能发送 同源策略目的为了保证用户信息的安全，防止恶意的网站窃取并利用数据 比如用户登录一家银行网站后，又去浏览其他站点, 如果没有同源策略限制, 其他站点就也能读取银行网站的 Cookie, 这样的话，如果 Cookie 包含用户的私密信息，泄漏给第三方站点就比较危险, 当然, Cookie中包含的敏感信息通常经过加密，很难将其反向破解, 但这并不意味着绝对安全;虽然第三方无法通过解密获取cookie中的信息, 但它可以不解密,而是直接使用Cookie去骗取银行网站的信任;由此可见，”同源政策” 是必需的，否则, 各站点的 Cookie 可以随便共享，那互联网就毫无安全可言了; 同源策略和CSRF安全问题需要注意一点: 同源策略的限制, 并没有限制住CSRF攻击 假如你当前已经登录了邮箱，或bbs，同时你又访问了另外一个站点，假设这就是一个钓鱼网站(站点中伪装了很多诱导用户去点击的超链接, 而这些超链接都是其他站点的一些敏感操作, 就这样放好诱饵等待曾经登陆过那些站点的用户去点击, 等鱼儿上钩);假设这个网站上面可能因为某个图片吸引你，你去点击一下，而这个点击正是去往你的bbs站点进行一个发帖操作，由于当前你的浏览器状态已经是登陆了bbs站点，此时你点击这个钓鱼网站的连接是就会使用你之前登陆bbs站点在浏览器cookie罐中保存的信息, 就和正常的请求一样。于是钓鱼站点就纯天然的利用了其他站点的登陆状态，让用户在不知情的情况下，帮“它们”发帖或干其他更多危险的事情; 这也就是我们通常所说的CSRF攻击, CSRF攻击的主要目的是用户在不知情的情况下无辜使用自己在某个已登录系统的cookie信息，执行一个对自己有害的操作; 引出跨域问题由于同源策略的这些限制都是为了安全考虑, 自然是必要的; 但是有时很不方便, 可能会导致合理的用途也受到影响, 接下来将详细介绍如何在需要的时候合理地去 规避”同源政策”的限制; 参考https://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html 认证 (Authentication) 和 授权 (Authorization) 的区别？这是一个绝大多数人都会混淆的问题。简单点说：认证 (Authentication)： 你是谁是验证您的身份的凭据（例如用户名&#x2F;用户ID和密码），通过这个凭据，系统得以知道你就是你，也就是说系统是否存在你这个用户。所以，Authentication 被称为身份&#x2F;用户验证。 401 Unauthorized : 表示 认证(Authentication) 类型的错误比如当需要先进行登录操作, 而却没有告诉服务器端所需的会话信息(比如token..), 服务器端就会返回401状态码, 告知客户端出错的大致原因; 授权 (Authorization)： 你有权限干什么Authorization（授权） 发生在 Authentication（认证） 之后。它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。 403 Forbidden : 经常和401状态码混淆; 其实403表示的是 授权(Authotization) 类型的错误, 授权和认证的不同之处是:通俗地说: 401状态码表示”我不知道你是谁”, 403状态码表示”虽然知道你是谁, 但你没有执行该操作的权限” 这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。 Cookie Session 身份验证Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 用户成功登陆系统，然后返回给客户端具有 SessionID 的 Cookie，只有用户向再后端发起请求的时候会把 SessionID 带上，这样后端就知道你的身份状态了。 使用 Session 的时候需要注意下面几个点：依赖Session的关键业务一定要确保客户端开启了Cookie注意Session的过期时间 如果没有Cookie的话Session还能用吗？一般是通过 Cookie 来保存 SessionID，假如你使用了 Cookie 保存 SessionID的方案的话，如果客户端禁用了Cookie，那么 Session就无法正常工作。但是，并不是没有 Cookie 之后就不能用 Session 了，比如你可以将SessionID放在请求的 url 里面 https://javaguide.cn/?session_id=xxx 。这种方案可行，但是安全性和用户体验感降低。当然，你也可以对 SessionID 进行一次加密之后再传入后端。 Cookie 无法防止CSRF攻击，而token可以CSRF（Cross Site Request Forgery）一般被翻译为 跨站请求伪造 。简单来说就是用你的身份去发送一些对你不友好的请求。举个简单的例子：小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了10000元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。&lt;a src&#x3D;http://www.mybank.com/Transfer?bankId=11&amp;money=10000&gt;科学理财，年盈利率过万&lt;&#x2F;&gt;上面也提到过，进行Session 认证的时候，我们一般使用 Cookie 来存储 SessionId, 当我们登陆后后端生成一个SessionId放在Cookie中返回给客户端，服务端通过Redis或者其他存储工具记录保存着这个Sessionid，客户端登录以后每次请求都会带上这个SessionId，服务端通过这个SessionId来标识你这个人。如果别人通过 cookie拿到了 SessionId ，那他就可以代替你的身份访问系统了。而 Session 认证中，Cookie 中的 SessionId是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。 但是，我们使用 token 的话就不会存在这个问题，在我们登录成功获得 token 之后，一般会选择存放在 local storage 中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 token,这样就不会出现 CSRF 漏洞的问题。因为，即使你点击了某个非法链接发送请求到服务端，这个非法请求是无法自动携带 token 的，所以这个请求将是非法的。 其实CSRF主要是利用浏览器会携带已登录的用户标识，来达到冒充用户的目的，从而对被攻击的网站执行某项操作。 无论 Cookie 还是 token 都无法避免 跨站脚本攻击（Cross Site Scripting）XSS跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为XSS。XSS中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如cookie。 推荐阅读：如何防止CSRF攻击？—美团技术团队CSRF的特点： 攻击一般发起在第三方网站，而不是被攻击的网站。被攻击的网站无法防止攻击发生。 攻击利用受害者在被攻击网站的登录凭证，冒充受害者提交操作；而不是直接窃取数据。 整个过程攻击者并不能获取到受害者的登录凭证，仅仅是“冒用”。 跨站请求可以用各种方式：图片URL、超链接、CORS、Form提交等等。部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪。CSRF通常是跨域的，因为外域通常更容易被攻击者掌控。但是如果本域下有容易被利用的功能，比如可以发图和链接的论坛和评论区，攻击可以直接在本域下进行，而且这种攻击更加危险。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"http://rymuscle.github.io/tags/HTTP/"}]}]