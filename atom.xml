<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>rymuscle的技术博客</title>
  
  <subtitle>一切美好都如约而至!</subtitle>
  <link href="http://rymuscle.github.io/atom.xml" rel="self"/>
  
  <link href="http://rymuscle.github.io/"/>
  <updated>2024-04-26T10:52:48.836Z</updated>
  <id>http://rymuscle.github.io/</id>
  
  <author>
    <name>Rymuscle</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>05.支撑 TCP 协议的基石 —— 剖析首部字段</title>
    <link href="http://rymuscle.github.io/2022/01/25/TCP/05.%E6%94%AF%E6%92%91TCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%9F%BA%E7%9F%B3--%E5%89%96%E6%9E%90%E9%A6%96%E9%83%A8%E5%AD%97%E6%AE%B5/"/>
    <id>http://rymuscle.github.io/2022/01/25/TCP/05.%E6%94%AF%E6%92%91TCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%9F%BA%E7%9F%B3--%E5%89%96%E6%9E%90%E9%A6%96%E9%83%A8%E5%AD%97%E6%AE%B5/</id>
    <published>2022-01-25T14:03:16.000Z</published>
    <updated>2024-04-26T10:52:48.836Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章来讲讲 TCP 报文首部相关的概念，这些头部是支撑 TCP 复杂功能的基石。 完整的 TCP 头部如下图所示<br><img src="/images/tcp/05/1.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>我们用一次访问百度网页抓包的例子来开始。<br><code>curl -v www.baidu.com</code><br>完整的抓包文件可以来 github 下载：curl_baidu.pcapng<br><img src="/images/tcp/05/2.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><h1 id="源端口号、目标端口号"><a href="#源端口号、目标端口号" class="headerlink" title="源端口号、目标端口号"></a>源端口号、目标端口号</h1><p>在第一个包的详情中，首先看到的高亮部分的源端口号（Src Port）和目标端口号（Dst Port)，这个例子中本地源端口号为 61024，百度目标端口号是 80。<br><img src="/images/tcp/05/3.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>TCP 报文头部里没有源 ip 和目标 ip 地址，只有源端口号和目标端口号</p><p>这也是初学 wireshark 抓包时很多人会有的一个疑问：过滤 ip 地址为 172.19.214.24 包的条件为什么不是 “tcp.addr &#x3D;&#x3D; 172.19.214.24”，而是 “ip.addr &#x3D;&#x3D; 172.19.214.24”<br>TCP 的报文里是没有源 ip 和目标 ip 的，因为那是 IP 层协议的事情，TCP 层只有源端口和目标端口。<br><img src="/images/tcp/05/4.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><p>源 IP、源端口、目标 IP、目标端口构成了 TCP 连接的「四元组」。一个四元组可以唯一标识一个连接。</p><p>后面文章中专门有一节是用来介绍端口号相关的知识。</p><p>接下来，我们看到的是序列号，如截图中 2 的标识。</p><h1 id="序列号（Sequence-number）"><a href="#序列号（Sequence-number）" class="headerlink" title="序列号（Sequence number）"></a>序列号（Sequence number）</h1><p>TCP 是面向字节流的协议，通过 TCP 传输的字节流的每个字节都分配了序列号，序列号（Sequence number）指的是本报文段第一个字节的序列号。<br><img src="/images/tcp/05/5.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>序列号加上报文的长度，就可以确定传输的是哪一段数据。序列号是一个 32 位的无符号整数，达到 2^32-1 后循环到 0。</p><p>在 SYN 报文中，序列号用于交换彼此的初始序列号，在其它报文中，序列号用于保证包的顺序。</p><p>因为网络层（IP 层）不保证包的顺序，TCP 协议利用序列号来解决网络包乱序、重复的问题，以保证数据包以正确的顺序组装传递给上层应用。</p><p>如果发送方发送的是四个报文序列号分别是1、2、3、4，但到达接收方的顺序是 2、4、3、1，接收方就可以通过序列号的大小顺序组装出原始的数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这篇文章来讲讲 TCP 报文首部相关的概念，这些头部是支撑 TCP 复杂功能的基石。 完整的 TCP 头部如下图所示&lt;br&gt;&lt;img src=&quot;/images/tcp/05/1.awebp&quot; width=&quot;500&quot; style=&quot;margin-left:0px;border</summary>
      
    
    
    
    <category term="TCP 读书笔记" scheme="http://rymuscle.github.io/categories/TCP-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="TCP" scheme="http://rymuscle.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>04.来自 Google 的协议栈测试神器 —— packetdrill</title>
    <link href="http://rymuscle.github.io/2022/01/24/TCP/04.%E6%9D%A5%E8%87%AA%20Google%20%E7%9A%84%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%B5%8B%E8%AF%95%E7%A5%9E%E5%99%A8%20packetdrill/"/>
    <id>http://rymuscle.github.io/2022/01/24/TCP/04.%E6%9D%A5%E8%87%AA%20Google%20%E7%9A%84%E5%8D%8F%E8%AE%AE%E6%A0%88%E6%B5%8B%E8%AF%95%E7%A5%9E%E5%99%A8%20packetdrill/</id>
    <published>2022-01-24T13:17:36.000Z</published>
    <updated>2024-04-26T10:47:21.664Z</updated>
    
    <content type="html"><![CDATA[<p>从大学开始懵懵懂懂粗略学习（死记硬背）了一些 TCP 协议的内容，到工作多年以后，一直没有找到顺手的<code>网络协议栈调试工具</code>，对于纷繁复杂 TCP 协议。<br>业界流行的 scapy 不是很好用，有很多局限性。直到前段时间看到了 Google 开源的 <code>packetdrill</code>，真有一种相见恨晚的感觉。<br>这篇文章讲介绍 packetdrill 的基本原理和用法。</p><p>packetdrill 在 2013 年开源，在 Google 内部久经考验，Google 用它发现了 10 余个 Linux 内核 bug，同时用测试驱动开发的方式开发新的网络特性和进行回归测试，确保新功能的添加不影响网络协议栈的可用性。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>以 centos7 为例</p><ol><li>首先从 github 上 clone 最新的源码 <code>github.com/google/pack…</code></li><li>进入源码目录 <code>cd gtests/net/packetdrill</code></li><li>安装 bison 和 flex 库：<code>sudo yum install -y bison flex</code></li><li>为避免 offload 机制对包大小的影响，修改 netdev.c 注释掉 set_device_offload_flags 函数所有内容</li><li>执行 .&#x2F;configure</li><li>修改 Makefile，去掉第一行的末尾的 -static</li><li>执行 make 命令编译</li><li>确认编译无误地生成了 packetdrill 可执行文件</li></ol><h1 id="初体验"><a href="#初体验" class="headerlink" title="初体验"></a>初体验</h1><p>packetdrill 脚本采用 c 语言和 tcpdump 混合的语法。脚本文件名一般以 .pkt 为后缀，执行脚本的方式为 <code>sudo ./packetdrill test.pkt</code></p><p>脚本的每一行可以由以下几种类型的语句构成：</p><ul><li>执行系统调用（system call），对比返回值是否符合预期</li><li>把数据包（packet）注入到内核协议栈，模拟协议栈收到包</li><li>比较内核协议栈发出的包与预期是否相符</li><li>执行 shell 命令</li><li>执行 python 命令</li></ul><p>脚本每一行都有一个时间参数用来表明执行的时间或者预期事件发生的时间，packetdrill 支持绝对时间和相对时间。绝对时间就是一个简单的数字，相对时间会在数字前面添加一个+号。比如下面这两个例子</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 300ms 时执行 accept 调用</span><br><span class="line">0.300 accept(3, ..., ...) = 4</span><br><span class="line"></span><br><span class="line">// 在上一行语句执行结束 10ms 以后执行</span><br><span class="line">+.010 write(4, ..., 1000) = 1000`</span><br></pre></td></tr></table></figure><p>如果预期的事件在指定的时间没有发生，脚本执行会抛出异常，由于不同机器的响应时间不同，所以 packetdrill 提供了参数（–tolerance_usecs）用来设置误差范围，默认值是 4000us（微秒），也即 4ms。这个参数默认值在 config.c 的 set_default_config 函数里进行设置config-&gt;tolerance_usecs &#x3D; 4000;</p><p>我们以一个最简单的 demo 来演示 packetdrill 的用法。乍一看很懵，容我慢慢道来</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1 0   socket(..., SOCK_STREAM, IPPROTO_TCP) = 3</span><br><span class="line">2 +0  setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0</span><br><span class="line">3 +0  bind(3, ..., ...) = 0</span><br><span class="line">4 +0  listen(3, 1) = 0</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7 +0  &lt; S 0:0(0) win 4000 &lt;mss 1000&gt;</span><br><span class="line">8 +0  &gt; S. 0:0(0) ack 1 &lt;...&gt;</span><br><span class="line">9 +.1 &lt; . 1:1(0) ack 1 win 1000</span><br><span class="line">10</span><br><span class="line">11 +0 accept(3, ..., ...) = 4</span><br><span class="line">12 +0 &lt; P. 1:201(200) win 4000</span><br><span class="line">13 +0 &gt; . 1:1(0) ack 201</span><br></pre></td></tr></table></figure><p>第 1 行：0 socket(…, SOCK_STREAM, IPPROTO_TCP) &#x3D; 3<br>在脚本执行的第 0s 创建一个 socket，使用的是系统调用的方式，socket 函数的签名和用法如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/socket.h&gt;</span><br><span class="line">int socket(int domain, int type, int protocol);</span><br><span class="line"></span><br><span class="line">成功时返回文件描述符，失败时返回 -1</span><br><span class="line">int socket_fd = socket(AF_INET, SOCK_STREAM, 0);</span><br></pre></td></tr></table></figure><ul><li>domain 表示套接字使用的协议族信息，IPv4、IPv6等。AF_INET 表示 IPv4 协议族，AF_INET6 表示 IPv6 协议族。绝大部分使用场景下都是用 AF_INET，即 IPv4 协议族</li><li>type 表示套接字数据传输类型信息，主要分为两种：面向连接的套接字（SOCK_STREAM）和面向无连接报文的套接字（SOCK_DGRAM）。众所周知，SOCK_STREAM 默认协议是 TCP，SOCK_DGRAM 的默认协议是 UDP。</li><li>protocol 这个参数通常是 0，表示为给定的协议族和套接字类型选择默认协议。</li></ul><p>在 packetdrill 脚本中用 … 来表示当前参数省略不相关的细节信息，使用 packetdrill 程序的默认值。</p><p>脚本返回新建的 socket 文件句柄，这里用&#x3D;来断言会返回3，因为linux 在每个程序开始的时刻，都会有 3 个已经打开的文件句柄，分别是：标准输入stdin(0)、标准输出stdout(1)、错误输出stderr(2) 默认的，其它新建的文件句柄则排在之后，从 3 开始。</p><img src="/images/tcp/04/1.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2 +0  setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0</span><br><span class="line">3 +0  bind(3, ..., ...) = 0</span><br><span class="line">4 +0  listen(3, 1) = 0</span><br></pre></td></tr></table></figure>第 2 行：调用 setsockopt 函数设置端口重用。第 3 行：调用 bind 函数，这里的 socket 地址省略会使用默认的端口 8080，第一个参数 3 是套接字的 fd第 4 行：调用 listen 函数，第一个参数 3 也是套接字 fd 到此为止，socket 已经可以接受客户端的 tcp 连接了。第 7 ~ 9 行是经典的三次握手，packetdrill 的语法非常类似 tcpdump 的语法<p><code>&lt;</code> 表示输入的数据包（input packets)， packetdrill 会构造一个真实的数据包，注入到内核协议栈。比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 构造 SYN 包注入到协议栈</span><br><span class="line">+0  &lt; S 0:0(0) win 32792 &lt;mss 1000,sackOK,nop,nop,nop,wscale 7&gt;</span><br><span class="line">// 构造 icmp echo_reply 包注入到协议栈</span><br><span class="line">0.400 &lt; icmp echo_reply</span><br></pre></td></tr></table></figure><p><code>&gt;</code> 表示预期协议栈会响应的包（outbound packets），这个包不是 packetdrill 构造的，是由协议栈发出的，packetdrill 会检查协议栈是不是真的发出了这个包，如果没有，则脚本报错停止执行。比如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// 调用 write 函数调用以后，检查协议栈是否真正发出了 PSH+ACK 包</span><br><span class="line">+0  write(4, ..., 1000) = 1000</span><br><span class="line">+0  &gt; P. 1:1001(1000) ack 1</span><br><span class="line"></span><br><span class="line">// 三次握手中过程向协议栈注入 SYN 包以后，检查协议栈是否发出了 SYN+ACK 包以及 ack 是否等于 1</span><br><span class="line">0.100 &lt; S 0:0(0) win 32792 &lt;mss 1000,nop,wscale 7&gt;</span><br><span class="line">0.100 &gt; S. 0:0(0) ack 1 &lt;mss 1460,nop,wscale 6&gt;</span><br></pre></td></tr></table></figure><img src="/images/tcp/04/2.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><p>第 7 行：+0 &lt; S 0:0(0) win 1000 &lt;mss 1000&gt;</p><p>packetdrill 构造一个 SYN 包发送到协议栈，它使用与 tcpdump 类似的相对 sequence 序号，S 后面的三个 0 ，分别表示发送包的起始 seq、结束 seq、包的长度。比如P. 1:1001(1000)表示发送的包起始序号为 1，结束 seq 为 1001，长度为1000。紧随其后的 win 表示发送端的接收窗口大小 1000。依据 TCP 协议，SYN 包也必须带上自身的 MSS 选项，这里的 MSS 大小为 1000</p><p>第 8 行：+0 &gt; S. 0:0(0) ack 1 &lt;…&gt;</p><p>预期协议栈会立刻回复 SYN+ACK 包，因为还没有发送数据，所以包的 seq开始值、结束值、长度都为 0，ack 为上次 seq + 1，表示第一个 SYN 包已收到。</p><p>第 9 行：+.1 &lt; . 1:1(0) ack 1 win 1000</p><p>0.1s 以后注入一个 ACK 包到协议栈，没有携带数据，包的长度为 0，至此三次握手完成，过程如下图<br><img src="/images/tcp/04/3.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><p>+0 accept(3, …, …) &#x3D; 4 accept 系统调用返回了一个值为 4 的新的文件 fd，这时 packetdrill 可以往这个 fd 里面写数据了</p><p>+0 write(4, …, 10)&#x3D;10<br>+0 &gt; P. 1:11(10) ack 1<br>+.1 &lt; . 1:1(0) ack 11 win 1000<br>packetdrill 调用 write 函数往 socket 里写了 10 字节的数据，协议栈立刻发出这 10 个字节数据包，同时把 PSH 标记置为 1。这个包的起始 seq 为 1，结束 seq 为 10，长度为 10。100ms 以后注入 ACK 包，模拟协议栈收到 ACK 包。</p><p>整个过程如下<br><img src="/images/tcp/04/4.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>采用 tcpdump 对 8080 端口进行抓包，结果如下</p><p>sudo tcpdump -i any port 8080 -nn<br>10:02:36.591911 IP 192.0.2.1.37786 &gt; 192.168.31.139.8080: Flags [S], seq 0, win 4000, options [mss 1000], length 0<br>10:02:36.591961 IP 192.168.31.139.8080 &gt; 192.0.2.1.37786: Flags [S.], seq 2327356581, ack 1, win 29200, options [mss 1460], length 0<br>10:02:36.693785 IP 192.0.2.1.37786 &gt; 192.168.31.139.8080: Flags [.], ack 1, win 1000, length 0<br>10:02:36.693926 IP 192.168.31.139.8080 &gt; 192.0.2.1.37786: Flags [P.], seq 1:11, ack 1, win 29200, length 10<br>10:02:36.801092 IP 192.0.2.1.37786 &gt; 192.168.31.139.8080: Flags [.], ack 11, win 1000, length 0</p><h1 id="packetdrill-原理简述"><a href="#packetdrill-原理简述" class="headerlink" title="packetdrill 原理简述"></a>packetdrill 原理简述</h1><p>在脚本的最后一行，加上<br>+0 <code>sleep 1000000</code><br>让脚本执行完不要退出，执行 ifconfig 可以看到，比没有执行脚本之前多了一个虚拟的网卡 tun0。<br><img src="/images/tcp/04/5.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>packetdrill 就是在执行脚本前创建了一个名为 tun0 的虚拟网卡，脚本执行完，tun0 会被销毁。该虚拟网卡对应于操作系统中&#x2F;dev&#x2F;net&#x2F;tun文件，每次程序通过 write 等系统调用将数据写入到这个文件 fd 时，这些数据会经过 tun0 这个虚拟网卡，将数据写入到内核协议栈，read 系统调用读取数据的过程类似。协议栈可以向操作普通网卡一样操作虚拟网卡 tun0。</p><p>关于 linux 下 tun 的详细使用介绍，可以参考 IBM 的文章 <a href="http://www.ibm.com/developerwo%E2%80%A6">www.ibm.com/developerwo…</a></p><h1 id="把-packetdrill-命令加到环境变量里"><a href="#把-packetdrill-命令加到环境变量里" class="headerlink" title="把 packetdrill 命令加到环境变量里"></a>把 packetdrill 命令加到环境变量里</h1><p>把 packetdrill 加入到环境变量里以便于可以在任意目录可以执行。第一步是修改&#x2F;etc&#x2F;profile或者.zshrc（如果你用的是最好用的 zsh 的话）等可以修改环境变量的文件。</p><p>export PATH&#x3D;&#x2F;path_to_packetdrill&#x2F;:$PATH</p><p>source ~&#x2F;.zshrc<br>在命令行中输入 packetdrill 如果有输出 packetdrill 的 usage 文档说明第一步成功啦。</p><p>但是 packetdrill 命令是需要 sudo 权限执行的，如果现在我们在命令行中输入sudo packetdrill，会提示找不到 packetdrill 命令</p><p>sudo：packetdrill：找不到命令<br>这是因为 sudo 命令为了安全性的考虑，覆盖了用户自己 PATH 环境变量，我们可以用sudo sudo -V | grep PATH 来看</p><p>sudo sudo -V | grep  PATH<br>覆盖用户的 $PATH 变量的值：&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin<br>可以看到 sudo 命令覆盖了用户的 PATH 变量。这些初始值是在&#x2F;etc&#x2F;sudoers中定义的</p><p>sudo cat &#x2F;etc&#x2F;sudoers | grep -i PATH<br>Defaults    secure_path &#x3D; &#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin<br>一个最简单的办法是在sudo 启动时重新赋值它的 PATH 变量：sudo env PATH&#x3D;”$PATH” cmd_x，可以用sudo env PATH&#x3D;”$PATH” env | grep PATH与sudo env | grep PATH做前后对比</p><p>对于本文中的 packetdrill，可以用sudo env PATH&#x3D;$PATH packetdrill delay_ack.pkt来执行，当然你可以做一个 sudo 的 alias</p><p>alias sudo&#x3D;’sudo env PATH&#x3D;”$PATH”‘<br>这样就可以在任意地方执行sudo packetdrill了</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>packetdrill 上手的难度有一点大，但是熟悉了以后用起来特别顺手，后面很多 TCP 包超时重传、快速重传、滑动窗口、nagle 算法都是会用这个工具来进行测试，希望你可以熟练掌握。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从大学开始懵懵懂懂粗略学习（死记硬背）了一些 TCP 协议的内容，到工作多年以后，一直没有找到顺手的&lt;code&gt;网络协议栈调试工具&lt;/code&gt;，对于纷繁复杂 TCP 协议。&lt;br&gt;业界流行的 scapy 不是很好用，有很多局限性。直到前段时间看到了 Google 开源的 </summary>
      
    
    
    
    <category term="TCP 读书笔记" scheme="http://rymuscle.github.io/categories/TCP-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="TCP" scheme="http://rymuscle.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>03.TCP概述 -- 可靠的、面向连接的、基于字节流、全双工的协议</title>
    <link href="http://rymuscle.github.io/2022/01/23/TCP/03.TCP%E6%A6%82%E8%BF%B0%20--%20%E5%8F%AF%E9%9D%A0%E7%9A%84%E3%80%81%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E3%80%81%E5%9F%BA%E4%BA%8E%E5%AD%97%E8%8A%82%E6%B5%81%E3%80%81%E5%85%A8%E5%8F%8C%E5%B7%A5%E7%9A%84%E5%8D%8F%E8%AE%AE/"/>
    <id>http://rymuscle.github.io/2022/01/23/TCP/03.TCP%E6%A6%82%E8%BF%B0%20--%20%E5%8F%AF%E9%9D%A0%E7%9A%84%E3%80%81%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E3%80%81%E5%9F%BA%E4%BA%8E%E5%AD%97%E8%8A%82%E6%B5%81%E3%80%81%E5%85%A8%E5%8F%8C%E5%B7%A5%E7%9A%84%E5%8D%8F%E8%AE%AE/</id>
    <published>2022-01-23T11:43:20.000Z</published>
    <updated>2024-04-26T10:30:48.532Z</updated>
    
    <content type="html"><![CDATA[<p>如果要用一句话来描述 TCP 协议，我想应该是：TCP 是一个<code>可靠的(reliable)</code>、<code>面向连接的(connection-oriented)</code>、<code>基于字节流(byte-stream)</code>、<code>全双工的(full-duplex)</code> 协议。</p><h1 id="TCP-是面向连接的协议"><a href="#TCP-是面向连接的协议" class="headerlink" title="TCP 是面向连接的协议"></a>TCP 是<code>面向连接</code>的协议</h1><p>一开始学习 TCP 的时候，我们就被告知 TCP 是面向连接的协议，那什么是面向连接，什么是无连接呢？</p><ul><li><code>面向连接(connection-oriented)</code>：面向连接的协议要求正式发送数据之前需要通过「握手」建立一个逻辑连接，结束通信时也是通过有序的四次挥手来断开连接。</li><li><code>无连接(connectionless)</code>：无连接的协议则不需要</li></ul><h1 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h1><p>建立连接的过程是通过「三次握手」来完成的，顾名思义，通过三次数据交换建立一个连接。 通过三次握手协商好双方后续通信的<code>起始序列号</code>、<code>窗口缩放大小</code>等信息。<br><img src="/images/tcp/03/1.awebp" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><h1 id="TCP-协议是可靠的"><a href="#TCP-协议是可靠的" class="headerlink" title="TCP 协议是可靠的"></a>TCP 协议是可靠的</h1><p>IP 是一种无连接、不可靠的协议：它尽最大可能将数据报从发送者传输给接收者，但并不保证包到达的顺序会与它们被传输的顺序一致，也不保证包是否重复，甚至都不保证包是否会达到接收者。</p><p>TCP 要想在 IP 基础上构建可靠的传输层协议，必须有一个复杂的机制来保障可靠性。 主要有下面几个方面：</p><ul><li>对每个包提供校验和</li><li>包的序列号解决了接收数据的乱序、重复问题</li><li>超时重传</li><li>流量控制、拥塞控制</li></ul><h2 id="校验和（checksum）"><a href="#校验和（checksum）" class="headerlink" title="校验和（checksum）"></a>校验和（checksum）</h2><p>每个 TCP 包首部中都有两字节用来表示校验和，防止在传输过程中有损坏。如果收到一个校验和有差错的报文，TCP 不会发送任何确认直接丢弃它，等待发送端重传。<br><img src="/images/tcp/03/2.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><h2 id="包的序列号保证了接收数据的乱序和重复问题"><a href="#包的序列号保证了接收数据的乱序和重复问题" class="headerlink" title="包的序列号保证了接收数据的乱序和重复问题"></a>包的序列号保证了接收数据的乱序和重复问题</h2><p>假设我们往 TCP 套接字里写 3000 字节的数据导致 TCP发送了 3 个数据包，每个数据包大小为 1000 字节：第一个包序列号为[11001)，第二个包序列号为 [10012001)，第三个包序号为[2001~3001)<br><img src="/images/tcp/03/3.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>假如因为网络的原因导致第二个、第三个包先到接收端，第一个包最后才到，接收端也不会因为他们到达的顺序不一致把包弄错，TCP 会根据他们的序号进行重新的排列然后把结果传递给上层应用程序。<br>如果 TCP 接收到重复的数据，可能的原因是超时重传了两次但这个包并没有丢失，接收端会收到两次同样的数据，它能够根据包序号丢弃重复的数据。</p><h2 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h2><p>TCP 发送数据后会启动一个定时器，等待对端确认收到这个数据包。如果在指定的时间内没有收到 ACK 确认，就会重传数据包，然后等待更长时间，如果还没有收到就再重传，在多次重传仍然失败以后，TCP 会放弃这个包。<br>后面我们讲到超时重传模块的时候会详细介绍这部分内容。</p><h2 id="流量控制、拥塞控制"><a href="#流量控制、拥塞控制" class="headerlink" title="流量控制、拥塞控制"></a>流量控制、拥塞控制</h2><p>这部分内容较复杂，后面有专门的文章进行讲解，这里先不展开。</p><h1 id="TCP-是面向字节流的协议"><a href="#TCP-是面向字节流的协议" class="headerlink" title="TCP 是面向字节流的协议"></a>TCP 是面向字节流的协议</h1><p>TCP 是一种字节流（byte-stream）协议，流的含义是没有固定的报文边界。</p><p>假设你调用 2 次 write 函数往 socket 里依次写 500 字节、800 字节。write 函数只是把字节拷贝到内核缓冲区，最终会以多少条报文发送出去是不确定的，如下图所示<br><img src="/images/tcp/03/4.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>情况 1：分为两条报文依次发出去 500 字节 和 800 字节数据<br>情况 2：两部分数据合并为一个长度为 1300 字节的报文，一次发送<br>情况 3：第一部分的 500 字节与第二部分的 500 字节合并为一个长度为 1000 字节的报文，第二部分剩下的 300 字节单独作为一个报文发送<br>情况 4：第一部分的 400 字节单独发送，剩下100字节与第二部分的 800 字节合并为一个 900 字节的包一起发送<br>情况 N：还有更多可能的拆分组合</p><p>上面出现的情况取决于诸多因素：<code>路径最大传输单元 MTU</code>、<code>发送窗口大小</code>、<code>拥塞窗口大小</code>等。</p><p>当接收方从 TCP 套接字读数据时，它是没法得知对方每次写入的字节是多少的。接收端可能分2次每次 650 字节读取，也有可能先分三次，一次 100 字节，一次 200 字节，一次 1000 字节进行读取。</p><h1 id="TCP-是全双工的协议"><a href="#TCP-是全双工的协议" class="headerlink" title="TCP 是全双工的协议"></a>TCP 是全双工的协议</h1><p>在 TCP 中发送端和接收端可以是客户端&#x2F;服务端，也可以是服务器&#x2F;客户端，通信的双方在任意时刻既可以是接收数据也可以是发送数据，每个方向的数据流都独立管理<code>序列号</code>、<code>滑动窗口大小</code>、<code>MSS</code> 等信息。</p><h1 id="小结与思考"><a href="#小结与思考" class="headerlink" title="小结与思考"></a>小结与思考</h1><p>TCP 是一个可靠的（reliable）、面向连接的（connection-oriented）、基于字节流（byte-stream）、全双工（full-duplex）的协议。发送端在发送数据以后启动一个定时器，如果超时没有收到对端确认会进行重传，接收端利用序列号对收到的包进行排序、丢弃重复数据，TCP 还提供了流量控制、拥塞控制等机制保证了稳定性。<br><img src="/images/tcp/03/5.awebp" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;如果要用一句话来描述 TCP 协议，我想应该是：TCP 是一个&lt;code&gt;可靠的(reliable)&lt;/code&gt;、&lt;code&gt;面向连接的(connection-oriented)&lt;/code&gt;、&lt;code&gt;基于字节流(byte-stream)&lt;/code&gt;、&lt;code&gt;全</summary>
      
    
    
    
    <category term="TCP 读书笔记" scheme="http://rymuscle.github.io/categories/TCP-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="TCP" scheme="http://rymuscle.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>02.TCP/IP 历史与分层模型</title>
    <link href="http://rymuscle.github.io/2022/01/22/TCP/02.TCP%E3%80%81IP%20%E5%8E%86%E5%8F%B2%E4%B8%8E%E5%88%86%E5%B1%82%E6%A8%A1%E5%9E%8B/"/>
    <id>http://rymuscle.github.io/2022/01/22/TCP/02.TCP%E3%80%81IP%20%E5%8E%86%E5%8F%B2%E4%B8%8E%E5%88%86%E5%B1%82%E6%A8%A1%E5%9E%8B/</id>
    <published>2022-01-22T11:43:20.000Z</published>
    <updated>2024-04-26T09:59:59.283Z</updated>
    
    
    
    
    <category term="TCP 读书笔记" scheme="http://rymuscle.github.io/categories/TCP-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="TCP" scheme="http://rymuscle.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>01. 环境</title>
    <link href="http://rymuscle.github.io/2022/01/21/TCP/01.%E7%8E%AF%E5%A2%83/"/>
    <id>http://rymuscle.github.io/2022/01/21/TCP/01.%E7%8E%AF%E5%A2%83/</id>
    <published>2022-01-21T11:43:20.000Z</published>
    <updated>2024-04-26T09:59:47.158Z</updated>
    
    
    
    
    <category term="TCP 读书笔记" scheme="http://rymuscle.github.io/categories/TCP-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="TCP" scheme="http://rymuscle.github.io/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>23. 锁</title>
    <link href="http://rymuscle.github.io/2021/12/19/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/23.%E9%94%81/"/>
    <id>http://rymuscle.github.io/2021/12/19/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/23.%E9%94%81/</id>
    <published>2021-12-19T14:08:18.000Z</published>
    <updated>2024-04-24T07:21:55.839Z</updated>
    
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>22. undo日志(上)</title>
    <link href="http://rymuscle.github.io/2021/12/15/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/22.undo%E6%97%A5%E5%BF%97(%E4%B8%8A)/"/>
    <id>http://rymuscle.github.io/2021/12/15/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/22.undo%E6%97%A5%E5%BF%97(%E4%B8%8A)/</id>
    <published>2021-12-15T13:19:56.000Z</published>
    <updated>2024-04-26T09:52:55.957Z</updated>
    
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>22. undo日志</title>
    <link href="http://rymuscle.github.io/2021/12/15/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/22.undo%E6%97%A5%E5%BF%97(%E4%B8%8B)/"/>
    <id>http://rymuscle.github.io/2021/12/15/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/22.undo%E6%97%A5%E5%BF%97(%E4%B8%8B)/</id>
    <published>2021-12-15T13:19:56.000Z</published>
    <updated>2024-04-24T07:15:54.192Z</updated>
    
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>21.2 redo日志后续知识点</title>
    <link href="http://rymuscle.github.io/2021/12/13/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/21.2%20redo%E6%97%A5%E5%BF%97%20%E5%90%8E%E7%BB%AD%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>http://rymuscle.github.io/2021/12/13/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/21.2%20redo%E6%97%A5%E5%BF%97%20%E5%90%8E%E7%BB%AD%E7%9F%A5%E8%AF%86%E7%82%B9/</id>
    <published>2021-12-13T05:10:27.000Z</published>
    <updated>2024-05-02T03:57:02.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h1><p>有一个很不幸的事实就是我们的<code>redo日志文件组</code>容量是有限的，我们不得不选择循环使用<code>redo日志文件组</code>中的文件，但是这会造成<span style="font-weight:600;color:#FF416C">最后写的redo日志与最开始写的redo日志追尾</span>。</p><p>这时应该想到: redo日志只是为了在系统奔溃后恢复脏⻚用的，如果对应的脏⻚已经刷新到了磁盘，那么即使现在系统奔溃，那么在重启后也用不着使用redo日志恢复该⻚面了，所以该redo日志也就没有存在的必要了，那么它占用的磁盘空间就可以被后续的redo日志所重用。也就是说: 判断某些redo日志占用的磁盘空间是否可以覆盖的依据就是<code>它对应的脏⻚是否已经刷新到磁盘里</code>。</p><p>我们看一下前边一直唠叨的那个例子:</p><blockquote><img src="/images/MySQL/21/17.png" width="550" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>如图，虽然mtr_1和mtr_2生成的redo日志都已经被写到了磁盘上，但是它们修改的脏⻚仍然留在Buffer Pool中，所以它们生成的redo日志在磁盘上的空间是不可以被覆盖的。<p>之后随着系统的运行，如果⻚a被刷新到了磁盘，那么它对应的控制块就会从flush链表中移除，就像这样子:<br><img src="/images/MySQL/21/18.png" width="550" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>这样mtr_1生成的redo日志就没有用了，这些redo日志占用的磁盘空间就可以被覆盖掉了。</p><p>设计InnoDB的大叔提出了一个<code>全局变量 checkpoint_lsn</code> 来代表当前系统中可以被覆盖的redo日志总量是多少，这个变量初始值也是8704。<br>比方说现在⻚a被刷新到了磁盘，mtr_1生成的redo日志就可以被覆盖了，所以我们需要进行一个增加<code>checkpoint_lsn</code>的操作，我们把这个过程称为<code>执行一次checkpoint</code>。<br>执行一次checkpoint其实可 以分为两个步骤:</p><ul><li>步骤一:计算一下当前系统中可以被覆盖的redo日志对应的lsn值最大是多少。<br>redo日志可以被覆盖，意味着它对应的脏⻚被刷到了磁盘，只要我们计算出当前系统中被最早修改的脏⻚对应的 oldest_modification 值，那凡是在系统lsn值小于该节点的oldest_modification值时产生的redo日志都是可以被覆盖掉的，我们就把该脏⻚的oldest_modification赋值给 checkpoint_lsn。<br>比方说当前系统中⻚a已经被刷新到磁盘，那么flush链表的尾节点就是⻚c，该节点就是当前系统中最早修改的脏⻚了， 它的oldest_modification值为8404，我们就把8404赋值给checkpoint_lsn(也就是说在redo日志对应的lsn值小于8404时就可以被覆盖掉)。</li><li>步骤二:将checkpoint_lsn和对应的redo日志文件组偏移量以及此次checkpint的编号写到日志文件的管理信息(就是checkpoint1或者checkpoint2)中。<br>设计InnoDB的大叔维护了一个目前系统做了多少次checkpoint的变量checkpoint_no，每做一次checkpoint，该变量的值就加1。我们前边说过计算一个lsn值对应的redo日志文件组偏移量是很容易的，所以可以计算得到该checkpoint_lsn在redo日志文件组中对应的偏移量checkpoint_offset，然后把这三个值都写到redo日志文件组的管理信息中。</li></ul></blockquote><blockquote><p>我们说过，每一个redo日志文件都有2048个字节的管理信息，但是上述关于checkpoint的信息只会被写到日志文件组的第一个日志文件的管理信息中。<br>不过它们应该存储到checkpoint1中还是checkpoint2中呢? 设计InnoDB的大叔规定，当checkpoint_no的值是偶数时，就写到checkpoint1中，是奇数时，就写到checkpoint2中。</p></blockquote><blockquote><p>记录完checkpoint的信息之后，redo日志文件组中各个lsn值的关系就像这样:<br><img src="/images/MySQL/21/19.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p></blockquote><h1 id="批量从flush链表中刷出脏⻚"><a href="#批量从flush链表中刷出脏⻚" class="headerlink" title="批量从flush链表中刷出脏⻚"></a>批量从flush链表中刷出脏⻚</h1><p>我们在介绍Buffer Pool的时候说过，一般情况下都是后台的线程在对<code>LRU链表</code>和<code>flush链表</code>进行刷脏操作，这主要因为刷脏操作比较慢，不想影响用户线程处理请求。<br>但是如果当前系统修改⻚面的操作十分频繁，这样就导致写日志操作十分频繁，系统lsn值增⻓过快。 如果后台的刷脏操作不能将脏⻚刷出，那么系统无法及时做checkpoint，可能就需要用户线程同步的从flush链表中把那些最早修改的脏⻚(oldest_modification最小的脏⻚)刷新到磁盘，这样这些脏⻚对应的redo日志就没用了，然后就可以去做checkpoint了。</p><h1 id="查看系统中的各种LSN值"><a href="#查看系统中的各种LSN值" class="headerlink" title="查看系统中的各种LSN值"></a>查看系统中的各种LSN值</h1><p>我们可以使用<code>SHOW ENGINE INNODB STATUS</code>命令查看当前InnoDB存储引擎中的各种LSN值的情况，比如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW ENGINE INNODB STATUS\G</span><br><span class="line">(...省略前边的许多状态)</span><br><span class="line">LOG</span><br><span class="line">---</span><br><span class="line">Log sequence number 124476971</span><br><span class="line">Log flushed up to 124099769</span><br><span class="line">Pages flushed up to 124052503</span><br><span class="line">Last checkpoint at 124052494</span><br><span class="line">0 pending log flushes, 0 pending chkp writes 24 log i/o&#x27;s done, 2.00 log i/o&#x27;s/second ----------------------</span><br><span class="line">(...省略后边的许多状态)</span><br></pre></td></tr></table></figure><p>其中:<br>Log sequence number: 代表系统中的lsn值，也就是当前 系统已经写入的redo日志量，包括写入log buffer中的日 志。<br>Log flushed up to: 代表flushed_to_disk_lsn的 值，也就是当前系统已经写入磁盘的redo日志量。<br>Pages flushed up to: 代表flush链表中被最早修改的那 个⻚面对应的oldest_modification属性值。<br>Last checkpoint at: 当前系统的checkpoint_lsn值。</p><h1 id="innodb-flush-log-at-trx-commit的用法"><a href="#innodb-flush-log-at-trx-commit的用法" class="headerlink" title="innodb_flush_log_at_trx_commit的用法"></a>innodb_flush_log_at_trx_commit的用法</h1><p>我们前边说为了保证事务的持久性，用户线程在事务提交时需要将该事务执行过程中产生的所有redo日志都刷新到磁盘上。这一条要求太狠了，会很明显的降低数据库性能。</p><p>如果有的同学对事务的持久性要求不是那么强烈的话，可以选择修改一个名为<code>innodb_flush_log_at_trx_commit</code>的系统变量的值，该变量有3个可选的值:</p><ul><li>0: 当该系统变量值为0时，表示在事务提交时不立即向磁盘中同步redo日志，这个任务是交给后台线程做的。<br>这样很明显会加快请求处理速度，但是如果事务提交后服务器挂了，后台线程没有及时将redo日志刷新到磁盘，那么该事务对⻚面的修改会丢失。</li><li>1: 当该系统变量值为0时，表示在事务提交时需要将redo日志同步到磁盘，可以保证事务的持久性。1也是默认值。</li><li>2: 当该系统变量值为0时，表示在事务提交时需要将redo日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘。<br>这种情况下如果数据库挂了，操作系统没挂的话，事务的持久性还是可以保证的，但是操作系统也挂了的话，那就不能保证持久性了。</li></ul><h1 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h1><p>在服务器不挂的情况下，redo日志简直就是个大累赘，不仅没用，反而让性能变得更差。<br>但是万一数据库挂了，那redo日志可是个宝了，我们就可以在重启时根据redo日志中的记录就可以将⻚面恢复到系统奔溃前的状态。<br>接下来大致看一下恢复过程是个啥样。</p><h2 id="确定恢复的起点"><a href="#确定恢复的起点" class="headerlink" title="确定恢复的起点"></a>确定恢复的起点</h2><p>我们前边说过，<code>checkpoint_lsn</code>之前的redo日志都可以被覆盖， 也就是说这些redo日志对应的脏⻚都已经被刷新到磁盘中了，既然它们已经被刷盘，我们就没必要恢复它们了。<br>对于 <code>checkpoint_lsn</code> 之后的redo日志，它们对应的脏⻚可能没被刷盘，也可能被刷盘了，我们不能确定，所以需要从 <code>checkpoint_lsn</code> 开始读取redo日志来恢复⻚面。<br>当然，redo日志文件组的第一个文件的管理信息中有两个block都存储了checkpoint_lsn的信息，我们当然是要选取最近发生的那次checkpoint的信息。衡量checkpoint发生时间早晚的信息就是所谓的<code>checkpoint_no</code>，我们只要把checkpoint1和checkpoint2这两个block中的checkpoint_no值读出来比一下大小，哪个的 checkpoint_no值更大，说明哪个block存储的就是最近的一次checkpoint信息。这样我们就能拿到最近发生的checkpoint对应的checkpoint_lsn值以及它在redo日志文件组中的偏移量 checkpoint_offset。</p><h2 id="确定恢复的终点"><a href="#确定恢复的终点" class="headerlink" title="确定恢复的终点"></a>确定恢复的终点</h2><p>redo日志恢复的起点确定了，那终点是哪个呢?这个还得从block的结构说起。我们说在写redo日志的时候都是顺序写的，写满了一个 block之后会再往下一个block中写:</p><blockquote><img src="/images/MySQL/21/20.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>普通block的`log block header`部分有一个名为`LOG_BLOCK_HDR_DATA_LEN`的属性，该属性值记录了当前block里使用了多少字节的空间。对于被填满的block来说，该值永远为512。如果该属性的值不为512，那么就是它了，它就是此次奔溃恢复中需要扫描的最后一个block。</blockquote><h2 id="怎么恢复"><a href="#怎么恢复" class="headerlink" title="怎么恢复"></a>怎么恢复</h2><p>确定了需要扫描哪些redo日志进行奔溃恢复之后，接下来就是怎么进行恢复了。假设现在的redo日志文件中有5条redo日志，如图:</p><blockquote><img src="/images/MySQL/21/21.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></blockquote><p>由于redo 0在checkpoint_lsn后边，恢复时可以不管它。我们现在可以按照redo日志的顺序依次扫描checkpoint_lsn之后的各条redo日志，按照日志中记载的内容将对应的⻚面恢复出来。这样没什么问题，不过设计InnoDB的大叔还是想了一些办法加快这个恢复的过程:</p><ul><li><p>使用哈希表<br>根据redo日志的space ID和page number属性计算出散列值，把space ID和page number相同的redo日志放到哈希表的同一个槽里，如果有多个space ID和page number都相同的redo日志，那么它们之间使用链表连接起来，按照生成的先后顺序链接起来的，如图所示:</p><blockquote><img src="/images/MySQL/21/22.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>之后就可以遍历哈希表，因为对同一个⻚面进行修改的redo日志都放在了一个槽里，所以可以一次性将一个⻚面修复好(避免了很多读取⻚面的随机IO)，这样可以加快恢复速度。另外需要注意一点的是，同一个⻚面的redo日志是按照生成时间顺序进行排序的，所以恢复的时候也是按照这个顺序进行恢复， 如果不按照生成时间顺序进行排序的话，那么可能出现错误。 比如原先的修改操作是先插入一条记录，再删除该条记录，如果恢复时不按照这个顺序来，就可能变成先删除一条记录，再插入一条记录，这显然是错误的。</blockquote></li><li><p>跳过已经刷新到磁盘的⻚面<br>我们前边说过，checkpoint_lsn之前的redo日志对应的脏⻚确定都已经刷到磁盘了，但是checkpoint_lsn之后的redo日志我们不能确定是否已经刷到磁盘，主要是因为在最近做的一次checkpoint后，可能后台线程又不断的从LRU链表和flush链表中将一些脏⻚刷出Buffer Pool。这些在checkpoint_lsn之后的redo日志，如果它们对应的脏⻚在奔溃发生时已经刷新到磁盘，那在恢复时也就没有必要根据redo日志的内容修改该⻚面了。</p></li></ul><p>那在恢复时怎么知道某个redo日志对应的脏⻚是否在奔溃发生时已经刷新到磁盘了呢?这还得从⻚面的结构说起，我们前边说过每个⻚面都有一个称之为File Header的部分，在File Header里有一个称之为FIL_PAGE_LSN的属性，该属性记载了最近一次修改⻚面时对应的lsn值(其实就是⻚面控制块中 的newest_modification值)。如果在做了某次checkpoint之后有脏⻚被刷新到磁盘中，那么该⻚对应的 FIL_PAGE_LSN代表的lsn值肯定大于checkpoint_lsn的值，凡是符合这种情况的⻚面就不需要做恢复操作了，所以更进一步提升了奔溃恢复的速度。</p><h1 id="遗漏的问题-LOG-BLOCK-HDR-NO是如何计算的"><a href="#遗漏的问题-LOG-BLOCK-HDR-NO是如何计算的" class="headerlink" title="遗漏的问题:LOG_BLOCK_HDR_NO是如何计算的"></a>遗漏的问题:LOG_BLOCK_HDR_NO是如何计算的</h1><p>我们前边说过，对于实际存储redo日志的普通的log block来说， 在log block header处有一个称之为LOG_BLOCK_HDR_NO的属 性(忘记了的话回头再看看哈)，我们说这个属性代表一个唯一的标 号。这个属性是初次使用该block时分配的，跟当时的系统lsn值有 关。使用下边的公式计算该block的LOG_BLOCK_HDR_NO值:<br><code>((lsn / 512) &amp; 0x3FFFFFFFUL) + 1</code></p><p>这个公式里的0x3FFFFFFFUL可能让大家有点困惑，其实它的二进 制表示可能更亲切一点:</p><blockquote><img src="/images/MySQL/21/23.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>从图中可以看出，0x3FFFFFFFUL对应的二进制数的前2位为0，后 30位的值都为1。我们刚开始学计算机的时候就学过，一个二进制位 与0做与运算(&)的结果肯定是0，一个二进制位与1做与运算 (&)的结果就是原值。让一个数和0x3FFFFFFFUL做与运算的意思 就是要将该值的前2个比特位的值置为0，这样该值就肯定小于或等 于0x3FFFFFFFUL了。这也就说明了，不论lsn多大，((lsn / 512) & 0x3FFFFFFFUL)的值肯定在0~0x3FFFFFFFUL之间，再 加1的话肯定在1~0x40000000UL之间。而0x40000000UL这个值 大家应该很熟悉，这个值就代表着1GB。也就是说系统最多能产生不 重复的LOG_BLOCK_HDR_NO值只有1GB个。设计InnoDB的大叔规定 redo日志文件组中包含的所有文件大小总和不得超过512GB，一个 block大小是512字节，也就是说redo日志文件组中包含的block块 最多为1GB个，所以有1GB个不重复的编号值也就够用了。另外，LOG_BLOCK_HDR_NO值的第一个比特位比较特殊，称之 为flush bit，如果该值为1，代表着本block是在某次将log buffer中的block刷新到磁盘的操作中的第一个被刷入的block。</blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;checkpoint&quot;&gt;&lt;a href=&quot;#checkpoint&quot; class=&quot;headerlink&quot; title=&quot;checkpoint&quot;&gt;&lt;/a&gt;checkpoint&lt;/h1&gt;&lt;p&gt;有一个很不幸的事实就是我们的&lt;code&gt;redo日志文件组&lt;/code&gt;容量</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>21.1 Log Sequeue Number</title>
    <link href="http://rymuscle.github.io/2021/12/12/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/21.1%20Log%20Sequeue%20Number/"/>
    <id>http://rymuscle.github.io/2021/12/12/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/21.1%20Log%20Sequeue%20Number/</id>
    <published>2021-12-12T14:19:04.000Z</published>
    <updated>2024-04-28T10:15:56.636Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Log-Sequeue-Number"><a href="#Log-Sequeue-Number" class="headerlink" title="Log Sequeue Number"></a>Log Sequeue Number</h1><p>自系统开始运行，就在不断地修改⻚面，这也就意味着会不断的生成redo日志。redo日志的量在不断的递增，就像人的年龄一样，自打出生起就不断递增，永远不可能缩减。</p><p>设计InnoDB的大叔设计了一个名为<code>Log Sequeue Number</code>的<code>全局变量</code>(<code>日志序列号</code>，简称<code>lsn</code>)，用来记录当前总共已经写入的redo日志量。 不过不像人一出生的年龄是0岁，设计InnoDB的大叔规定初始的lsn值为8704(人家就这么规定的,也就是一条redo日志也没写入时，lsn的值就是8704)。</p><p>我们知道在向<code>log buffer</code>中写入<code>redo日志</code>时不是一条一条写入的，而是以<code>mtr</code>生成的<code>一组redo日志</code>为单位进行写入的。而且实际上是把日志内容写在了<code>log blcok body</code>处。<br>但是在统计<code>lsn</code>的增⻓量时，是按照实际写入的日志量加上占用的<code>log block header</code>和<code>log block trailer</code>来计算的。我们来看一个例子:</p><ul><li>系统第一次启动后初始化<code>log buffer</code>时，<code>buf_free</code>(就是标记下一条redo日志应该写入到log buffer的位置的变量) 就会指向第一个block的偏移量为12字节(log block header的大小)的地方，那么lsn值也会跟着增加12:<blockquote><img src="/images/MySQL/21/6.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></blockquote></li><li>如果某个mtr产生的一组redo日志占用的存储空间比较小，也就是待插入的block剩余空闲空间能容纳这个mtr提交的日志时，lsn增⻓的量就是该mtr生成的redo日志占用的字节数， 就像这样<blockquote><img src="/images/MySQL/21/7.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>我们假设上图中mtr_1产生的redo日志量为200字节，那么lsn就要在8716的基础上增加200，变为8916。</blockquote></li><li>如果某个mtr产生的一组redo日志占用的存储空间比较大，也就是待插入的block剩余空闲空间不足以容纳这个mtr提交的日志时，lsn增⻓的量就是该mtr生成的redo日志占用的字节数加上额外占用的<code>log block header</code>和<code>log block trailer</code>的字节数，就像这样:<blockquote><img src="/images/MySQL/21/8.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>我们假设上图中mtr_2产生的redo日志量为1000字节，为了将mtr_2产生的redo日志写入log buffer，我们不得不额外多分配两个block，所以lsn的值需要在8916的基础上增加 1000 + 12×2 + 4 × 2 = 1032。</blockquote></li></ul><p>从上边的描述中可以看出来，<strong>每一组由mtr生成的redo日志都有一个唯一的LSN值与其对应，LSN值越小，说明redo日志产生的越早。</strong></p><h1 id="flushed-to-disk-lsn"><a href="#flushed-to-disk-lsn" class="headerlink" title="flushed_to_disk_lsn"></a>flushed_to_disk_lsn</h1><p><code>redo日志</code>是先写到<code>Log buffer</code>中，之后才会被刷新到磁盘的<code>redo日志文件</code>中。所以设计InnoDB的大叔提出了一个名为<code>buf_next_to_write</code>的全局变量，用来标记当前<code>log buffer</code>中已经有哪些日志被刷新到磁盘中了。如下图:</p><blockquote><img src="/images/MySQL/21/9.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></blockquote><p>我们前边说<code>lsn</code>是表示当前系统中写入的redo日志量，这包括了写到log buffer而没有刷新到磁盘的日志。<br>相应的，设计InnoDB的大叔提出了一个表示刷新到磁盘中的redo日志量的全局变量，名为<code>flushed_to_disk_lsn</code>。 </p><p>系统第一次启动时，该变量的值和初始的lsn值是相同的，都是8704。<br>随着系统的运行，<code>redo日志</code>被不断写入<code>log buffer</code>，但是并不会立即刷新到磁盘，<code>lsn</code>的值 就和 <code>flushed_to_disk_lsn</code> 的值拉开了差距。我们演示一下:</p><ul><li>系统第一次启动后，向log buffer中写入了 mtr_1、mtr_2、mtr_3这三个mtr产生的redo日志，假设这三个mtr开始和结束时对应的lsn值分别是: <code>mtr_1:8716 ~ 8916</code>、 <code>mtr_2:8916 ~ 9948</code>、 <code>mtr_3:9948 ~ 10000</code><br>此时的lsn已经增⻓到了10000，但是由于没有刷新操作，所以此时flushed_to_disk_lsn的值仍为8704，如图:<blockquote><img src="/images/MySQL/21/10.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></blockquote></li><li>随后进行将log buffer中的block刷新到redo日志文件的操作，假设将mtr_1和mtr_2的日志刷新到磁盘，那么flushed_to_disk_lsn就应该增⻓mtr_1和mtr_2写入的日志量，所以flushed_to_disk_lsn的值增⻓到了9948， 如图:<blockquote><img src="/images/MySQL/21/11.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></blockquote></li></ul><p>综上所述，当有新的redo日志写入到log buffer时，首先lsn的值会增⻓，但flushed_to_disk_lsn不变，随后随着不断有log buffer中的日志被刷新到磁盘上，flushed_to_disk_lsn的值也跟着增⻓。如果两者的值相同时，说明log buffer中的所有redo日志都已经刷新到磁盘中了。</p><h1 id="lsn值和redo日志文件偏移量的对应关系"><a href="#lsn值和redo日志文件偏移量的对应关系" class="headerlink" title="lsn值和redo日志文件偏移量的对应关系"></a>lsn值和redo日志文件偏移量的对应关系</h1><p>因为lsn的值是代表系统写入的redo日志量的一个总和，一个mtr中产生多少日志，lsn的值就增加多少(当然有时候要加上log block header和log block trailer的大小)，这样mtr产生的日志写到磁盘中时，很容易计算某一个lsn值在redo日志文件组中的偏移量，如图:</p><blockquote><img src="/images/MySQL/21/12.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>初始时的LSN值是8704，对应文件偏移量2048，之后每个mtr向磁盘中写入多少字节日志，lsn的值就增⻓多少。</blockquote><h1 id="flush链表中的LSN"><a href="#flush链表中的LSN" class="headerlink" title="flush链表中的LSN"></a>flush链表中的LSN</h1><p>我们知道一个mtr代表一次对底层⻚面的原子访问，在访问过程中可能会产生一组不可分割的redo日志，在mtr结束时，会把这一组redo日志写入到<code>log buffer</code>中。除此之外，在mtr结束时还有一件非常重要的事情要做，就是把在mtr执行过程中可能修改过的⻚面加入到Buffer Pool的flush链表。</p><blockquote><p>为了防止大家早已忘记flush链表是个啥，我们再看一下图:<br><img src="/images/MySQL/21/13.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>当第一次修改某个缓存在Buffer Pool中的⻚面时，就会把这个⻚面对应的控制块插入到flush链表的头部，之后再修改该⻚面时由于 它已经在flush链表中了，就不再次插入了。也就是说flush链表中的脏⻚是按照⻚面的第一次修改时间从大到小进行排序的。在这个过程中会在缓存⻚对应的控制块中记录两个关于⻚面何时修改的属性:</p><ul><li><code>oldest_modification</code>：如果某个⻚面被加载到Buffer Pool后进行第一次修改，那么就将修改该⻚面的mtr开始时对应的lsn值写入这个属性。</li><li><code>newest_modification</code>：每修改一次⻚面，都会将修改该⻚面的mtr结束时对应的lsn值写入这个属性。也就是说该属性表示⻚面最近一次修改后对应的系统lsn值。</li></ul></blockquote><blockquote><p>我们接着上边唠叨flushed_to_disk_lsn的例子看一下:</p><ul><li>假设mtr_1执行过程中修改了⻚a，那么在mtr_1执行结束时，就会将⻚a对应的控制块加入到flush链表的头部。并且将mtr_1开始时对应的lsn，也就是8716写入⻚a对应的控制块的oldest_modification属性中，把mtr_1结束时对应的lsn，也就是8404写入⻚a对应的控制块的newest_modification属性中。<br>画个图表示一下(为了让图 片美观一些，我们把oldest_modification缩写成了o_m， 把newest_modification缩写成了n_m):<img src="/images/MySQL/21/14.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></li><li>接着假设mtr_2执行过程中又修改了⻚b和⻚c两个⻚面，那么在mtr_2执行结束时，就会将⻚b和⻚c对应的控制块都加入到flush链表的头部。并且将mtr_2开始时对应的lsn，也就是8404写入⻚b和⻚c对应的控制块的oldest_modification属性中，把mtr_2结束时对应的lsn，也就是9436写入⻚b和⻚c对应的控制块的newest_modification属性中。<br>画个图表示一下:<img src="/images/MySQL/21/15.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>从图中可以看出来，每次新插入到flush链表中的节点都是被放在了头部，也就是说flush链表中前边的脏⻚修改的时间比较晚，后边的脏⻚修改时间比较早。</li><li>接着假设mtr_3执行过程中修改了⻚b和⻚d，不过⻚b之前已经被修改过了，所以它对应的控制块已经被插入到了flush链表，所以在mtr_3执行结束时，只需要将⻚d对应的控制块都加入到flush链表的头部即可。所以需要将mtr_3开始时对应的lsn，也就是9436写入⻚c对应的控制块的oldest_modification属性中，把mtr_3结束时对应的lsn，也就是10000写入⻚c对应的控制块的newest_modification属性中。另外，由于⻚b在mtr_3执行过程中又发生了一次修改，所以需要更新⻚b对应的控制块中newest_modification的值为10000。<br>画个图表示一下:<img src="/images/MySQL/21/16.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></li></ul></blockquote><p>总结一下上边说的，就是:flush链表中的脏⻚按照修改发生的时间顺序进行排序，也就是按照oldest_modification代表的LSN值进行排序，被多次更新的⻚面不会重复插入到flush链表中，但是会更新newest_modification属性的值。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Log-Sequeue-Number&quot;&gt;&lt;a href=&quot;#Log-Sequeue-Number&quot; class=&quot;headerlink&quot; title=&quot;Log Sequeue Number&quot;&gt;&lt;/a&gt;Log Sequeue Number&lt;/h1&gt;&lt;p&gt;自系统开始运</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>21.0 redo日志文件</title>
    <link href="http://rymuscle.github.io/2021/12/12/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/21.0%20redo%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/"/>
    <id>http://rymuscle.github.io/2021/12/12/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/21.0%20redo%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/</id>
    <published>2021-12-12T12:23:11.000Z</published>
    <updated>2024-04-28T07:06:52.023Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redo日志刷盘时机"><a href="#redo日志刷盘时机" class="headerlink" title="redo日志刷盘时机"></a>redo日志刷盘时机</h1><p>前边说过，<code>MTR</code> 运行过程中产生的一组redo日志在<code>mtr</code>结束时会被复制到<code>log buffer</code>中。可这些日志总在内存里呆着也不是个办法，在一些情况下它们会被刷新到磁盘里，比如:</p><ul><li><code>log buffer</code>空间不足时<br>log buffer的大小是有限的(通过系统变量 <code>innodb_log_buffer_size</code> 指定)，如果不停的往这个有限大小的log buffer里塞入日志，很快它就会被填满。<br>设计 InnoDB的大叔认为，如果当前写入log buffer的redo日志量已经占满了log buffer总容量的50%左右，就需要把这些日志刷新到磁盘中。</li><li><strong>事务提交时</strong><br>我们前边说过之所以使用redo日志主要是因为它占用的<code>空间少</code>，还是<code>顺序写</code>，在事务提交时可以不把修改过的<code>Buffer Pool⻚面</code>刷新到磁盘，<strong>但是为了保证持久性，必须要把修改这些⻚面对应的redo日志刷新到磁盘</strong> 。 否则系统崩溃后，无法将该事务对页面所做的修改恢复过来。</li><li>后台有一个线程，大约以每秒一次的频率将log buffer中的redo日志刷新到磁盘。</li><li>正常关闭服务器时。</li><li>做所谓的checkpoint时(我们现在没介绍过checkpoint的概念，稍后会仔细唠叨，稍安勿躁)</li></ul><h1 id="redo日志文件组"><a href="#redo日志文件组" class="headerlink" title="redo日志文件组"></a>redo日志文件组</h1><p>MySQL的数据目录(使用 <code>SHOW VARIABLES LIKE &#39;datadir&#39;</code>查看)下默认有两个名为<code>ib_logfile0</code>和<code>ib_logfile1</code>的文件，<strong>log buffer中的日志默认情况下就是刷新到这两个磁盘文件中。</strong></p><p>如果我们对默认的redo日志文件不满意，可以通过下边几个启动参数来调节:</p><ul><li><code>innodb_log_group_home_dir</code>：该参数指定了redo日志文件所在的目录，默认值就是当前的数据目录。</li><li><code>innodb_log_file_size</code>：该参数指定了每个redo日志文件的大小，在MySQL 5.7.21 这个版本中的默认值为48MB。</li><li><code>innodb_log_files_in_group</code>：该参数指定redo日志文件的个数，默认值为2，最大值为 100。</li></ul><div style="font-weight:500;border: 1px solid #33b045;border-radius: 5px;padding:10px 10px 0 25px;"><p>从上边的描述中可以看到，磁盘上的redo日志文件不只一个，而是以一个日志文件组的形式出现的。 这些文件以<code>ib_logfile[数字]</code> (数字可以是0、1、2…)的形式进行命名。<br>在将redo日志写入日志文件组时，是从ib_logfile0开始写，如果ib_logfile0写满了，就接着ib_logfile1写，同理，ib_logfile1写满了就去写ib_logfile2，依此类推。 如果写到最后一个文件该咋办? 那就重新转到ib_logfile0继续写，所以整个过程如下图所示:<br><img src="/images/MySQL/21/1.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>总共的redo日志文件大小其实就是：<code>innodb_log_file_size × innodb_log_files_in_group</code>。</p></div><p><strong>Tips: 如果采用循环使用的方式向redo日志文件组里写数据的话，那岂不是要追尾，也就是后写入的redo日志覆盖掉前边写的redo日志? 当然可能了! 所以设计InnoDB的大叔提出了<code>checkpoint</code>的概念，稍后我们重点唠叨。</strong></p><h1 id="redo日志的文件格式"><a href="#redo日志的文件格式" class="headerlink" title="redo日志的文件格式"></a>redo日志的<code>文件格式</code></h1><p>我们前边说过<code>log buffer</code>本质上是一片连续的内存空间，被划分成了若干个512字节大小的<code>block</code>。<br><strong>将<code>log buffer</code>中的redo日志刷新到磁盘的本质就是把block的镜像写入<code>日志文件</code>中，所以<code>redo日志文件</code>其实也是由若干个512字节大小的block组成。</strong></p><p><code>redo日志文件组</code>中的每个文件大小都一样，格式也一样，都是由两部分组成:</p><ul><li>前2048个字节，也就是前4个block是用来存储一些管理信息的；</li><li>从第2048字节往后是用来存储<code>log buffer</code>中的block镜像的；</li></ul><p>所以我们前边所说的循环使用redo日志文件，其实是从每个日志文件的第2048个字节开始算，示意图就是:<br><img src="/images/MySQL/21/2.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><hr><p>普通block的格式我们在唠叨<code>log buffer</code>时都说过了，就是<code>log block header</code>、<code>log block body</code>、<code>log block trialer</code>这三个部分，就不重复介绍了。</p><p>这里需要介绍一下每个<code>redo日志文件</code>前2048个字节，也就是<code>前4个特殊block</code>的格式都是干嘛的，先看图:<br><img src="/images/MySQL/21/3.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>从图中可以看出来，这4个block分别是:</p><ul><li><code>log file header</code>:描述该redo日志文件的一些整体属性，它的结构:<blockquote><img src="/images/MySQL/21/4.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><p><code>LOG_HEADER_FORMAT</code>: 4字节，redo日志的版本，在MySQL 5.7.21中该值永远为1<br><code>LOG_HEADER_PAD1</code>： 4字节，做字节填充用的，没什么实际意义，忽略~<br><code>LOG_HEADER_START_LSN</code>: 8字节，标记本redo日志文件开始的LSN值，也就是文件偏移量为2048字节初对应的LSN值(关于什么是LSN我们稍后再看哈，看不懂的先忽略)。<br><code>LOG_HEADER_CREATOR</code>：32字节，一个字符串标记本redo日志文件的创建者是谁。正常运行时该值为MySQL的版本号，比如:”MySQL 5.7.21”，使用mysqlbackup命令创建的redo日志文件的该值为”ibbackup”和创建时间。<br><code>LOG_BLOCK_CHECKSUM</code>: 4字节，本block的校验值，所有block都有，我们不关心</p><p>Tips: 设计InnoDB的大叔对redo日志的block格式做了很多次修改，如果你阅读的其他书籍中发现上述的属性和你阅读书籍中的属性有些出入，不要慌，正常现象，忘记以前的版本吧。另外，LSN值我们后边才会介绍，现在千万别纠结LSN是个啥。</p></blockquote></li><li><code>checkpoint1</code>: 记录关于checkpoint的一些属性，看一下它的结构:<blockquote><img src="/images/MySQL/21/5.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><p><code>LOG_CHECKPOINT_NO</code>：8字节，服务器执行checkpoint的编号，每执行一次checkpoint，该值就加1。<br><code>LOG_CHECKPOINT_LSN</code>：8字节，服务器在结束checkpoint时对应的LSN值；系统在奔溃恢复时将从该值开始。<br><code>LOG_CHECKPOINT_OFFSET</code>：8字节，上个属性中的LSN值在redo日志文件组中的偏移量<br><code>LOG_CHECKPOINT_LOG_BUF_SIZE</code>：8字节，服务器在执行checkpoint操作时对应的log buffer的大小<br><code>LOG_BLOCK_CHECKSUM</code>：4字节，本block的校验值，所有block都有该值，我们不用关心</p><p>Tips: 小贴士:现在看不懂上边这些关于checkpoint和LSN的属性的释义是很正常的，我就是想让大家对上边这些属性混个脸熟，后边我们后详细唠叨的。</p></blockquote></li><li>第三个block未使用，忽略~</li><li><code>checkpoint2</code>: 结构和checkpoint1一样。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redo日志刷盘时机&quot;&gt;&lt;a href=&quot;#redo日志刷盘时机&quot; class=&quot;headerlink&quot; title=&quot;redo日志刷盘时机&quot;&gt;&lt;/a&gt;redo日志刷盘时机&lt;/h1&gt;&lt;p&gt;前边说过，&lt;code&gt;MTR&lt;/code&gt; 运行过程中产生的一组redo日志</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>20.3 redo日志的写入过程</title>
    <link href="http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.3%20redo%E6%97%A5%E5%BF%97%E7%9A%84%E5%86%99%E5%85%A5%E8%BF%87%E7%A8%8B/"/>
    <id>http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.3%20redo%E6%97%A5%E5%BF%97%E7%9A%84%E5%86%99%E5%85%A5%E8%BF%87%E7%A8%8B/</id>
    <published>2021-12-11T15:15:21.000Z</published>
    <updated>2024-04-28T09:58:36.190Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redo-log-block-页"><a href="#redo-log-block-页" class="headerlink" title="redo log block(页)"></a>redo log <code>block(页)</code></h1><p>设计InnoDB的大叔为了更好的进行系统奔溃恢复，他们把通过<code>MTR</code>生成的redo日志都放在了大小为512字节的⻚中。</p><p>为了和我们前边提到的<code>表空间中的⻚</code>做区别，我们这里把用来存储redo日志的⻚称为 <code>block</code> (你心里清楚⻚和block的意思其实差不多就行了)。</p><p>一个 <code>redo log block</code> 的示意图如下:<br><img src="/images/MySQL/20/9.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>真正的redo日志都是存储到占用496字节大小的<code>log block body</code>中，图中的<code>log block header</code>和<code>log block trailer</code>存储的是一些管理信息。我们来看看这些所谓的管理信息都是啥:<br><img src="/images/MySQL/20/10.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><p>其中<code>log block header</code>的几个属性的意思分别如下:</p><ul><li><code>LOG_BLOCK_HDR_NO</code>: 每一个block都有一个大于0的唯一标号，本属性就表示该标号值。</li><li><code>LOG_BLOCK_HDR_DATA_LEN</code>: 表示block中已经使用了多少字节，初始值为12(因为log block body从第12个字节处开始)。随着往block中写入的redo日志越来也多，本属性值也跟着增⻓。如果log block body已经被全部写满，那么本属性的值被设置为512。</li><li><code>LOG_BLOCK_FIRST_REC_GROUP</code>: 一条redo日志也可以称为一条redo日志记录(redo log record)。一个<code>mtr</code>会生产多条redo日志记录，这个<code>MTR</code>生成的这些redo日志记录被称为一个<code>redo日志记录组(redo log record group)</code>。<br><code>LOG_BLOCK_FIRST_REC_GROUP</code>就代表该block中第一个mtr生成的redo日志记录组的偏移量(其实也就是这个block里第一个mtr生成的第一条redo日志的偏移量)。<br>如果一个MTR生成的redo日志横跨了好多个block,那么最后一个block中的<code>LOG_BLOCK_FIRST_REC_GROUP</code>属性就表示这个MTR对应的redo日志结束的地方，也就是下一个MTR生成redo日志开始的地方。</li><li><code>LOG_BLOCK_CHECKPOINT_NO</code>: 表示所谓的checkpoint的序号，checkpoint是我们后续内容的重点，现在先不用清楚它的意思，稍安勿躁。</li></ul><p><code>log block trailer</code> 中属性的意思如下: </p><ul><li><code>LOG_BLOCK_CHECKSUM</code>:表示block的校验值，用于正确性校验，我们暂时不关心它。</li></ul><h1 id="redo日志缓冲区"><a href="#redo日志缓冲区" class="headerlink" title="redo日志缓冲区"></a>redo日志缓冲区</h1><p>我们前边说过，设计InnoDB的大叔为了解决磁盘速度过慢的问题而引入了 <code>Buffer Pool</code>。<br>同理，写入redo日志时也不能直接直接写到磁盘上，实际上在服务器启动时就向操作系统申请了一大片称之为 <code>redo log buffer(redo日志缓冲区)</code> 的连续内存空间，也可以简称为<code>log buffer</code>。这片内存空间被划分成若干个连续的<code>redo log block</code>，就像这样:<br><img src="/images/MySQL/20/11.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>我们可以通过启动参数<code>innodb_log_buffer_size</code>来指定<code>log buffer</code>的大小，在MySQL 5.7.21这个版本中，该启动参数的默认值为16MB。</p><h1 id="redo日志写入log-buffer"><a href="#redo日志写入log-buffer" class="headerlink" title="redo日志写入log buffer"></a>redo日志写入<code>log buffer</code></h1><p>向<code>log buffer</code>中写入<code>redo日志</code>的过程是<code>顺序写入</code>的，也就是先往前边的block中写，当该block的空闲空间用完之后再往下一个block中写。<br>当想往<code>log buffer</code>中写入<code>redo日志</code>时，第一个遇到的问题就是应该写在哪个block的哪个偏移量处。设计InnoDB的大叔特意提供了一个称之为<code>buf_free的全局变量</code>，该变量指明后续写入的redo日志应该写入到log buffer中的哪个位置，如图所示:<br><img src="/images/MySQL/20/12.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><p>我们前边说过一个<code>mtr</code>执行过程中可能产生若干条redo日志，这些redo日志是一个不可分割的组，所以并不是每生成一条redo日志就将其插入到log buffer中，而是每个mtr运行过程中产生的日志先暂时存到一个地方；当该mtr结束的时候，再将过程中产生的一组redo日志全部复制到log buffer中。</p><blockquote><p>我们现在假设有两个名为T1、T2的事务，每个事务都包含2个mtr，我们给这几个mtr命名一下:</p><ul><li>事务T1的两个mtr分别称为mtr_T1_1和mtr_T1_2；</li><li>事务T2的两个mtr分别称为mtr_T2_1和mtr_T2_2；</li></ul><p>每个mtr都会产生一组redo日志，用示意图来描述一下这些mtr产生的日志情况:<br><img src="/images/MySQL/20/13.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><p>不同的事务可能是并发执行的，所以T1、T2之间的mtr可能是交替执行的。每当一个mtr执行完成时，伴随该mtr生成的一组redo日志就需要被复制到log buffer中，也就是说不同事务的mtr可能是交替写入log buffer的，我们画个示意图(为了美观，我们把一个mtr中产生的所有的redo日志当作一个整体来画):<br><img src="/images/MySQL/20/14.png" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>从示意图中我们可以看出来，不同的mtr产生的一组redo日志占用的存储空间可能不一样</p><ul><li>有的mtr产生的redo日志量很少，比如 mtr_t1_1、mtr_t2_1就被放到同一个block中存储</li><li>有的mtr产生的redo日志量非常大，比如 mtr_t1_2 产生的redo日志甚至占用了3个block来存储。</li></ul></blockquote><blockquote><p>Tips:<br>对照着上图，自己分析一下每个block的 LOG_BLOCK_HDR_DATA_LEN、LOG_BLOCK_FIRST_REC_GROUP 属性值都是什么哈</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redo-log-block-页&quot;&gt;&lt;a href=&quot;#redo-log-block-页&quot; class=&quot;headerlink&quot; title=&quot;redo log block(页)&quot;&gt;&lt;/a&gt;redo log &lt;code&gt;block(页)&lt;/code&gt;&lt;/h1&gt;&lt;p</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>20.2 Mini-Transcation</title>
    <link href="http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.2%20Mini-Transcation/"/>
    <id>http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.2%20Mini-Transcation/</id>
    <published>2021-12-11T14:46:19.000Z</published>
    <updated>2024-04-28T03:40:06.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="以组的形式写入redo日志"><a href="#以组的形式写入redo日志" class="headerlink" title="以组的形式写入redo日志"></a>以组的形式写入redo日志</h1><p>语句在执行过程中可能修改若干个⻚面。比如我们前边说的一条INSERT语句可能修改 <code>系统表空间⻚号为7的⻚面的Max Row ID 属性</code> (当然也可能更新别的系统⻚面，只不过我们没有都列举出来而已)，还会更新<code>聚簇索引</code>和<code>二级索引</code>对应B+树中的⻚面。</p><p>由于对这些⻚面的更改都发生在<code>Buffer Pool</code>中，所以在修改完⻚面之后，需要记录一下相应的redo日志。</p><p>在执行语句的过程中产生的redo日志被设计InnoDB的大叔人为的划分成了若干个不可分割的组，比如:</p><blockquote><ul><li>更新<code>Max Row ID属性</code>时产生的redo日志是不可分割的。 </li><li>向聚簇索引对应B+树的⻚面中插入一条记录时产生的redo日志是不可分割的。 </li><li>向某个二级索引对应B+树的⻚面中插入一条记录时产生的redo日志是不可分割的。 </li><li>还有其他的一些对⻚面的访问操作时产生的redo日志是不可分割的。。。</li></ul></blockquote><p>怎么理解这个不可分割的意思呢? </p><blockquote><p>我们以向某个索引对应的B+树插入一条记录为例，在向B+树中插入这条记录之前，需要先定位到这条记录应该被插入到哪个叶子节点代表的数据⻚中，定位到具体的数据⻚之后，有两种可能的情况:</p><ul><li>情况一: 该数据⻚的剩余的空闲空间充足，足够容纳这一条待插入记录，那么事情很简单，直接把记录插入到这个数据⻚中，记录一条类型为MLOG_COMP_REC_INSERT的redo日志就好了，我们把这种情况称之为<code>乐观插入</code>。</li><li>情况二: 该数据⻚剩余的空闲空间不足，那么事情就悲剧了， 我们前边说过，遇到这种情况要进行所谓的<code>⻚分裂</code>操作，也就是新建一个叶子节点，然后把原先数据⻚中的一部分记录复制到这个新的数据⻚中，然后再把记录插入进去，把这个叶子节点插入到叶子节点链表中，最后还要在内节点中添加一条目录项记录指向这个新创建的⻚面。<br>很显然，这个过程要对多个⻚面进行修改，也就意味着会产生多条redo日志，我们把这种情况称之为<code>悲观插入</code>。<br>如果作为<code>内节点</code>的⻚a的剩余空闲空间也不足以容纳增加一条<code>目录项记录</code>，那需要继续做<code>内节点⻚a的分裂操作</code>，也就意味 着会修改更多的⻚面，从而产生更多的redo日志。<br>另外，对于 <code>悲观插入</code> 来说，由于需要新申请数据⻚，还需要改动一些系统⻚面，比方说要修改各种段、区的统计信息信息，各种链表的统计信息(比如什么FREE链表、FSP_FREE_FRAG链表吧啦吧啦，我们在唠叨表空间那一章中介绍过的各种东东)等等等等， 反正总共需要记录的redo日志有二、三十条。</li></ul></blockquote><p>设计InnoDB的大叔们认为向某个索引对应的B+树中插入一条记录的这个过程必须是原子的，不能说插了一半之后就停止了。</p><blockquote><p>比方说在<code>悲观插入</code>过程中，新的⻚面已经分配好了，数据也复制过去了，新的记录也插入到⻚面中了，可是没有向内节点中插入一条目录项记录，这个插入过程就是不完整的，这样会形成一棵不正确的B+树。</p><p>而redo日志是为了在系统奔溃重启时恢复崩溃前的状态，<strong>如果在悲观插入的过程中只记录了一部分redo日志，那么在系统奔溃重启时会将索引对应的B+树恢复成一种不正确的状态</strong> ，这是设计InnoDB的大叔们所不能忍受的。</p><p>所以他们规定在执行这些<code>需要保证原子性的操作</code>时必须以<code>组</code>的形式来记录的redo日志，在进行系统奔溃重启恢复时，针对某个<code>组</code>中的redo日志，要么把全部的日志都恢复掉，要么一条也不恢复。</p></blockquote><p>怎么做到的呢? 这得分情况讨论:</p><blockquote><ul><li><p>有的需要保证原子性的操作会生成多条redo日志，比如向某个索引对应的B+树中进行一次<code>悲观插入</code>就需要生成许多条redo日志。<br>如何把这些redo日志划分到一个组里边儿呢? 设计InnoDB的大叔做了一个很简单的小把戏，就是在该组中的最后一条redo日志后边加上一条特殊类型的redo日志，该类型名称为 <code>MLOG_MULTI_REC_END</code>，type字段对应的十进制数字为31，该类型的redo日志结构很简单，只有一个<code>type</code>字段。<br>所以某个需要保证原子性的操作产生的一系列redo日志必须要以一个类型为MLOG_MULTI_REC_END结尾，就像这样:</p><img src="/images/MySQL/20/6.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>这样在系统奔溃重启进行恢复时，只有当解析到类型为 `MLOG_MULTI_REC_END` 的redo日志，才认为解析到了一组完整的redo日志，才会进行恢复。否则的话直接放弃前边解析到的redo日志。</li><li><p>有的需要保证原子性的操作只生成一条redo日志，比如更新 Max Row ID属性的操作就只会生成一条redo日志。<br>其实在一条日志后边跟一个类型为<code>MLOG_MULTI_REC_END</code>的redo日志也是可以的，不过设计InnoDB的大叔比较勤俭节约，它们不想浪费一个比特位。别忘了虽然redo日志的类型比较多，但撑死了也就是几十种，是小于127这个数字的，也就是说我们用7个比特位就足以包括所有的redo日志类型，而type字段其实是占用1个字节的，也就是说我们可以省出来一个比特位用来表示该需要保证原子性的操作只产生单一的一条redo日志，示意图如下:</p><img src="/images/MySQL/20/7.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/>如果type字段的第一个比特为为1，代表该需要保证原子性的操作只产生了单一的一条redo日志，否则表示该需要保证原子性的操作产生了一系列的redo日志。</li></ul></blockquote><h1 id="Mini-Transaction的概念"><a href="#Mini-Transaction的概念" class="headerlink" title="Mini-Transaction的概念"></a>Mini-Transaction的概念</h1><p>设计MySQL的大叔把对底层⻚面中的一次<code>原子访问</code>的过程称之为一个<code>Mini-Transaction</code>，简称<code>mtr</code>，比如上边所说的修改一次Max Row ID的值算是一个Mini-Transaction，向某个索引对应的B+树中插入一条记录的过程也算是一个Mini-Transaction。</p><p>通过上边的叙述我们也知道，<strong>一个所谓的mtr可以包含一组redo日志 ， 在进行奔溃恢复时这一组redo日志作为一个不可分割的整体。</strong> </p><p>一个事务可以包含若干条语句，<strong>每一条语句其实是由若干个mtr组成</strong> ，<strong>每一个mtr又可以包含若干条redo日志</strong> ，画个图表示它们的关系就是这样:<br><img src="/images/MySQL/20/8.png" width="400" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;以组的形式写入redo日志&quot;&gt;&lt;a href=&quot;#以组的形式写入redo日志&quot; class=&quot;headerlink&quot; title=&quot;以组的形式写入redo日志&quot;&gt;&lt;/a&gt;以组的形式写入redo日志&lt;/h1&gt;&lt;p&gt;语句在执行过程中可能修改若干个⻚面。比如我们前边说的</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>20.1 redo日志格式</title>
    <link href="http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.1%20redo%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F%E5%92%8C%E7%B1%BB%E5%9E%8B/"/>
    <id>http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.1%20redo%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F%E5%92%8C%E7%B1%BB%E5%9E%8B/</id>
    <published>2021-12-11T14:16:41.000Z</published>
    <updated>2024-04-27T09:10:32.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redo-日志格式"><a href="#redo-日志格式" class="headerlink" title="redo 日志格式"></a>redo 日志格式</h1><p>通过上边的内容我们知道，redo日志本质上只是记录了一下事务对数据库做了哪些修改。 </p><blockquote><p>设计InnoDB的大叔们针对 事务对数据库的不同修改场景 定义了多种类型的redo日志，但大部分类型都有下边这种通用的结构:<br><img src="/images/MySQL/20/1.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br><code>type</code>: 该条redo日志的类型 (在MySQL 5.7.21中，设计InnoDB的大叔一共为redo日志设计了53种不同的类型，稍后会详细介绍不同类型的redo日志。)<br><code>space ID</code>: 表空间ID<br><code>page number</code>: ⻚号<br><code>data</code>: 该条redo日志的具体内容</p></blockquote><h1 id="简单的redo日志类型"><a href="#简单的redo日志类型" class="headerlink" title="简单的redo日志类型"></a>简单的redo日志类型</h1><blockquote><p>前边介绍InnoDB的<code>记录行格式</code>时说过，如果我们没有为某个表显式的定义主键，并且表中也没有定义Unique键，InnoDB会自动的为表添加一个称之为<code>row_id</code>的隐藏列作为主键。</p><p>这个<code>row_id隐藏列</code>的赋值方式如下:</p><ul><li>服务器会在内存中维护一个<code>全局变量</code>，每当向某个包含隐藏的row_id列的表中插入一条记录时，就会把该<code>全局变量</code>的值当作新记录的row_id列的值，并且把该<code>全局变量</code>自增1。</li><li>每当这个变量的值为256的倍数时，就会将该变量的值刷新到系统表空间的⻚号为7的⻚面中一个称之为<code>Max Row ID</code>的属性处(前边介绍表空间结构时详细说过)。</li><li>当系统启动时，会将上边提到的<code>Max Row ID</code>属性加载到内存中，将该值加上256之后赋值给我们前边提到的全局变量(因为在上次关机时该<code>全局变量</code>的值可能大于<code>Max Row ID</code>属性值(lant: 关机时，全局变量可能会没即时刷到表空间的⻚号为7的⻚面中的Max Row ID属性 😝))。</li></ul></blockquote><blockquote><p>这个<code>Max Row ID</code>属性占用的存储空间是8个字节，当某个事务向某个包含row_id隐藏列的表插入一条记录，并且为该记录分配的row_id值为256的倍数时，就会向系统表空间⻚号为7的⻚面的相应偏移量处写入8个字节的值。<br>但是我们要知道，这个写入实际上是在 <code>Buffer Pool</code> 中完成的，我们需要为这个⻚面的修改记录一条redo日志，以便在系统奔溃后能将已经提交的该事务对该⻚面所做的修改恢复出来。<br>这种情况下对⻚面的修改是极其简单的，redo日志中只需要记录一下在某个⻚面的某个偏移量处修改了几个字节的值，具体被修改的内容是啥就好了，设计InnoDB的大叔把这种极其简单的redo日志称之为 <code>物理日志</code>，并且根据在⻚面中写入数据的多少划分了几种不同的redo日志类型:</p><ul><li><code>MLOG_1BYTE</code>(type字段对应的十进制数字为1): 表示在⻚面的某个偏移量处写入1个字节的redo日志类型。</li><li><code>MLOG_2BYTE</code>(type字段对应的十进制数字为2): 表示在⻚面的某个偏移量处写入2个字节的redo日志类型。</li><li><code>MLOG_4BYTE</code>(type字段对应的十进制数字为4): 表示在⻚面的某个偏移量处写入4个字节的redo日志类型。</li><li><code>MLOG_8BYTE</code>(type字段对应的十进制数字为8): 表示在⻚面的某个偏移量处写入8个字节的redo日志类型。</li><li><code>MLOG_WRITE_STRING</code>(type字段对应的十进制数字 为30): 表示在⻚面的某个偏移量处写入一串数据。</li></ul></blockquote><blockquote><p>我们上边提到的 <code>Max Row ID</code> 属性实际占用8个字节的存储空间，所以在修改⻚面中的该属性时，会记录一条类型为 <code>MLOG_8BYTE</code> 的redo日志，MLOG_8BYTE的redo日志结构如下所示:<br><img src="/images/MySQL/20/2.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>其余 MLOG_1BYTE、MLOG_2BYTE、MLOG_4BYTE类型的redo日志结构和MLOG_8BYTE的类似，只不过具体数据中包含对应个字节的数据罢了。</p><p>MLOG_WRITE_STRING类型的redo日志表示写入一串数据，但是因为不能确定写入的具体数据占用多少字节，所以需要在日志结构中添加一个<code>len</code>字段:<br><img src="/images/MySQL/20/3.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p></blockquote><h1 id="复杂一些的redo日志类型"><a href="#复杂一些的redo日志类型" class="headerlink" title="复杂一些的redo日志类型"></a>复杂一些的redo日志类型</h1><blockquote><p>有时候执行一条语句会修改非常多的⻚面，包括<code>系统数据⻚面</code>和<code>用户数据⻚面</code>(用户数据指的就是聚簇索引和二级索引对应的B+树)。<br>以一条INSERT语句为例，它除了要向B+树的⻚面中插入数据，也可能更新系统数据<code>Max Row ID</code>的值，不过对于我们用户来说，平时更关心的是语句对B+树所做更新:</p><ul><li>表中包含多少个索引，一条INSERT语句就可能更新多少棵B+树。</li><li>针对某一棵B+树来说，既可能更新<code>叶子节点⻚面</code>，也可能更新<code>内节点⻚面</code>，也可能创建新的⻚面(<strong>在该记录插入的叶子节点的剩余空间比较少，不足以存放该记录时，会进行⻚面的分裂，在内节点⻚面中添加目录项记录</strong>)。</li></ul></blockquote><hr><blockquote><p>在语句执行过程中，INSERT语句对所有⻚面的修改都得保存到 <code>redo日志</code> 中去。<br>这句话说的比较轻巧，做起来可就比较麻烦了，比方说将记录插入到聚簇索引中时，如果定位到的叶子节点的剩余空间足够存储该记录时，那么只更新该叶子节点⻚面就好，那么只记录一条<code>MLOG_WRITE_STRING</code>类型的redo日志，表明在⻚面的某个偏移量处增加了哪些数据就好了么? 那就too young too naive了<br>别忘了一个数据⻚中除了存储实际的记录之后，还有什么 File Header、Page Header、Page Directory 等等部分(在唠叨数据⻚的章节有详细讲解)，所以每往叶子节点代表的数据⻚里插入一条记录时，还有其他很多地方会跟着更新，比如说:</p><ul><li>可能更新 <code>Page Directory</code> 中的<code>槽</code>信息</li><li>Page Header中的各种⻚面统计信息，比如 PAGE_N_DIR_SLOTS表示的槽数量可能会更改，PAGE_HEAP_TOP代表的还未使用的空间最小地址可能会更改，PAGE_N_HEAP代表的本⻚面中的记录数量可能会更改，吧啦吧啦，各种信息都可能会被修改。</li><li>我们知道在数据⻚里的记录是按照索引列从小到大的顺序组成一个单向链表的，每插入一条记录，还需要更新上一条记录的记录头信息中的next_record属性来维护这个单向链表。</li><li>还有别的吧啦吧啦的更新的地方，就不一一唠叨了…</li></ul><p>画一个简易的示意图就像是这样:<br><img src="/images/MySQL/20/4.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p></blockquote><hr><blockquote><p>说了这么多，就是想表达: <strong>把一条记录插入到一个⻚面时需要更改的地方非常多</strong>。<br>这时我们如果使用上边介绍的简单的物理redo日志来记录这些修改时，可以有两种解决方案:</p><ul><li>方案一:在每个修改的地方都记录一条redo日志。<blockquote><p>也就是如上图所示，有多少个加粗的块，就写多少条物理redo日志。<br>这样子记录redo日志的缺点是显而易⻅的，因为被修改的地方是在太多了，可能记录的redo日志占用的空间都比整个⻚面占用的空间都多了 😓</p></blockquote></li><li>方案二:将整个⻚面的第一个被修改的字节到最后一个修改的字节之间所有的数据当成是一条物理redo日志中的具体数据。<blockquote><p>从图中也可以看出来，第一个被修改的字节到最后一个修改的字节之间仍然有许多没有修改过的数据，我们把这些没有修改的数据也加入到redo日志中去岂不是太浪费了 😓</p></blockquote></li></ul></blockquote><hr><blockquote><p>正因为上述两种使用<code>物理redo日志</code>的方式来记录某个⻚面中做了哪些修改比较浪费，设计InnoDB的大叔本着勤俭节约的初心，提出了一些新的redo日志类型，比如:</p><ul><li><code>MLOG_REC_INSERT</code>(对应的十进制数字为9): 表示插入一条使用非紧凑行格式的记录时的redo日志类型。</li><li><code>MLOG_COMP_REC_INSERT</code>(对应的十进制数字为38): 表示插入一条使用紧凑行格式的记录时的redo日志类型。<blockquote><p>Tips:<br>Redundant是一种比较原始的行格式，它就是非紧凑的。而 Compact、Dynamic以及Compressed行格式是较新的行格式，它们是紧凑的(占用更小的存储空间)。</p></blockquote></li><li><code>MLOG_COMP_PAGE_CREATE</code>(type字段对应的十进制数字为58): 表示创建一个存储紧凑行格式记录的⻚面的redo日志类型。</li><li><code>MLOG_COMP_REC_DELETE</code>(type字段对应的十进制数字为42): 表示删除一条使用紧凑行格式记录的redo日志类型。</li><li><code>MLOG_COMP_LIST_START_DELETE</code>(type字段对应的十进制数字为44): 表示从某条给定记录开始删除⻚面中的一系列使用紧凑行格式记录的redo日志类型。</li><li><code>MLOG_COMP_LIST_END_DELETE</code>(type字段对应的十进制数字为43): 与MLOG_COMP_LIST_START_DELETE类型的redo日志呼应，表示删除一系列记录直到MLOG_COMP_LIST_END_DELETE类型的redo日志对应的记录为止。<blockquote><p>小贴士:<br>我们前边唠叨InnoDB数据⻚格式的时候重点强调过，数据⻚中的记录是按照索引列大小的顺序组成单向链表的。有时候我们会有删除索引列的值在某个区间范围内的所有记录的需求，这时候如果我们每删除一条记录就写一条redo日志的话，效率可能有点低，所以提出 <code>MLOG_COMP_LIST_START_DELETE</code> 和 <code>MLOG_COMP_LIST_END_DELETE</code> 类型的redo日志，<strong>可以很大程度上减少redo日志的条数</strong> 。</p></blockquote></li><li><code>MLOG_ZIP_PAGE_COMPRESS</code>(type字段对应的十进制数字为51): 表示压缩一个数据⻚的redo日志类型。<br>······还有很多很多种类型，这就不列举了，等用到再说哈~</li></ul></blockquote><hr><blockquote><p>这些类型的redo日志既包含<code>物理层面</code>的意思，也包含<code>逻辑层面</code>的意思，具体指:</p><ul><li>物理层面看，这些日志都指明了对哪个表空间的哪个⻚进行了修改。</li><li>逻辑层面看，在系统奔溃重启时，并不能直接根据这些日志里的记载，将⻚面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将⻚面恢复成系统奔溃前的样子。</li></ul><p>大家看到这可能有些懵逼，我们还是以类型为 <code>MLOG_COMP_REC_INSERT</code> 这个代表插入一条使用紧凑行格式的记录时的redo日志为例来理解一下我们上边所说的物理层面和逻辑层面到底是个啥意思。废话少说，直接看一下这个类型为 <code>MLOG_COMP_REC_INSERT</code> 的redo日志的结构(由于字段太多了，我们把它们竖着看效果好些):<br><img src="/images/MySQL/20/5.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志结构有几个地方需要大家注意:</p><ul><li>我们前边在唠叨索引的时候说过，在一个数据⻚里，不论是<code>叶子节点</code>还是<code>非叶子节点</code>，记录都是按照索引列从小到大的顺序排序的。对于二级索引来说，当索引列的值相同时，记录还需要按照主键值进行排序。<br>图中<code>n_uniques</code>的值的含义是在一条记录中，需要几个字段的值才能确保记录的唯一性，这样当插入一条记录时就可以按照记录的前<code>n_uniques</code>个字段进行排序。<br>对于<code>聚簇索引</code>来说，n_uniques的值为主键的列数，对于其他二级索引来说，该值为<code>索引列数+主键列数</code>。这里需要注意的是，唯一二级索引的值可能为NULL，所以该值仍然为 <code>索引列数+主键列数</code>。</li><li>field1_len ~ fieldn_len 代表着该记录若干个字段占用存储空间的大小，需要注意的是，这里不管该字段的类型是固定⻓度大小的(比如INT)，还是可变⻓度大小(比如 VARCHAR(M))的，该字段占用的大小始终要写入redo日志中。</li><li>offset 代表的是该记录的前一条记录在⻚面中的地址。为啥要记录前一条记录的地址呢? 这是因为每向数据⻚插入一条记录，都需要修改该⻚面中维护的记录链表，每条记录的记录头信息中都包含一个称为next_record的属性，所以在插入新记录时，需要修改前一条记录的next_record属性。</li><li>我们知道一条记录其实由<code>额外信息</code>和<code>真实数据</code>这两部分组成，这两个部分的总大小就是一条记录占用存储空间的总大小。通过<code>end_seg_len</code>的值可以间接的计算出一条记录占用存储空间的总大小，为啥不直接存储一条记录占用存储空间的总大小呢?<br>这是因为写redo日志是一个非常频繁的操作，设计InnoDB的大叔想方设法想减小redo日志本身占用的存储空间大小，所以想了一些弯弯绕的算法来实现这个目标，<code>end_seg_len</code>这个字段就是为了节省redo日志存储空间而提出来的。<br>至于具体设计InnoDB的大叔到底是用了什么神奇魔法减小redo日志大小的，我们这就不多唠叨了，因为的确有那么一丢丢小复杂，说清楚还是有一点点麻烦的，而且说明白了也没啥用。</li><li><code>mismatch_index</code>的值也是为了节省redo日志的大小而设立的，大家可以忽略。</li></ul><p>很显然这个类型为<code>MLOG_COMP_REC_INSERT</code>的redo日志并没有记录<code>PAGE_N_DIR_SLOTS</code>的值修改为了啥，PAGE_HEAP_TOP的值修改为了啥，PAGE_N_HEAP的值修改为了啥等等这些信息，而只是把在本⻚面中插入一条记录所有必备的要素记了下来，之后系统奔溃重启时，服务器会调用相关向某个⻚面插入一条记录的那个函数，而redo日志中的那些数据就可以被当成是调用这个函数所需的参数，在调用完该函数后，⻚面中的 PAGE_N_DIR_SLOTS、PAGE_HEAP_TOP、PAGE_N_HEAP等等的值也就都被恢复到系统奔溃前的样子了。这就是所谓的<code>逻辑日志</code>的意思。</p></blockquote><h1 id="redo日志格式小结"><a href="#redo日志格式小结" class="headerlink" title="redo日志格式小结"></a>redo日志格式小结</h1><p>虽然上边说了一大堆关于redo日志格式的内容，但是如果你不是为了写一个解析redo日志的工具或者自己开发一套redo日志系统的话，那就没必要把InnoDB中的各种类型的redo日志格式都研究的透透的，没那个必要。<br>上边只是象征性的介绍了几种类型的redo日志格式，目的还是想让大家明白: redo日志会把事务在执行过程中对数据库所做的所有修改都记录下来，在之后系统奔溃重启后可以把事务所做的任何修改都恢复出来。</p><p>Tips: 为了节省redo日志占用的存储空间大小，设计InnoDB的大叔对redo日志中的某些数据还可能进行压缩处理，比方说spacd ID和 page number一般占用4个字节来存储，但是经过压缩后，可能使用更小的空间来存储。具体压缩算法就不唠叨了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;redo-日志格式&quot;&gt;&lt;a href=&quot;#redo-日志格式&quot; class=&quot;headerlink&quot; title=&quot;redo 日志格式&quot;&gt;&lt;/a&gt;redo 日志格式&lt;/h1&gt;&lt;p&gt;通过上边的内容我们知道，redo日志本质上只是记录了一下事务对数据库做了哪些修改。 </summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>20.0 redo日志是个啥</title>
    <link href="http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.0%20redo%E6%97%A5%E5%BF%97/"/>
    <id>http://rymuscle.github.io/2021/12/11/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/20.0%20redo%E6%97%A5%E5%BF%97/</id>
    <published>2021-12-11T13:07:32.000Z</published>
    <updated>2024-04-27T09:10:57.372Z</updated>
    
    <content type="html"><![CDATA[<p>前置知识点 : InnoDB<code>记录行格式</code>、<code>⻚面格式</code>、<code>索引原理</code>、<code>表空间的组成</code>等各种基础知识</p><h1 id="redo日志是个啥"><a href="#redo日志是个啥" class="headerlink" title="redo日志是个啥"></a>redo日志是个啥</h1><div style="font-weight:500;border: 1px solid #33b045;border-radius: 5px;padding:10px 10px 0 25px;"><div style="font-weight:500;color:#33b045;margin-bottom:10px;"><p>我们知道 InnoDB存储引擎是以<code>⻚</code>为单位来管理存储空间的 ，我们进行的增删改查操作本质上都是在访问<code>⻚</code>(包括对⻚面的读、写、创建等操作)。</p></div><div style="font-weight:500;color:#f8b500;margin-bottom:10px;"><p>我们前边讲<code>Buffer Pool</code>时说过，在真正访问<code>⻚</code>之前，需要把在<code>磁盘上的⻚</code>缓存到<code>内存中的 Buffer Pool</code>之后才可以访问。</p><p>但是在讲<code>事务</code>时又强调过一个称之为<code>持久性</code>的特性，就是说对于一个已经提交的事务，在事务提交后即使系统发生了崩溃，这个事务对数据库中所做的更改也不能丢失。<br><span style="color:#FF416C;">但如果我们只在内存的<code>Buffer Pool</code>中修改了⻚面，假设在事务提交后突然发生了某个故障，导致内存中的数据都失效了，那么这个已经提交了的事务对数据库中所做的更改也就跟着丢失了，这是我们所不能忍受的。</span></p></div></div><div style="border: 1px solid #000;border-radius: 5px;padding:10px 10px 0 25px;margin-top:20px;"><p>那到底该如何来保证这个持久性呢?</p><p>一个很简单的做法就是<span style="color:#FF416C;font-weight:600;">在事务提交完成之前把该事务所修改的所有⻚面都刷新到磁盘</span>，但是这个做法太<span style="color:#FF416C;">简单粗暴</span>了，是有问题的:</p><ul><li><span style="color:#FF416C;font-weight:600;">刷新一个完整的数据⻚太浪费了</span><br>有时候我们仅仅修改了某个⻚面中的一个字节，但是InnoDB是以⻚为单位来进行磁盘IO的，也就是说我们在该事务提交时不得不将一个完整的⻚面从内存中刷新到磁盘，只修改一个字节就要刷新16KB的数据到磁盘上显然是太浪费了；</li><li><span style="color:#FF416C;font-weight:600;">随机IO刷起来比较慢</span><br>一个事务可能包含很多语句，即使是一条语句也可能修改许多个⻚，<span style="color:#FF416C;font-weight:600;">这些⻚可能并不相邻，这就意味着在将某个事务修改的<code>Buffer Pool</code>中的<code>⻚</code>刷新到磁盘时，需要进行很多的<code>随机IO</code></span>，随机IO比顺序IO要慢，尤其对于传统的机械硬盘来说；</li></ul></div><div style="border: 1px solid #000;border-radius: 5px;padding:10px 10px 0 25px;margin-top:20px;"><p>咋办呢?<br><span style="color:#FF416C;font-weight:600;">其实没有必要在每次事务提交时就把该事务在内存中修改过的全部⻚面刷新到磁盘</span>，<span style="color:#33b045;font-weight:600;">只需要把修改了哪些东⻄记录一下就好</span>，比方说某个事务将系统表空间中的第100号⻚面中偏移量为1000处的那个字节的值1改成2我们只需要记录一下:<code>将第0号表空间的100号⻚面的偏移量为1000处的值更新为2。</code></p><p>这样我们在事务提交时，只用把上述内容刷新到磁盘中，即使之后系统崩溃了，重启之后只要按照上述内容所记录的步骤重新更新一下数据⻚，那么该事务对数据库中所做的修改又可以被恢复出来。<br>因为在系统奔溃重启时需要按照上述内容所记录的步骤重新更新数据⻚，所以上述内容也被称之为<code>重做日志</code>，英文名为<code>redo log</code>。</p></div><div style="font-weight:500;border: 2px solid #33b045;border-radius: 5px;margin-top:10px;padding:10px 10px 0 25px;"><p>与在事务提交时将所有修改过的内存中的⻚面刷新到磁盘中相比，只将该事务执行过程中产生的redo日志刷新到磁盘的好处如下:</p><ul><li><span style="color:#33b045;font-weight:600;">redo日志占用的空间非常小</span><br>存储表空间ID、⻚号、偏移量以及需要更新的值所需的存储空间是很小的，关于redo日志的格式我们稍后会详细唠叨，现在只要知道一条redo日志占用的空间不是很大就好了。</li><li><span style="color:#33b045;font-weight:600;">redo日志是顺序写入磁盘的</span><br>在执行事务的过程中，每执行一条语句，可能会产生若干条redo日志，不过，这些日志是按照产生的顺序写入磁盘的，也就是使用<code>顺序IO</code>，比你每次提交去将不相邻的页(<code>随机IO</code>)落盘强多了。</li></ul></div>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前置知识点 : InnoDB&lt;code&gt;记录行格式&lt;/code&gt;、&lt;code&gt;⻚面格式&lt;/code&gt;、&lt;code&gt;索引原理&lt;/code&gt;、&lt;code&gt;表空间的组成&lt;/code&gt;等各种基础知识&lt;/p&gt;
&lt;h1 id=&quot;redo日志是个啥&quot;&gt;&lt;a href=&quot;#redo日志是个</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>19. 事务简介</title>
    <link href="http://rymuscle.github.io/2021/12/10/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/19.%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B/"/>
    <id>http://rymuscle.github.io/2021/12/10/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/19.%E4%BA%8B%E5%8A%A1%E7%AE%80%E4%BB%8B/</id>
    <published>2021-12-10T13:06:17.000Z</published>
    <updated>2024-04-27T05:31:37.559Z</updated>
    
    <content type="html"><![CDATA[<h1 id="事务的起源"><a href="#事务的起源" class="headerlink" title="事务的起源"></a>事务的起源</h1><blockquote><p>对于大部分程序员来说，他们的任务就是把现实世界的业务场景映射到数据库世界。</p><p>比如银行为了存储人们的账户信息会建立一个account表:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE account (</span><br><span class="line">    id INT NOT NULL AUTO_INCREMENT COMMENT &#x27;自增id&#x27;,</span><br><span class="line">    name VARCHAR(100) COMMENT &#x27;客户名称&#x27;, </span><br><span class="line">    balance INT COMMENT &#x27;余额&#x27;,</span><br><span class="line">    PRIMARY KEY (id)</span><br><span class="line">) Engine=InnoDB CHARSET=utf8;</span><br></pre></td></tr></table></figure><p>狗哥和猫爷是一对好基友，他们都到银行开一个账户，他们在现实世界中拥有的资产就会体现在数据库世界的account表中。<br>比如现在狗哥有11元，猫爷只有2元，那么现实中的这个情况映射到数据库的account表就是这样:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+----+------+---------+ </span><br><span class="line">| id | name | balance | </span><br><span class="line">+----+------+---------+ </span><br><span class="line">| 1  |  狗哥 |    11   | </span><br><span class="line">| 2  |  猫爷 |    2    | </span><br><span class="line">+----+------+---------+</span><br></pre></td></tr></table></figure></blockquote><hr><blockquote><p>随着时间的流逝，狗哥和猫爷可能陆续进行向账户中存钱、取钱或者向别人转账，这样他们账户中的余额就可能发生变动。<br>不变不知道，一变吓一跳，现实世界中一些看似很简单的状态转换，映射到数据库世界却不是那么容易的。</p><p>比方说有一次猫爷在赌场赌博输了钱，急忙打电话给狗哥要借10块钱，不然那些看场子的就会把自己剁了。<br>现实世界中的狗哥走向了ATM机，输入了猫爷的账号以及10元的转账金额，然后按下确认，狗哥就拔卡走人了。<br>对于数据库世界来说，相当于执行了下边这两条语句:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UPDATE account SET balance = balance - 10 WHERE id = 1;</span><br><span class="line">UPDATE account SET balance = balance + 10 WHERE id = 2;</span><br></pre></td></tr></table></figure></blockquote><div style="font-weight:500;border: 1px solid #33b045;border-radius: 5px;padding:10px 10px 0 25px;"><p><strong>但是这里头有个问题，上述两条语句如果只执行了一条时，忽然服务器断电了咋办?</strong> </p><ul><li>把狗哥的钱扣了，但是没给猫爷转过去，那猫爷还是逃脱不了被砍死的噩运。</li><li><span style="font-weight:600;color:#FF416C">即使对于<code>单独的一条语句</code>，我们前边唠叨<code>Buffer Pool</code>时也说过，在对某个⻚面进行读写访问时，都会先把这个⻚面加载到<code>Buffer Pool</code>中，之后如果修改了某个⻚面，也不会立即把修改同步到磁盘，而只是把这个修改了的⻚面加到<code>Buffer Pool</code>的<code>flush链表</code>中，在之后的某个时间点才会刷新到磁盘。如果在将修改过的⻚刷新到磁盘之前系统崩溃了那岂不是猫爷还是要被砍死? </span></li><li>或者<span style="font-weight:600;color:#FF416C">在刷新磁盘的过程中 只刷新部分数据到磁盘上时，系统奔溃了</span> 猫爷也会被砍死?</li></ul></div><hr><p>怎么才能保证让可怜的猫爷不被砍死呢?<br>其实再仔细想想，我们只是想让某些数据库操作符合现实世界中状态转换的规则而已，设计数据库的大叔们仔细盘算了盘算，现实世界中状态转换的规则有好几条，待我们慢慢道来。</p><h1 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性(Atomicity)"></a>原子性(Atomicity)</h1><p>现实世界中转账操作是一个不可分割的操作，也就是说要么压根儿就没转，要么转账成功，不能存在中间的状态，也就是转了一半的这种情况。<br>设计数据库的大叔们把这种要么全做，要么全不做的规则称之为<code>原子性</code>。</p><div style="font-weight:500;border: 1px solid #33b045;border-radius: 5px;"><ul><li>但是在现实世界中的<span style="font-weight:600;color:#FF416C">一个不可分割的操作却可能对应着数据库世界若干条不同的操作</span>；</li><li><span style="font-weight:600;color:#FF416C">数据库中的一条操作也可能被分解成若干个步骤</span> (比如<code>先修改缓存⻚</code>，<code>之后再刷新到磁盘</code>等)；</li><li><span style="color:#FF416C;font-weight:600;">最要命的是在任何一个可能的时间都可能发生意想不到的错误(可能是数据库本身的错误，或者是操作系统错误，甚至是直接断电之类的)而使操作执行不下去</span>；</li></ul><p>所以猫爷可能会被砍死。</p></div><p>为了保证在数据库世界中某些操作的<code>原子性</code>，设计数据库的大叔 <strong>需要费一些心机来保证如果在执行操作的过程中发生了错误，得把已经做了的操作恢复成没执行之前的样子</strong> ，这也是我们后边章节要仔细唠叨的内容。</p><h1 id="隔离性-Isolation"><a href="#隔离性-Isolation" class="headerlink" title="隔离性(Isolation)"></a>隔离性(Isolation)</h1><blockquote><p><strong>现实世界中的两次状态转换应该是互不影响的</strong> ，比如说狗哥向猫爷同时进行的两次金额为5元的转账(假设可以在两个ATM机上同时操作)。那么最后狗哥的账户里肯定会少10元，猫爷的账户里肯定多了10元。</p><p>但是到对应的数据库世界中，事情又变的复杂了一些。 为了简化问题，我们粗略的假设狗哥向猫爷转账5元的过程是由下边几个步骤组成的:</p><ul><li>步骤一: 读取狗哥账户的余额到变量A中，这一步骤简写为<code>read(A)</code>。</li><li>步骤二: 将狗哥账户的余额减去转账金额，这一步骤简写为 <code>A = A - 5</code>。</li><li>步骤三: 将狗哥账户修改过的余额写到磁盘里，这一步骤简写为 <code>write(A)</code>。</li><li>步骤四: 读取猫爷账户的余额到变量B，这一步骤简写为 <code>read(B)</code>。</li><li>步骤五: 将猫爷账户的余额加上转账金额，这一步骤简写为 <code>B = B + 5</code>。</li><li>步骤六: 将猫爷账户修改过的余额写到磁盘里，这一步骤简写为 <code>write(B)</code>。</li></ul><p>我们将狗哥向猫爷同时进行的<strong>两次</strong>转账操作分别称为T1和T2，在现实世界中T1和T2是应该没有关系的，可以先执行完T1，再执行T2，或者先执行完T2，再执行T1，对应的数据库操作就像这样:<br><img src="/images/MySQL/19/1.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br><span style="font-weight:600;color:#FF416C">但是很不幸，真实的数据库中T1和T2的操作可能交替执行</span>:<br><img src="/images/MySQL/19/2.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>如果按照上图中的执行顺序来进行两次转账的话，最终狗哥的账户里还剩6元钱，相当于只扣了5元钱，但是猫爷的账户里却成了12元钱，相当于多了10元钱，这银行岂不是要亏死了?</p></blockquote><hr><blockquote><p>所以对于现实世界中状态转换对应的某些数据库操作来说，不仅要保证这些操作以<code>原子性</code>的方式执行完成，而且要保证其它的状态转换不会影响到本次状态转换，这个规则被称之为<code>隔离性</code>。<br>这时设计数据库的大叔们就需要采取一些措施来让访问相同数据(上例中的A账户和B账户)的不同状态转换(上例中的T1和T2)<strong>对应的数据库操作的执行顺序有一定规律</strong>，这也是我们后边章节要仔细唠叨的内容。</p></blockquote><h1 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性(Consistency)"></a>一致性(Consistency)</h1><blockquote><p>lant:<br>一致性是指事务执行前后，数据库从一个一致性状态转换到另一个一致性状态。这个一致性包括业务上的一些规则。<br>换句话说，事务应确保数据库的完整性约束得到维护。</p><p>例如，如果有一个完整性约束要求一个账户的余额不能为负数，那么在事务执行之后，这个约束仍然应该得到满足。<br>再比如执行转账操作前，我们业务上认为 “A用户100元,B用户0元” 是一个一致性状态，转账成功后，“A用户0元,B用户100元” 是另一个一致性状态。 </p><p>事务应该保证这样的状态转变。</p></blockquote><h1 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h1><blockquote><p>lant: 持久性是指事务一旦提交，对数据库所做的修改将会在磁盘上保留下来。即使在系统故障或重启的情况下，已提交的事务对数据库的更改也不会丢失。</p></blockquote><h1 id="MySQL中事务的语法"><a href="#MySQL中事务的语法" class="headerlink" title="MySQL中事务的语法"></a>MySQL中事务的语法</h1><ol><li>开启事务(可以使用下边两种语句之一来开启一个事务)</li></ol><ul><li><code>BEGIN [WORK]</code> :<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//BEGIN 语句代表开启一个事务，后边的单词`WORK`可有可无。</span><br><span class="line">//开启事务后，就可以继续写若干条语句，这些语句都属于刚刚开启的这个事务。</span><br><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; 加入事务的语句...</span><br></pre></td></tr></table></figure></li><li><code>START TRANSACTION</code> : 和<code>BEGIN</code>语句有着相同的功效，都标志着开启一个事务<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; START TRANSACTION;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; 加入事务的语句...</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li><p>提交事务<br>开启事务之后就可以继续写需要放到该事务中的语句了，当最后一条语句写完了之后，我们就可以提交该事务了，提交的语句也很简单：<code>COMMIT [WORK]</code>， 一个简单的事务的完整过程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;</span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE account SET balance = balance + 10 WHERE id = 2;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">// `COMMIT`语句就代表提交一个事务，后边的`WORK`可有可无。</span><br><span class="line">mysql&gt; COMMIT;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure></li><li><p>手动中止事务<br>如果我们写了几条语句之后发现上边的某条语句写错了，我们可以手动的使用下边这个语句来将数据库恢复到事务执行之前的样子：<code>ROLLBACK [WORK]</code>， 一个简单的事务回滚案例如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE account SET balance = balance + 1 WHERE id = 2;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">// `ROLLBACK`语句就代表中止并回滚一个事务，后边的`WORK`可有可无类似的</span><br><span class="line">mysql&gt; ROLLBACK;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><p>这里需要强调一下，<code>ROLLBACK</code>语句是我们程序员手动的去回滚事务时才去使用的。 <strong>如果事务在执行过程中遇到了某些错误而无法继续执行的话，事务自身会自动的回滚。</strong></p></li></ol><h1 id="事务的-自动提交"><a href="#事务的-自动提交" class="headerlink" title="事务的 自动提交"></a>事务的 自动提交</h1><ol><li><p><code>MySQL</code>中有一个系统变量<code>autocommit</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW VARIABLES LIKE &#x27;autocommit&#x27;;</span><br><span class="line">+---------------+-------+</span><br><span class="line">| Variable_name | Value |</span><br><span class="line">+---------------+-------+</span><br><span class="line">| autocommit    | ON    |</span><br><span class="line">+---------------+-------+</span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><p>可以看到它的默认值为<code>ON</code>。<br>也就是说默认情况下，如果我们不显式的使用<code>START TRANSACTION</code>或者<code>BEGIN</code>语句开启一个事务，那么每一条sql语句都算是一个独立的事务，这种特性称之为事务的<code>自动提交</code>。</p></li><li><p>当然，如果我们想关闭这种<code>自动提交</code>的功能，可以使用下边两种方法之一：</p></li></ol><ul><li>显式的的使用<code>START TRANSACTION</code>或者<code>BEGIN</code>语句开启一个事务。这样在本次事务提交或者回滚前会暂时关闭掉自动提交的功能。</li><li>把系统变量<code>autocommit</code>的值设置为<code>OFF</code> (<code>SET autocommit = OFF;</code>)<br>这样的话，我们写入的多条语句就算是属于同一个事务了，直到我们显式的写出<code>COMMIT</code>语句来把这个事务提交掉，或者显式的写出<code>ROLLBACK</code>语句来把这个事务回滚掉。</li></ul><h1 id="事务的-隐式提交"><a href="#事务的-隐式提交" class="headerlink" title="事务的 隐式提交"></a>事务的 隐式提交</h1><p>当我们使用<code>START TRANSACTION</code>或者<code>BEGIN</code>语句开启了一个事务，或者把系统变量<code>autocommit</code>的值设置为<code>OFF</code>时，事务就不会进行<code>自动提交</code>了。<br>但是如果我们输入了某些语句之后，事务是会<code>悄悄的</code>提交的，就像我们输入了<code>COMMIT</code>语句了一样，这种因为某些特殊的语句而导致事务提交的情况称为<code>隐式提交</code>，这些会导致事务隐式提交的语句包括：</p><ol><li><p>定义或修改数据库对象的数据定义语言(Data definition language，缩写为：<code>DDL</code>)。</p><ul><li>所谓的数据库对象，指的就是<code>数据库</code>、<code>表</code>、<code>视图</code>、<code>存储过程</code>等等这些东西。</li><li>当我们使用<code>CREATE</code>、<code>ALTER</code>、<code>DROP</code>等语句去修改这些所谓的数据库对象时，就会隐式的提交前边语句所属于的事务，就像这样：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">SELECT ... # 事务中的一条语句</span><br><span class="line">UPDATE ... # 事务中的一条语句</span><br><span class="line">... # 事务中的其它语句</span><br><span class="line"></span><br><span class="line">CREATE TABLE ... # 此语句会隐式的提交前边语句所属于的事务</span><br></pre></td></tr></table></figure></li></ul></li><li><p>隐式使用或修改<code>mysql</code>数据库中的表<br>当我们使用<code>ALTER USER</code>、<code>CREATE USER</code>、<code>DROP USER</code>、<code>GRANT</code>、<code>RENAME USER</code>、<code>REVOKE</code>、<code>SET PASSWORD</code>等语句时也会隐式的提交前边语句所属于的事务。</p></li><li><p>事务控制或关于锁定的语句<br>当我们在一个事务还没提交或者回滚时就又使用<code>START TRANSACTION</code>或者<code>BEGIN</code>语句开启了另一个事务时，会隐式的提交上一个事务，比如这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BEGIN;</span><br><span class="line"></span><br><span class="line">SELECT ... # 事务中的一条语句</span><br><span class="line">UPDATE ... # 事务中的一条语句</span><br><span class="line">... # 事务中的其它语句</span><br><span class="line"></span><br><span class="line">BEGIN; # 此语句会隐式的提交前边语句所属于的事务</span><br></pre></td></tr></table></figure></li><li><p>或者当前的<code>autocommit</code>系统变量的值为<code>OFF</code>，我们手动把它调为<code>ON</code>时，也会隐式的提交前边语句所属的事务。</p></li><li><p>或者使用<code>LOCK TABLES</code>、<code>UNLOCK TABLES</code>等关于锁定的语句也会隐式的提交前边语句所属的事务。</p></li><li><p>加载数据的语句<br>比如我们使用<code>LOAD DATA</code>语句来批量往数据库中导入数据时，也会隐式的提交前边语句所属的事务。</p></li><li><p>关于<code>MySQL</code>复制的一些语句<br>使用<code>START SLAVE</code>、<code>STOP SLAVE</code>、<code>RESET SLAVE</code>、<code>CHANGE MASTER TO</code>等语句时也会隐式的提交前边语句所属的事务。</p></li><li><p>其它的一些语句<br>使用<code>ANALYZE TABLE</code>、<code>CACHE INDEX</code>、<code>CHECK TABLE</code>、<code>FLUSH</code>、 <code>LOAD INDEX INTO CACHE</code>、<code>OPTIMIZE TABLE</code>、<code>REPAIR TABLE</code>、<code>RESET</code>等语句也会隐式的提交前边语句所属的事务。</p></li></ol><p>Tips: 上边提到的一些语句，如果你都认识并且知道是干嘛用的那再好不过了，不认识也不要气馁，这里写出来只是为了内容的完整性，把可能会导致事务隐式提交的情况都列举一下，具体每个语句都是干嘛用的等我们遇到了再说哈。</p><h1 id="事务的-保存点"><a href="#事务的-保存点" class="headerlink" title="事务的 保存点"></a>事务的 保存点</h1><ol><li><p>如果你开启了一个事务，并且已经敲了很多语句，忽然发现上一条语句有点问题，你只好使用<code>ROLLBACK</code>语句来让数据库状态恢复到事务执行之前的样子，然后一切从头再来，总有一种一夜回到解放前的感觉。</p></li><li><p>所以设计数据库的大叔们提出了一个<code>保存点</code>(savepoint)的概念，就是在事务对应的数据库语句中打几个点，我们在调用<code>ROLLBACK</code>语句时可以指定会滚到哪个点，而不是回到最初的原点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// 定义保存点的语法如下：</span><br><span class="line">SAVEPOINT 保存点名称;</span><br><span class="line"></span><br><span class="line">//当我们想回滚到某个保存点时，可以使用下边这个语句（下边语句中的单词`WORK`和`SAVEPOINT`是可有可无的）：</span><br><span class="line">ROLLBACK [WORK] TO [SAVEPOINT] 保存点名称;</span><br><span class="line">// 如果`ROLLBACK`语句后边不跟随保存点名称的话，会直接回滚到事务执行之前的状态。</span><br><span class="line"></span><br><span class="line">//如果我们想删除某个保存点，可以使用这个语句：</span><br><span class="line">RELEASE SAVEPOINT 保存点名称;</span><br></pre></td></tr></table></figure></li><li><p>下面还是以转账的例子展示一下<code>保存点</code>的用法，在执行完扣除狗哥账户的钱<code>10</code>元的语句之后打一个<code>保存点</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM account;</span><br><span class="line">+----+--------+---------+</span><br><span class="line">| id | name   | balance |</span><br><span class="line">+----+--------+---------+</span><br><span class="line">|  1 | 狗哥   |      11 |</span><br><span class="line">|  2 | 猫爷   |       2 |</span><br><span class="line">+----+-------+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; BEGIN;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE account SET balance = balance - 10 WHERE id = 1;</span><br><span class="line">Query OK, 1 row affected (0.01 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; SAVEPOINT s1;    # 一个保存点</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM account;</span><br><span class="line">+----+--------+---------+</span><br><span class="line">| id | name   | balance |</span><br><span class="line">+----+--------+---------+</span><br><span class="line">|  1 | 狗哥   |       1 |</span><br><span class="line">|  2 | 猫爷   |       2 |</span><br><span class="line">+----+--------+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; UPDATE account SET balance = balance + 1 WHERE id = 2; # 更新错了</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line"></span><br><span class="line">mysql&gt; ROLLBACK TO s1;  # 回滚到保存点s1处</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT * FROM account;</span><br><span class="line">+----+--------+---------+</span><br><span class="line">| id | name   | balance |</span><br><span class="line">-----+--------+---------+</span><br><span class="line">|  1 | 狗哥   |       1  |</span><br><span class="line">|  2 | 猫爷   |       2  |</span><br><span class="line">+----+--------+---------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;事务的起源&quot;&gt;&lt;a href=&quot;#事务的起源&quot; class=&quot;headerlink&quot; title=&quot;事务的起源&quot;&gt;&lt;/a&gt;事务的起源&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;对于大部分程序员来说，他们的任务就是把现实世界的业务场景映射到数据库世界。&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>18. 调节磁盘和CPU的矛盾--InnoDB的Buffer Pool</title>
    <link href="http://rymuscle.github.io/2021/12/06/MySQL-InnoDB-%E9%A1%B5%E7%BB%93%E6%9E%84/18.%E8%B0%83%E8%8A%82%E7%A3%81%E7%9B%98%E5%92%8CCPU%E7%9A%84%E7%9F%9B%E7%9B%BE--InnoDB%E7%9A%84Buffer%20Pool/"/>
    <id>http://rymuscle.github.io/2021/12/06/MySQL-InnoDB-%E9%A1%B5%E7%BB%93%E6%9E%84/18.%E8%B0%83%E8%8A%82%E7%A3%81%E7%9B%98%E5%92%8CCPU%E7%9A%84%E7%9F%9B%E7%9B%BE--InnoDB%E7%9A%84Buffer%20Pool/</id>
    <published>2021-12-06T14:01:26.000Z</published>
    <updated>2024-04-25T06:27:52.442Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓存的重要性"><a href="#缓存的重要性" class="headerlink" title="缓存的重要性"></a>缓存的重要性</h1><p>通过前边的唠叨我们知道，对于使用InnoDB作为存储引擎的表来说，不管是用于存储用户数据的索引(包括<code>聚簇索引</code>和<code>二级索引</code>)， 还是各种系统数据，都是以<code>⻚</code>的形式存放在<code>表空间</code>中的，而<strong>所谓的<code>表空间</code>只不过是InnoDB对文件系统上一个或几个实际文件的抽象</strong> ，也就是说我们的数据说到底还是存储在磁盘上的。<br>但是各位也都知道，磁盘的速度慢的跟乌龟一样，怎么能配得上“快如⻛，疾如电”的CPU呢? 所以InnoDB存储引擎在处理客户端的请求时，<strong>当需要访问某个⻚的数据时，就会把完整的⻚的数据全部加载到内存中</strong> ，<span style="color:#FF416C">也就是说即使我们只需要访问一个⻚的一条记录，那也需要先把整个⻚的数据加载到内存中</span>。<br>将整个⻚加载到内存中后就可以进行读写访问了，在进行完读写访问之后并不着急把该⻚对应的内存空间释放掉，而是将其缓存起来，这样将来有请求再次访问该⻚面时，就可以省去磁盘IO的开销了。</p><h1 id="啥是个Buffer-Pool"><a href="#啥是个Buffer-Pool" class="headerlink" title="啥是个Buffer Pool"></a>啥是个Buffer Pool</h1><p>设计InnoDB的大叔为了缓存磁盘中的⻚，在MySQL服务器启动的时候就向操作系统申请了一片连续的内存，他们给这片内存起了个名，叫做 <code>Buffer Pool(中文名是缓冲池)</code>。</p><p>那它有多大呢? 这个其实看我们机器的配置，如果你是土豪，你有512G内存，你分配个几百G作为Buffer Pool也可以啊，当然你要是没那么有钱，设置小点也行呀。<br>默认情况下<code>Buffer Pool</code>只有128M大小。当然如果你嫌这个128M太大或者太小，可以在启动服务器的时候配置 <code>innodb_buffer_pool_size</code> 参数的值，它表示Buffer Pool 的大小，就像这样:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[server]</span><br><span class="line">innodb_buffer_pool_size = 268435456</span><br><span class="line"># 268435456的单位是字节，也就是我指定Buffer Pool的大小为256M。</span><br><span class="line"># 需要注意的是，Buffer Pool也不能太小，最小值为5M(当小于该值时会自动设置成5M)。</span><br></pre></td></tr></table></figure><h1 id="Buffer-Pool内部组成"><a href="#Buffer-Pool内部组成" class="headerlink" title="Buffer Pool内部组成"></a>Buffer Pool内部组成</h1><p><code>Buffer Pool</code>中默认的<code>缓存⻚</code>大小和在磁盘上默认的⻚大小是一样的，都是16KB。<br>为了更好的管理这些在Buffer Pool中的缓存⻚， 设计InnoDB的大叔为每一个缓存⻚都创建了一些所谓的控制信息， 这些控制信息包括该⻚所属的表空间编号、⻚号、缓存⻚在Buffer Pool中的地址、链表节点信息、一些锁信息以及LSN信息(锁和LSN 我们之后会具体唠叨，现在可以先忽略)，当然还有一些别的控制信息，我们这就不全唠叨一遍了，挑重要的说嘛。</p><p>每个缓存⻚对应的控制信息占用的内存大小是相同的，我们就把每个⻚对应的控制信息占用的一块内存称为一个<code>控制块</code>吧，<code>控制块</code>和<code>缓存⻚</code>是一一对应的，它们都被存放到 Buffer Pool 中，其中控制块被存放到 Buffer Pool 的前边，缓存⻚被存放到 Buffer Pool 后边，所以整个Buffer Pool对应的内存空间看起来就是这样的:<br><img src="/images/MySQL/18/1.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><blockquote><p>咦? <code>控制块</code>和<code>缓存⻚</code>之间的那个碎片是个什么玩意儿?<br>你想想啊，每一个控制块都对应一个缓存⻚，那在分配足够多的控制块和缓存⻚后，可能剩余的那点儿空间不够一对控制块和缓存⻚的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。<br>当然，如果你把Buffer Pool的大小设置的刚刚好的话，也可能不会产生碎片。</p></blockquote><blockquote><p>Tips:<br>每个<code>控制块</code>大约占用<code>缓存⻚</code>大小的5%，在MySQL5.7.21这个版本中，每个控制块占用的大小是808字节。而我们设置的<code>innodb_buffer_pool_size</code> 并不包含这部分控制块占用的内存空间大小，也就是说InnoDB在为Buffer Pool向操作系统申请连续的内存空间时，这片连续的内存空间一般会比 innodb_buffer_pool_size的值大5%左右。</p></blockquote><h1 id="free链表的管理"><a href="#free链表的管理" class="headerlink" title="free链表的管理"></a>free链表的管理</h1><p>当我们最初启动MySQL服务器的时候，需要完成对Buffer Pool的初始化过程，就是先向操作系统申请Buffer Pool的内存空间，然后把它划分成若干对<code>控制块</code>和<code>缓存⻚</code>。</p><p>但是此时并没有真实的磁盘⻚被缓存到Buffer Pool中(因为还没有用到)，之后随着程序的运行，会不断的有磁盘上的⻚被缓存到Buffer Pool中。</p><p>那么问题来了，从磁盘上读取一个⻚到Buffer Pool中的时候该放到哪个缓存⻚的位置呢? 或者说怎么区分Buffer Pool中哪些缓存⻚是空闲的，哪些已经被使用了呢?<br>我们最好在某个地方记录一下Buffer Pool中哪些缓存⻚是可用的，这个时候缓存⻚对应的控制块就派上大用场了，我们可以把所有空闲的缓存⻚对应的控制块作为一个节点放到一个链表中，这个链表也可以被称作 <code>free链表</code>(或者说<code>空闲链表</code>)。<br>刚刚完成初始化的Buffer Pool中所有的缓存⻚都是空闲的，所以每一个缓存⻚对应的控制块都会被加入到free链表中，假设该Buffer Pool中可容纳的缓存⻚数量为n，那增加了free链表的效果图就是这样的:<br><img src="/images/MySQL/18/2.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/><br>从图中可以看出，我们为了管理好这个free链表，特意为这个链表定义了一个<code>基节点</code>，里边儿包含着链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。<br>这里需要注意的是，链表的基节点占用的内存空间并不包含在为Buffer Pool申请的一大片连续内存空间之内，而是单独申请的一块内存空间。</p><p>Tips:<br>链表基节点占用的内存空间并不大，在MySQL5.7.21这个版本里， 每个基节点只占用40字节大小。<br>后边我们即将介绍许多不同的链表，它们的基节点和free链表的基节点的内存分配方式是一样一样的，都是单独申请的一块40字节大小的内存空间，并不包含在为 Buffer Pool申请的一大片连续内存空间之内。</p><p>有了这个<code>free链表</code>之后事儿就好办了，每当需要从磁盘中加载一个⻚到Buffer Pool中时，就从free链表中取一个空闲的缓存⻚，并且把该缓存⻚对应的控制块的信息填上(就是该⻚所在的表空间、⻚ 号之类的信息)，然后把该缓存⻚对应的free链表节点从链表中移除，表示该缓存⻚已经被使用了。</p><h1 id="缓存⻚的哈希处理"><a href="#缓存⻚的哈希处理" class="headerlink" title="缓存⻚的哈希处理"></a>缓存⻚的哈希处理</h1><p>我们前边说过，当我们需要访问某个⻚中的数据时，就会把该⻚从磁盘加载到Buffer Pool中，如果该⻚已经在Buffer Pool中的话直接使用就可以了。</p><p>那么问题也就来了，我们怎么知道该⻚在不在Buffer Pool中呢? 难不成需要依次遍历Buffer Pool中各个缓存⻚么? 一个Buffer Pool中的缓存⻚这么多，都遍历完岂不是要累死?<br>再回头想想，我们其实是根据 <code>表空间号 + ⻚号</code> 来定位一个⻚的，也就相当于 <code>表空间号 + ⻚号</code> 是一个key，缓存⻚就是对应的value， 怎么通过一个key来快速找着一个value呢? 哈哈，那肯定是哈希表喽。</p><p>所以我们可以用 <code>表空间号 + ⻚号</code> 作为key，缓存⻚作为value创建一个哈希表，在需要访问某个⻚的数据时，先从哈希表中根据 <code>表空间号 + ⻚号</code> 看看有没有对应的缓存⻚，如果有，直接使用该缓存⻚就好，如果没有，那就从<code>free链表</code>中选一个空闲的<code>缓存⻚</code>，然后把磁盘中对应的⻚加载到该缓存⻚的位置。</p><h1 id="flush链表的管理"><a href="#flush链表的管理" class="headerlink" title="flush链表的管理"></a>flush链表的管理</h1><p>如果我们修改了Buffer Pool中某个缓存⻚的数据，那它就和磁盘上的⻚不一致了，这样的缓存⻚也被称为<code>脏⻚</code>(英文名:dirty page)。<br>当然，最简单的做法就是每发生一次修改就立即同步到磁盘上对应的⻚上，<span style="color:#FF416C; font-weight:600;">但是频繁的往磁盘中写数据会严重的影响程序的性能(毕竟磁盘慢的像乌龟一样)</span>。<br>所以每次修改缓存⻚后，我们并不着急立即把修改同步到磁盘上，而是在未来的某个时间点进行同步， 至于这个同步的时间点我们后边会作说明说明的，现在先不用管哈。<br>但是如果不立即同步到磁盘的话，那之后再同步的时候我们怎么知道Buffer Pool中哪些⻚是脏⻚，哪些⻚从来没被修改过呢? 总不能把所有的缓存⻚都同步到磁盘上吧，假如Buffer Pool被设置的很大，比方说300G，那一次性同步这么多数据岂不是要慢死!<br>所以，我们不得不再创建一个<code>存储脏⻚的链表</code>，凡是修改过的缓存⻚对应的控制块都会作为一个节点加入到一个链表中，因为这个链表节点对应的缓存⻚都是需要被刷新到磁盘上的，所以也叫<code>flush链表</code>。链表的构造和free链表差不多，假设某个时间点Buffer Pool中的脏⻚数量为n，那么对应的flush链表就⻓这样:<br><img src="/images/MySQL/18/3.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></p><h1 id="LRU链表的管理"><a href="#LRU链表的管理" class="headerlink" title="LRU链表的管理"></a>LRU链表的管理</h1><h2 id="缓存不够的窘境"><a href="#缓存不够的窘境" class="headerlink" title="缓存不够的窘境"></a>缓存不够的窘境</h2><p>Buffer Pool对应的内存大小毕竟是有限的，如果需要缓存的⻚占用的内存大小超过了Buffer Pool大小，也就是<code>free链表</code>中已经没有多余的空闲缓存⻚的时候岂不是很尴尬，发生了这样的事儿该咋办?<br>当然是把某些旧的缓存⻚从Buffer Pool中移除，然后再把新的⻚放进来喽。 那么问题来了，移除哪些缓存⻚呢?</p><p>为了回答这个问题，我们还需要回到我们设立Buffer Pool的初衷，我们就是想减少和磁盘的IO交互，最好每次在访问某个⻚时它都已经被缓存到Buffer Pool中了。<br>假设我们一共访问了n次⻚，那么被访问的⻚已经在缓存中的次数除以n就是所谓的缓存命中率，我们的期望就是让缓存命中率越高越好。<br>从这个⻆度出发，回想一下我们的微信聊天列表，排在前边的都是最近很频繁使用的，排在后边的自然就是最近很少使用的，假如列表能容纳下的联系人有限，你是会把最近很频繁使用的留下还是最近很少使用的留下呢? 当然是留下最近很频繁使用的了。</p><h2 id="简单的LRU链表"><a href="#简单的LRU链表" class="headerlink" title="简单的LRU链表"></a>简单的LRU链表</h2><p>管理Buffer Pool的缓存⻚其实也是这个道理，当Buffer Pool 中不再有空闲的缓存⻚时，就需要淘汰掉部分最近很少使用的缓存⻚。</p><p>不过，我们怎么知道哪些缓存⻚最近频繁使用，哪些最近很少使用呢?<br>呵呵，神奇的链表再一次派上了用场，我们可以再创建一个链表，由于这个链表是为了按照<code>最近最少使用</code>的原则去淘汰缓存⻚的， 所以这个链表可以被称为<code>LRU链表</code>(LRU的英文全称:Least Recently Used)。<br>当我们需要访问某个⻚时，可以这样处理LRU链表:</p><ul><li>如果该⻚不在Buffer Pool中，在把该⻚从磁盘加载到Buffer Pool中的缓存⻚时，就把该缓存⻚对应的控制块作为节点塞到链表的头部。</li><li>如果该⻚已经缓存在Buffer Pool中，则直接把该⻚对应的控制块移动到LRU链表的头部。</li></ul><p>也就是说: 只要我们使用到某个缓存⻚，就把该缓存⻚调整到LRU链表的头部，这样LRU链表尾部就是最近最少使用的缓存⻚喽。<br>所以当Buffer Pool中的空闲缓存⻚使用完时，到LRU链表的尾部找些缓存⻚淘汰就OK啦，真简单，啧啧…</p><h2 id="划分区域的LRU链表"><a href="#划分区域的LRU链表" class="headerlink" title="划分区域的LRU链表"></a>划分区域的LRU链表</h2><p>高兴的太早了，上边的这个简单的LRU链表用了没多⻓时间就发现问题了，因为存在这两种比较尴尬的情况:</p><ol><li><p>情况一: InnoDB提供了一个看起来比较贴心的服务–预读 (英文名:read ahead)。</p><blockquote><p>所谓预读，就是InnoDB认为执行当前的请求可能之后会读取某些⻚面，就预先把它们加载到Buffer Pool中。<br>根据触发方式的不同，预读又可以细分为下边两种:</p><ul><li>线性预读<blockquote><p>设计InnoDB的大叔提供了一个系统变量 <code>innodb_read_ahead_threshold</code>，如果顺序访问了某个区(extent)的⻚面超过这个系统变量的值，就会触发一次异步读取下一个区中全部的⻚面到Buffer Pool的请求，注意异步读取意味着从磁盘中加载这些被预读的⻚面并不会影响到当前工作线程的正常执行。<br>这个 <code>innodb_read_ahead_threshold</code> 系统变量的值默认是56，我们可以在服务器启动时通过启动参数或者服务器运行过程中直接调整该系统变量的值，不过它是一个<code>全局变量</code>，注意使用<code>SET GLOBAL</code>命令来修改哦。<br>Tips:<br>InnoDB是怎么实现异步读取的呢? 在Windows或者 Linux平台上，可能是直接调用操作系统内核提供的AIO接口，在其它类Unix操作系统中，使用了一种模拟AIO接口的方式来实现异步读取，其实就是让别的线程去读取需要预读的⻚面。如果你读不懂上边这段话，那也就没必要懂了，和我们主题其实没太多关系，你只需要知道异步读取并不会影响到当前工作线程的正常执行就好了。其实这个过程涉及到操作系统如何处理IO以及多线程的问题，找本操作系统的书看看吧。</p></blockquote></li><li>随机预读<blockquote><p>如果Buffer Pool中已经缓存了某个区的13个连续的⻚面，不论这些⻚面是不是顺序读取的，都会触发一次异步读取本区中所有其的⻚面到Buffer Pool的请求。设计InnoDB的大叔同时提供了 <code>innodb_random_read_ahead</code> 系统变量，它的默认值为OFF，也就意味着InnoDB并不会默认开启随机预读的功能，如果我们想开启该功能，可以通过修改启动参数或者直接使用<code>SET GLOBAL</code>命令把该变量的值设置为ON。</p></blockquote></li></ul><p>预读本来是个好事儿，如果预读到Buffer Pool中的⻚成功的被使用到，那就可以极大的提高语句执行的效率。可是如果用不到呢?这些预读的⻚都会放到LRU链表的头部，但是如果此时Buffer Pool的容量不太大而且很多预读的⻚面都没有用到的话，这就会导致处在LRU链表尾部的一些缓存⻚会很快的被淘汰掉，也就是所谓的劣币驱逐良币，会大大降低缓存命中率。</p></blockquote></li><li><p>情况二:有的小伙伴可能会写一些需要扫描全表的查询语句(比如没有建立合适的索引或者压根儿没有WHERE子句的查询)。</p><blockquote><p>扫描全表意味着将访问到该表所在的所有⻚! 假设这个表中记录非常多的话，那该表会占用特别多的⻚，当需要访问这些⻚时，会把它们统统都加载到Buffer Pool中， 这也就意味着吧唧一下，Buffer Pool中的所有⻚都被换了一次血，其他查询语句在执行时又得执行一次从磁盘加载到Buffer Pool的操作。<br><strong>而这种全表扫描的语句执行的频率也不高，但每次执行都要把Buffer Pool中的缓存⻚换一次血，这严重的影响到其他查询对 Buffer Pool的使用，从而大大降低了缓存命中率。</strong></p></blockquote></li></ol><p>总结一下上边说的可能降低Buffer Pool的两种情况:</p><ul><li>加载到Buffer Pool中的⻚不一定被用到。</li><li>如果非常多的使用频率偏低的⻚被同时加载到Buffer Pool 时，可能会把那些使用频率非常高的⻚从Buffer Pool中淘汰掉。</li></ul><hr><p>因为有这两种情况的存在，所以设计InnoDB的大叔把这个LRU链表按照一定比例分成两截，分别是: </p><ul><li><p>一部分存储使用频率非常高的缓存⻚，所以这一部分链表也叫做<code>热数据</code>，或者称young区域。 </p></li><li><p>另一部分存储使用频率不是很高的缓存⻚，所以这一部分链表也叫做<code>冷数据</code>，或者称old区域。 </p></li><li><p>为了方便大家理解，我们把示意图做了简化，各位领会精神就好:</p><img src="/images/MySQL/18/4.png" width="500" style="margin-left:0px;border: 1px solid #ccc;border-radius: 5px;"/></li></ul><hr><p>大家要特别注意一个事儿:我们是按照某个比例将LRU链表分成两半的，不是某些节点固定是young区域的，某些节点固定是old区域的，随着程序的运行，某个节点所属的区域也可能发生变化。那这个划分成两截的比例怎么确定呢?对于InnoDB存储引擎来说，我们可以通过查看系统变量<code>innodb_old_blocks_pct</code>的值来确定old区域在LRU链表中所占的比例，比方说这样:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW VARIABLES LIKE &#x27;innodb_old_blocks_pct&#x27;; </span><br><span class="line">+-----------------------+-------+ </span><br><span class="line">| Variable_name | Value | </span><br><span class="line">+-----------------------+-------+ </span><br><span class="line">| innodb_old_blocks_pct | 37 | </span><br><span class="line">+-----------------------+-------+ </span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><p>从结果可以看出来，默认情况下，old区域在LRU链表中所占的比例是37%，也就是说old区域大约占LRU链表的3&#x2F;8。这个比例我们是可以设置的，我们可以在启动时修改innodb_old_blocks_pct参数来控制old区域在LRU链表中所占的比例，比方说这样修改配置文件:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[server] </span><br><span class="line">innodb_old_blocks_pct = 40</span><br></pre></td></tr></table></figure><p>这样我们在启动服务器后，old区域占LRU链表的比例就是40%。当然，如果在服务器运行期间，我们也可以修改这个系统变量的值，不过需要注意的是，这个系统变量属于全局变量，一经修改，会对所有客户端生效，所以我们只能这样修改:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET GLOBAL innodb_old_blocks_pct = 40;</span><br></pre></td></tr></table></figure><hr><p>有了这个被划分成young和old区域的LRU链表之后，设计InnoDB的大叔就可以针对我们上边提到的两种可能降低缓存命中率的情况进行优化了:</p><ul><li><p>针对预读的⻚面可能不进行后续访情况的优化<br>设计InnoDB的大叔规定，当磁盘上的某个⻚面在初次加载到Buffer Pool中的某个缓存⻚时，该缓存⻚对应的控制块会被放到old区域的头部。<br>这样针对预读到Buffer Pool却不进行后续访问的⻚面就会被逐渐从old区域逐出，而不会影响young区域中被使用比较频繁的缓存⻚。</p></li><li><p>针对全表扫描时，短时间内访问大量使用频率非常低的⻚面情况的优化<br>在进行全表扫描时，虽然首次被加载到Buffer Pool的⻚被放到了old区域的头部，但是后续会被⻢上访问到，每次进行访问的时候又会把该⻚放到young区域的头部，这样仍然会把那些使用频率比较高的⻚面给顶下去。<br>有同学会想:可不可以在第一次访问该⻚面时不将其从old区域移动到young区域的头部，后续访问时再将其移动到young区域的头部。<br>回答是: 行不通! 因为设计InnoDB的大叔规定每次去⻚面中读取一条记录时，都算是访问一次⻚面，而一个⻚面中可能会包含很多条记录，也就是说读取完某个⻚面的记录就相当于访问了这个⻚面好多次。<br>咋办? 全表扫描有一个特点，那就是它的执行频率非常低，谁也不会没事儿老在那写全表扫描的语句玩，而且在执行全表扫描的过程中，即使某个⻚面中有很多条记录，也就是去多次访问这个⻚面所花费的时间也是非常少的。<br>所以我们只需要规定，在对某个处在old区域的缓存⻚进行第一次访问时就在它对应的控制块中记录下来这个访问时间，如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该⻚面就不会被从old区域移动到young区域的头部，否则将它移动到young区域的头部。<br>上述的这个间隔时间是由系统变量 <code>innodb_old_blocks_time</code> 控制的，你看:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW VARIABLES LIKE &#x27;innodb_old_blocks_time&#x27;; </span><br><span class="line">+------------------------+-------+ </span><br><span class="line">| Variable_name | Value | </span><br><span class="line">+------------------------+-------+ </span><br><span class="line">| innodb_old_blocks_time | 1000 | </span><br><span class="line">+------------------------+-------+ </span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure><p>这个<code>innodb_old_blocks_time</code>的默认值是1000，它的单位是毫秒，也就意味着对于从磁盘上被加载到LRU链表的old区域的某个⻚来说，如果第一次和最后一次访问该⻚面的时间间隔小于1s(很明显在一次全表扫描的过程中，多次访问一个⻚面中的时间不会超过 1s)，那么该⻚是不会被加入到young区域的。<br>当然，像 <code>innodb_old_blocks_pct</code> 一样，我们也可以在服务器启动或运行时设置<code>innodb_old_blocks_time</code>的值，这里就不赘述了，你自己试试吧。<br>这里需要注意的是，如果我们把 <code>innodb_old_blocks_time</code> 的值设置为0，那么每次我们访问一个⻚面时就会把该⻚面放到young区域的头部。</p></li></ul><p>综上所述，正是因为将LRU链表划分为<code>young</code>和<code>old</code>区域这两个部分，又添加了<code>innodb_old_blocks_time</code>这个系统变量，才使得预读机制和全表扫描造成的缓存命中率降低的问题得到了遏制，因为用不到的预读⻚面以及全表扫描的⻚面都只会被放到old区域，而不影响young区域中的缓存⻚。</p><h1 id="更进一步优化LRU链表"><a href="#更进一步优化LRU链表" class="headerlink" title="更进一步优化LRU链表"></a>更进一步优化LRU链表</h1><p>LRU链表这就说完了么? 没有，早着呢…<br>对于young区域的缓存⻚来说，我们每次访问一个缓存⻚就要把它移动到LRU链表的头部，这样开销是不是太大啦，毕竟在young区域的缓存⻚都是热点数据，也就是可能被经常访问的，这样频繁的对LRU链表进行节点移动操作是不是不太好啊?<br>是的，为了解决这个问题其实我们还可以提出一些优化策略，比如只有被访问的缓存⻚位于young区域的1&#x2F;4的后边，才会被移动到LRU链表头部，这样就可以降低调整LRU链表的频率，从而提升性能(也就是说如果某个缓存⻚对应的节点在young区域的 1&#x2F;4中，再次访问该缓存⻚时也不会将其移动到LRU链表头部)。</p><p>Tips:<br>我们之前介绍随机预读的时候曾说，如果Buffer Pool中有某个区的13个连续⻚面就会触发随机预读，这其实是不严谨的(不幸的是MySQL文档就是这么说的[摊手])，其实还要求这13个⻚面是非常热的⻚面，所谓的非常热，指的是这些⻚面在整个young区域的头1&#x2F;4处。<br>还有没有什么别的针对LRU链表的优化措施呢? 当然有啊，你要是好好学，写篇论文，写本书都不是问题，可是这毕竟是一个介绍MySQL基础知识的文章，再说多了篇幅就受不了了，也影响大家的阅读体验，所以适可而止，想了解更多的优化知识，自己去看源码或者更多关于LRU链表的知识喽。<br>但是不论怎么优化，千万别忘了我们的初心:尽量高效的提高 Buffer Pool 的缓存命中率。</p><h1 id="刷新脏⻚到磁盘"><a href="#刷新脏⻚到磁盘" class="headerlink" title="刷新脏⻚到磁盘"></a>刷新脏⻚到磁盘</h1><p>后台有专⻔的线程每隔一段时间负责把脏⻚刷新到磁盘，这样可以不影响用户线程处理正常的请求。</p><p>主要有两种刷新路径:</p><ul><li>从<code>LRU链表</code>的<code>冷数据</code>中刷新一部分⻚面到磁盘<br>后台线程会定时从LRU链表尾部开始扫描一些⻚面，扫描的⻚面数量可以通过系统变量<code>innodb_lru_scan_depth</code>来指定，如果从里边儿发现脏⻚，会把它们刷新到磁盘。<br>这种刷新⻚面的方式被称之为<code>BUF_FLUSH_LRU</code>。</li><li>从<code>flush链表</code>中刷新一部分⻚面到磁盘<br>后台线程也会定时从flush链表中刷新一部分⻚面到磁盘，刷新的速率取决于当时系统是不是很繁忙。<br>这种刷新⻚面的方式 被称之为<code>BUF_FLUSH_LIST</code>。</li></ul><p>有时候后台线程刷新脏⻚的进度比较慢，导致用户线程在准备加载一个磁盘⻚到Buffer Pool时没有可用的缓存⻚，这时就会尝试看看LRU链表尾部有没有可以直接释放掉的未修改⻚面，如果没有的话会不得不将LRU链表尾部的一个脏⻚同步刷新到磁盘(和磁盘交互是很慢的，这会降低处理用户请求的速度)。这种刷新单个⻚面到磁盘中的刷新方式被称之为 <code>BUF_FLUSH_SINGLE_PAGE</code>。<br>当然，有时候系统特别繁忙时，也可能出现用户线程批量的从flush链表中刷新脏⻚的情况，很显然在处理用户请求过程中去刷新脏⻚是一种严重降低处理速度的行为(毕竟磁盘的速度满的要死)，这属于一种迫不得已的情况，不过这得放在后边唠叨redo日志的 checkpoint时说了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;缓存的重要性&quot;&gt;&lt;a href=&quot;#缓存的重要性&quot; class=&quot;headerlink&quot; title=&quot;缓存的重要性&quot;&gt;&lt;/a&gt;缓存的重要性&lt;/h1&gt;&lt;p&gt;通过前边的唠叨我们知道，对于使用InnoDB作为存储引擎的表来说，不管是用于存储用户数据的索引(包括&lt;cod</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>16. explain详解(下)</title>
    <link href="http://rymuscle.github.io/2021/11/27/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/16.%20explain%E8%AF%A6%E8%A7%A3(%E4%B8%8B)/"/>
    <id>http://rymuscle.github.io/2021/11/27/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/16.%20explain%E8%AF%A6%E8%A7%A3(%E4%B8%8B)/</id>
    <published>2021-11-27T14:11:31.000Z</published>
    <updated>2024-04-24T07:11:42.338Z</updated>
    
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>15.0 explain详解(上)</title>
    <link href="http://rymuscle.github.io/2021/11/24/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/15.0%20explain%E8%AF%A6%E8%A7%A3(%E4%B8%8A)/"/>
    <id>http://rymuscle.github.io/2021/11/24/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/15.0%20explain%E8%AF%A6%E8%A7%A3(%E4%B8%8A)/</id>
    <published>2021-11-24T05:02:16.000Z</published>
    <updated>2024-04-25T00:47:04.963Z</updated>
    
    <content type="html"><![CDATA[<h1 id="尝试用Explain查看执行计划"><a href="#尝试用Explain查看执行计划" class="headerlink" title="尝试用Explain查看执行计划"></a>尝试用<code>Explain</code>查看<code>执行计划</code></h1><p>一条查询语句在经过MySQL<code>查询优化器</code>的各种<code>基于成本</code>和<code>规则</code>的优化后，会生成一个所谓的<code>执行计划</code>，这个执行计划展示了接下来具体执行查询的方式，比如多表连接的顺序是什么，对于每个表采用什么<code>访问方法</code>来具体执行查询等等。</p><p>设计MySQL的大叔贴心的为我们提供了<code>EXPLAIN</code>语句来帮助我们查看某个查询语句的具体<code>执行计划</code>，本章的内容就是为了帮助大家看懂EXPLAIN语句的各个输出项都是干嘛使的，从而可以有针对性的提升我们查询语句的性能。</p><p>如果我们想看看某个查询的执行计划的话，可以在具体的<code>查询语句</code>前边加一个<code>EXPLAIN</code>，就像这样:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select 1;</span><br><span class="line">+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra          |</span><br><span class="line">+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+</span><br><span class="line">|  1 | SIMPLE      | NULL  | NULL       | NULL | NULL          | NULL | NULL    | NULL | NULL |     NULL | No tables used |</span><br><span class="line">+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><blockquote><p>上面输出的一大坨东⻄就是所谓的执行计划，我的任务就是带领大家看懂这一大坨东⻄里边的每个列都是干啥用的，以及在这个执行计划的辅助下，我们应该怎样改进自己的查询语句以使查询执行起来更高效。<br>其实除了以SELECT开头的查询语句，其余的 DELETE、INSERT、REPLACE以及UPDATE语句前边都可以加上EXPLAIN这个词儿，用来查看这些语句的执行计划，不过我们这里对SELECT语句更感兴趣，所以后边只会以SELECT语句为例来描述EXPLAIN语句的用法。<br>为了让大家先有一个感性的认识，我们把EXPLAIN语句输出的各个列的作用先大致罗列一下:</p><ul><li><code>id</code> : 在一个大的查询语句中每个SELECT关键字都对应一个唯一的id</li><li><code>select_type</code>: SELECT关键字对应的那个查询的类型 </li><li><code>table</code>: 表名</li><li><code>partitions</code>: 匹配的分区信息</li><li><code>type</code>: 针对单表的访问方法</li><li><code>possible_keys</code>: 可能用到的索引</li><li><code>key</code>: 实际上使用的索引</li><li><code>key_len</code>: 实际使用到的索引⻓度</li><li><code>ref</code>: 当使用索引列等值查询时，与索引列进行等值匹配的对象信息</li><li><code>rows</code>: 预估的需要读取的记录条数</li><li><code>filtered</code>: 某个表经过搜索条件过滤后剩余记录条数的百分比</li><li><code>Extra</code>: 一些额外的信息</li></ul></blockquote><p>需要注意的是，大家如果看不懂上边列的含义，那是正常的，千万不要纠结。<br>这里把它们都列出来只是为了描述一个轮廓，让大家有一个大致的印象，下边会细细道来，等会儿说完了不信你不会~<br>为了故事的顺利发展，我们还是要请出我们前边已经用了n遍的 single_table表:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE single_table (</span><br><span class="line">    id INT NOT NULL AUTO_INCREMENT,</span><br><span class="line">    key1 VARCHAR(100),</span><br><span class="line">    key2 INT,</span><br><span class="line">    key3 VARCHAR(100),</span><br><span class="line">    key_part1 VARCHAR(100),</span><br><span class="line">    key_part2 VARCHAR(100),</span><br><span class="line">    key_part3 VARCHAR(100),</span><br><span class="line">    common_field VARCHAR(100),</span><br><span class="line">    PRIMARY KEY (id),</span><br><span class="line">    KEY idx_key1 (key1),</span><br><span class="line">    UNIQUE KEY idx_key2 (key2),</span><br><span class="line">    KEY idx_key3 (key3),</span><br><span class="line">    KEY idx_key_part(key_part1, key_part2,</span><br><span class="line">    key_part3)</span><br><span class="line">) Engine=InnoDB CHARSET=utf8;</span><br></pre></td></tr></table></figure><p>我们仍然假设有两个和single_table表构造一模一样的s1、s2表，而且这两个表里边儿有10000条记录，除id列外其余的列都插入随机值。<br>为了让大家有比较好的阅读体验，我们下边并不准备严格按照EXPLAIN输出列的顺序来介绍这些列分别是干嘛的，大家注意一下就好了。</p><h1 id="执行计划输出中的各列详解"><a href="#执行计划输出中的各列详解" class="headerlink" title="执行计划输出中的各列详解"></a>执行计划输出中的各列详解</h1><h2 id="table"><a href="#table" class="headerlink" title="table"></a>table</h2><p>不论我们的查询语句有多复杂，里边儿包含了多少个表，到最后也是需要对每个表进行<code>单表访问</code>的。<br>所以设计MySQL的大叔规定 <code>EXPLAIN语句</code>输出的每条记录都对应着某个单表的<code>访问方法</code>，该条记录的<code>table列</code>代表着该表的表名。<br>所以我们看一条比较简单的查询语句:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM s1; </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+-------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+-------+</span><br><span class="line">| 1  |   SIMPLE    |  s1   |    NULL    |  ALL |      NULL     | NULL|   NULL  | NULL| 9688 |  100.00  |  NULL | </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+-------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><p>这个查询语句只涉及对s1表的单表查询，所以EXPLAIN输出中只有一条记录，其中的table列的值是s1，表明这条记录是用来说明对s1表的单表访问方法的。</p><hr><p>再看一个<code>连接查询</code>的<code>执行计划</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 INNER JOIN s2; </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+---------------------------------------+ </span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra</span><br><span class="line">| +----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+---------------------------------------+ </span><br><span class="line">|  1 |   SIMPLE    |  s1   |    NULL    |  ALL |      NULL     | NULL|  NULL   | NULL| 9688 |  100.00  | NULL | </span><br><span class="line">|  1 |   SIMPLE    |  s2   |    NULL    |  ALL |      NULL     | NULL|  NULL   | NULL| 9954 |  100.00  | Using join buffer (Block Nested Loop) | </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+------+---------+------+------+--- -------+---------------------------------------+ </span><br><span class="line">2 rows in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure><p>可以看到这个连接查询的执行计划中有两条记录，这两条记录的table列分别是s1和s2，这两条记录用来分别说明对s1表和s2表的访问方法是什么。</p><h2 id="id"><a href="#id" class="headerlink" title="id"></a>id</h2><p>我们写的查询语句一般都以SELECT关键字开头，比较简单的查询语句里只有一个SELECT关键字，比如:<code>SELECT * FROM s1 WHERE key1 = &#39;a&#39;;</code><br>稍微复杂一点的<code>连接查询</code>中也只有一个SELECT关键字，比如:<code>SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key1 WHERE s1.common_field = &#39;a&#39;;</code></p><p>但是下边两种情况下, 在一条查询语句中会出现多个SELECT关键字: </p><ul><li>查询中包含子查询的情况，比如下边这个查询语句中就包含2个SELECT关键字:<br><code>SELECT * FROM s1 WHERE key1 IN (SELECT * FROM s2);</code></li><li>查询中包含<code>UNION语句</code>的情况 比如下边这个查询语句中也包含2个SELECT关键字:<br><code>SELECT * FROM s1 UNION SELECT * FROM s2;</code></li></ul><hr><p>查询语句中每出现一个SELECT关键字，设计MySQL的大叔就会为它分配一个唯一的id值。这个id值就是EXPLAIN语句的第一个列，比如下边这个查询中只有一个SELECT关键字，所以EXPLAIN的结果中也就只有一条id列为1的记录:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 WHERE key1 = &#x27;a&#x27;; </span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys |   key    | key_len |  ref  | rows | filtered | Extra | </span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+-------+-----+----------+-------+</span><br><span class="line">| 1  |   SIMPLE    |  s1   |   NULL     |  ref |    idx_key1   | idx_key1 |   303   | const |   8  |  100.00  | NULL  | </span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+-------+------+----------+-------+</span><br><span class="line">1 row in set, 1 warning (0.03 sec)</span><br></pre></td></tr></table></figure><hr><p>对于连接查询来说，一个SELECT关键字后边的FROM子句中可以跟随多个表，所以在连接查询的<code>执行计划</code>中，每个表都会对应一条记录，但是这些记录的id值都是相同的，比如:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 INNER JOIN s2; </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+------+---------+------+------+----------+------------------------------------+ </span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra</span><br><span class="line">+----+-------------+-------+------------+------+---------------+-----+---------+-----+------+----------+---------------------------------------+ </span><br><span class="line">|  1 |   SIMPLE    |  s1   |    NULL    |  ALL |      NULL     | NULL|  NULL   | NULL| 9688 |  100.00  | NULL</span><br><span class="line">|  1 |   SIMPLE    |  s2   |    NULL    |  ALL |      NULL     | NULL|  NULL   | NULL| 9954 |  100.00  | Using join buffer (Block Nested Loop) | </span><br><span class="line">+----+-------------+-------+------------+------+---------------+-----+---------+------+------+--- -------+-------------------------------------+ </span><br><span class="line">2 rows in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure><p>可以看到，上述连接查询中参与连接的s1和s2表分别对应一条记录，但是这两条记录对应的id值都是1。<br>这里需要大家记住的是，在连接查询的执行计划中，每个表都会对应一条记录，这些记录的id列的值是相同的，出现在前边的表表示<code>驱动表</code>，出现在后边的表表示<code>被驱动表</code>。<br>所以从上边的EXPLAIN输出中我们可以看出，查询优化器准备让s1表作为驱动表，让s2表作为被驱动表来执行查询。</p><hr><p>对于包含子查询的查询语句来说，就可能涉及多个SELECT关键字， 所以在包含子查询的查询语句的执行计划中，每个SELECT关键字都会对应一个唯一的id值，比如这样:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = &#x27;a&#x27;; </span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+------+------+----------+-------------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys |   key    | key_len |  ref | rows | filtered |    Extra    | </span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+------+------+----------+-------------+ </span><br><span class="line">|  1 |   PRIMARY   |  s1   |    NULL    |  ALL |    idx_key3   |   NULL   |   NULL  | NULL | 9688 |  100.00  | Using where |</span><br><span class="line">|  2 |   SUBQUERY  |  s2   |    NULL    | index|    idx_key1   | idx_key1 |   303   | NULL | 9954 |  100.00  | Using index | </span><br><span class="line">+----+-------------+-------+------------+-------+---------------+----------+---------+------+---- --+----------+-------------+</span><br><span class="line">2 rows in set, 1 warning (0.02 sec)</span><br></pre></td></tr></table></figure><p>从输出结果中我们可以看到，s1表在外层查询中，外层查询有一个独立的SELECT关键字，所以第一条记录的id值就是1，s2表在子查询中，子查询有一个独立的SELECT关键字，所以第二条记录的id值就是2。<br>但是这里大家需要特别注意，查询优化器可能对涉及子查询的查询语句进行重写，从而转换为连接查询。</p><hr><p>所以如果我们想知道查询优化器对某个包含子查询的语句是否进行了重写，直接查看执行计划就好了，比如说:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2 WHERE common_field = &#x27;a&#x27;); </span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+------------------------------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys |    key   | key_len |        ref        | rows | filtered | Extra</span><br><span class="line">+----+-------------+-------+------------+------+---------------+----------+---------+-------------------+------+----------+------------------------------+</span><br><span class="line">| 1  |    SIMPLE   |  s2   |   NULL     |  ALL |    idx_key3   |  NULL    |  NULL   |        NULL       | 9954 |  10.00   | Using where; Start temporary |</span><br><span class="line">| 1  |    SIMPLE   |  s1   |   NULL     |  ref |    idx_key1   | idx_key1 |  303    | xiaohaizi.s2.key3 |  1   |  100.00  | End temporary | </span><br><span class="line">+----+-------------+-------+------------+------+- --------------+----------+---------+------------- ------+------+----------+----------------------------+</span><br><span class="line">2 rows in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><p>可以看到，虽然我们的查询语句是一个子查询，但是执行计划中s1和s2表对应的记录的id值全部是1，<strong>这就表明了查询优化器将子查询转换为了连接查询</strong> 。</p><hr><p>对于包含UNION子句的查询语句来说，每个SELECT关键字对应一个id值也是没错的，不过还是有点儿特别的东⻄，比方说下边这个查询:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2; </span><br><span class="line">+----+-------------+------------+------------+-- ----+---------------+------+---------+------+------+----------+-----------------+</span><br><span class="line">| id | select_type |    table   | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | </span><br><span class="line">+----+-------------+------------+------------+------+---------------+-----+---------+-----+------+----------+-----------------+</span><br><span class="line">| 1  |   PRIMARY   |     s1     |    NULL    | ALL  |      NULL     |NULL |   NULL  | NULL| 9688 |  100.00  | NULL |</span><br><span class="line">| 2  |    UNION    |     s2     |    NULL    | ALL  |      NULL     |NULL |   NULL  | NULL| 9954 |  100.00  | NULL |</span><br><span class="line">|NULL| UNION RESULT| &lt;union1,2&gt; |    NULL    | ALL  |      NULL     |NULL |   NULL  | NULL| NULL |  NULL    | Using temporary | </span><br><span class="line">+----+-------------+------------+------------+------+---------------+-----+---------+------+-----+----------+-----------------+</span><br><span class="line">3 rows in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><p>这个语句的执行计划的第三条记录是个什么⻤?  为毛id值是NULL， 而且table列⻓的也怪怪的?<br>大家别忘了UNION子句是干嘛用的，它会把多个查询的结果集合并起来并对结果集中的记录进行去重，怎么去重呢? MySQL使用的是内部的<code>临时表</code>。<br>正如上边的查询计划中所示，UNION子句是为了把id为1的查询和id为2的查询的结果集合并起来并去重，所以在内部创建了一个名为&lt;union1, 2&gt;的临时表 (就是执行计划第三条记录的table列的名称)，id为NULL表明这个临时表是为了合并两个查询的结果集而创建的。</p><hr><p>跟UNION对比起来，<code>UNION ALL</code>就不需要为最终的结果集进行去重，它只是单纯的把多个查询的结果集中的记录合并成一个并返回给用户，所以也就不需要使用临时表。<br>所以在包含<code>UNION ALL</code>子句的查询的执行计划中，就没有那个id为NULL的记录，如下所示:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; EXPLAIN SELECT * FROM s1 UNION ALL SELECT * FROM s2; </span><br><span class="line">+----+-------------+-------+------------+------+---------------+-----+---------+-----+------+----------+-------+</span><br><span class="line">| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | </span><br><span class="line">+----+-------------+-------+------------+------+---------------+-----+---------+------+------+---------+-------+</span><br><span class="line">| 1  |   PRIMARY   |  s1   |   NULL     |  ALL |      NULL     | NULL|  NULL   |  NULL|  9688| 100.00  |  NULL |</span><br><span class="line">| 2  |    UNION    |  s2   |   NULL     |  ALL |      NULL     | NULL|  NULL   |  NULL|  9954| 100.00  |  NULL | </span><br><span class="line">+----+-------------+-------+------------+------+---------------+-----+---------+------+------+---------+-------+</span><br><span class="line">2 rows in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure><h2 id="select-type"><a href="#select-type" class="headerlink" title="select_type"></a>select_type</h2><p>通过上边的内容我们知道，一条大的查询语句里边可以包含若干个SELECT关键字，每个SELECT关键字代表着一个小的查询语句， 而每个SELECT关键字的FROM子句中都可以包含若干张表(这些表用来做连接查询)，每一张表都对应着执行计划输出中的一条记录，对于在同一个SELECT关键字中的表来说，它们的id值是相同的。<br>设计MySQL的大叔为每一个SELECT关键字代表的小查询都定义了一个称之为select_type的属性，意思是我们只要知道了某个小查询的select_type属性，就知道了这个小查询在整个大查询中扮演了一个什么⻆色，口说无凭，我们还是先来⻅识⻅识这个select_type都能取哪些值:</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;尝试用Explain查看执行计划&quot;&gt;&lt;a href=&quot;#尝试用Explain查看执行计划&quot; class=&quot;headerlink&quot; title=&quot;尝试用Explain查看执行计划&quot;&gt;&lt;/a&gt;尝试用&lt;code&gt;Explain&lt;/code&gt;查看&lt;code&gt;执行计划&lt;/c</summary>
      
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>14. 基于规则的优化</title>
    <link href="http://rymuscle.github.io/2021/11/21/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/14.%20%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <id>http://rymuscle.github.io/2021/11/21/MySQL%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/14.%20%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E4%BC%98%E5%8C%96/</id>
    <published>2021-11-21T12:31:27.000Z</published>
    <updated>2024-04-24T07:08:23.147Z</updated>
    
    
    
    
    <category term="MySQL 读书笔记" scheme="http://rymuscle.github.io/categories/MySQL-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="MySQL" scheme="http://rymuscle.github.io/tags/MySQL/"/>
    
  </entry>
  
</feed>
